{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq Train and Greedy search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. GPU测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "#sys.path.append('/mnt/pycharm_class04')\n",
    "sys.path.append('/Users/ianxiao/Code/DeepLearning/class04')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from utils.data_loader import build_dataset,load_dataset,preprocess_sentence,load_test_dataset,load_train_dataset\n",
    "from utils.wv_loader import load_embedding_matrix, Vocab\n",
    "from utils.config import *\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "from utils.gpu_utils import config_gpu\n",
    "import tensorflow as tf\n",
    "from utils.plot_utils import plot_attention\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from seq2seq_tf2.batcher import train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 预处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build_dataset(train_data_path,test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  加载vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(vocab_file=vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<START>', 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.START_DECODING, vocab.START_DECODING_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31819"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"vocab_size\"] = vocab.count\n",
    "params[\"embedding_dim\"] = 300\n",
    "params[\"enc_units\"] = 512\n",
    "params[\"attn_units\"] = 512\n",
    "params[\"dec_units\"] = 512\n",
    "params[\"batch_size\"] = 32\n",
    "params[\"epochs\"] = 5\n",
    "params[\"max_enc_len\"] = 200\n",
    "params[\"max_dec_len\"] = 41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 加载数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, steps_per_epoch = train_batch_generator(batch_size=params[\"batch_size\"] ,\n",
    "                                                 max_enc_len=params[\"max_enc_len\"],\n",
    "                                                 max_dec_len=params[\"max_dec_len\"])\n",
    "test_X = load_test_dataset(params[\"max_enc_len\"])\n",
    "train_X, train_Y = load_train_dataset(params['max_enc_len'], params['max_dec_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82873, 82873, 20000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_Y), len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2589"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "82873 // params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((32, 200), (32, 40)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 加载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix=load_embedding_matrix(embedding_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31819, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq_tf2.seq2seq_model import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Seq2Seq(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 读取训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import seq2seq_checkpoint_dir,seq2seq_checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(Seq2Seq=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, seq2seq_checkpoint_prefix, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "print(\"Model restored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(name='Adam',learning_rate=0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    pad_mask = tf.math.equal(real, vocab.PAD_TOKEN_INDEX)\n",
    "    unk_mask = tf.math.equal(real, vocab.UNKNOWN_TOKEN_INDEX)\n",
    "    mask = tf.math.logical_not(tf.math.logical_or(pad_mask,unk_mask))\n",
    "    \n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(inp, targ):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # 1. 构建encoder\n",
    "        enc_output, enc_hidden = model.call_encoder(inp)\n",
    "        # 2. 复制\n",
    "        dec_hidden = enc_hidden\n",
    "        # 3. <START> * BATCH_SIZE \n",
    "        dec_input = tf.expand_dims([vocab.START_DECODING_INDEX] * params[\"batch_size\"], 1)\n",
    "        \n",
    "        # 逐个预测序列\n",
    "        predictions, _ = model(dec_input, dec_hidden, enc_output, targ)\n",
    "        \n",
    "        batch_loss = loss_function(targ[:, 1:], predictions)\n",
    "\n",
    "        variables = model.encoder.trainable_variables + model.decoder.trainable_variables+ model.attention.trainable_variables\n",
    "    \n",
    "        gradients = tape.gradient(batch_loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.5357\n",
      "Epoch 1 Batch 1 Loss 4.0905\n",
      "Epoch 1 Batch 2 Loss 4.0176\n",
      "Epoch 1 Batch 3 Loss 4.6302\n",
      "Epoch 1 Batch 4 Loss 3.5611\n",
      "Epoch 1 Batch 5 Loss 4.3306\n",
      "Epoch 1 Batch 6 Loss 4.1487\n",
      "Epoch 1 Batch 7 Loss 3.6022\n",
      "Epoch 1 Batch 8 Loss 3.9256\n",
      "Epoch 1 Batch 9 Loss 3.0930\n",
      "Epoch 1 Batch 10 Loss 3.1431\n",
      "Epoch 1 Batch 11 Loss 3.2329\n",
      "Epoch 1 Batch 12 Loss 2.9203\n",
      "Epoch 1 Batch 13 Loss 2.4651\n",
      "Epoch 1 Batch 14 Loss 2.4738\n",
      "Epoch 1 Batch 15 Loss 3.4383\n",
      "Epoch 1 Batch 16 Loss 2.7624\n",
      "Epoch 1 Batch 17 Loss 3.5343\n",
      "Epoch 1 Batch 18 Loss 2.9936\n",
      "Epoch 1 Batch 19 Loss 2.7242\n",
      "Epoch 1 Batch 20 Loss 3.2700\n",
      "Epoch 1 Batch 21 Loss 3.2139\n",
      "Epoch 1 Batch 22 Loss 3.1080\n",
      "Epoch 1 Batch 23 Loss 3.0818\n",
      "Epoch 1 Batch 24 Loss 2.9912\n",
      "Epoch 1 Batch 25 Loss 3.1859\n",
      "Epoch 1 Batch 26 Loss 3.4706\n",
      "Epoch 1 Batch 27 Loss 2.9746\n",
      "Epoch 1 Batch 28 Loss 2.3567\n",
      "Epoch 1 Batch 29 Loss 2.7548\n",
      "Epoch 1 Batch 30 Loss 2.8786\n",
      "Epoch 1 Batch 31 Loss 2.9916\n",
      "Epoch 1 Batch 32 Loss 2.6941\n",
      "Epoch 1 Batch 33 Loss 2.7119\n",
      "Epoch 1 Batch 34 Loss 3.1096\n",
      "Epoch 1 Batch 35 Loss 3.3511\n",
      "Epoch 1 Batch 36 Loss 2.5037\n",
      "Epoch 1 Batch 37 Loss 2.6663\n",
      "Epoch 1 Batch 38 Loss 2.8480\n",
      "Epoch 1 Batch 39 Loss 2.5831\n",
      "Epoch 1 Batch 40 Loss 3.1380\n",
      "Epoch 1 Batch 41 Loss 2.6821\n",
      "Epoch 1 Batch 42 Loss 2.9982\n",
      "Epoch 1 Batch 43 Loss 2.3142\n",
      "Epoch 1 Batch 44 Loss 2.9236\n",
      "Epoch 1 Batch 45 Loss 2.9789\n",
      "Epoch 1 Batch 46 Loss 3.0008\n",
      "Epoch 1 Batch 47 Loss 2.4702\n",
      "Epoch 1 Batch 48 Loss 2.3851\n",
      "Epoch 1 Batch 49 Loss 2.8780\n",
      "Epoch 1 Batch 50 Loss 2.7443\n",
      "Epoch 1 Batch 51 Loss 2.7406\n",
      "Epoch 1 Batch 52 Loss 2.8485\n",
      "Epoch 1 Batch 53 Loss 2.5693\n",
      "Epoch 1 Batch 54 Loss 3.0617\n",
      "Epoch 1 Batch 55 Loss 2.4846\n",
      "Epoch 1 Batch 56 Loss 2.7295\n",
      "Epoch 1 Batch 57 Loss 2.0147\n",
      "Epoch 1 Batch 58 Loss 3.0705\n",
      "Epoch 1 Batch 59 Loss 2.9017\n",
      "Epoch 1 Batch 60 Loss 2.7748\n",
      "Epoch 1 Batch 61 Loss 2.0850\n",
      "Epoch 1 Batch 62 Loss 2.6885\n",
      "Epoch 1 Batch 63 Loss 2.4873\n",
      "Epoch 1 Batch 64 Loss 2.7927\n",
      "Epoch 1 Batch 65 Loss 2.6819\n",
      "Epoch 1 Batch 66 Loss 2.6073\n",
      "Epoch 1 Batch 67 Loss 2.0477\n",
      "Epoch 1 Batch 68 Loss 2.3689\n",
      "Epoch 1 Batch 69 Loss 2.3028\n",
      "Epoch 1 Batch 70 Loss 2.6025\n",
      "Epoch 1 Batch 71 Loss 2.9692\n",
      "Epoch 1 Batch 72 Loss 2.5284\n",
      "Epoch 1 Batch 73 Loss 3.1904\n",
      "Epoch 1 Batch 74 Loss 2.4177\n",
      "Epoch 1 Batch 75 Loss 2.2079\n",
      "Epoch 1 Batch 76 Loss 2.7609\n",
      "Epoch 1 Batch 77 Loss 2.3767\n",
      "Epoch 1 Batch 78 Loss 2.5011\n",
      "Epoch 1 Batch 79 Loss 2.7175\n",
      "Epoch 1 Batch 80 Loss 2.6330\n",
      "Epoch 1 Batch 81 Loss 3.1437\n",
      "Epoch 1 Batch 82 Loss 3.1252\n",
      "Epoch 1 Batch 83 Loss 2.6493\n",
      "Epoch 1 Batch 84 Loss 2.4202\n",
      "Epoch 1 Batch 85 Loss 2.7460\n",
      "Epoch 1 Batch 86 Loss 2.4222\n",
      "Epoch 1 Batch 87 Loss 3.0657\n",
      "Epoch 1 Batch 88 Loss 2.9257\n",
      "Epoch 1 Batch 89 Loss 2.8394\n",
      "Epoch 1 Batch 90 Loss 2.4127\n",
      "Epoch 1 Batch 91 Loss 2.6222\n",
      "Epoch 1 Batch 92 Loss 1.9638\n",
      "Epoch 1 Batch 93 Loss 3.0229\n",
      "Epoch 1 Batch 94 Loss 2.5916\n",
      "Epoch 1 Batch 95 Loss 3.1668\n",
      "Epoch 1 Batch 96 Loss 2.5290\n",
      "Epoch 1 Batch 97 Loss 2.6818\n",
      "Epoch 1 Batch 98 Loss 2.6090\n",
      "Epoch 1 Batch 99 Loss 2.5740\n",
      "Epoch 1 Batch 100 Loss 3.5855\n",
      "Epoch 1 Batch 101 Loss 2.6048\n",
      "Epoch 1 Batch 102 Loss 2.3768\n",
      "Epoch 1 Batch 103 Loss 2.6134\n",
      "Epoch 1 Batch 104 Loss 2.9071\n",
      "Epoch 1 Batch 105 Loss 3.0542\n",
      "Epoch 1 Batch 106 Loss 2.5131\n",
      "Epoch 1 Batch 107 Loss 2.6622\n",
      "Epoch 1 Batch 108 Loss 2.4129\n",
      "Epoch 1 Batch 109 Loss 2.9891\n",
      "Epoch 1 Batch 110 Loss 2.4925\n",
      "Epoch 1 Batch 111 Loss 2.8831\n",
      "Epoch 1 Batch 112 Loss 2.8316\n",
      "Epoch 1 Batch 113 Loss 2.6334\n",
      "Epoch 1 Batch 114 Loss 2.3380\n",
      "Epoch 1 Batch 115 Loss 2.3706\n",
      "Epoch 1 Batch 116 Loss 2.4753\n",
      "Epoch 1 Batch 117 Loss 2.1920\n",
      "Epoch 1 Batch 118 Loss 2.6754\n",
      "Epoch 1 Batch 119 Loss 2.3975\n",
      "Epoch 1 Batch 120 Loss 2.6902\n",
      "Epoch 1 Batch 121 Loss 3.2377\n",
      "Epoch 1 Batch 122 Loss 2.5809\n",
      "Epoch 1 Batch 123 Loss 2.3085\n",
      "Epoch 1 Batch 124 Loss 3.2302\n",
      "Epoch 1 Batch 125 Loss 3.1156\n",
      "Epoch 1 Batch 126 Loss 3.2270\n",
      "Epoch 1 Batch 127 Loss 3.2218\n",
      "Epoch 1 Batch 128 Loss 2.6888\n",
      "Epoch 1 Batch 129 Loss 2.7926\n",
      "Epoch 1 Batch 130 Loss 2.4853\n",
      "Epoch 1 Batch 131 Loss 2.6649\n",
      "Epoch 1 Batch 132 Loss 2.7902\n",
      "Epoch 1 Batch 133 Loss 2.4557\n",
      "Epoch 1 Batch 134 Loss 3.0579\n",
      "Epoch 1 Batch 135 Loss 3.1704\n",
      "Epoch 1 Batch 136 Loss 2.9707\n",
      "Epoch 1 Batch 137 Loss 2.6579\n",
      "Epoch 1 Batch 138 Loss 2.4904\n",
      "Epoch 1 Batch 139 Loss 2.4748\n",
      "Epoch 1 Batch 140 Loss 2.6613\n",
      "Epoch 1 Batch 141 Loss 3.1132\n",
      "Epoch 1 Batch 142 Loss 2.8598\n",
      "Epoch 1 Batch 143 Loss 2.3907\n",
      "Epoch 1 Batch 144 Loss 2.6293\n",
      "Epoch 1 Batch 145 Loss 3.2308\n",
      "Epoch 1 Batch 146 Loss 2.7371\n",
      "Epoch 1 Batch 147 Loss 2.8954\n",
      "Epoch 1 Batch 148 Loss 2.7084\n",
      "Epoch 1 Batch 149 Loss 2.6918\n",
      "Epoch 1 Batch 150 Loss 2.9491\n",
      "Epoch 1 Batch 151 Loss 2.4892\n",
      "Epoch 1 Batch 152 Loss 2.7055\n",
      "Epoch 1 Batch 153 Loss 2.5114\n",
      "Epoch 1 Batch 154 Loss 2.8868\n",
      "Epoch 1 Batch 155 Loss 2.4045\n",
      "Epoch 1 Batch 156 Loss 2.8766\n",
      "Epoch 1 Batch 157 Loss 2.0879\n",
      "Epoch 1 Batch 158 Loss 2.8161\n",
      "Epoch 1 Batch 159 Loss 2.6055\n",
      "Epoch 1 Batch 160 Loss 2.6046\n",
      "Epoch 1 Batch 161 Loss 2.3821\n",
      "Epoch 1 Batch 162 Loss 2.1162\n",
      "Epoch 1 Batch 163 Loss 2.5932\n",
      "Epoch 1 Batch 164 Loss 2.3751\n",
      "Epoch 1 Batch 165 Loss 2.8933\n",
      "Epoch 1 Batch 166 Loss 2.8965\n",
      "Epoch 1 Batch 167 Loss 2.6398\n",
      "Epoch 1 Batch 168 Loss 2.1188\n",
      "Epoch 1 Batch 169 Loss 2.8436\n",
      "Epoch 1 Batch 170 Loss 2.6750\n",
      "Epoch 1 Batch 171 Loss 2.6200\n",
      "Epoch 1 Batch 172 Loss 2.3693\n",
      "Epoch 1 Batch 173 Loss 2.2728\n",
      "Epoch 1 Batch 174 Loss 2.5053\n",
      "Epoch 1 Batch 175 Loss 2.5118\n",
      "Epoch 1 Batch 176 Loss 2.4346\n",
      "Epoch 1 Batch 177 Loss 2.8754\n",
      "Epoch 1 Batch 178 Loss 2.4736\n",
      "Epoch 1 Batch 179 Loss 2.8901\n",
      "Epoch 1 Batch 180 Loss 2.7390\n",
      "Epoch 1 Batch 181 Loss 2.3650\n",
      "Epoch 1 Batch 182 Loss 2.3077\n",
      "Epoch 1 Batch 183 Loss 2.6212\n",
      "Epoch 1 Batch 184 Loss 2.5032\n",
      "Epoch 1 Batch 185 Loss 2.6639\n",
      "Epoch 1 Batch 186 Loss 2.8728\n",
      "Epoch 1 Batch 187 Loss 3.4866\n",
      "Epoch 1 Batch 188 Loss 2.5475\n",
      "Epoch 1 Batch 189 Loss 2.7498\n",
      "Epoch 1 Batch 190 Loss 2.2990\n",
      "Epoch 1 Batch 191 Loss 2.5544\n",
      "Epoch 1 Batch 192 Loss 2.3184\n",
      "Epoch 1 Batch 193 Loss 2.7790\n",
      "Epoch 1 Batch 194 Loss 2.9436\n",
      "Epoch 1 Batch 195 Loss 2.5504\n",
      "Epoch 1 Batch 196 Loss 3.0800\n",
      "Epoch 1 Batch 197 Loss 2.5691\n",
      "Epoch 1 Batch 198 Loss 3.1710\n",
      "Epoch 1 Batch 199 Loss 2.9950\n",
      "Epoch 1 Batch 200 Loss 3.0956\n",
      "Epoch 1 Batch 201 Loss 2.7085\n",
      "Epoch 1 Batch 202 Loss 2.7592\n",
      "Epoch 1 Batch 203 Loss 3.0168\n",
      "Epoch 1 Batch 204 Loss 2.9392\n",
      "Epoch 1 Batch 205 Loss 3.2596\n",
      "Epoch 1 Batch 206 Loss 2.6391\n",
      "Epoch 1 Batch 207 Loss 2.5213\n",
      "Epoch 1 Batch 208 Loss 2.7770\n",
      "Epoch 1 Batch 209 Loss 2.6823\n",
      "Epoch 1 Batch 210 Loss 2.6724\n",
      "Epoch 1 Batch 211 Loss 2.7241\n",
      "Epoch 1 Batch 212 Loss 2.3511\n",
      "Epoch 1 Batch 213 Loss 2.7914\n",
      "Epoch 1 Batch 214 Loss 2.5850\n",
      "Epoch 1 Batch 215 Loss 2.6707\n",
      "Epoch 1 Batch 216 Loss 2.4146\n",
      "Epoch 1 Batch 217 Loss 2.7123\n",
      "Epoch 1 Batch 218 Loss 2.6482\n",
      "Epoch 1 Batch 219 Loss 2.1363\n",
      "Epoch 1 Batch 220 Loss 3.3386\n",
      "Epoch 1 Batch 221 Loss 2.9334\n",
      "Epoch 1 Batch 222 Loss 3.3192\n",
      "Epoch 1 Batch 223 Loss 2.7122\n",
      "Epoch 1 Batch 224 Loss 2.4567\n",
      "Epoch 1 Batch 225 Loss 2.7454\n",
      "Epoch 1 Batch 226 Loss 2.7142\n",
      "Epoch 1 Batch 227 Loss 2.4081\n",
      "Epoch 1 Batch 228 Loss 2.7264\n",
      "Epoch 1 Batch 229 Loss 2.5632\n",
      "Epoch 1 Batch 230 Loss 2.9970\n",
      "Epoch 1 Batch 231 Loss 2.3119\n",
      "Epoch 1 Batch 232 Loss 2.4556\n",
      "Epoch 1 Batch 233 Loss 2.3703\n",
      "Epoch 1 Batch 234 Loss 2.7836\n",
      "Epoch 1 Batch 235 Loss 2.4773\n",
      "Epoch 1 Batch 236 Loss 2.9030\n",
      "Epoch 1 Batch 237 Loss 2.5247\n",
      "Epoch 1 Batch 238 Loss 2.9903\n",
      "Epoch 1 Batch 239 Loss 2.6295\n",
      "Epoch 1 Batch 240 Loss 2.7089\n",
      "Epoch 1 Batch 241 Loss 2.7292\n",
      "Epoch 1 Batch 242 Loss 2.5834\n",
      "Epoch 1 Batch 243 Loss 2.8091\n",
      "Epoch 1 Batch 244 Loss 2.4372\n",
      "Epoch 1 Batch 245 Loss 2.8351\n",
      "Epoch 1 Batch 246 Loss 2.3947\n",
      "Epoch 1 Batch 247 Loss 2.7241\n",
      "Epoch 1 Batch 248 Loss 3.1953\n",
      "Epoch 1 Batch 249 Loss 2.5737\n",
      "Epoch 1 Batch 250 Loss 2.1392\n",
      "Epoch 1 Batch 251 Loss 2.5305\n",
      "Epoch 1 Batch 252 Loss 2.3334\n",
      "Epoch 1 Batch 253 Loss 2.6254\n",
      "Epoch 1 Batch 254 Loss 2.3575\n",
      "Epoch 1 Batch 255 Loss 2.5939\n",
      "Epoch 1 Batch 256 Loss 2.4987\n",
      "Epoch 1 Batch 257 Loss 2.6171\n",
      "Epoch 1 Batch 258 Loss 2.9218\n",
      "Epoch 1 Batch 259 Loss 2.8616\n",
      "Epoch 1 Batch 260 Loss 2.9015\n",
      "Epoch 1 Batch 261 Loss 2.5712\n",
      "Epoch 1 Batch 262 Loss 2.8837\n",
      "Epoch 1 Batch 263 Loss 2.3100\n",
      "Epoch 1 Batch 264 Loss 2.5226\n",
      "Epoch 1 Batch 265 Loss 2.7253\n",
      "Epoch 1 Batch 266 Loss 2.7673\n",
      "Epoch 1 Batch 267 Loss 3.3885\n",
      "Epoch 1 Batch 268 Loss 2.7056\n",
      "Epoch 1 Batch 269 Loss 2.7521\n",
      "Epoch 1 Batch 270 Loss 2.6428\n",
      "Epoch 1 Batch 271 Loss 2.9801\n",
      "Epoch 1 Batch 272 Loss 2.6153\n",
      "Epoch 1 Batch 273 Loss 3.1751\n",
      "Epoch 1 Batch 274 Loss 2.7007\n",
      "Epoch 1 Batch 275 Loss 2.3923\n",
      "Epoch 1 Batch 276 Loss 2.7222\n",
      "Epoch 1 Batch 277 Loss 2.5748\n",
      "Epoch 1 Batch 278 Loss 2.6095\n",
      "Epoch 1 Batch 279 Loss 2.5049\n",
      "Epoch 1 Batch 280 Loss 2.8857\n",
      "Epoch 1 Batch 281 Loss 2.2275\n",
      "Epoch 1 Batch 282 Loss 2.5454\n",
      "Epoch 1 Batch 283 Loss 2.1625\n",
      "Epoch 1 Batch 284 Loss 2.4818\n",
      "Epoch 1 Batch 285 Loss 2.7712\n",
      "Epoch 1 Batch 286 Loss 2.2188\n",
      "Epoch 1 Batch 287 Loss 2.5527\n",
      "Epoch 1 Batch 288 Loss 3.4063\n",
      "Epoch 1 Batch 289 Loss 2.4095\n",
      "Epoch 1 Batch 290 Loss 2.8495\n",
      "Epoch 1 Batch 291 Loss 2.6626\n",
      "Epoch 1 Batch 292 Loss 2.4974\n",
      "Epoch 1 Batch 293 Loss 2.4327\n",
      "Epoch 1 Batch 294 Loss 2.7242\n",
      "Epoch 1 Batch 295 Loss 2.4777\n",
      "Epoch 1 Batch 296 Loss 2.5979\n",
      "Epoch 1 Batch 297 Loss 2.6562\n",
      "Epoch 1 Batch 298 Loss 2.3794\n",
      "Epoch 1 Batch 299 Loss 2.5418\n",
      "Epoch 1 Batch 300 Loss 2.2506\n",
      "Epoch 1 Batch 301 Loss 2.7977\n",
      "Epoch 1 Batch 302 Loss 2.4666\n",
      "Epoch 1 Batch 303 Loss 2.0981\n",
      "Epoch 1 Batch 304 Loss 2.5292\n",
      "Epoch 1 Batch 305 Loss 2.6333\n",
      "Epoch 1 Batch 306 Loss 2.7030\n",
      "Epoch 1 Batch 307 Loss 2.7903\n",
      "Epoch 1 Batch 308 Loss 2.3078\n",
      "Epoch 1 Batch 309 Loss 2.7210\n",
      "Epoch 1 Batch 310 Loss 2.5721\n",
      "Epoch 1 Batch 311 Loss 2.7740\n",
      "Epoch 1 Batch 312 Loss 2.8048\n",
      "Epoch 1 Batch 313 Loss 2.7645\n",
      "Epoch 1 Batch 314 Loss 2.6356\n",
      "Epoch 1 Batch 315 Loss 3.0779\n",
      "Epoch 1 Batch 316 Loss 2.7255\n",
      "Epoch 1 Batch 317 Loss 2.8838\n",
      "Epoch 1 Batch 318 Loss 2.8049\n",
      "Epoch 1 Batch 319 Loss 2.6714\n",
      "Epoch 1 Batch 320 Loss 2.3043\n",
      "Epoch 1 Batch 321 Loss 3.1428\n",
      "Epoch 1 Batch 322 Loss 2.4489\n",
      "Epoch 1 Batch 323 Loss 2.3476\n",
      "Epoch 1 Batch 324 Loss 2.3921\n",
      "Epoch 1 Batch 325 Loss 2.6350\n",
      "Epoch 1 Batch 326 Loss 2.6985\n",
      "Epoch 1 Batch 327 Loss 2.6752\n",
      "Epoch 1 Batch 328 Loss 2.9360\n",
      "Epoch 1 Batch 329 Loss 2.2783\n",
      "Epoch 1 Batch 330 Loss 2.2232\n",
      "Epoch 1 Batch 331 Loss 2.3332\n",
      "Epoch 1 Batch 332 Loss 3.2861\n",
      "Epoch 1 Batch 333 Loss 2.5386\n",
      "Epoch 1 Batch 334 Loss 2.9434\n",
      "Epoch 1 Batch 335 Loss 2.6942\n",
      "Epoch 1 Batch 336 Loss 2.3400\n",
      "Epoch 1 Batch 337 Loss 3.1141\n",
      "Epoch 1 Batch 338 Loss 2.5666\n",
      "Epoch 1 Batch 339 Loss 2.9353\n",
      "Epoch 1 Batch 340 Loss 2.1170\n",
      "Epoch 1 Batch 341 Loss 3.0452\n",
      "Epoch 1 Batch 342 Loss 2.4398\n",
      "Epoch 1 Batch 343 Loss 2.6813\n",
      "Epoch 1 Batch 344 Loss 2.2807\n",
      "Epoch 1 Batch 345 Loss 2.4767\n",
      "Epoch 1 Batch 346 Loss 2.9331\n",
      "Epoch 1 Batch 347 Loss 2.4707\n",
      "Epoch 1 Batch 348 Loss 2.8023\n",
      "Epoch 1 Batch 349 Loss 3.0229\n",
      "Epoch 1 Batch 350 Loss 1.8578\n",
      "Epoch 1 Batch 351 Loss 2.6072\n",
      "Epoch 1 Batch 352 Loss 3.1677\n",
      "Epoch 1 Batch 353 Loss 2.1139\n",
      "Epoch 1 Batch 354 Loss 2.6538\n",
      "Epoch 1 Batch 355 Loss 2.7008\n",
      "Epoch 1 Batch 356 Loss 2.1897\n",
      "Epoch 1 Batch 357 Loss 2.3181\n",
      "Epoch 1 Batch 358 Loss 2.6194\n",
      "Epoch 1 Batch 359 Loss 2.8191\n",
      "Epoch 1 Batch 360 Loss 2.3943\n",
      "Epoch 1 Batch 361 Loss 2.6490\n",
      "Epoch 1 Batch 362 Loss 1.9358\n",
      "Epoch 1 Batch 363 Loss 2.8238\n",
      "Epoch 1 Batch 364 Loss 2.8837\n",
      "Epoch 1 Batch 365 Loss 2.5248\n",
      "Epoch 1 Batch 366 Loss 2.2885\n",
      "Epoch 1 Batch 367 Loss 2.5971\n",
      "Epoch 1 Batch 368 Loss 2.3322\n",
      "Epoch 1 Batch 369 Loss 3.0478\n",
      "Epoch 1 Batch 370 Loss 2.8024\n",
      "Epoch 1 Batch 371 Loss 3.0073\n",
      "Epoch 1 Batch 372 Loss 2.6521\n",
      "Epoch 1 Batch 373 Loss 2.2971\n",
      "Epoch 1 Batch 374 Loss 2.4148\n",
      "Epoch 1 Batch 375 Loss 2.5614\n",
      "Epoch 1 Batch 376 Loss 2.5934\n",
      "Epoch 1 Batch 377 Loss 2.6817\n",
      "Epoch 1 Batch 378 Loss 2.7610\n",
      "Epoch 1 Batch 379 Loss 2.0838\n",
      "Epoch 1 Batch 380 Loss 2.5778\n",
      "Epoch 1 Batch 381 Loss 2.6347\n",
      "Epoch 1 Batch 382 Loss 2.1877\n",
      "Epoch 1 Batch 383 Loss 3.0246\n",
      "Epoch 1 Batch 384 Loss 2.4250\n",
      "Epoch 1 Batch 385 Loss 3.0690\n",
      "Epoch 1 Batch 386 Loss 2.6280\n",
      "Epoch 1 Batch 387 Loss 2.9274\n",
      "Epoch 1 Batch 388 Loss 2.2299\n",
      "Epoch 1 Batch 389 Loss 2.6408\n",
      "Epoch 1 Batch 390 Loss 2.1423\n",
      "Epoch 1 Batch 391 Loss 2.6463\n",
      "Epoch 1 Batch 392 Loss 2.7723\n",
      "Epoch 1 Batch 393 Loss 2.7614\n",
      "Epoch 1 Batch 394 Loss 2.5404\n",
      "Epoch 1 Batch 395 Loss 2.9823\n",
      "Epoch 1 Batch 396 Loss 2.9016\n",
      "Epoch 1 Batch 397 Loss 2.2402\n",
      "Epoch 1 Batch 398 Loss 2.0614\n",
      "Epoch 1 Batch 399 Loss 2.7854\n",
      "Epoch 1 Batch 400 Loss 2.6771\n",
      "Epoch 1 Batch 401 Loss 2.4370\n",
      "Epoch 1 Batch 402 Loss 2.7063\n",
      "Epoch 1 Batch 403 Loss 2.7587\n",
      "Epoch 1 Batch 404 Loss 2.0928\n",
      "Epoch 1 Batch 405 Loss 2.4440\n",
      "Epoch 1 Batch 406 Loss 2.7383\n",
      "Epoch 1 Batch 407 Loss 3.3047\n",
      "Epoch 1 Batch 408 Loss 2.7230\n",
      "Epoch 1 Batch 409 Loss 2.7428\n",
      "Epoch 1 Batch 410 Loss 2.4738\n",
      "Epoch 1 Batch 411 Loss 2.7640\n",
      "Epoch 1 Batch 412 Loss 2.5239\n",
      "Epoch 1 Batch 413 Loss 2.4434\n",
      "Epoch 1 Batch 414 Loss 2.2160\n",
      "Epoch 1 Batch 415 Loss 2.5153\n",
      "Epoch 1 Batch 416 Loss 2.6898\n",
      "Epoch 1 Batch 417 Loss 2.3224\n",
      "Epoch 1 Batch 418 Loss 2.8444\n",
      "Epoch 1 Batch 419 Loss 2.3913\n",
      "Epoch 1 Batch 420 Loss 2.7532\n",
      "Epoch 1 Batch 421 Loss 2.7874\n",
      "Epoch 1 Batch 422 Loss 2.6642\n",
      "Epoch 1 Batch 423 Loss 2.5863\n",
      "Epoch 1 Batch 424 Loss 2.7027\n",
      "Epoch 1 Batch 425 Loss 2.6834\n",
      "Epoch 1 Batch 426 Loss 2.5191\n",
      "Epoch 1 Batch 427 Loss 2.1269\n",
      "Epoch 1 Batch 428 Loss 2.4898\n",
      "Epoch 1 Batch 429 Loss 2.8324\n",
      "Epoch 1 Batch 430 Loss 2.6058\n",
      "Epoch 1 Batch 431 Loss 2.6800\n",
      "Epoch 1 Batch 432 Loss 2.3100\n",
      "Epoch 1 Batch 433 Loss 2.3751\n",
      "Epoch 1 Batch 434 Loss 2.4633\n",
      "Epoch 1 Batch 435 Loss 2.7675\n",
      "Epoch 1 Batch 436 Loss 2.6913\n",
      "Epoch 1 Batch 437 Loss 3.1315\n",
      "Epoch 1 Batch 438 Loss 2.7924\n",
      "Epoch 1 Batch 439 Loss 2.7904\n",
      "Epoch 1 Batch 440 Loss 2.7050\n",
      "Epoch 1 Batch 441 Loss 2.2522\n",
      "Epoch 1 Batch 442 Loss 2.7939\n",
      "Epoch 1 Batch 443 Loss 3.0899\n",
      "Epoch 1 Batch 444 Loss 2.3458\n",
      "Epoch 1 Batch 445 Loss 2.3566\n",
      "Epoch 1 Batch 446 Loss 2.5406\n",
      "Epoch 1 Batch 447 Loss 2.6627\n",
      "Epoch 1 Batch 448 Loss 2.5908\n",
      "Epoch 1 Batch 449 Loss 2.3446\n",
      "Epoch 1 Batch 450 Loss 2.7282\n",
      "Epoch 1 Batch 451 Loss 2.9830\n",
      "Epoch 1 Batch 452 Loss 2.4344\n",
      "Epoch 1 Batch 453 Loss 2.6382\n",
      "Epoch 1 Batch 454 Loss 2.8730\n",
      "Epoch 1 Batch 455 Loss 2.2781\n",
      "Epoch 1 Batch 456 Loss 2.1338\n",
      "Epoch 1 Batch 457 Loss 2.2500\n",
      "Epoch 1 Batch 458 Loss 2.6079\n",
      "Epoch 1 Batch 459 Loss 2.1516\n",
      "Epoch 1 Batch 460 Loss 2.7823\n",
      "Epoch 1 Batch 461 Loss 2.2440\n",
      "Epoch 1 Batch 462 Loss 2.4006\n",
      "Epoch 1 Batch 463 Loss 2.1849\n",
      "Epoch 1 Batch 464 Loss 2.3998\n",
      "Epoch 1 Batch 465 Loss 2.9032\n",
      "Epoch 1 Batch 466 Loss 2.5140\n",
      "Epoch 1 Batch 467 Loss 2.7828\n",
      "Epoch 1 Batch 468 Loss 2.4148\n",
      "Epoch 1 Batch 469 Loss 2.7983\n",
      "Epoch 1 Batch 470 Loss 2.6434\n",
      "Epoch 1 Batch 471 Loss 2.5361\n",
      "Epoch 1 Batch 472 Loss 2.3603\n",
      "Epoch 1 Batch 473 Loss 2.5011\n",
      "Epoch 1 Batch 474 Loss 2.4192\n",
      "Epoch 1 Batch 475 Loss 2.4633\n",
      "Epoch 1 Batch 476 Loss 3.2273\n",
      "Epoch 1 Batch 477 Loss 2.3738\n",
      "Epoch 1 Batch 478 Loss 3.0864\n",
      "Epoch 1 Batch 479 Loss 2.8768\n",
      "Epoch 1 Batch 480 Loss 2.4129\n",
      "Epoch 1 Batch 481 Loss 2.5091\n",
      "Epoch 1 Batch 482 Loss 2.6141\n",
      "Epoch 1 Batch 483 Loss 2.3982\n",
      "Epoch 1 Batch 484 Loss 3.1566\n",
      "Epoch 1 Batch 485 Loss 2.0650\n",
      "Epoch 1 Batch 486 Loss 2.8961\n",
      "Epoch 1 Batch 487 Loss 3.2996\n",
      "Epoch 1 Batch 488 Loss 2.6904\n",
      "Epoch 1 Batch 489 Loss 2.2772\n",
      "Epoch 1 Batch 490 Loss 2.8564\n",
      "Epoch 1 Batch 491 Loss 2.7210\n",
      "Epoch 1 Batch 492 Loss 2.7569\n",
      "Epoch 1 Batch 493 Loss 2.1405\n",
      "Epoch 1 Batch 494 Loss 2.3284\n",
      "Epoch 1 Batch 495 Loss 2.8046\n",
      "Epoch 1 Batch 496 Loss 2.4823\n",
      "Epoch 1 Batch 497 Loss 2.5421\n",
      "Epoch 1 Batch 498 Loss 2.3868\n",
      "Epoch 1 Batch 499 Loss 2.3494\n",
      "Epoch 1 Batch 500 Loss 2.4798\n",
      "Epoch 1 Batch 501 Loss 2.0821\n",
      "Epoch 1 Batch 502 Loss 2.6172\n",
      "Epoch 1 Batch 503 Loss 2.1054\n",
      "Epoch 1 Batch 504 Loss 2.7592\n",
      "Epoch 1 Batch 505 Loss 2.5035\n",
      "Epoch 1 Batch 506 Loss 3.1576\n",
      "Epoch 1 Batch 507 Loss 2.4302\n",
      "Epoch 1 Batch 508 Loss 2.1641\n",
      "Epoch 1 Batch 509 Loss 2.5397\n",
      "Epoch 1 Batch 510 Loss 2.2856\n",
      "Epoch 1 Batch 511 Loss 2.7308\n",
      "Epoch 1 Batch 512 Loss 2.7178\n",
      "Epoch 1 Batch 513 Loss 2.0539\n",
      "Epoch 1 Batch 514 Loss 2.6306\n",
      "Epoch 1 Batch 515 Loss 2.4873\n",
      "Epoch 1 Batch 516 Loss 2.7903\n",
      "Epoch 1 Batch 517 Loss 2.6629\n",
      "Epoch 1 Batch 518 Loss 3.0156\n",
      "Epoch 1 Batch 519 Loss 2.0578\n",
      "Epoch 1 Batch 520 Loss 2.9256\n",
      "Epoch 1 Batch 521 Loss 2.4096\n",
      "Epoch 1 Batch 522 Loss 2.9755\n",
      "Epoch 1 Batch 523 Loss 2.5299\n",
      "Epoch 1 Batch 524 Loss 2.4987\n",
      "Epoch 1 Batch 525 Loss 2.6876\n",
      "Epoch 1 Batch 526 Loss 2.8373\n",
      "Epoch 1 Batch 527 Loss 2.5121\n",
      "Epoch 1 Batch 528 Loss 2.3736\n",
      "Epoch 1 Batch 529 Loss 2.1812\n",
      "Epoch 1 Batch 530 Loss 1.7969\n",
      "Epoch 1 Batch 531 Loss 2.2541\n",
      "Epoch 1 Batch 532 Loss 2.4637\n",
      "Epoch 1 Batch 533 Loss 2.9406\n",
      "Epoch 1 Batch 534 Loss 2.0945\n",
      "Epoch 1 Batch 535 Loss 2.6487\n",
      "Epoch 1 Batch 536 Loss 2.8678\n",
      "Epoch 1 Batch 537 Loss 2.9716\n",
      "Epoch 1 Batch 538 Loss 2.1585\n",
      "Epoch 1 Batch 539 Loss 2.5057\n",
      "Epoch 1 Batch 540 Loss 2.3452\n",
      "Epoch 1 Batch 541 Loss 2.6017\n",
      "Epoch 1 Batch 542 Loss 2.3136\n",
      "Epoch 1 Batch 543 Loss 2.4319\n",
      "Epoch 1 Batch 544 Loss 2.3379\n",
      "Epoch 1 Batch 545 Loss 1.7546\n",
      "Epoch 1 Batch 546 Loss 2.8334\n",
      "Epoch 1 Batch 547 Loss 2.2445\n",
      "Epoch 1 Batch 548 Loss 2.3373\n",
      "Epoch 1 Batch 549 Loss 1.8864\n",
      "Epoch 1 Batch 550 Loss 2.4883\n",
      "Epoch 1 Batch 551 Loss 2.5056\n",
      "Epoch 1 Batch 552 Loss 2.7387\n",
      "Epoch 1 Batch 553 Loss 2.8543\n",
      "Epoch 1 Batch 554 Loss 2.4493\n",
      "Epoch 1 Batch 555 Loss 2.8021\n",
      "Epoch 1 Batch 556 Loss 1.8363\n",
      "Epoch 1 Batch 557 Loss 2.7671\n",
      "Epoch 1 Batch 558 Loss 2.6018\n",
      "Epoch 1 Batch 559 Loss 2.5951\n",
      "Epoch 1 Batch 560 Loss 3.1132\n",
      "Epoch 1 Batch 561 Loss 2.3383\n",
      "Epoch 1 Batch 562 Loss 2.3820\n",
      "Epoch 1 Batch 563 Loss 2.5549\n",
      "Epoch 1 Batch 564 Loss 2.2490\n",
      "Epoch 1 Batch 565 Loss 2.6369\n",
      "Epoch 1 Batch 566 Loss 2.6737\n",
      "Epoch 1 Batch 567 Loss 2.2389\n",
      "Epoch 1 Batch 568 Loss 2.4850\n",
      "Epoch 1 Batch 569 Loss 2.5904\n",
      "Epoch 1 Batch 570 Loss 2.5744\n",
      "Epoch 1 Batch 571 Loss 3.1426\n",
      "Epoch 1 Batch 572 Loss 2.8178\n",
      "Epoch 1 Batch 573 Loss 2.9221\n",
      "Epoch 1 Batch 574 Loss 2.2456\n",
      "Epoch 1 Batch 575 Loss 2.3824\n",
      "Epoch 1 Batch 576 Loss 2.2829\n",
      "Epoch 1 Batch 577 Loss 2.6310\n",
      "Epoch 1 Batch 578 Loss 2.4425\n",
      "Epoch 1 Batch 579 Loss 3.1027\n",
      "Epoch 1 Batch 580 Loss 2.5694\n",
      "Epoch 1 Batch 581 Loss 2.6390\n",
      "Epoch 1 Batch 582 Loss 2.8272\n",
      "Epoch 1 Batch 583 Loss 2.9223\n",
      "Epoch 1 Batch 584 Loss 2.2595\n",
      "Epoch 1 Batch 585 Loss 2.4586\n",
      "Epoch 1 Batch 586 Loss 2.6918\n",
      "Epoch 1 Batch 587 Loss 2.5416\n",
      "Epoch 1 Batch 588 Loss 2.2604\n",
      "Epoch 1 Batch 589 Loss 2.8091\n",
      "Epoch 1 Batch 590 Loss 3.0916\n",
      "Epoch 1 Batch 591 Loss 2.7946\n",
      "Epoch 1 Batch 592 Loss 2.3922\n",
      "Epoch 1 Batch 593 Loss 2.4474\n",
      "Epoch 1 Batch 594 Loss 3.0296\n",
      "Epoch 1 Batch 595 Loss 2.2490\n",
      "Epoch 1 Batch 596 Loss 2.9375\n",
      "Epoch 1 Batch 597 Loss 2.3392\n",
      "Epoch 1 Batch 598 Loss 2.6445\n",
      "Epoch 1 Batch 599 Loss 2.4136\n",
      "Epoch 1 Batch 600 Loss 1.9559\n",
      "Epoch 1 Batch 601 Loss 2.4095\n",
      "Epoch 1 Batch 602 Loss 2.3457\n",
      "Epoch 1 Batch 603 Loss 2.2870\n",
      "Epoch 1 Batch 604 Loss 2.7008\n",
      "Epoch 1 Batch 605 Loss 2.5037\n",
      "Epoch 1 Batch 606 Loss 2.2976\n",
      "Epoch 1 Batch 607 Loss 2.5500\n",
      "Epoch 1 Batch 608 Loss 2.5444\n",
      "Epoch 1 Batch 609 Loss 2.3934\n",
      "Epoch 1 Batch 610 Loss 2.7570\n",
      "Epoch 1 Batch 611 Loss 2.2045\n",
      "Epoch 1 Batch 612 Loss 2.3545\n",
      "Epoch 1 Batch 613 Loss 2.3979\n",
      "Epoch 1 Batch 614 Loss 2.5629\n",
      "Epoch 1 Batch 615 Loss 2.4198\n",
      "Epoch 1 Batch 616 Loss 2.6734\n",
      "Epoch 1 Batch 617 Loss 3.0568\n",
      "Epoch 1 Batch 618 Loss 2.5173\n",
      "Epoch 1 Batch 619 Loss 2.5605\n",
      "Epoch 1 Batch 620 Loss 2.7348\n",
      "Epoch 1 Batch 621 Loss 2.2729\n",
      "Epoch 1 Batch 622 Loss 2.6186\n",
      "Epoch 1 Batch 623 Loss 1.9163\n",
      "Epoch 1 Batch 624 Loss 2.9276\n",
      "Epoch 1 Batch 625 Loss 2.0135\n",
      "Epoch 1 Batch 626 Loss 2.4249\n",
      "Epoch 1 Batch 627 Loss 2.9748\n",
      "Epoch 1 Batch 628 Loss 2.5763\n",
      "Epoch 1 Batch 629 Loss 2.6893\n",
      "Epoch 1 Batch 630 Loss 2.7086\n",
      "Epoch 1 Batch 631 Loss 2.0028\n",
      "Epoch 1 Batch 632 Loss 2.2191\n",
      "Epoch 1 Batch 633 Loss 2.2547\n",
      "Epoch 1 Batch 634 Loss 2.4332\n",
      "Epoch 1 Batch 635 Loss 2.6384\n",
      "Epoch 1 Batch 636 Loss 2.3981\n",
      "Epoch 1 Batch 637 Loss 2.8455\n",
      "Epoch 1 Batch 638 Loss 2.8508\n",
      "Epoch 1 Batch 639 Loss 2.8008\n",
      "Epoch 1 Batch 640 Loss 2.3972\n",
      "Epoch 1 Batch 641 Loss 2.9190\n",
      "Epoch 1 Batch 642 Loss 2.1652\n",
      "Epoch 1 Batch 643 Loss 2.3601\n",
      "Epoch 1 Batch 644 Loss 2.0028\n",
      "Epoch 1 Batch 645 Loss 2.3419\n",
      "Epoch 1 Batch 646 Loss 2.3960\n",
      "Epoch 1 Batch 647 Loss 2.3692\n",
      "Epoch 1 Batch 648 Loss 2.1045\n",
      "Epoch 1 Batch 649 Loss 2.5147\n",
      "Epoch 1 Batch 650 Loss 2.6367\n",
      "Epoch 1 Batch 651 Loss 2.6917\n",
      "Epoch 1 Batch 652 Loss 2.8020\n",
      "Epoch 1 Batch 653 Loss 1.7415\n",
      "Epoch 1 Batch 654 Loss 2.6578\n",
      "Epoch 1 Batch 655 Loss 2.7473\n",
      "Epoch 1 Batch 656 Loss 2.6638\n",
      "Epoch 1 Batch 657 Loss 2.6503\n",
      "Epoch 1 Batch 658 Loss 2.5596\n",
      "Epoch 1 Batch 659 Loss 2.4402\n",
      "Epoch 1 Batch 660 Loss 2.6546\n",
      "Epoch 1 Batch 661 Loss 2.1308\n",
      "Epoch 1 Batch 662 Loss 2.1973\n",
      "Epoch 1 Batch 663 Loss 2.2510\n",
      "Epoch 1 Batch 664 Loss 2.7887\n",
      "Epoch 1 Batch 665 Loss 2.3622\n",
      "Epoch 1 Batch 666 Loss 2.2941\n",
      "Epoch 1 Batch 667 Loss 2.0499\n",
      "Epoch 1 Batch 668 Loss 2.5429\n",
      "Epoch 1 Batch 669 Loss 2.2717\n",
      "Epoch 1 Batch 670 Loss 2.4134\n",
      "Epoch 1 Batch 671 Loss 2.6395\n",
      "Epoch 1 Batch 672 Loss 2.0590\n",
      "Epoch 1 Batch 673 Loss 2.7638\n",
      "Epoch 1 Batch 674 Loss 2.4924\n",
      "Epoch 1 Batch 675 Loss 2.6309\n",
      "Epoch 1 Batch 676 Loss 2.7053\n",
      "Epoch 1 Batch 677 Loss 2.7275\n",
      "Epoch 1 Batch 678 Loss 2.8605\n",
      "Epoch 1 Batch 679 Loss 2.4088\n",
      "Epoch 1 Batch 680 Loss 2.5136\n",
      "Epoch 1 Batch 681 Loss 2.8210\n",
      "Epoch 1 Batch 682 Loss 2.3389\n",
      "Epoch 1 Batch 683 Loss 1.8000\n",
      "Epoch 1 Batch 684 Loss 2.4128\n",
      "Epoch 1 Batch 685 Loss 2.0674\n",
      "Epoch 1 Batch 686 Loss 2.3515\n",
      "Epoch 1 Batch 687 Loss 2.6809\n",
      "Epoch 1 Batch 688 Loss 3.0186\n",
      "Epoch 1 Batch 689 Loss 2.2719\n",
      "Epoch 1 Batch 690 Loss 2.2380\n",
      "Epoch 1 Batch 691 Loss 1.9631\n",
      "Epoch 1 Batch 692 Loss 2.3667\n",
      "Epoch 1 Batch 693 Loss 2.4401\n",
      "Epoch 1 Batch 694 Loss 2.4069\n",
      "Epoch 1 Batch 695 Loss 2.6495\n",
      "Epoch 1 Batch 696 Loss 2.2711\n",
      "Epoch 1 Batch 697 Loss 2.5576\n",
      "Epoch 1 Batch 698 Loss 2.6582\n",
      "Epoch 1 Batch 699 Loss 2.3003\n",
      "Epoch 1 Batch 700 Loss 2.1090\n",
      "Epoch 1 Batch 701 Loss 2.2905\n",
      "Epoch 1 Batch 702 Loss 2.4778\n",
      "Epoch 1 Batch 703 Loss 2.2623\n",
      "Epoch 1 Batch 704 Loss 2.3239\n",
      "Epoch 1 Batch 705 Loss 2.1660\n",
      "Epoch 1 Batch 706 Loss 2.6615\n",
      "Epoch 1 Batch 707 Loss 2.4494\n",
      "Epoch 1 Batch 708 Loss 2.3832\n",
      "Epoch 1 Batch 709 Loss 2.8462\n",
      "Epoch 1 Batch 710 Loss 2.3637\n",
      "Epoch 1 Batch 711 Loss 2.3941\n",
      "Epoch 1 Batch 712 Loss 2.7947\n",
      "Epoch 1 Batch 713 Loss 2.4092\n",
      "Epoch 1 Batch 714 Loss 2.0579\n",
      "Epoch 1 Batch 715 Loss 2.5765\n",
      "Epoch 1 Batch 716 Loss 2.4683\n",
      "Epoch 1 Batch 717 Loss 2.6810\n",
      "Epoch 1 Batch 718 Loss 2.2493\n",
      "Epoch 1 Batch 719 Loss 2.5049\n",
      "Epoch 1 Batch 720 Loss 2.2363\n",
      "Epoch 1 Batch 721 Loss 2.5050\n",
      "Epoch 1 Batch 722 Loss 2.0773\n",
      "Epoch 1 Batch 723 Loss 2.5553\n",
      "Epoch 1 Batch 724 Loss 2.2928\n",
      "Epoch 1 Batch 725 Loss 2.6957\n",
      "Epoch 1 Batch 726 Loss 2.9386\n",
      "Epoch 1 Batch 727 Loss 2.4238\n",
      "Epoch 1 Batch 728 Loss 2.4076\n",
      "Epoch 1 Batch 729 Loss 1.8961\n",
      "Epoch 1 Batch 730 Loss 2.0585\n",
      "Epoch 1 Batch 731 Loss 2.2336\n",
      "Epoch 1 Batch 732 Loss 2.0041\n",
      "Epoch 1 Batch 733 Loss 2.1291\n",
      "Epoch 1 Batch 734 Loss 2.5879\n",
      "Epoch 1 Batch 735 Loss 2.3974\n",
      "Epoch 1 Batch 736 Loss 2.2247\n",
      "Epoch 1 Batch 737 Loss 2.1589\n",
      "Epoch 1 Batch 738 Loss 2.4496\n",
      "Epoch 1 Batch 739 Loss 2.3228\n",
      "Epoch 1 Batch 740 Loss 2.0103\n",
      "Epoch 1 Batch 741 Loss 2.1667\n",
      "Epoch 1 Batch 742 Loss 2.5941\n",
      "Epoch 1 Batch 743 Loss 2.1121\n",
      "Epoch 1 Batch 744 Loss 2.3407\n",
      "Epoch 1 Batch 745 Loss 2.6005\n",
      "Epoch 1 Batch 746 Loss 2.4794\n",
      "Epoch 1 Batch 747 Loss 2.6063\n",
      "Epoch 1 Batch 748 Loss 2.1009\n",
      "Epoch 1 Batch 749 Loss 2.5833\n",
      "Epoch 1 Batch 750 Loss 2.4133\n",
      "Epoch 1 Batch 751 Loss 2.3048\n",
      "Epoch 1 Batch 752 Loss 2.1994\n",
      "Epoch 1 Batch 753 Loss 2.4159\n",
      "Epoch 1 Batch 754 Loss 2.3443\n",
      "Epoch 1 Batch 755 Loss 2.2829\n",
      "Epoch 1 Batch 756 Loss 2.4556\n",
      "Epoch 1 Batch 757 Loss 2.1030\n",
      "Epoch 1 Batch 758 Loss 2.7908\n",
      "Epoch 1 Batch 759 Loss 2.4549\n",
      "Epoch 1 Batch 760 Loss 2.2385\n",
      "Epoch 1 Batch 761 Loss 2.2165\n",
      "Epoch 1 Batch 762 Loss 2.3856\n",
      "Epoch 1 Batch 763 Loss 2.5815\n",
      "Epoch 1 Batch 764 Loss 2.4369\n",
      "Epoch 1 Batch 765 Loss 2.3490\n",
      "Epoch 1 Batch 766 Loss 2.5389\n",
      "Epoch 1 Batch 767 Loss 2.1587\n",
      "Epoch 1 Batch 768 Loss 2.7779\n",
      "Epoch 1 Batch 769 Loss 2.0106\n",
      "Epoch 1 Batch 770 Loss 2.1958\n",
      "Epoch 1 Batch 771 Loss 2.7127\n",
      "Epoch 1 Batch 772 Loss 2.3091\n",
      "Epoch 1 Batch 773 Loss 2.0314\n",
      "Epoch 1 Batch 774 Loss 1.9639\n",
      "Epoch 1 Batch 775 Loss 2.2690\n",
      "Epoch 1 Batch 776 Loss 2.4082\n",
      "Epoch 1 Batch 777 Loss 2.2656\n",
      "Epoch 1 Batch 778 Loss 2.5129\n",
      "Epoch 1 Batch 779 Loss 2.5070\n",
      "Epoch 1 Batch 780 Loss 2.4077\n",
      "Epoch 1 Batch 781 Loss 2.7228\n",
      "Epoch 1 Batch 782 Loss 2.5887\n",
      "Epoch 1 Batch 783 Loss 2.6255\n",
      "Epoch 1 Batch 784 Loss 2.5856\n",
      "Epoch 1 Batch 785 Loss 2.3107\n",
      "Epoch 1 Batch 786 Loss 2.1567\n",
      "Epoch 1 Batch 787 Loss 2.3049\n",
      "Epoch 1 Batch 788 Loss 2.4240\n",
      "Epoch 1 Batch 789 Loss 2.3319\n",
      "Epoch 1 Batch 790 Loss 2.6514\n",
      "Epoch 1 Batch 791 Loss 2.5939\n",
      "Epoch 1 Batch 792 Loss 2.0759\n",
      "Epoch 1 Batch 793 Loss 2.3069\n",
      "Epoch 1 Batch 794 Loss 2.3111\n",
      "Epoch 1 Batch 795 Loss 2.4346\n",
      "Epoch 1 Batch 796 Loss 2.3904\n",
      "Epoch 1 Batch 797 Loss 2.0894\n",
      "Epoch 1 Batch 798 Loss 2.7032\n",
      "Epoch 1 Batch 799 Loss 2.2991\n",
      "Epoch 1 Batch 800 Loss 2.7671\n",
      "Epoch 1 Batch 801 Loss 2.1419\n",
      "Epoch 1 Batch 802 Loss 1.8520\n",
      "Epoch 1 Batch 803 Loss 1.9825\n",
      "Epoch 1 Batch 804 Loss 2.1881\n",
      "Epoch 1 Batch 805 Loss 2.5382\n",
      "Epoch 1 Batch 806 Loss 2.3030\n",
      "Epoch 1 Batch 807 Loss 2.5531\n",
      "Epoch 1 Batch 808 Loss 2.5142\n",
      "Epoch 1 Batch 809 Loss 2.4433\n",
      "Epoch 1 Batch 810 Loss 2.3412\n",
      "Epoch 1 Batch 811 Loss 2.3951\n",
      "Epoch 1 Batch 812 Loss 1.6568\n",
      "Epoch 1 Batch 813 Loss 2.7621\n",
      "Epoch 1 Batch 814 Loss 2.3120\n",
      "Epoch 1 Batch 815 Loss 2.1106\n",
      "Epoch 1 Batch 816 Loss 2.1312\n",
      "Epoch 1 Batch 817 Loss 2.1880\n",
      "Epoch 1 Batch 818 Loss 2.5123\n",
      "Epoch 1 Batch 819 Loss 2.1267\n",
      "Epoch 1 Batch 820 Loss 2.1004\n",
      "Epoch 1 Batch 821 Loss 2.4827\n",
      "Epoch 1 Batch 822 Loss 2.7898\n",
      "Epoch 1 Batch 823 Loss 2.1638\n",
      "Epoch 1 Batch 824 Loss 1.7146\n",
      "Epoch 1 Batch 825 Loss 2.1700\n",
      "Epoch 1 Batch 826 Loss 2.3414\n",
      "Epoch 1 Batch 827 Loss 2.4363\n",
      "Epoch 1 Batch 828 Loss 2.6497\n",
      "Epoch 1 Batch 829 Loss 2.3800\n",
      "Epoch 1 Batch 830 Loss 2.6298\n",
      "Epoch 1 Batch 831 Loss 2.0541\n",
      "Epoch 1 Batch 832 Loss 2.0439\n",
      "Epoch 1 Batch 833 Loss 2.5016\n",
      "Epoch 1 Batch 834 Loss 2.4006\n",
      "Epoch 1 Batch 835 Loss 2.4043\n",
      "Epoch 1 Batch 836 Loss 1.8431\n",
      "Epoch 1 Batch 837 Loss 2.5218\n",
      "Epoch 1 Batch 838 Loss 1.9761\n",
      "Epoch 1 Batch 839 Loss 2.8132\n",
      "Epoch 1 Batch 840 Loss 2.8300\n",
      "Epoch 1 Batch 841 Loss 2.2169\n",
      "Epoch 1 Batch 842 Loss 1.9750\n",
      "Epoch 1 Batch 843 Loss 2.2340\n",
      "Epoch 1 Batch 844 Loss 2.2291\n",
      "Epoch 1 Batch 845 Loss 2.3820\n",
      "Epoch 1 Batch 846 Loss 2.1417\n",
      "Epoch 1 Batch 847 Loss 2.2788\n",
      "Epoch 1 Batch 848 Loss 2.3791\n",
      "Epoch 1 Batch 849 Loss 2.0040\n",
      "Epoch 1 Batch 850 Loss 2.2089\n",
      "Epoch 1 Batch 851 Loss 1.9216\n",
      "Epoch 1 Batch 852 Loss 2.4112\n",
      "Epoch 1 Batch 853 Loss 2.2699\n",
      "Epoch 1 Batch 854 Loss 1.9511\n",
      "Epoch 1 Batch 855 Loss 1.8601\n",
      "Epoch 1 Batch 856 Loss 2.3252\n",
      "Epoch 1 Batch 857 Loss 1.7770\n",
      "Epoch 1 Batch 858 Loss 2.3113\n",
      "Epoch 1 Batch 859 Loss 2.1124\n",
      "Epoch 1 Batch 860 Loss 1.6982\n",
      "Epoch 1 Batch 861 Loss 2.2224\n",
      "Epoch 1 Batch 862 Loss 1.8803\n",
      "Epoch 1 Batch 863 Loss 2.4675\n",
      "Epoch 1 Batch 864 Loss 2.0287\n",
      "Epoch 1 Batch 865 Loss 2.4342\n",
      "Epoch 1 Batch 866 Loss 2.2786\n",
      "Epoch 1 Batch 867 Loss 2.2648\n",
      "Epoch 1 Batch 868 Loss 1.8934\n",
      "Epoch 1 Batch 869 Loss 2.3401\n",
      "Epoch 1 Batch 870 Loss 2.4016\n",
      "Epoch 1 Batch 871 Loss 2.0658\n",
      "Epoch 1 Batch 872 Loss 2.0833\n",
      "Epoch 1 Batch 873 Loss 2.1261\n",
      "Epoch 1 Batch 874 Loss 2.3938\n",
      "Epoch 1 Batch 875 Loss 2.2478\n",
      "Epoch 1 Batch 876 Loss 1.9796\n",
      "Epoch 1 Batch 877 Loss 2.3634\n",
      "Epoch 1 Batch 878 Loss 2.0446\n",
      "Epoch 1 Batch 879 Loss 1.9000\n",
      "Epoch 1 Batch 880 Loss 2.3426\n",
      "Epoch 1 Batch 881 Loss 2.2342\n",
      "Epoch 1 Batch 882 Loss 1.7933\n",
      "Epoch 1 Batch 883 Loss 2.2756\n",
      "Epoch 1 Batch 884 Loss 2.0702\n",
      "Epoch 1 Batch 885 Loss 2.1625\n",
      "Epoch 1 Batch 886 Loss 2.0651\n",
      "Epoch 1 Batch 887 Loss 2.3466\n",
      "Epoch 1 Batch 888 Loss 2.2345\n",
      "Epoch 1 Batch 889 Loss 1.8764\n",
      "Epoch 1 Batch 890 Loss 1.9920\n",
      "Epoch 1 Batch 891 Loss 2.5764\n",
      "Epoch 1 Batch 892 Loss 2.4867\n",
      "Epoch 1 Batch 893 Loss 2.3430\n",
      "Epoch 1 Batch 894 Loss 2.0003\n",
      "Epoch 1 Batch 895 Loss 1.7629\n",
      "Epoch 1 Batch 896 Loss 2.4124\n",
      "Epoch 1 Batch 897 Loss 2.0423\n",
      "Epoch 1 Batch 898 Loss 2.4510\n",
      "Epoch 1 Batch 899 Loss 1.8319\n",
      "Epoch 1 Batch 900 Loss 1.8249\n",
      "Epoch 1 Batch 901 Loss 2.2898\n",
      "Epoch 1 Batch 902 Loss 2.3903\n",
      "Epoch 1 Batch 903 Loss 2.1488\n",
      "Epoch 1 Batch 904 Loss 2.4234\n",
      "Epoch 1 Batch 905 Loss 1.9408\n",
      "Epoch 1 Batch 906 Loss 1.9204\n",
      "Epoch 1 Batch 907 Loss 2.1814\n",
      "Epoch 1 Batch 908 Loss 2.0080\n",
      "Epoch 1 Batch 909 Loss 1.8480\n",
      "Epoch 1 Batch 910 Loss 1.8680\n",
      "Epoch 1 Batch 911 Loss 2.0442\n",
      "Epoch 1 Batch 912 Loss 1.9278\n",
      "Epoch 1 Batch 913 Loss 2.2124\n",
      "Epoch 1 Batch 914 Loss 1.5226\n",
      "Epoch 1 Batch 915 Loss 2.3260\n",
      "Epoch 1 Batch 916 Loss 2.2452\n",
      "Epoch 1 Batch 917 Loss 2.0903\n",
      "Epoch 1 Batch 918 Loss 2.3057\n",
      "Epoch 1 Batch 919 Loss 2.3304\n",
      "Epoch 1 Batch 920 Loss 2.4251\n",
      "Epoch 1 Batch 921 Loss 2.0540\n",
      "Epoch 1 Batch 922 Loss 2.2587\n",
      "Epoch 1 Batch 923 Loss 2.1648\n",
      "Epoch 1 Batch 924 Loss 2.3427\n",
      "Epoch 1 Batch 925 Loss 2.0660\n",
      "Epoch 1 Batch 926 Loss 1.9730\n",
      "Epoch 1 Batch 927 Loss 2.2404\n",
      "Epoch 1 Batch 928 Loss 2.2462\n",
      "Epoch 1 Batch 929 Loss 2.4085\n",
      "Epoch 1 Batch 930 Loss 2.0221\n",
      "Epoch 1 Batch 931 Loss 2.3746\n",
      "Epoch 1 Batch 932 Loss 2.1387\n",
      "Epoch 1 Batch 933 Loss 1.8806\n",
      "Epoch 1 Batch 934 Loss 1.6484\n",
      "Epoch 1 Batch 935 Loss 2.2077\n",
      "Epoch 1 Batch 936 Loss 2.1251\n",
      "Epoch 1 Batch 937 Loss 2.1767\n",
      "Epoch 1 Batch 938 Loss 2.3084\n",
      "Epoch 1 Batch 939 Loss 2.0711\n",
      "Epoch 1 Batch 940 Loss 2.0698\n",
      "Epoch 1 Batch 941 Loss 2.4191\n",
      "Epoch 1 Batch 942 Loss 1.9352\n",
      "Epoch 1 Batch 943 Loss 1.9660\n",
      "Epoch 1 Batch 944 Loss 2.1548\n",
      "Epoch 1 Batch 945 Loss 1.9680\n",
      "Epoch 1 Batch 946 Loss 2.3994\n",
      "Epoch 1 Batch 947 Loss 1.9708\n",
      "Epoch 1 Batch 948 Loss 1.6314\n",
      "Epoch 1 Batch 949 Loss 2.2816\n",
      "Epoch 1 Batch 950 Loss 2.1003\n",
      "Epoch 1 Batch 951 Loss 2.3938\n",
      "Epoch 1 Batch 952 Loss 2.2996\n",
      "Epoch 1 Batch 953 Loss 2.3447\n",
      "Epoch 1 Batch 954 Loss 2.0467\n",
      "Epoch 1 Batch 955 Loss 1.7511\n",
      "Epoch 1 Batch 956 Loss 1.8599\n",
      "Epoch 1 Batch 957 Loss 2.4067\n",
      "Epoch 1 Batch 958 Loss 2.0855\n",
      "Epoch 1 Batch 959 Loss 2.0817\n",
      "Epoch 1 Batch 960 Loss 2.3888\n",
      "Epoch 1 Batch 961 Loss 2.3637\n",
      "Epoch 1 Batch 962 Loss 2.0829\n",
      "Epoch 1 Batch 963 Loss 2.0769\n",
      "Epoch 1 Batch 964 Loss 2.2599\n",
      "Epoch 1 Batch 965 Loss 2.2468\n",
      "Epoch 1 Batch 966 Loss 2.4214\n",
      "Epoch 1 Batch 967 Loss 2.3396\n",
      "Epoch 1 Batch 968 Loss 1.9161\n",
      "Epoch 1 Batch 969 Loss 2.3593\n",
      "Epoch 1 Batch 970 Loss 2.0879\n",
      "Epoch 1 Batch 971 Loss 2.0769\n",
      "Epoch 1 Batch 972 Loss 1.7067\n",
      "Epoch 1 Batch 973 Loss 2.0532\n",
      "Epoch 1 Batch 974 Loss 1.8967\n",
      "Epoch 1 Batch 975 Loss 2.3629\n",
      "Epoch 1 Batch 976 Loss 2.0218\n",
      "Epoch 1 Batch 977 Loss 2.2009\n",
      "Epoch 1 Batch 978 Loss 1.8454\n",
      "Epoch 1 Batch 979 Loss 1.7375\n",
      "Epoch 1 Batch 980 Loss 1.8265\n",
      "Epoch 1 Batch 981 Loss 2.2500\n",
      "Epoch 1 Batch 982 Loss 2.3855\n",
      "Epoch 1 Batch 983 Loss 2.1966\n",
      "Epoch 1 Batch 984 Loss 2.4768\n",
      "Epoch 1 Batch 985 Loss 2.0691\n",
      "Epoch 1 Batch 986 Loss 1.6951\n",
      "Epoch 1 Batch 987 Loss 2.2272\n",
      "Epoch 1 Batch 988 Loss 2.3772\n",
      "Epoch 1 Batch 989 Loss 2.1683\n",
      "Epoch 1 Batch 990 Loss 2.3322\n",
      "Epoch 1 Batch 991 Loss 1.9706\n",
      "Epoch 1 Batch 992 Loss 2.0752\n",
      "Epoch 1 Batch 993 Loss 1.8689\n",
      "Epoch 1 Batch 994 Loss 1.6853\n",
      "Epoch 1 Batch 995 Loss 2.0223\n",
      "Epoch 1 Batch 996 Loss 2.0920\n",
      "Epoch 1 Batch 997 Loss 1.8530\n",
      "Epoch 1 Batch 998 Loss 2.4027\n",
      "Epoch 1 Batch 999 Loss 1.9536\n",
      "Epoch 1 Batch 1000 Loss 1.5357\n",
      "Epoch 1 Batch 1001 Loss 2.2289\n",
      "Epoch 1 Batch 1002 Loss 2.1580\n",
      "Epoch 1 Batch 1003 Loss 2.0679\n",
      "Epoch 1 Batch 1004 Loss 1.6702\n",
      "Epoch 1 Batch 1005 Loss 2.2845\n",
      "Epoch 1 Batch 1006 Loss 2.3666\n",
      "Epoch 1 Batch 1007 Loss 2.3249\n",
      "Epoch 1 Batch 1008 Loss 2.2718\n",
      "Epoch 1 Batch 1009 Loss 1.7796\n",
      "Epoch 1 Batch 1010 Loss 2.0956\n",
      "Epoch 1 Batch 1011 Loss 2.4683\n",
      "Epoch 1 Batch 1012 Loss 1.8948\n",
      "Epoch 1 Batch 1013 Loss 2.0887\n",
      "Epoch 1 Batch 1014 Loss 1.9480\n",
      "Epoch 1 Batch 1015 Loss 1.9268\n",
      "Epoch 1 Batch 1016 Loss 1.8364\n",
      "Epoch 1 Batch 1017 Loss 1.8909\n",
      "Epoch 1 Batch 1018 Loss 2.2215\n",
      "Epoch 1 Batch 1019 Loss 1.9588\n",
      "Epoch 1 Batch 1020 Loss 2.1067\n",
      "Epoch 1 Batch 1021 Loss 1.9765\n",
      "Epoch 1 Batch 1022 Loss 2.1581\n",
      "Epoch 1 Batch 1023 Loss 1.9113\n",
      "Epoch 1 Batch 1024 Loss 1.9298\n",
      "Epoch 1 Batch 1025 Loss 2.1255\n",
      "Epoch 1 Batch 1026 Loss 2.0000\n",
      "Epoch 1 Batch 1027 Loss 1.8664\n",
      "Epoch 1 Batch 1028 Loss 2.0633\n",
      "Epoch 1 Batch 1029 Loss 2.2504\n",
      "Epoch 1 Batch 1030 Loss 2.2727\n",
      "Epoch 1 Batch 1031 Loss 2.3681\n",
      "Epoch 1 Batch 1032 Loss 2.0932\n",
      "Epoch 1 Batch 1033 Loss 1.9168\n",
      "Epoch 1 Batch 1034 Loss 2.4548\n",
      "Epoch 1 Batch 1035 Loss 2.3045\n",
      "Epoch 1 Batch 1036 Loss 2.1494\n",
      "Epoch 1 Batch 1037 Loss 1.9586\n",
      "Epoch 1 Batch 1038 Loss 2.0360\n",
      "Epoch 1 Batch 1039 Loss 2.0935\n",
      "Epoch 1 Batch 1040 Loss 2.1925\n",
      "Epoch 1 Batch 1041 Loss 2.1726\n",
      "Epoch 1 Batch 1042 Loss 2.0313\n",
      "Epoch 1 Batch 1043 Loss 2.5645\n",
      "Epoch 1 Batch 1044 Loss 2.0419\n",
      "Epoch 1 Batch 1045 Loss 2.0151\n",
      "Epoch 1 Batch 1046 Loss 2.3579\n",
      "Epoch 1 Batch 1047 Loss 2.1247\n",
      "Epoch 1 Batch 1048 Loss 1.8727\n",
      "Epoch 1 Batch 1049 Loss 1.9954\n",
      "Epoch 1 Batch 1050 Loss 1.9410\n",
      "Epoch 1 Batch 1051 Loss 2.3779\n",
      "Epoch 1 Batch 1052 Loss 1.7417\n",
      "Epoch 1 Batch 1053 Loss 1.9893\n",
      "Epoch 1 Batch 1054 Loss 1.9323\n",
      "Epoch 1 Batch 1055 Loss 2.0808\n",
      "Epoch 1 Batch 1056 Loss 1.9003\n",
      "Epoch 1 Batch 1057 Loss 2.0045\n",
      "Epoch 1 Batch 1058 Loss 2.3639\n",
      "Epoch 1 Batch 1059 Loss 2.0397\n",
      "Epoch 1 Batch 1060 Loss 2.3139\n",
      "Epoch 1 Batch 1061 Loss 2.1812\n",
      "Epoch 1 Batch 1062 Loss 2.1176\n",
      "Epoch 1 Batch 1063 Loss 2.0773\n",
      "Epoch 1 Batch 1064 Loss 1.8760\n",
      "Epoch 1 Batch 1065 Loss 2.6746\n",
      "Epoch 1 Batch 1066 Loss 2.0162\n",
      "Epoch 1 Batch 1067 Loss 2.0065\n",
      "Epoch 1 Batch 1068 Loss 1.9438\n",
      "Epoch 1 Batch 1069 Loss 1.7450\n",
      "Epoch 1 Batch 1070 Loss 2.1692\n",
      "Epoch 1 Batch 1071 Loss 1.9500\n",
      "Epoch 1 Batch 1072 Loss 1.9620\n",
      "Epoch 1 Batch 1073 Loss 1.9289\n",
      "Epoch 1 Batch 1074 Loss 2.0647\n",
      "Epoch 1 Batch 1075 Loss 2.0083\n",
      "Epoch 1 Batch 1076 Loss 2.2923\n",
      "Epoch 1 Batch 1077 Loss 1.8489\n",
      "Epoch 1 Batch 1078 Loss 1.7001\n",
      "Epoch 1 Batch 1079 Loss 1.9141\n",
      "Epoch 1 Batch 1080 Loss 2.0946\n",
      "Epoch 1 Batch 1081 Loss 1.8419\n",
      "Epoch 1 Batch 1082 Loss 2.0804\n",
      "Epoch 1 Batch 1083 Loss 1.9365\n",
      "Epoch 1 Batch 1084 Loss 2.3751\n",
      "Epoch 1 Batch 1085 Loss 1.7961\n",
      "Epoch 1 Batch 1086 Loss 1.9662\n",
      "Epoch 1 Batch 1087 Loss 2.0030\n",
      "Epoch 1 Batch 1088 Loss 2.4917\n",
      "Epoch 1 Batch 1089 Loss 1.6982\n",
      "Epoch 1 Batch 1090 Loss 2.1492\n",
      "Epoch 1 Batch 1091 Loss 2.0960\n",
      "Epoch 1 Batch 1092 Loss 1.8913\n",
      "Epoch 1 Batch 1093 Loss 1.9824\n",
      "Epoch 1 Batch 1094 Loss 2.0678\n",
      "Epoch 1 Batch 1095 Loss 1.8693\n",
      "Epoch 1 Batch 1096 Loss 2.2095\n",
      "Epoch 1 Batch 1097 Loss 2.1698\n",
      "Epoch 1 Batch 1098 Loss 2.2361\n",
      "Epoch 1 Batch 1099 Loss 2.0297\n",
      "Epoch 1 Batch 1100 Loss 1.8307\n",
      "Epoch 1 Batch 1101 Loss 2.2703\n",
      "Epoch 1 Batch 1102 Loss 2.0739\n",
      "Epoch 1 Batch 1103 Loss 2.1414\n",
      "Epoch 1 Batch 1104 Loss 1.6719\n",
      "Epoch 1 Batch 1105 Loss 2.1402\n",
      "Epoch 1 Batch 1106 Loss 1.8039\n",
      "Epoch 1 Batch 1107 Loss 1.5251\n",
      "Epoch 1 Batch 1108 Loss 1.7437\n",
      "Epoch 1 Batch 1109 Loss 2.2388\n",
      "Epoch 1 Batch 1110 Loss 1.7865\n",
      "Epoch 1 Batch 1111 Loss 1.9862\n",
      "Epoch 1 Batch 1112 Loss 1.4724\n",
      "Epoch 1 Batch 1113 Loss 1.7778\n",
      "Epoch 1 Batch 1114 Loss 1.8186\n",
      "Epoch 1 Batch 1115 Loss 2.0145\n",
      "Epoch 1 Batch 1116 Loss 2.0709\n",
      "Epoch 1 Batch 1117 Loss 1.8132\n",
      "Epoch 1 Batch 1118 Loss 2.3216\n",
      "Epoch 1 Batch 1119 Loss 2.0368\n",
      "Epoch 1 Batch 1120 Loss 1.5770\n",
      "Epoch 1 Batch 1121 Loss 2.1411\n",
      "Epoch 1 Batch 1122 Loss 1.9230\n",
      "Epoch 1 Batch 1123 Loss 2.0015\n",
      "Epoch 1 Batch 1124 Loss 1.9967\n",
      "Epoch 1 Batch 1125 Loss 2.4845\n",
      "Epoch 1 Batch 1126 Loss 1.6564\n",
      "Epoch 1 Batch 1127 Loss 2.1398\n",
      "Epoch 1 Batch 1128 Loss 1.9366\n",
      "Epoch 1 Batch 1129 Loss 2.0722\n",
      "Epoch 1 Batch 1130 Loss 2.2369\n",
      "Epoch 1 Batch 1131 Loss 1.7845\n",
      "Epoch 1 Batch 1132 Loss 2.2736\n",
      "Epoch 1 Batch 1133 Loss 2.0880\n",
      "Epoch 1 Batch 1134 Loss 1.9256\n",
      "Epoch 1 Batch 1135 Loss 1.6455\n",
      "Epoch 1 Batch 1136 Loss 1.8301\n",
      "Epoch 1 Batch 1137 Loss 1.9382\n",
      "Epoch 1 Batch 1138 Loss 2.0709\n",
      "Epoch 1 Batch 1139 Loss 2.1316\n",
      "Epoch 1 Batch 1140 Loss 2.0007\n",
      "Epoch 1 Batch 1141 Loss 2.1657\n",
      "Epoch 1 Batch 1142 Loss 1.8587\n",
      "Epoch 1 Batch 1143 Loss 1.4787\n",
      "Epoch 1 Batch 1144 Loss 1.6074\n",
      "Epoch 1 Batch 1145 Loss 1.9484\n",
      "Epoch 1 Batch 1146 Loss 1.6821\n",
      "Epoch 1 Batch 1147 Loss 2.0595\n",
      "Epoch 1 Batch 1148 Loss 1.7168\n",
      "Epoch 1 Batch 1149 Loss 1.7923\n",
      "Epoch 1 Batch 1150 Loss 2.1229\n",
      "Epoch 1 Batch 1151 Loss 2.2671\n",
      "Epoch 1 Batch 1152 Loss 2.0057\n",
      "Epoch 1 Batch 1153 Loss 2.0984\n",
      "Epoch 1 Batch 1154 Loss 1.8337\n",
      "Epoch 1 Batch 1155 Loss 2.2242\n",
      "Epoch 1 Batch 1156 Loss 1.8522\n",
      "Epoch 1 Batch 1157 Loss 2.0542\n",
      "Epoch 1 Batch 1158 Loss 1.9092\n",
      "Epoch 1 Batch 1159 Loss 1.5184\n",
      "Epoch 1 Batch 1160 Loss 1.5910\n",
      "Epoch 1 Batch 1161 Loss 2.3671\n",
      "Epoch 1 Batch 1162 Loss 2.0702\n",
      "Epoch 1 Batch 1163 Loss 1.9679\n",
      "Epoch 1 Batch 1164 Loss 2.1222\n",
      "Epoch 1 Batch 1165 Loss 2.0258\n",
      "Epoch 1 Batch 1166 Loss 2.1051\n",
      "Epoch 1 Batch 1167 Loss 1.7927\n",
      "Epoch 1 Batch 1168 Loss 2.1376\n",
      "Epoch 1 Batch 1169 Loss 2.0364\n",
      "Epoch 1 Batch 1170 Loss 2.0343\n",
      "Epoch 1 Batch 1171 Loss 1.7762\n",
      "Epoch 1 Batch 1172 Loss 2.4020\n",
      "Epoch 1 Batch 1173 Loss 1.8651\n",
      "Epoch 1 Batch 1174 Loss 1.4545\n",
      "Epoch 1 Batch 1175 Loss 1.8327\n",
      "Epoch 1 Batch 1176 Loss 2.0595\n",
      "Epoch 1 Batch 1177 Loss 1.9463\n",
      "Epoch 1 Batch 1178 Loss 2.2932\n",
      "Epoch 1 Batch 1179 Loss 1.6247\n",
      "Epoch 1 Batch 1180 Loss 1.6308\n",
      "Epoch 1 Batch 1181 Loss 2.5376\n",
      "Epoch 1 Batch 1182 Loss 2.0885\n",
      "Epoch 1 Batch 1183 Loss 2.1113\n",
      "Epoch 1 Batch 1184 Loss 1.9729\n",
      "Epoch 1 Batch 1185 Loss 2.1229\n",
      "Epoch 1 Batch 1186 Loss 1.5993\n",
      "Epoch 1 Batch 1187 Loss 2.2590\n",
      "Epoch 1 Batch 1188 Loss 2.4249\n",
      "Epoch 1 Batch 1189 Loss 1.7088\n",
      "Epoch 1 Batch 1190 Loss 1.7301\n",
      "Epoch 1 Batch 1191 Loss 1.8401\n",
      "Epoch 1 Batch 1192 Loss 2.0066\n",
      "Epoch 1 Batch 1193 Loss 1.7192\n",
      "Epoch 1 Batch 1194 Loss 2.1755\n",
      "Epoch 1 Batch 1195 Loss 1.7297\n",
      "Epoch 1 Batch 1196 Loss 1.9465\n",
      "Epoch 1 Batch 1197 Loss 2.0491\n",
      "Epoch 1 Batch 1198 Loss 1.9609\n",
      "Epoch 1 Batch 1199 Loss 1.9743\n",
      "Epoch 1 Batch 1200 Loss 1.8605\n",
      "Epoch 1 Batch 1201 Loss 1.7567\n",
      "Epoch 1 Batch 1202 Loss 1.8102\n",
      "Epoch 1 Batch 1203 Loss 2.2195\n",
      "Epoch 1 Batch 1204 Loss 1.7212\n",
      "Epoch 1 Batch 1205 Loss 1.7142\n",
      "Epoch 1 Batch 1206 Loss 2.0404\n",
      "Epoch 1 Batch 1207 Loss 1.9645\n",
      "Epoch 1 Batch 1208 Loss 1.9230\n",
      "Epoch 1 Batch 1209 Loss 1.9264\n",
      "Epoch 1 Batch 1210 Loss 2.1974\n",
      "Epoch 1 Batch 1211 Loss 1.6293\n",
      "Epoch 1 Batch 1212 Loss 1.8199\n",
      "Epoch 1 Batch 1213 Loss 2.3980\n",
      "Epoch 1 Batch 1214 Loss 2.1395\n",
      "Epoch 1 Batch 1215 Loss 1.8184\n",
      "Epoch 1 Batch 1216 Loss 1.9851\n",
      "Epoch 1 Batch 1217 Loss 1.7420\n",
      "Epoch 1 Batch 1218 Loss 1.9111\n",
      "Epoch 1 Batch 1219 Loss 1.9570\n",
      "Epoch 1 Batch 1220 Loss 1.8941\n",
      "Epoch 1 Batch 1221 Loss 1.9332\n",
      "Epoch 1 Batch 1222 Loss 1.9172\n",
      "Epoch 1 Batch 1223 Loss 2.1413\n",
      "Epoch 1 Batch 1224 Loss 1.9813\n",
      "Epoch 1 Batch 1225 Loss 1.9981\n",
      "Epoch 1 Batch 1226 Loss 1.8273\n",
      "Epoch 1 Batch 1227 Loss 1.8619\n",
      "Epoch 1 Batch 1228 Loss 1.3479\n",
      "Epoch 1 Batch 1229 Loss 1.8582\n",
      "Epoch 1 Batch 1230 Loss 1.7553\n",
      "Epoch 1 Batch 1231 Loss 1.8274\n",
      "Epoch 1 Batch 1232 Loss 2.0586\n",
      "Epoch 1 Batch 1233 Loss 1.5542\n",
      "Epoch 1 Batch 1234 Loss 2.0531\n",
      "Epoch 1 Batch 1235 Loss 1.8891\n",
      "Epoch 1 Batch 1236 Loss 1.7585\n",
      "Epoch 1 Batch 1237 Loss 2.2213\n",
      "Epoch 1 Batch 1238 Loss 2.3468\n",
      "Epoch 1 Batch 1239 Loss 1.6899\n",
      "Epoch 1 Batch 1240 Loss 2.1018\n",
      "Epoch 1 Batch 1241 Loss 2.3006\n",
      "Epoch 1 Batch 1242 Loss 2.0837\n",
      "Epoch 1 Batch 1243 Loss 2.3491\n",
      "Epoch 1 Batch 1244 Loss 1.6093\n",
      "Epoch 1 Batch 1245 Loss 1.5043\n",
      "Epoch 1 Batch 1246 Loss 1.7477\n",
      "Epoch 1 Batch 1247 Loss 1.8279\n",
      "Epoch 1 Batch 1248 Loss 1.9068\n",
      "Epoch 1 Batch 1249 Loss 1.8526\n",
      "Epoch 1 Batch 1250 Loss 1.9850\n",
      "Epoch 1 Batch 1251 Loss 1.8010\n",
      "Epoch 1 Batch 1252 Loss 1.6870\n",
      "Epoch 1 Batch 1253 Loss 2.1541\n",
      "Epoch 1 Batch 1254 Loss 1.9227\n",
      "Epoch 1 Batch 1255 Loss 1.6938\n",
      "Epoch 1 Batch 1256 Loss 1.8464\n",
      "Epoch 1 Batch 1257 Loss 2.4281\n",
      "Epoch 1 Batch 1258 Loss 2.2324\n",
      "Epoch 1 Batch 1259 Loss 2.1493\n",
      "Epoch 1 Batch 1260 Loss 1.6325\n",
      "Epoch 1 Batch 1261 Loss 2.0561\n",
      "Epoch 1 Batch 1262 Loss 1.8920\n",
      "Epoch 1 Batch 1263 Loss 2.0624\n",
      "Epoch 1 Batch 1264 Loss 1.9927\n",
      "Epoch 1 Batch 1265 Loss 2.2793\n",
      "Epoch 1 Batch 1266 Loss 1.6591\n",
      "Epoch 1 Batch 1267 Loss 2.1240\n",
      "Epoch 1 Batch 1268 Loss 1.2228\n",
      "Epoch 1 Batch 1269 Loss 1.7966\n",
      "Epoch 1 Batch 1270 Loss 1.6304\n",
      "Epoch 1 Batch 1271 Loss 1.6650\n",
      "Epoch 1 Batch 1272 Loss 1.9224\n",
      "Epoch 1 Batch 1273 Loss 1.6543\n",
      "Epoch 1 Batch 1274 Loss 1.8835\n",
      "Epoch 1 Batch 1275 Loss 1.8763\n",
      "Epoch 1 Batch 1276 Loss 1.9438\n",
      "Epoch 1 Batch 1277 Loss 2.0306\n",
      "Epoch 1 Batch 1278 Loss 1.8287\n",
      "Epoch 1 Batch 1279 Loss 2.2944\n",
      "Epoch 1 Batch 1280 Loss 2.0275\n",
      "Epoch 1 Batch 1281 Loss 1.4646\n",
      "Epoch 1 Batch 1282 Loss 2.2500\n",
      "Epoch 1 Batch 1283 Loss 1.6454\n",
      "Epoch 1 Batch 1284 Loss 1.8126\n",
      "Epoch 1 Batch 1285 Loss 1.4419\n",
      "Epoch 1 Batch 1286 Loss 1.8840\n",
      "Epoch 1 Batch 1287 Loss 1.7480\n",
      "Epoch 1 Batch 1288 Loss 2.1297\n",
      "Epoch 1 Batch 1289 Loss 1.8577\n",
      "Epoch 1 Batch 1290 Loss 1.8665\n",
      "Epoch 1 Batch 1291 Loss 1.7374\n",
      "Epoch 1 Batch 1292 Loss 1.5130\n",
      "Epoch 1 Batch 1293 Loss 1.7672\n",
      "Epoch 1 Batch 1294 Loss 2.1230\n",
      "Epoch 1 Batch 1295 Loss 2.2993\n",
      "Epoch 1 Batch 1296 Loss 1.9261\n",
      "Epoch 1 Batch 1297 Loss 1.8017\n",
      "Epoch 1 Batch 1298 Loss 1.9788\n",
      "Epoch 1 Batch 1299 Loss 1.7880\n",
      "Epoch 1 Batch 1300 Loss 2.4219\n",
      "Epoch 1 Batch 1301 Loss 1.9096\n",
      "Epoch 1 Batch 1302 Loss 1.6805\n",
      "Epoch 1 Batch 1303 Loss 1.7476\n",
      "Epoch 1 Batch 1304 Loss 2.1733\n",
      "Epoch 1 Batch 1305 Loss 1.6318\n",
      "Epoch 1 Batch 1306 Loss 1.9618\n",
      "Epoch 1 Batch 1307 Loss 1.9290\n",
      "Epoch 1 Batch 1308 Loss 1.9748\n",
      "Epoch 1 Batch 1309 Loss 2.1747\n",
      "Epoch 1 Batch 1310 Loss 1.8954\n",
      "Epoch 1 Batch 1311 Loss 1.9688\n",
      "Epoch 1 Batch 1312 Loss 1.7039\n",
      "Epoch 1 Batch 1313 Loss 1.6528\n",
      "Epoch 1 Batch 1314 Loss 1.9473\n",
      "Epoch 1 Batch 1315 Loss 1.8948\n",
      "Epoch 1 Batch 1316 Loss 2.2659\n",
      "Epoch 1 Batch 1317 Loss 2.2862\n",
      "Epoch 1 Batch 1318 Loss 1.9451\n",
      "Epoch 1 Batch 1319 Loss 1.6645\n",
      "Epoch 1 Batch 1320 Loss 1.6797\n",
      "Epoch 1 Batch 1321 Loss 2.1551\n",
      "Epoch 1 Batch 1322 Loss 1.9876\n",
      "Epoch 1 Batch 1323 Loss 1.8163\n",
      "Epoch 1 Batch 1324 Loss 1.6532\n",
      "Epoch 1 Batch 1325 Loss 1.7225\n",
      "Epoch 1 Batch 1326 Loss 1.9742\n",
      "Epoch 1 Batch 1327 Loss 2.1293\n",
      "Epoch 1 Batch 1328 Loss 2.0226\n",
      "Epoch 1 Batch 1329 Loss 1.8120\n",
      "Epoch 1 Batch 1330 Loss 1.8341\n",
      "Epoch 1 Batch 1331 Loss 1.5749\n",
      "Epoch 1 Batch 1332 Loss 2.2176\n",
      "Epoch 1 Batch 1333 Loss 2.0754\n",
      "Epoch 1 Batch 1334 Loss 1.8323\n",
      "Epoch 1 Batch 1335 Loss 1.6395\n",
      "Epoch 1 Batch 1336 Loss 1.4143\n",
      "Epoch 1 Batch 1337 Loss 2.0445\n",
      "Epoch 1 Batch 1338 Loss 2.1720\n",
      "Epoch 1 Batch 1339 Loss 1.4467\n",
      "Epoch 1 Batch 1340 Loss 1.7662\n",
      "Epoch 1 Batch 1341 Loss 1.7182\n",
      "Epoch 1 Batch 1342 Loss 1.4204\n",
      "Epoch 1 Batch 1343 Loss 1.8024\n",
      "Epoch 1 Batch 1344 Loss 1.7933\n",
      "Epoch 1 Batch 1345 Loss 1.7890\n",
      "Epoch 1 Batch 1346 Loss 1.6869\n",
      "Epoch 1 Batch 1347 Loss 2.0095\n",
      "Epoch 1 Batch 1348 Loss 1.9437\n",
      "Epoch 1 Batch 1349 Loss 1.9635\n",
      "Epoch 1 Batch 1350 Loss 1.8611\n",
      "Epoch 1 Batch 1351 Loss 2.2232\n",
      "Epoch 1 Batch 1352 Loss 2.0104\n",
      "Epoch 1 Batch 1353 Loss 2.0695\n",
      "Epoch 1 Batch 1354 Loss 1.9192\n",
      "Epoch 1 Batch 1355 Loss 1.8140\n",
      "Epoch 1 Batch 1356 Loss 1.9071\n",
      "Epoch 1 Batch 1357 Loss 1.8201\n",
      "Epoch 1 Batch 1358 Loss 1.3529\n",
      "Epoch 1 Batch 1359 Loss 1.7962\n",
      "Epoch 1 Batch 1360 Loss 1.5078\n",
      "Epoch 1 Batch 1361 Loss 1.8823\n",
      "Epoch 1 Batch 1362 Loss 2.0186\n",
      "Epoch 1 Batch 1363 Loss 2.2717\n",
      "Epoch 1 Batch 1364 Loss 1.6945\n",
      "Epoch 1 Batch 1365 Loss 2.1465\n",
      "Epoch 1 Batch 1366 Loss 2.1343\n",
      "Epoch 1 Batch 1367 Loss 1.3502\n",
      "Epoch 1 Batch 1368 Loss 2.2350\n",
      "Epoch 1 Batch 1369 Loss 1.8794\n",
      "Epoch 1 Batch 1370 Loss 1.7867\n",
      "Epoch 1 Batch 1371 Loss 2.1764\n",
      "Epoch 1 Batch 1372 Loss 2.3242\n",
      "Epoch 1 Batch 1373 Loss 1.4225\n",
      "Epoch 1 Batch 1374 Loss 1.8164\n",
      "Epoch 1 Batch 1375 Loss 1.9936\n",
      "Epoch 1 Batch 1376 Loss 2.1614\n",
      "Epoch 1 Batch 1377 Loss 1.5077\n",
      "Epoch 1 Batch 1378 Loss 1.5815\n",
      "Epoch 1 Batch 1379 Loss 2.1209\n",
      "Epoch 1 Batch 1380 Loss 1.6291\n",
      "Epoch 1 Batch 1381 Loss 1.8962\n",
      "Epoch 1 Batch 1382 Loss 2.0161\n",
      "Epoch 1 Batch 1383 Loss 1.9609\n",
      "Epoch 1 Batch 1384 Loss 2.1102\n",
      "Epoch 1 Batch 1385 Loss 2.1129\n",
      "Epoch 1 Batch 1386 Loss 1.9815\n",
      "Epoch 1 Batch 1387 Loss 2.0395\n",
      "Epoch 1 Batch 1388 Loss 2.1637\n",
      "Epoch 1 Batch 1389 Loss 2.1116\n",
      "Epoch 1 Batch 1390 Loss 1.9283\n",
      "Epoch 1 Batch 1391 Loss 1.9058\n",
      "Epoch 1 Batch 1392 Loss 2.0640\n",
      "Epoch 1 Batch 1393 Loss 2.0039\n",
      "Epoch 1 Batch 1394 Loss 1.9772\n",
      "Epoch 1 Batch 1395 Loss 1.8786\n",
      "Epoch 1 Batch 1396 Loss 2.2891\n",
      "Epoch 1 Batch 1397 Loss 2.0740\n",
      "Epoch 1 Batch 1398 Loss 1.7083\n",
      "Epoch 1 Batch 1399 Loss 2.3091\n",
      "Epoch 1 Batch 1400 Loss 1.9740\n",
      "Epoch 1 Batch 1401 Loss 1.9134\n",
      "Epoch 1 Batch 1402 Loss 1.7438\n",
      "Epoch 1 Batch 1403 Loss 2.0468\n",
      "Epoch 1 Batch 1404 Loss 1.8039\n",
      "Epoch 1 Batch 1405 Loss 1.9833\n",
      "Epoch 1 Batch 1406 Loss 2.2114\n",
      "Epoch 1 Batch 1407 Loss 1.9378\n",
      "Epoch 1 Batch 1408 Loss 1.8626\n",
      "Epoch 1 Batch 1409 Loss 2.2195\n",
      "Epoch 1 Batch 1410 Loss 1.7349\n",
      "Epoch 1 Batch 1411 Loss 2.0231\n",
      "Epoch 1 Batch 1412 Loss 2.0580\n",
      "Epoch 1 Batch 1413 Loss 1.7152\n",
      "Epoch 1 Batch 1414 Loss 1.9041\n",
      "Epoch 1 Batch 1415 Loss 2.4427\n",
      "Epoch 1 Batch 1416 Loss 1.8832\n",
      "Epoch 1 Batch 1417 Loss 2.3694\n",
      "Epoch 1 Batch 1418 Loss 1.7995\n",
      "Epoch 1 Batch 1419 Loss 2.0970\n",
      "Epoch 1 Batch 1420 Loss 1.7057\n",
      "Epoch 1 Batch 1421 Loss 1.8685\n",
      "Epoch 1 Batch 1422 Loss 1.5473\n",
      "Epoch 1 Batch 1423 Loss 1.9603\n",
      "Epoch 1 Batch 1424 Loss 1.9139\n",
      "Epoch 1 Batch 1425 Loss 1.8075\n",
      "Epoch 1 Batch 1426 Loss 1.8798\n",
      "Epoch 1 Batch 1427 Loss 1.8671\n",
      "Epoch 1 Batch 1428 Loss 1.4942\n",
      "Epoch 1 Batch 1429 Loss 1.9483\n",
      "Epoch 1 Batch 1430 Loss 1.5236\n",
      "Epoch 1 Batch 1431 Loss 2.0442\n",
      "Epoch 1 Batch 1432 Loss 1.5043\n",
      "Epoch 1 Batch 1433 Loss 1.7397\n",
      "Epoch 1 Batch 1434 Loss 1.8645\n",
      "Epoch 1 Batch 1435 Loss 1.8746\n",
      "Epoch 1 Batch 1436 Loss 1.5695\n",
      "Epoch 1 Batch 1437 Loss 1.8459\n",
      "Epoch 1 Batch 1438 Loss 1.7441\n",
      "Epoch 1 Batch 1439 Loss 2.1010\n",
      "Epoch 1 Batch 1440 Loss 1.9026\n",
      "Epoch 1 Batch 1441 Loss 1.8669\n",
      "Epoch 1 Batch 1442 Loss 1.6574\n",
      "Epoch 1 Batch 1443 Loss 1.5636\n",
      "Epoch 1 Batch 1444 Loss 2.3698\n",
      "Epoch 1 Batch 1445 Loss 1.9126\n",
      "Epoch 1 Batch 1446 Loss 1.6072\n",
      "Epoch 1 Batch 1447 Loss 1.8702\n",
      "Epoch 1 Batch 1448 Loss 1.6915\n",
      "Epoch 1 Batch 1449 Loss 1.7282\n",
      "Epoch 1 Batch 1450 Loss 2.0096\n",
      "Epoch 1 Batch 1451 Loss 1.6804\n",
      "Epoch 1 Batch 1452 Loss 1.7013\n",
      "Epoch 1 Batch 1453 Loss 2.1960\n",
      "Epoch 1 Batch 1454 Loss 1.7268\n",
      "Epoch 1 Batch 1455 Loss 1.9374\n",
      "Epoch 1 Batch 1456 Loss 1.7705\n",
      "Epoch 1 Batch 1457 Loss 1.6277\n",
      "Epoch 1 Batch 1458 Loss 1.8719\n",
      "Epoch 1 Batch 1459 Loss 2.1119\n",
      "Epoch 1 Batch 1460 Loss 1.8836\n",
      "Epoch 1 Batch 1461 Loss 1.5819\n",
      "Epoch 1 Batch 1462 Loss 1.9132\n",
      "Epoch 1 Batch 1463 Loss 1.3832\n",
      "Epoch 1 Batch 1464 Loss 1.8089\n",
      "Epoch 1 Batch 1465 Loss 1.7766\n",
      "Epoch 1 Batch 1466 Loss 1.6947\n",
      "Epoch 1 Batch 1467 Loss 2.0531\n",
      "Epoch 1 Batch 1468 Loss 1.1693\n",
      "Epoch 1 Batch 1469 Loss 1.6630\n",
      "Epoch 1 Batch 1470 Loss 1.7068\n",
      "Epoch 1 Batch 1471 Loss 1.9818\n",
      "Epoch 1 Batch 1472 Loss 1.8990\n",
      "Epoch 1 Batch 1473 Loss 1.5401\n",
      "Epoch 1 Batch 1474 Loss 1.5144\n",
      "Epoch 1 Batch 1475 Loss 2.0193\n",
      "Epoch 1 Batch 1476 Loss 1.6247\n",
      "Epoch 1 Batch 1477 Loss 2.0432\n",
      "Epoch 1 Batch 1478 Loss 2.1565\n",
      "Epoch 1 Batch 1479 Loss 1.9162\n",
      "Epoch 1 Batch 1480 Loss 1.7016\n",
      "Epoch 1 Batch 1481 Loss 2.1874\n",
      "Epoch 1 Batch 1482 Loss 1.6893\n",
      "Epoch 1 Batch 1483 Loss 1.9516\n",
      "Epoch 1 Batch 1484 Loss 1.7382\n",
      "Epoch 1 Batch 1485 Loss 2.3904\n",
      "Epoch 1 Batch 1486 Loss 2.2033\n",
      "Epoch 1 Batch 1487 Loss 2.2346\n",
      "Epoch 1 Batch 1488 Loss 1.7735\n",
      "Epoch 1 Batch 1489 Loss 1.8964\n",
      "Epoch 1 Batch 1490 Loss 1.5018\n",
      "Epoch 1 Batch 1491 Loss 2.1910\n",
      "Epoch 1 Batch 1492 Loss 1.7420\n",
      "Epoch 1 Batch 1493 Loss 1.6543\n",
      "Epoch 1 Batch 1494 Loss 1.8849\n",
      "Epoch 1 Batch 1495 Loss 1.9430\n",
      "Epoch 1 Batch 1496 Loss 1.9500\n",
      "Epoch 1 Batch 1497 Loss 1.9173\n",
      "Epoch 1 Batch 1498 Loss 1.8786\n",
      "Epoch 1 Batch 1499 Loss 1.5138\n",
      "Epoch 1 Batch 1500 Loss 1.3619\n",
      "Epoch 1 Batch 1501 Loss 1.8107\n",
      "Epoch 1 Batch 1502 Loss 1.6272\n",
      "Epoch 1 Batch 1503 Loss 1.9094\n",
      "Epoch 1 Batch 1504 Loss 1.7949\n",
      "Epoch 1 Batch 1505 Loss 1.6649\n",
      "Epoch 1 Batch 1506 Loss 1.7557\n",
      "Epoch 1 Batch 1507 Loss 1.9886\n",
      "Epoch 1 Batch 1508 Loss 1.4888\n",
      "Epoch 1 Batch 1509 Loss 1.6874\n",
      "Epoch 1 Batch 1510 Loss 2.2055\n",
      "Epoch 1 Batch 1511 Loss 1.5698\n",
      "Epoch 1 Batch 1512 Loss 1.4840\n",
      "Epoch 1 Batch 1513 Loss 1.6892\n",
      "Epoch 1 Batch 1514 Loss 2.1675\n",
      "Epoch 1 Batch 1515 Loss 1.4280\n",
      "Epoch 1 Batch 1516 Loss 1.8845\n",
      "Epoch 1 Batch 1517 Loss 2.0367\n",
      "Epoch 1 Batch 1518 Loss 1.5209\n",
      "Epoch 1 Batch 1519 Loss 1.7305\n",
      "Epoch 1 Batch 1520 Loss 1.6377\n",
      "Epoch 1 Batch 1521 Loss 1.8147\n",
      "Epoch 1 Batch 1522 Loss 1.7438\n",
      "Epoch 1 Batch 1523 Loss 1.8042\n",
      "Epoch 1 Batch 1524 Loss 2.4098\n",
      "Epoch 1 Batch 1525 Loss 2.1475\n",
      "Epoch 1 Batch 1526 Loss 2.1901\n",
      "Epoch 1 Batch 1527 Loss 2.1078\n",
      "Epoch 1 Batch 1528 Loss 1.6824\n",
      "Epoch 1 Batch 1529 Loss 2.0041\n",
      "Epoch 1 Batch 1530 Loss 1.6792\n",
      "Epoch 1 Batch 1531 Loss 1.8601\n",
      "Epoch 1 Batch 1532 Loss 1.7181\n",
      "Epoch 1 Batch 1533 Loss 1.6956\n",
      "Epoch 1 Batch 1534 Loss 1.5982\n",
      "Epoch 1 Batch 1535 Loss 1.9459\n",
      "Epoch 1 Batch 1536 Loss 1.2747\n",
      "Epoch 1 Batch 1537 Loss 1.8763\n",
      "Epoch 1 Batch 1538 Loss 1.7316\n",
      "Epoch 1 Batch 1539 Loss 1.5349\n",
      "Epoch 1 Batch 1540 Loss 1.6683\n",
      "Epoch 1 Batch 1541 Loss 1.9032\n",
      "Epoch 1 Batch 1542 Loss 2.1623\n",
      "Epoch 1 Batch 1543 Loss 2.0990\n",
      "Epoch 1 Batch 1544 Loss 1.9587\n",
      "Epoch 1 Batch 1545 Loss 1.7958\n",
      "Epoch 1 Batch 1546 Loss 1.8324\n",
      "Epoch 1 Batch 1547 Loss 1.7913\n",
      "Epoch 1 Batch 1548 Loss 1.8404\n",
      "Epoch 1 Batch 1549 Loss 1.9262\n",
      "Epoch 1 Batch 1550 Loss 1.9037\n",
      "Epoch 1 Batch 1551 Loss 2.0649\n",
      "Epoch 1 Batch 1552 Loss 1.9135\n",
      "Epoch 1 Batch 1553 Loss 1.5947\n",
      "Epoch 1 Batch 1554 Loss 1.8114\n",
      "Epoch 1 Batch 1555 Loss 2.0209\n",
      "Epoch 1 Batch 1556 Loss 1.8441\n",
      "Epoch 1 Batch 1557 Loss 2.0735\n",
      "Epoch 1 Batch 1558 Loss 1.9572\n",
      "Epoch 1 Batch 1559 Loss 2.0619\n",
      "Epoch 1 Batch 1560 Loss 1.4397\n",
      "Epoch 1 Batch 1561 Loss 1.9555\n",
      "Epoch 1 Batch 1562 Loss 1.6659\n",
      "Epoch 1 Batch 1563 Loss 2.1774\n",
      "Epoch 1 Batch 1564 Loss 1.5899\n",
      "Epoch 1 Batch 1565 Loss 1.7750\n",
      "Epoch 1 Batch 1566 Loss 2.0197\n",
      "Epoch 1 Batch 1567 Loss 1.8107\n",
      "Epoch 1 Batch 1568 Loss 2.2304\n",
      "Epoch 1 Batch 1569 Loss 2.2338\n",
      "Epoch 1 Batch 1570 Loss 2.2112\n",
      "Epoch 1 Batch 1571 Loss 1.7125\n",
      "Epoch 1 Batch 1572 Loss 1.8469\n",
      "Epoch 1 Batch 1573 Loss 1.5366\n",
      "Epoch 1 Batch 1574 Loss 2.1293\n",
      "Epoch 1 Batch 1575 Loss 1.7712\n",
      "Epoch 1 Batch 1576 Loss 1.9456\n",
      "Epoch 1 Batch 1577 Loss 2.0075\n",
      "Epoch 1 Batch 1578 Loss 1.8978\n",
      "Epoch 1 Batch 1579 Loss 1.4588\n",
      "Epoch 1 Batch 1580 Loss 1.9805\n",
      "Epoch 1 Batch 1581 Loss 1.4469\n",
      "Epoch 1 Batch 1582 Loss 1.5627\n",
      "Epoch 1 Batch 1583 Loss 1.9065\n",
      "Epoch 1 Batch 1584 Loss 2.0650\n",
      "Epoch 1 Batch 1585 Loss 1.7044\n",
      "Epoch 1 Batch 1586 Loss 2.1192\n",
      "Epoch 1 Batch 1587 Loss 1.7325\n",
      "Epoch 1 Batch 1588 Loss 1.9112\n",
      "Epoch 1 Batch 1589 Loss 2.1657\n",
      "Epoch 1 Batch 1590 Loss 1.6318\n",
      "Epoch 1 Batch 1591 Loss 2.4009\n",
      "Epoch 1 Batch 1592 Loss 2.2606\n",
      "Epoch 1 Batch 1593 Loss 1.8041\n",
      "Epoch 1 Batch 1594 Loss 1.7351\n",
      "Epoch 1 Batch 1595 Loss 1.8210\n",
      "Epoch 1 Batch 1596 Loss 1.8235\n",
      "Epoch 1 Batch 1597 Loss 1.7672\n",
      "Epoch 1 Batch 1598 Loss 1.9067\n",
      "Epoch 1 Batch 1599 Loss 1.9185\n",
      "Epoch 1 Batch 1600 Loss 1.8485\n",
      "Epoch 1 Batch 1601 Loss 1.5386\n",
      "Epoch 1 Batch 1602 Loss 1.7504\n",
      "Epoch 1 Batch 1603 Loss 1.5630\n",
      "Epoch 1 Batch 1604 Loss 1.7348\n",
      "Epoch 1 Batch 1605 Loss 1.4702\n",
      "Epoch 1 Batch 1606 Loss 1.7094\n",
      "Epoch 1 Batch 1607 Loss 1.7682\n",
      "Epoch 1 Batch 1608 Loss 1.7568\n",
      "Epoch 1 Batch 1609 Loss 1.8168\n",
      "Epoch 1 Batch 1610 Loss 1.6269\n",
      "Epoch 1 Batch 1611 Loss 1.5436\n",
      "Epoch 1 Batch 1612 Loss 1.5562\n",
      "Epoch 1 Batch 1613 Loss 1.9405\n",
      "Epoch 1 Batch 1614 Loss 2.0450\n",
      "Epoch 1 Batch 1615 Loss 1.8891\n",
      "Epoch 1 Batch 1616 Loss 1.8869\n",
      "Epoch 1 Batch 1617 Loss 1.8827\n",
      "Epoch 1 Batch 1618 Loss 1.7672\n",
      "Epoch 1 Batch 1619 Loss 1.8952\n",
      "Epoch 1 Batch 1620 Loss 1.5412\n",
      "Epoch 1 Batch 1621 Loss 1.9268\n",
      "Epoch 1 Batch 1622 Loss 1.7386\n",
      "Epoch 1 Batch 1623 Loss 1.7161\n",
      "Epoch 1 Batch 1624 Loss 1.8222\n",
      "Epoch 1 Batch 1625 Loss 1.7985\n",
      "Epoch 1 Batch 1626 Loss 1.6269\n",
      "Epoch 1 Batch 1627 Loss 2.1762\n",
      "Epoch 1 Batch 1628 Loss 1.8963\n",
      "Epoch 1 Batch 1629 Loss 1.6214\n",
      "Epoch 1 Batch 1630 Loss 1.8818\n",
      "Epoch 1 Batch 1631 Loss 1.7122\n",
      "Epoch 1 Batch 1632 Loss 1.7102\n",
      "Epoch 1 Batch 1633 Loss 1.4101\n",
      "Epoch 1 Batch 1634 Loss 2.2680\n",
      "Epoch 1 Batch 1635 Loss 1.7944\n",
      "Epoch 1 Batch 1636 Loss 1.9711\n",
      "Epoch 1 Batch 1637 Loss 2.0193\n",
      "Epoch 1 Batch 1638 Loss 1.7717\n",
      "Epoch 1 Batch 1639 Loss 1.9543\n",
      "Epoch 1 Batch 1640 Loss 1.9929\n",
      "Epoch 1 Batch 1641 Loss 1.4686\n",
      "Epoch 1 Batch 1642 Loss 1.7702\n",
      "Epoch 1 Batch 1643 Loss 1.7409\n",
      "Epoch 1 Batch 1644 Loss 1.9341\n",
      "Epoch 1 Batch 1645 Loss 1.8285\n",
      "Epoch 1 Batch 1646 Loss 1.9752\n",
      "Epoch 1 Batch 1647 Loss 1.6239\n",
      "Epoch 1 Batch 1648 Loss 1.9619\n",
      "Epoch 1 Batch 1649 Loss 1.8737\n",
      "Epoch 1 Batch 1650 Loss 1.8186\n",
      "Epoch 1 Batch 1651 Loss 1.8261\n",
      "Epoch 1 Batch 1652 Loss 1.9264\n",
      "Epoch 1 Batch 1653 Loss 1.9671\n",
      "Epoch 1 Batch 1654 Loss 1.7191\n",
      "Epoch 1 Batch 1655 Loss 2.1320\n",
      "Epoch 1 Batch 1656 Loss 2.0509\n",
      "Epoch 1 Batch 1657 Loss 1.6166\n",
      "Epoch 1 Batch 1658 Loss 1.9119\n",
      "Epoch 1 Batch 1659 Loss 1.9307\n",
      "Epoch 1 Batch 1660 Loss 1.4563\n",
      "Epoch 1 Batch 1661 Loss 1.7342\n",
      "Epoch 1 Batch 1662 Loss 1.5616\n",
      "Epoch 1 Batch 1663 Loss 1.6162\n",
      "Epoch 1 Batch 1664 Loss 1.7404\n",
      "Epoch 1 Batch 1665 Loss 1.5446\n",
      "Epoch 1 Batch 1666 Loss 1.4820\n",
      "Epoch 1 Batch 1667 Loss 1.6794\n",
      "Epoch 1 Batch 1668 Loss 1.6898\n",
      "Epoch 1 Batch 1669 Loss 1.9372\n",
      "Epoch 1 Batch 1670 Loss 1.9385\n",
      "Epoch 1 Batch 1671 Loss 2.0469\n",
      "Epoch 1 Batch 1672 Loss 1.8860\n",
      "Epoch 1 Batch 1673 Loss 1.8583\n",
      "Epoch 1 Batch 1674 Loss 1.9497\n",
      "Epoch 1 Batch 1675 Loss 1.8294\n",
      "Epoch 1 Batch 1676 Loss 1.9823\n",
      "Epoch 1 Batch 1677 Loss 1.7799\n",
      "Epoch 1 Batch 1678 Loss 1.8460\n",
      "Epoch 1 Batch 1679 Loss 1.7316\n",
      "Epoch 1 Batch 1680 Loss 1.9845\n",
      "Epoch 1 Batch 1681 Loss 1.5754\n",
      "Epoch 1 Batch 1682 Loss 1.7178\n",
      "Epoch 1 Batch 1683 Loss 2.0642\n",
      "Epoch 1 Batch 1684 Loss 1.9734\n",
      "Epoch 1 Batch 1685 Loss 1.9243\n",
      "Epoch 1 Batch 1686 Loss 1.8301\n",
      "Epoch 1 Batch 1687 Loss 1.9601\n",
      "Epoch 1 Batch 1688 Loss 1.7788\n",
      "Epoch 1 Batch 1689 Loss 1.8456\n",
      "Epoch 1 Batch 1690 Loss 1.8656\n",
      "Epoch 1 Batch 1691 Loss 1.3507\n",
      "Epoch 1 Batch 1692 Loss 1.6944\n",
      "Epoch 1 Batch 1693 Loss 1.5212\n",
      "Epoch 1 Batch 1694 Loss 1.7145\n",
      "Epoch 1 Batch 1695 Loss 1.6883\n",
      "Epoch 1 Batch 1696 Loss 1.6628\n",
      "Epoch 1 Batch 1697 Loss 1.4965\n",
      "Epoch 1 Batch 1698 Loss 1.6809\n",
      "Epoch 1 Batch 1699 Loss 1.8305\n",
      "Epoch 1 Batch 1700 Loss 1.4004\n",
      "Epoch 1 Batch 1701 Loss 1.5190\n",
      "Epoch 1 Batch 1702 Loss 2.1889\n",
      "Epoch 1 Batch 1703 Loss 1.5747\n",
      "Epoch 1 Batch 1704 Loss 1.8080\n",
      "Epoch 1 Batch 1705 Loss 1.8561\n",
      "Epoch 1 Batch 1706 Loss 1.4909\n",
      "Epoch 1 Batch 1707 Loss 1.6573\n",
      "Epoch 1 Batch 1708 Loss 1.7102\n",
      "Epoch 1 Batch 1709 Loss 1.7267\n",
      "Epoch 1 Batch 1710 Loss 1.6285\n",
      "Epoch 1 Batch 1711 Loss 1.8824\n",
      "Epoch 1 Batch 1712 Loss 1.7510\n",
      "Epoch 1 Batch 1713 Loss 1.7287\n",
      "Epoch 1 Batch 1714 Loss 1.8821\n",
      "Epoch 1 Batch 1715 Loss 2.0467\n",
      "Epoch 1 Batch 1716 Loss 1.6195\n",
      "Epoch 1 Batch 1717 Loss 1.7243\n",
      "Epoch 1 Batch 1718 Loss 1.9323\n",
      "Epoch 1 Batch 1719 Loss 1.8104\n",
      "Epoch 1 Batch 1720 Loss 1.6192\n",
      "Epoch 1 Batch 1721 Loss 1.6031\n",
      "Epoch 1 Batch 1722 Loss 1.8118\n",
      "Epoch 1 Batch 1723 Loss 1.7849\n",
      "Epoch 1 Batch 1724 Loss 1.6211\n",
      "Epoch 1 Batch 1725 Loss 1.7290\n",
      "Epoch 1 Batch 1726 Loss 2.2252\n",
      "Epoch 1 Batch 1727 Loss 2.0790\n",
      "Epoch 1 Batch 1728 Loss 1.9283\n",
      "Epoch 1 Batch 1729 Loss 1.8823\n",
      "Epoch 1 Batch 1730 Loss 1.9433\n",
      "Epoch 1 Batch 1731 Loss 1.8003\n",
      "Epoch 1 Batch 1732 Loss 1.6348\n",
      "Epoch 1 Batch 1733 Loss 1.8534\n",
      "Epoch 1 Batch 1734 Loss 1.8410\n",
      "Epoch 1 Batch 1735 Loss 2.0289\n",
      "Epoch 1 Batch 1736 Loss 1.5131\n",
      "Epoch 1 Batch 1737 Loss 1.9630\n",
      "Epoch 1 Batch 1738 Loss 1.7110\n",
      "Epoch 1 Batch 1739 Loss 1.6994\n",
      "Epoch 1 Batch 1740 Loss 1.8068\n",
      "Epoch 1 Batch 1741 Loss 2.0471\n",
      "Epoch 1 Batch 1742 Loss 2.1990\n",
      "Epoch 1 Batch 1743 Loss 1.6086\n",
      "Epoch 1 Batch 1744 Loss 2.0905\n",
      "Epoch 1 Batch 1745 Loss 1.4355\n",
      "Epoch 1 Batch 1746 Loss 1.6805\n",
      "Epoch 1 Batch 1747 Loss 1.5399\n",
      "Epoch 1 Batch 1748 Loss 1.5839\n",
      "Epoch 1 Batch 1749 Loss 1.2840\n",
      "Epoch 1 Batch 1750 Loss 1.8583\n",
      "Epoch 1 Batch 1751 Loss 1.8869\n",
      "Epoch 1 Batch 1752 Loss 2.1263\n",
      "Epoch 1 Batch 1753 Loss 2.0258\n",
      "Epoch 1 Batch 1754 Loss 1.6058\n",
      "Epoch 1 Batch 1755 Loss 1.4603\n",
      "Epoch 1 Batch 1756 Loss 1.6892\n",
      "Epoch 1 Batch 1757 Loss 1.7503\n",
      "Epoch 1 Batch 1758 Loss 1.6810\n",
      "Epoch 1 Batch 1759 Loss 1.9440\n",
      "Epoch 1 Batch 1760 Loss 1.9134\n",
      "Epoch 1 Batch 1761 Loss 1.8580\n",
      "Epoch 1 Batch 1762 Loss 1.9155\n",
      "Epoch 1 Batch 1763 Loss 1.5041\n",
      "Epoch 1 Batch 1764 Loss 1.8899\n",
      "Epoch 1 Batch 1765 Loss 1.6791\n",
      "Epoch 1 Batch 1766 Loss 2.0079\n",
      "Epoch 1 Batch 1767 Loss 1.7072\n",
      "Epoch 1 Batch 1768 Loss 1.7602\n",
      "Epoch 1 Batch 1769 Loss 1.8733\n",
      "Epoch 1 Batch 1770 Loss 1.6765\n",
      "Epoch 1 Batch 1771 Loss 1.5841\n",
      "Epoch 1 Batch 1772 Loss 1.8649\n",
      "Epoch 1 Batch 1773 Loss 1.7954\n",
      "Epoch 1 Batch 1774 Loss 1.6852\n",
      "Epoch 1 Batch 1775 Loss 1.5910\n",
      "Epoch 1 Batch 1776 Loss 1.5678\n",
      "Epoch 1 Batch 1777 Loss 1.6875\n",
      "Epoch 1 Batch 1778 Loss 1.8013\n",
      "Epoch 1 Batch 1779 Loss 1.5299\n",
      "Epoch 1 Batch 1780 Loss 1.9483\n",
      "Epoch 1 Batch 1781 Loss 1.5979\n",
      "Epoch 1 Batch 1782 Loss 1.3908\n",
      "Epoch 1 Batch 1783 Loss 2.1886\n",
      "Epoch 1 Batch 1784 Loss 2.0109\n",
      "Epoch 1 Batch 1785 Loss 1.3992\n",
      "Epoch 1 Batch 1786 Loss 1.6148\n",
      "Epoch 1 Batch 1787 Loss 1.7858\n",
      "Epoch 1 Batch 1788 Loss 1.7728\n",
      "Epoch 1 Batch 1789 Loss 1.7475\n",
      "Epoch 1 Batch 1790 Loss 1.7914\n",
      "Epoch 1 Batch 1791 Loss 1.8114\n",
      "Epoch 1 Batch 1792 Loss 1.8551\n",
      "Epoch 1 Batch 1793 Loss 1.6955\n",
      "Epoch 1 Batch 1794 Loss 1.7941\n",
      "Epoch 1 Batch 1795 Loss 1.7848\n",
      "Epoch 1 Batch 1796 Loss 1.6193\n",
      "Epoch 1 Batch 1797 Loss 1.7922\n",
      "Epoch 1 Batch 1798 Loss 1.6926\n",
      "Epoch 1 Batch 1799 Loss 1.9288\n",
      "Epoch 1 Batch 1800 Loss 1.4543\n",
      "Epoch 1 Batch 1801 Loss 2.0494\n",
      "Epoch 1 Batch 1802 Loss 1.9617\n",
      "Epoch 1 Batch 1803 Loss 1.7905\n",
      "Epoch 1 Batch 1804 Loss 1.8161\n",
      "Epoch 1 Batch 1805 Loss 1.7472\n",
      "Epoch 1 Batch 1806 Loss 1.5910\n",
      "Epoch 1 Batch 1807 Loss 1.7239\n",
      "Epoch 1 Batch 1808 Loss 1.9264\n",
      "Epoch 1 Batch 1809 Loss 1.2884\n",
      "Epoch 1 Batch 1810 Loss 1.8701\n",
      "Epoch 1 Batch 1811 Loss 1.4813\n",
      "Epoch 1 Batch 1812 Loss 1.7449\n",
      "Epoch 1 Batch 1813 Loss 1.7815\n",
      "Epoch 1 Batch 1814 Loss 2.0062\n",
      "Epoch 1 Batch 1815 Loss 1.6608\n",
      "Epoch 1 Batch 1816 Loss 1.7674\n",
      "Epoch 1 Batch 1817 Loss 1.7699\n",
      "Epoch 1 Batch 1818 Loss 1.5897\n",
      "Epoch 1 Batch 1819 Loss 2.0190\n",
      "Epoch 1 Batch 1820 Loss 1.6742\n",
      "Epoch 1 Batch 1821 Loss 1.7975\n",
      "Epoch 1 Batch 1822 Loss 2.0206\n",
      "Epoch 1 Batch 1823 Loss 1.7262\n",
      "Epoch 1 Batch 1824 Loss 1.4130\n",
      "Epoch 1 Batch 1825 Loss 1.5933\n",
      "Epoch 1 Batch 1826 Loss 1.5814\n",
      "Epoch 1 Batch 1827 Loss 1.8997\n",
      "Epoch 1 Batch 1828 Loss 1.6221\n",
      "Epoch 1 Batch 1829 Loss 2.1713\n",
      "Epoch 1 Batch 1830 Loss 1.6813\n",
      "Epoch 1 Batch 1831 Loss 1.4721\n",
      "Epoch 1 Batch 1832 Loss 2.0245\n",
      "Epoch 1 Batch 1833 Loss 1.6462\n",
      "Epoch 1 Batch 1834 Loss 1.9492\n",
      "Epoch 1 Batch 1835 Loss 1.7572\n",
      "Epoch 1 Batch 1836 Loss 1.8712\n",
      "Epoch 1 Batch 1837 Loss 1.1651\n",
      "Epoch 1 Batch 1838 Loss 1.8389\n",
      "Epoch 1 Batch 1839 Loss 1.4364\n",
      "Epoch 1 Batch 1840 Loss 1.7875\n",
      "Epoch 1 Batch 1841 Loss 1.5385\n",
      "Epoch 1 Batch 1842 Loss 1.8455\n",
      "Epoch 1 Batch 1843 Loss 2.1664\n",
      "Epoch 1 Batch 1844 Loss 1.7166\n",
      "Epoch 1 Batch 1845 Loss 1.8791\n",
      "Epoch 1 Batch 1846 Loss 1.7749\n",
      "Epoch 1 Batch 1847 Loss 1.5715\n",
      "Epoch 1 Batch 1848 Loss 1.9184\n",
      "Epoch 1 Batch 1849 Loss 1.5993\n",
      "Epoch 1 Batch 1850 Loss 1.9261\n",
      "Epoch 1 Batch 1851 Loss 1.5670\n",
      "Epoch 1 Batch 1852 Loss 1.9319\n",
      "Epoch 1 Batch 1853 Loss 1.9967\n",
      "Epoch 1 Batch 1854 Loss 1.7089\n",
      "Epoch 1 Batch 1855 Loss 1.6478\n",
      "Epoch 1 Batch 1856 Loss 1.6298\n",
      "Epoch 1 Batch 1857 Loss 2.0172\n",
      "Epoch 1 Batch 1858 Loss 1.7765\n",
      "Epoch 1 Batch 1859 Loss 1.6798\n",
      "Epoch 1 Batch 1860 Loss 2.1563\n",
      "Epoch 1 Batch 1861 Loss 1.7529\n",
      "Epoch 1 Batch 1862 Loss 1.8186\n",
      "Epoch 1 Batch 1863 Loss 1.4812\n",
      "Epoch 1 Batch 1864 Loss 1.8603\n",
      "Epoch 1 Batch 1865 Loss 1.4847\n",
      "Epoch 1 Batch 1866 Loss 1.9522\n",
      "Epoch 1 Batch 1867 Loss 1.7426\n",
      "Epoch 1 Batch 1868 Loss 1.8528\n",
      "Epoch 1 Batch 1869 Loss 1.5186\n",
      "Epoch 1 Batch 1870 Loss 1.6651\n",
      "Epoch 1 Batch 1871 Loss 1.9450\n",
      "Epoch 1 Batch 1872 Loss 1.9401\n",
      "Epoch 1 Batch 1873 Loss 1.9170\n",
      "Epoch 1 Batch 1874 Loss 1.5872\n",
      "Epoch 1 Batch 1875 Loss 1.7543\n",
      "Epoch 1 Batch 1876 Loss 1.9964\n",
      "Epoch 1 Batch 1877 Loss 1.6576\n",
      "Epoch 1 Batch 1878 Loss 1.4214\n",
      "Epoch 1 Batch 1879 Loss 1.8152\n",
      "Epoch 1 Batch 1880 Loss 1.6107\n",
      "Epoch 1 Batch 1881 Loss 1.6878\n",
      "Epoch 1 Batch 1882 Loss 2.2310\n",
      "Epoch 1 Batch 1883 Loss 1.5554\n",
      "Epoch 1 Batch 1884 Loss 1.5390\n",
      "Epoch 1 Batch 1885 Loss 1.4820\n",
      "Epoch 1 Batch 1886 Loss 2.0248\n",
      "Epoch 1 Batch 1887 Loss 1.9098\n",
      "Epoch 1 Batch 1888 Loss 1.6010\n",
      "Epoch 1 Batch 1889 Loss 1.8610\n",
      "Epoch 1 Batch 1890 Loss 1.5995\n",
      "Epoch 1 Batch 1891 Loss 2.0930\n",
      "Epoch 1 Batch 1892 Loss 1.9970\n",
      "Epoch 1 Batch 1893 Loss 1.7816\n",
      "Epoch 1 Batch 1894 Loss 1.6979\n",
      "Epoch 1 Batch 1895 Loss 1.9532\n",
      "Epoch 1 Batch 1896 Loss 1.8259\n",
      "Epoch 1 Batch 1897 Loss 1.9281\n",
      "Epoch 1 Batch 1898 Loss 1.7492\n",
      "Epoch 1 Batch 1899 Loss 2.0796\n",
      "Epoch 1 Batch 1900 Loss 1.8901\n",
      "Epoch 1 Batch 1901 Loss 1.8777\n",
      "Epoch 1 Batch 1902 Loss 1.7954\n",
      "Epoch 1 Batch 1903 Loss 1.8187\n",
      "Epoch 1 Batch 1904 Loss 1.6237\n",
      "Epoch 1 Batch 1905 Loss 2.0704\n",
      "Epoch 1 Batch 1906 Loss 1.5574\n",
      "Epoch 1 Batch 1907 Loss 1.4829\n",
      "Epoch 1 Batch 1908 Loss 1.8099\n",
      "Epoch 1 Batch 1909 Loss 1.7220\n",
      "Epoch 1 Batch 1910 Loss 1.6799\n",
      "Epoch 1 Batch 1911 Loss 2.2229\n",
      "Epoch 1 Batch 1912 Loss 1.7283\n",
      "Epoch 1 Batch 1913 Loss 1.4709\n",
      "Epoch 1 Batch 1914 Loss 1.4690\n",
      "Epoch 1 Batch 1915 Loss 1.9396\n",
      "Epoch 1 Batch 1916 Loss 1.4520\n",
      "Epoch 1 Batch 1917 Loss 1.7854\n",
      "Epoch 1 Batch 1918 Loss 1.5318\n",
      "Epoch 1 Batch 1919 Loss 1.8264\n",
      "Epoch 1 Batch 1920 Loss 1.5314\n",
      "Epoch 1 Batch 1921 Loss 1.9818\n",
      "Epoch 1 Batch 1922 Loss 1.6994\n",
      "Epoch 1 Batch 1923 Loss 2.0987\n",
      "Epoch 1 Batch 1924 Loss 1.8593\n",
      "Epoch 1 Batch 1925 Loss 1.5133\n",
      "Epoch 1 Batch 1926 Loss 1.7041\n",
      "Epoch 1 Batch 1927 Loss 1.7675\n",
      "Epoch 1 Batch 1928 Loss 1.8385\n",
      "Epoch 1 Batch 1929 Loss 1.5775\n",
      "Epoch 1 Batch 1930 Loss 1.5615\n",
      "Epoch 1 Batch 1931 Loss 1.9100\n",
      "Epoch 1 Batch 1932 Loss 1.5266\n",
      "Epoch 1 Batch 1933 Loss 1.7820\n",
      "Epoch 1 Batch 1934 Loss 1.5663\n",
      "Epoch 1 Batch 1935 Loss 1.5727\n",
      "Epoch 1 Batch 1936 Loss 1.6862\n",
      "Epoch 1 Batch 1937 Loss 1.9053\n",
      "Epoch 1 Batch 1938 Loss 1.7292\n",
      "Epoch 1 Batch 1939 Loss 1.4644\n",
      "Epoch 1 Batch 1940 Loss 2.0056\n",
      "Epoch 1 Batch 1941 Loss 1.5043\n",
      "Epoch 1 Batch 1942 Loss 1.5102\n",
      "Epoch 1 Batch 1943 Loss 1.6708\n",
      "Epoch 1 Batch 1944 Loss 1.6391\n",
      "Epoch 1 Batch 1945 Loss 1.6270\n",
      "Epoch 1 Batch 1946 Loss 1.3568\n",
      "Epoch 1 Batch 1947 Loss 1.7377\n",
      "Epoch 1 Batch 1948 Loss 1.9418\n",
      "Epoch 1 Batch 1949 Loss 1.9001\n",
      "Epoch 1 Batch 1950 Loss 1.4609\n",
      "Epoch 1 Batch 1951 Loss 1.8314\n",
      "Epoch 1 Batch 1952 Loss 1.5509\n",
      "Epoch 1 Batch 1953 Loss 1.6827\n",
      "Epoch 1 Batch 1954 Loss 1.7105\n",
      "Epoch 1 Batch 1955 Loss 1.9339\n",
      "Epoch 1 Batch 1956 Loss 1.4725\n",
      "Epoch 1 Batch 1957 Loss 1.7171\n",
      "Epoch 1 Batch 1958 Loss 1.4960\n",
      "Epoch 1 Batch 1959 Loss 1.8106\n",
      "Epoch 1 Batch 1960 Loss 1.7132\n",
      "Epoch 1 Batch 1961 Loss 1.8847\n",
      "Epoch 1 Batch 1962 Loss 1.5742\n",
      "Epoch 1 Batch 1963 Loss 1.7391\n",
      "Epoch 1 Batch 1964 Loss 1.7788\n",
      "Epoch 1 Batch 1965 Loss 1.8679\n",
      "Epoch 1 Batch 1966 Loss 1.7533\n",
      "Epoch 1 Batch 1967 Loss 1.7466\n",
      "Epoch 1 Batch 1968 Loss 1.3847\n",
      "Epoch 1 Batch 1969 Loss 1.5042\n",
      "Epoch 1 Batch 1970 Loss 1.6079\n",
      "Epoch 1 Batch 1971 Loss 1.4967\n",
      "Epoch 1 Batch 1972 Loss 1.6552\n",
      "Epoch 1 Batch 1973 Loss 1.6041\n",
      "Epoch 1 Batch 1974 Loss 1.5843\n",
      "Epoch 1 Batch 1975 Loss 1.3805\n",
      "Epoch 1 Batch 1976 Loss 2.0608\n",
      "Epoch 1 Batch 1977 Loss 1.7187\n",
      "Epoch 1 Batch 1978 Loss 1.9560\n",
      "Epoch 1 Batch 1979 Loss 1.9392\n",
      "Epoch 1 Batch 1980 Loss 1.7573\n",
      "Epoch 1 Batch 1981 Loss 2.1019\n",
      "Epoch 1 Batch 1982 Loss 1.5999\n",
      "Epoch 1 Batch 1983 Loss 2.0600\n",
      "Epoch 1 Batch 1984 Loss 1.6330\n",
      "Epoch 1 Batch 1985 Loss 1.9196\n",
      "Epoch 1 Batch 1986 Loss 2.2495\n",
      "Epoch 1 Batch 1987 Loss 1.5902\n",
      "Epoch 1 Batch 1988 Loss 1.8022\n",
      "Epoch 1 Batch 1989 Loss 1.7200\n",
      "Epoch 1 Batch 1990 Loss 1.4147\n",
      "Epoch 1 Batch 1991 Loss 1.6293\n",
      "Epoch 1 Batch 1992 Loss 1.7502\n",
      "Epoch 1 Batch 1993 Loss 1.6918\n",
      "Epoch 1 Batch 1994 Loss 2.1676\n",
      "Epoch 1 Batch 1995 Loss 1.5120\n",
      "Epoch 1 Batch 1996 Loss 1.8890\n",
      "Epoch 1 Batch 1997 Loss 1.9224\n",
      "Epoch 1 Batch 1998 Loss 1.6693\n",
      "Epoch 1 Batch 1999 Loss 2.0454\n",
      "Epoch 1 Batch 2000 Loss 2.1243\n",
      "Epoch 1 Batch 2001 Loss 1.5738\n",
      "Epoch 1 Batch 2002 Loss 1.6582\n",
      "Epoch 1 Batch 2003 Loss 1.4964\n",
      "Epoch 1 Batch 2004 Loss 1.7474\n",
      "Epoch 1 Batch 2005 Loss 1.9202\n",
      "Epoch 1 Batch 2006 Loss 1.7303\n",
      "Epoch 1 Batch 2007 Loss 1.6891\n",
      "Epoch 1 Batch 2008 Loss 2.1479\n",
      "Epoch 1 Batch 2009 Loss 1.6057\n",
      "Epoch 1 Batch 2010 Loss 1.8744\n",
      "Epoch 1 Batch 2011 Loss 1.4172\n",
      "Epoch 1 Batch 2012 Loss 1.6925\n",
      "Epoch 1 Batch 2013 Loss 1.8622\n",
      "Epoch 1 Batch 2014 Loss 1.6968\n",
      "Epoch 1 Batch 2015 Loss 1.5638\n",
      "Epoch 1 Batch 2016 Loss 1.8125\n",
      "Epoch 1 Batch 2017 Loss 1.6941\n",
      "Epoch 1 Batch 2018 Loss 2.0189\n",
      "Epoch 1 Batch 2019 Loss 2.1450\n",
      "Epoch 1 Batch 2020 Loss 1.6664\n",
      "Epoch 1 Batch 2021 Loss 1.5822\n",
      "Epoch 1 Batch 2022 Loss 1.7747\n",
      "Epoch 1 Batch 2023 Loss 1.7669\n",
      "Epoch 1 Batch 2024 Loss 1.7839\n",
      "Epoch 1 Batch 2025 Loss 1.6549\n",
      "Epoch 1 Batch 2026 Loss 1.6696\n",
      "Epoch 1 Batch 2027 Loss 1.8647\n",
      "Epoch 1 Batch 2028 Loss 1.4290\n",
      "Epoch 1 Batch 2029 Loss 1.6487\n",
      "Epoch 1 Batch 2030 Loss 2.0157\n",
      "Epoch 1 Batch 2031 Loss 1.0843\n",
      "Epoch 1 Batch 2032 Loss 1.9422\n",
      "Epoch 1 Batch 2033 Loss 1.6258\n",
      "Epoch 1 Batch 2034 Loss 1.7018\n",
      "Epoch 1 Batch 2035 Loss 1.9049\n",
      "Epoch 1 Batch 2036 Loss 1.6693\n",
      "Epoch 1 Batch 2037 Loss 1.7392\n",
      "Epoch 1 Batch 2038 Loss 1.7908\n",
      "Epoch 1 Batch 2039 Loss 1.4720\n",
      "Epoch 1 Batch 2040 Loss 1.4666\n",
      "Epoch 1 Batch 2041 Loss 2.0575\n",
      "Epoch 1 Batch 2042 Loss 1.6703\n",
      "Epoch 1 Batch 2043 Loss 1.7522\n",
      "Epoch 1 Batch 2044 Loss 2.2644\n",
      "Epoch 1 Batch 2045 Loss 1.9906\n",
      "Epoch 1 Batch 2046 Loss 1.6437\n",
      "Epoch 1 Batch 2047 Loss 1.5073\n",
      "Epoch 1 Batch 2048 Loss 1.9684\n",
      "Epoch 1 Batch 2049 Loss 1.6957\n",
      "Epoch 1 Batch 2050 Loss 1.6475\n",
      "Epoch 1 Batch 2051 Loss 1.3867\n",
      "Epoch 1 Batch 2052 Loss 1.5415\n",
      "Epoch 1 Batch 2053 Loss 1.4451\n",
      "Epoch 1 Batch 2054 Loss 1.7898\n",
      "Epoch 1 Batch 2055 Loss 2.3506\n",
      "Epoch 1 Batch 2056 Loss 1.8644\n",
      "Epoch 1 Batch 2057 Loss 1.3243\n",
      "Epoch 1 Batch 2058 Loss 1.8359\n",
      "Epoch 1 Batch 2059 Loss 1.8817\n",
      "Epoch 1 Batch 2060 Loss 1.9427\n",
      "Epoch 1 Batch 2061 Loss 1.6435\n",
      "Epoch 1 Batch 2062 Loss 2.4067\n",
      "Epoch 1 Batch 2063 Loss 1.5770\n",
      "Epoch 1 Batch 2064 Loss 1.8550\n",
      "Epoch 1 Batch 2065 Loss 1.6467\n",
      "Epoch 1 Batch 2066 Loss 1.6329\n",
      "Epoch 1 Batch 2067 Loss 1.5943\n",
      "Epoch 1 Batch 2068 Loss 1.2131\n",
      "Epoch 1 Batch 2069 Loss 1.8628\n",
      "Epoch 1 Batch 2070 Loss 1.5229\n",
      "Epoch 1 Batch 2071 Loss 1.7027\n",
      "Epoch 1 Batch 2072 Loss 1.9352\n",
      "Epoch 1 Batch 2073 Loss 1.3818\n",
      "Epoch 1 Batch 2074 Loss 1.6135\n",
      "Epoch 1 Batch 2075 Loss 1.7476\n",
      "Epoch 1 Batch 2076 Loss 1.6748\n",
      "Epoch 1 Batch 2077 Loss 1.7439\n",
      "Epoch 1 Batch 2078 Loss 1.5819\n",
      "Epoch 1 Batch 2079 Loss 1.6328\n",
      "Epoch 1 Batch 2080 Loss 2.0375\n",
      "Epoch 1 Batch 2081 Loss 1.2947\n",
      "Epoch 1 Batch 2082 Loss 1.8528\n",
      "Epoch 1 Batch 2083 Loss 1.5601\n",
      "Epoch 1 Batch 2084 Loss 2.1220\n",
      "Epoch 1 Batch 2085 Loss 1.3784\n",
      "Epoch 1 Batch 2086 Loss 1.7644\n",
      "Epoch 1 Batch 2087 Loss 1.8367\n",
      "Epoch 1 Batch 2088 Loss 1.8344\n",
      "Epoch 1 Batch 2089 Loss 1.8062\n",
      "Epoch 1 Batch 2090 Loss 1.8852\n",
      "Epoch 1 Batch 2091 Loss 1.4390\n",
      "Epoch 1 Batch 2092 Loss 1.8874\n",
      "Epoch 1 Batch 2093 Loss 1.9551\n",
      "Epoch 1 Batch 2094 Loss 1.7373\n",
      "Epoch 1 Batch 2095 Loss 1.3887\n",
      "Epoch 1 Batch 2096 Loss 1.5720\n",
      "Epoch 1 Batch 2097 Loss 1.6751\n",
      "Epoch 1 Batch 2098 Loss 1.8771\n",
      "Epoch 1 Batch 2099 Loss 1.4514\n",
      "Epoch 1 Batch 2100 Loss 1.5298\n",
      "Epoch 1 Batch 2101 Loss 1.6839\n",
      "Epoch 1 Batch 2102 Loss 1.7056\n",
      "Epoch 1 Batch 2103 Loss 1.5423\n",
      "Epoch 1 Batch 2104 Loss 1.8006\n",
      "Epoch 1 Batch 2105 Loss 1.6031\n",
      "Epoch 1 Batch 2106 Loss 2.0922\n",
      "Epoch 1 Batch 2107 Loss 1.4559\n",
      "Epoch 1 Batch 2108 Loss 1.6854\n",
      "Epoch 1 Batch 2109 Loss 1.5080\n",
      "Epoch 1 Batch 2110 Loss 1.6983\n",
      "Epoch 1 Batch 2111 Loss 1.8974\n",
      "Epoch 1 Batch 2112 Loss 1.9770\n",
      "Epoch 1 Batch 2113 Loss 1.7005\n",
      "Epoch 1 Batch 2114 Loss 1.6605\n",
      "Epoch 1 Batch 2115 Loss 1.6721\n",
      "Epoch 1 Batch 2116 Loss 1.7573\n",
      "Epoch 1 Batch 2117 Loss 1.9589\n",
      "Epoch 1 Batch 2118 Loss 1.3030\n",
      "Epoch 1 Batch 2119 Loss 1.3038\n",
      "Epoch 1 Batch 2120 Loss 2.1462\n",
      "Epoch 1 Batch 2121 Loss 1.5530\n",
      "Epoch 1 Batch 2122 Loss 1.9556\n",
      "Epoch 1 Batch 2123 Loss 1.6267\n",
      "Epoch 1 Batch 2124 Loss 1.5951\n",
      "Epoch 1 Batch 2125 Loss 1.7308\n",
      "Epoch 1 Batch 2126 Loss 1.9764\n",
      "Epoch 1 Batch 2127 Loss 2.0222\n",
      "Epoch 1 Batch 2128 Loss 1.9177\n",
      "Epoch 1 Batch 2129 Loss 1.4175\n",
      "Epoch 1 Batch 2130 Loss 1.8042\n",
      "Epoch 1 Batch 2131 Loss 1.3462\n",
      "Epoch 1 Batch 2132 Loss 1.6404\n",
      "Epoch 1 Batch 2133 Loss 1.5739\n",
      "Epoch 1 Batch 2134 Loss 1.8685\n",
      "Epoch 1 Batch 2135 Loss 2.0752\n",
      "Epoch 1 Batch 2136 Loss 1.8040\n",
      "Epoch 1 Batch 2137 Loss 1.9030\n",
      "Epoch 1 Batch 2138 Loss 1.7278\n",
      "Epoch 1 Batch 2139 Loss 2.0992\n",
      "Epoch 1 Batch 2140 Loss 1.9969\n",
      "Epoch 1 Batch 2141 Loss 1.7370\n",
      "Epoch 1 Batch 2142 Loss 1.5139\n",
      "Epoch 1 Batch 2143 Loss 1.5074\n",
      "Epoch 1 Batch 2144 Loss 1.6127\n",
      "Epoch 1 Batch 2145 Loss 1.8928\n",
      "Epoch 1 Batch 2146 Loss 1.5599\n",
      "Epoch 1 Batch 2147 Loss 1.8450\n",
      "Epoch 1 Batch 2148 Loss 1.4463\n",
      "Epoch 1 Batch 2149 Loss 1.5505\n",
      "Epoch 1 Batch 2150 Loss 1.7163\n",
      "Epoch 1 Batch 2151 Loss 1.5302\n",
      "Epoch 1 Batch 2152 Loss 1.6372\n",
      "Epoch 1 Batch 2153 Loss 1.3309\n",
      "Epoch 1 Batch 2154 Loss 2.4624\n",
      "Epoch 1 Batch 2155 Loss 1.6207\n",
      "Epoch 1 Batch 2156 Loss 1.4925\n",
      "Epoch 1 Batch 2157 Loss 1.6393\n",
      "Epoch 1 Batch 2158 Loss 1.5233\n",
      "Epoch 1 Batch 2159 Loss 1.9781\n",
      "Epoch 1 Batch 2160 Loss 1.7293\n",
      "Epoch 1 Batch 2161 Loss 1.4364\n",
      "Epoch 1 Batch 2162 Loss 2.1027\n",
      "Epoch 1 Batch 2163 Loss 1.4673\n",
      "Epoch 1 Batch 2164 Loss 1.6365\n",
      "Epoch 1 Batch 2165 Loss 1.6687\n",
      "Epoch 1 Batch 2166 Loss 1.5786\n",
      "Epoch 1 Batch 2167 Loss 1.9346\n",
      "Epoch 1 Batch 2168 Loss 1.8042\n",
      "Epoch 1 Batch 2169 Loss 1.7192\n",
      "Epoch 1 Batch 2170 Loss 1.8528\n",
      "Epoch 1 Batch 2171 Loss 1.8772\n",
      "Epoch 1 Batch 2172 Loss 1.8171\n",
      "Epoch 1 Batch 2173 Loss 1.6049\n",
      "Epoch 1 Batch 2174 Loss 1.8241\n",
      "Epoch 1 Batch 2175 Loss 1.9885\n",
      "Epoch 1 Batch 2176 Loss 1.6351\n",
      "Epoch 1 Batch 2177 Loss 1.6467\n",
      "Epoch 1 Batch 2178 Loss 1.6913\n",
      "Epoch 1 Batch 2179 Loss 2.0593\n",
      "Epoch 1 Batch 2180 Loss 1.7977\n",
      "Epoch 1 Batch 2181 Loss 1.6666\n",
      "Epoch 1 Batch 2182 Loss 1.3051\n",
      "Epoch 1 Batch 2183 Loss 1.6614\n",
      "Epoch 1 Batch 2184 Loss 1.4705\n",
      "Epoch 1 Batch 2185 Loss 1.8329\n",
      "Epoch 1 Batch 2186 Loss 1.2992\n",
      "Epoch 1 Batch 2187 Loss 1.6568\n",
      "Epoch 1 Batch 2188 Loss 1.4703\n",
      "Epoch 1 Batch 2189 Loss 2.2617\n",
      "Epoch 1 Batch 2190 Loss 1.9179\n",
      "Epoch 1 Batch 2191 Loss 1.8920\n",
      "Epoch 1 Batch 2192 Loss 1.7730\n",
      "Epoch 1 Batch 2193 Loss 1.3127\n",
      "Epoch 1 Batch 2194 Loss 1.5919\n",
      "Epoch 1 Batch 2195 Loss 2.1308\n",
      "Epoch 1 Batch 2196 Loss 1.5166\n",
      "Epoch 1 Batch 2197 Loss 1.6995\n",
      "Epoch 1 Batch 2198 Loss 1.7577\n",
      "Epoch 1 Batch 2199 Loss 1.5609\n",
      "Epoch 1 Batch 2200 Loss 1.9258\n",
      "Epoch 1 Batch 2201 Loss 1.7990\n",
      "Epoch 1 Batch 2202 Loss 2.0393\n",
      "Epoch 1 Batch 2203 Loss 1.7003\n",
      "Epoch 1 Batch 2204 Loss 1.6041\n",
      "Epoch 1 Batch 2205 Loss 1.3857\n",
      "Epoch 1 Batch 2206 Loss 1.2269\n",
      "Epoch 1 Batch 2207 Loss 1.7965\n",
      "Epoch 1 Batch 2208 Loss 1.9102\n",
      "Epoch 1 Batch 2209 Loss 1.2825\n",
      "Epoch 1 Batch 2210 Loss 1.6605\n",
      "Epoch 1 Batch 2211 Loss 1.4084\n",
      "Epoch 1 Batch 2212 Loss 1.5471\n",
      "Epoch 1 Batch 2213 Loss 2.0065\n",
      "Epoch 1 Batch 2214 Loss 1.5870\n",
      "Epoch 1 Batch 2215 Loss 1.7624\n",
      "Epoch 1 Batch 2216 Loss 2.0239\n",
      "Epoch 1 Batch 2217 Loss 1.8359\n",
      "Epoch 1 Batch 2218 Loss 1.6093\n",
      "Epoch 1 Batch 2219 Loss 1.5864\n",
      "Epoch 1 Batch 2220 Loss 1.5296\n",
      "Epoch 1 Batch 2221 Loss 1.6517\n",
      "Epoch 1 Batch 2222 Loss 1.8311\n",
      "Epoch 1 Batch 2223 Loss 1.7630\n",
      "Epoch 1 Batch 2224 Loss 1.5553\n",
      "Epoch 1 Batch 2225 Loss 1.6409\n",
      "Epoch 1 Batch 2226 Loss 1.6926\n",
      "Epoch 1 Batch 2227 Loss 1.9722\n",
      "Epoch 1 Batch 2228 Loss 1.5143\n",
      "Epoch 1 Batch 2229 Loss 1.8530\n",
      "Epoch 1 Batch 2230 Loss 1.7834\n",
      "Epoch 1 Batch 2231 Loss 2.1053\n",
      "Epoch 1 Batch 2232 Loss 1.3036\n",
      "Epoch 1 Batch 2233 Loss 1.7123\n",
      "Epoch 1 Batch 2234 Loss 1.6847\n",
      "Epoch 1 Batch 2235 Loss 1.6198\n",
      "Epoch 1 Batch 2236 Loss 1.7700\n",
      "Epoch 1 Batch 2237 Loss 1.7173\n",
      "Epoch 1 Batch 2238 Loss 1.6810\n",
      "Epoch 1 Batch 2239 Loss 1.6869\n",
      "Epoch 1 Batch 2240 Loss 1.9222\n",
      "Epoch 1 Batch 2241 Loss 1.8156\n",
      "Epoch 1 Batch 2242 Loss 1.8734\n",
      "Epoch 1 Batch 2243 Loss 1.5788\n",
      "Epoch 1 Batch 2244 Loss 1.6957\n",
      "Epoch 1 Batch 2245 Loss 1.5698\n",
      "Epoch 1 Batch 2246 Loss 1.9590\n",
      "Epoch 1 Batch 2247 Loss 1.5671\n",
      "Epoch 1 Batch 2248 Loss 1.6819\n",
      "Epoch 1 Batch 2249 Loss 1.9170\n",
      "Epoch 1 Batch 2250 Loss 1.7986\n",
      "Epoch 1 Batch 2251 Loss 1.5246\n",
      "Epoch 1 Batch 2252 Loss 1.8658\n",
      "Epoch 1 Batch 2253 Loss 1.6634\n",
      "Epoch 1 Batch 2254 Loss 1.8088\n",
      "Epoch 1 Batch 2255 Loss 1.5894\n",
      "Epoch 1 Batch 2256 Loss 1.5590\n",
      "Epoch 1 Batch 2257 Loss 1.6899\n",
      "Epoch 1 Batch 2258 Loss 1.7484\n",
      "Epoch 1 Batch 2259 Loss 1.6433\n",
      "Epoch 1 Batch 2260 Loss 1.3883\n",
      "Epoch 1 Batch 2261 Loss 1.6041\n",
      "Epoch 1 Batch 2262 Loss 1.9987\n",
      "Epoch 1 Batch 2263 Loss 1.5021\n",
      "Epoch 1 Batch 2264 Loss 1.7610\n",
      "Epoch 1 Batch 2265 Loss 1.9394\n",
      "Epoch 1 Batch 2266 Loss 1.5986\n",
      "Epoch 1 Batch 2267 Loss 1.6550\n",
      "Epoch 1 Batch 2268 Loss 1.5513\n",
      "Epoch 1 Batch 2269 Loss 1.6830\n",
      "Epoch 1 Batch 2270 Loss 1.9427\n",
      "Epoch 1 Batch 2271 Loss 1.6203\n",
      "Epoch 1 Batch 2272 Loss 1.4581\n",
      "Epoch 1 Batch 2273 Loss 1.4933\n",
      "Epoch 1 Batch 2274 Loss 1.6695\n",
      "Epoch 1 Batch 2275 Loss 1.7522\n",
      "Epoch 1 Batch 2276 Loss 1.7538\n",
      "Epoch 1 Batch 2277 Loss 1.6074\n",
      "Epoch 1 Batch 2278 Loss 2.0337\n",
      "Epoch 1 Batch 2279 Loss 1.3492\n",
      "Epoch 1 Batch 2280 Loss 1.7329\n",
      "Epoch 1 Batch 2281 Loss 1.8381\n",
      "Epoch 1 Batch 2282 Loss 1.6019\n",
      "Epoch 1 Batch 2283 Loss 1.5334\n",
      "Epoch 1 Batch 2284 Loss 1.7510\n",
      "Epoch 1 Batch 2285 Loss 1.7021\n",
      "Epoch 1 Batch 2286 Loss 1.8218\n",
      "Epoch 1 Batch 2287 Loss 1.7296\n",
      "Epoch 1 Batch 2288 Loss 1.6706\n",
      "Epoch 1 Batch 2289 Loss 1.4827\n",
      "Epoch 1 Batch 2290 Loss 1.6030\n",
      "Epoch 1 Batch 2291 Loss 1.8194\n",
      "Epoch 1 Batch 2292 Loss 1.9429\n",
      "Epoch 1 Batch 2293 Loss 1.5796\n",
      "Epoch 1 Batch 2294 Loss 1.8184\n",
      "Epoch 1 Batch 2295 Loss 1.7026\n",
      "Epoch 1 Batch 2296 Loss 1.3984\n",
      "Epoch 1 Batch 2297 Loss 1.7191\n",
      "Epoch 1 Batch 2298 Loss 1.6395\n",
      "Epoch 1 Batch 2299 Loss 1.9394\n",
      "Epoch 1 Batch 2300 Loss 1.7378\n",
      "Epoch 1 Batch 2301 Loss 1.6471\n",
      "Epoch 1 Batch 2302 Loss 1.9717\n",
      "Epoch 1 Batch 2303 Loss 1.9379\n",
      "Epoch 1 Batch 2304 Loss 1.4036\n",
      "Epoch 1 Batch 2305 Loss 1.9827\n",
      "Epoch 1 Batch 2306 Loss 1.9867\n",
      "Epoch 1 Batch 2307 Loss 1.8515\n",
      "Epoch 1 Batch 2308 Loss 1.6497\n",
      "Epoch 1 Batch 2309 Loss 1.4350\n",
      "Epoch 1 Batch 2310 Loss 1.4871\n",
      "Epoch 1 Batch 2311 Loss 1.8920\n",
      "Epoch 1 Batch 2312 Loss 1.4456\n",
      "Epoch 1 Batch 2313 Loss 1.6772\n",
      "Epoch 1 Batch 2314 Loss 1.8674\n",
      "Epoch 1 Batch 2315 Loss 1.8642\n",
      "Epoch 1 Batch 2316 Loss 2.0795\n",
      "Epoch 1 Batch 2317 Loss 1.8201\n",
      "Epoch 1 Batch 2318 Loss 1.5915\n",
      "Epoch 1 Batch 2319 Loss 1.6427\n",
      "Epoch 1 Batch 2320 Loss 1.8362\n",
      "Epoch 1 Batch 2321 Loss 2.1053\n",
      "Epoch 1 Batch 2322 Loss 1.7901\n",
      "Epoch 1 Batch 2323 Loss 1.7729\n",
      "Epoch 1 Batch 2324 Loss 1.6276\n",
      "Epoch 1 Batch 2325 Loss 1.9754\n",
      "Epoch 1 Batch 2326 Loss 1.7261\n",
      "Epoch 1 Batch 2327 Loss 1.6245\n",
      "Epoch 1 Batch 2328 Loss 1.7269\n",
      "Epoch 1 Batch 2329 Loss 2.0341\n",
      "Epoch 1 Batch 2330 Loss 2.3101\n",
      "Epoch 1 Batch 2331 Loss 1.2545\n",
      "Epoch 1 Batch 2332 Loss 1.6965\n",
      "Epoch 1 Batch 2333 Loss 1.7368\n",
      "Epoch 1 Batch 2334 Loss 1.4593\n",
      "Epoch 1 Batch 2335 Loss 1.3493\n",
      "Epoch 1 Batch 2336 Loss 1.3741\n",
      "Epoch 1 Batch 2337 Loss 1.6256\n",
      "Epoch 1 Batch 2338 Loss 1.3622\n",
      "Epoch 1 Batch 2339 Loss 1.7824\n",
      "Epoch 1 Batch 2340 Loss 1.8118\n",
      "Epoch 1 Batch 2341 Loss 1.5368\n",
      "Epoch 1 Batch 2342 Loss 1.5865\n",
      "Epoch 1 Batch 2343 Loss 1.5729\n",
      "Epoch 1 Batch 2344 Loss 2.0290\n",
      "Epoch 1 Batch 2345 Loss 1.8349\n",
      "Epoch 1 Batch 2346 Loss 1.5655\n",
      "Epoch 1 Batch 2347 Loss 1.7903\n",
      "Epoch 1 Batch 2348 Loss 1.8808\n",
      "Epoch 1 Batch 2349 Loss 2.2111\n",
      "Epoch 1 Batch 2350 Loss 1.6762\n",
      "Epoch 1 Batch 2351 Loss 1.4332\n",
      "Epoch 1 Batch 2352 Loss 1.5038\n",
      "Epoch 1 Batch 2353 Loss 1.4983\n",
      "Epoch 1 Batch 2354 Loss 1.5207\n",
      "Epoch 1 Batch 2355 Loss 1.8911\n",
      "Epoch 1 Batch 2356 Loss 1.8250\n",
      "Epoch 1 Batch 2357 Loss 1.2868\n",
      "Epoch 1 Batch 2358 Loss 1.4169\n",
      "Epoch 1 Batch 2359 Loss 1.8700\n",
      "Epoch 1 Batch 2360 Loss 1.8357\n",
      "Epoch 1 Batch 2361 Loss 1.7881\n",
      "Epoch 1 Batch 2362 Loss 1.7068\n",
      "Epoch 1 Batch 2363 Loss 1.6476\n",
      "Epoch 1 Batch 2364 Loss 1.2188\n",
      "Epoch 1 Batch 2365 Loss 1.7682\n",
      "Epoch 1 Batch 2366 Loss 1.4455\n",
      "Epoch 1 Batch 2367 Loss 1.4876\n",
      "Epoch 1 Batch 2368 Loss 1.5405\n",
      "Epoch 1 Batch 2369 Loss 1.7262\n",
      "Epoch 1 Batch 2370 Loss 2.0396\n",
      "Epoch 1 Batch 2371 Loss 2.1701\n",
      "Epoch 1 Batch 2372 Loss 1.5854\n",
      "Epoch 1 Batch 2373 Loss 1.8249\n",
      "Epoch 1 Batch 2374 Loss 1.8001\n",
      "Epoch 1 Batch 2375 Loss 1.5369\n",
      "Epoch 1 Batch 2376 Loss 1.3137\n",
      "Epoch 1 Batch 2377 Loss 1.5285\n",
      "Epoch 1 Batch 2378 Loss 1.3810\n",
      "Epoch 1 Batch 2379 Loss 1.7332\n",
      "Epoch 1 Batch 2380 Loss 1.6115\n",
      "Epoch 1 Batch 2381 Loss 1.5278\n",
      "Epoch 1 Batch 2382 Loss 1.3900\n",
      "Epoch 1 Batch 2383 Loss 1.8432\n",
      "Epoch 1 Batch 2384 Loss 1.4410\n",
      "Epoch 1 Batch 2385 Loss 1.6819\n",
      "Epoch 1 Batch 2386 Loss 1.6765\n",
      "Epoch 1 Batch 2387 Loss 1.7902\n",
      "Epoch 1 Batch 2388 Loss 1.5473\n",
      "Epoch 1 Batch 2389 Loss 1.7571\n",
      "Epoch 1 Batch 2390 Loss 1.7409\n",
      "Epoch 1 Batch 2391 Loss 1.6844\n",
      "Epoch 1 Batch 2392 Loss 1.7799\n",
      "Epoch 1 Batch 2393 Loss 1.6775\n",
      "Epoch 1 Batch 2394 Loss 1.3498\n",
      "Epoch 1 Batch 2395 Loss 1.8155\n",
      "Epoch 1 Batch 2396 Loss 1.4013\n",
      "Epoch 1 Batch 2397 Loss 1.5222\n",
      "Epoch 1 Batch 2398 Loss 1.6626\n",
      "Epoch 1 Batch 2399 Loss 2.0315\n",
      "Epoch 1 Batch 2400 Loss 1.4410\n",
      "Epoch 1 Batch 2401 Loss 1.5726\n",
      "Epoch 1 Batch 2402 Loss 2.0158\n",
      "Epoch 1 Batch 2403 Loss 2.3357\n",
      "Epoch 1 Batch 2404 Loss 1.8678\n",
      "Epoch 1 Batch 2405 Loss 1.4662\n",
      "Epoch 1 Batch 2406 Loss 1.3710\n",
      "Epoch 1 Batch 2407 Loss 1.4771\n",
      "Epoch 1 Batch 2408 Loss 1.7957\n",
      "Epoch 1 Batch 2409 Loss 1.7188\n",
      "Epoch 1 Batch 2410 Loss 1.8729\n",
      "Epoch 1 Batch 2411 Loss 1.5463\n",
      "Epoch 1 Batch 2412 Loss 1.7798\n",
      "Epoch 1 Batch 2413 Loss 1.3540\n",
      "Epoch 1 Batch 2414 Loss 1.8308\n",
      "Epoch 1 Batch 2415 Loss 1.7436\n",
      "Epoch 1 Batch 2416 Loss 1.7021\n",
      "Epoch 1 Batch 2417 Loss 1.4774\n",
      "Epoch 1 Batch 2418 Loss 1.4951\n",
      "Epoch 1 Batch 2419 Loss 1.3191\n",
      "Epoch 1 Batch 2420 Loss 1.4748\n",
      "Epoch 1 Batch 2421 Loss 1.5081\n",
      "Epoch 1 Batch 2422 Loss 1.4304\n",
      "Epoch 1 Batch 2423 Loss 1.6710\n",
      "Epoch 1 Batch 2424 Loss 1.3715\n",
      "Epoch 1 Batch 2425 Loss 1.6057\n",
      "Epoch 1 Batch 2426 Loss 1.8739\n",
      "Epoch 1 Batch 2427 Loss 1.7040\n",
      "Epoch 1 Batch 2428 Loss 1.8403\n",
      "Epoch 1 Batch 2429 Loss 1.9325\n",
      "Epoch 1 Batch 2430 Loss 1.7773\n",
      "Epoch 1 Batch 2431 Loss 1.7155\n",
      "Epoch 1 Batch 2432 Loss 1.8467\n",
      "Epoch 1 Batch 2433 Loss 1.5098\n",
      "Epoch 1 Batch 2434 Loss 1.8802\n",
      "Epoch 1 Batch 2435 Loss 1.6984\n",
      "Epoch 1 Batch 2436 Loss 1.4677\n",
      "Epoch 1 Batch 2437 Loss 1.5578\n",
      "Epoch 1 Batch 2438 Loss 1.2510\n",
      "Epoch 1 Batch 2439 Loss 1.6366\n",
      "Epoch 1 Batch 2440 Loss 1.6647\n",
      "Epoch 1 Batch 2441 Loss 1.7045\n",
      "Epoch 1 Batch 2442 Loss 1.5216\n",
      "Epoch 1 Batch 2443 Loss 1.7541\n",
      "Epoch 1 Batch 2444 Loss 1.7466\n",
      "Epoch 1 Batch 2445 Loss 1.5243\n",
      "Epoch 1 Batch 2446 Loss 1.5764\n",
      "Epoch 1 Batch 2447 Loss 1.7274\n",
      "Epoch 1 Batch 2448 Loss 1.7198\n",
      "Epoch 1 Batch 2449 Loss 1.5396\n",
      "Epoch 1 Batch 2450 Loss 1.5804\n",
      "Epoch 1 Batch 2451 Loss 1.9942\n",
      "Epoch 1 Batch 2452 Loss 1.5245\n",
      "Epoch 1 Batch 2453 Loss 1.2583\n",
      "Epoch 1 Batch 2454 Loss 1.7863\n",
      "Epoch 1 Batch 2455 Loss 1.9484\n",
      "Epoch 1 Batch 2456 Loss 1.7210\n",
      "Epoch 1 Batch 2457 Loss 1.9537\n",
      "Epoch 1 Batch 2458 Loss 1.5882\n",
      "Epoch 1 Batch 2459 Loss 1.5153\n",
      "Epoch 1 Batch 2460 Loss 1.9515\n",
      "Epoch 1 Batch 2461 Loss 1.6428\n",
      "Epoch 1 Batch 2462 Loss 1.5513\n",
      "Epoch 1 Batch 2463 Loss 1.6580\n",
      "Epoch 1 Batch 2464 Loss 1.6155\n",
      "Epoch 1 Batch 2465 Loss 1.7338\n",
      "Epoch 1 Batch 2466 Loss 1.3430\n",
      "Epoch 1 Batch 2467 Loss 1.6414\n",
      "Epoch 1 Batch 2468 Loss 1.6642\n",
      "Epoch 1 Batch 2469 Loss 1.6250\n",
      "Epoch 1 Batch 2470 Loss 1.7006\n",
      "Epoch 1 Batch 2471 Loss 1.6355\n",
      "Epoch 1 Batch 2472 Loss 1.7669\n",
      "Epoch 1 Batch 2473 Loss 1.8004\n",
      "Epoch 1 Batch 2474 Loss 1.3930\n",
      "Epoch 1 Batch 2475 Loss 2.0180\n",
      "Epoch 1 Batch 2476 Loss 1.9955\n",
      "Epoch 1 Batch 2477 Loss 1.9523\n",
      "Epoch 1 Batch 2478 Loss 1.8164\n",
      "Epoch 1 Batch 2479 Loss 1.3642\n",
      "Epoch 1 Batch 2480 Loss 1.5180\n",
      "Epoch 1 Batch 2481 Loss 1.5823\n",
      "Epoch 1 Batch 2482 Loss 1.6768\n",
      "Epoch 1 Batch 2483 Loss 1.7154\n",
      "Epoch 1 Batch 2484 Loss 1.6852\n",
      "Epoch 1 Batch 2485 Loss 1.6822\n",
      "Epoch 1 Batch 2486 Loss 1.7137\n",
      "Epoch 1 Batch 2487 Loss 1.6181\n",
      "Epoch 1 Batch 2488 Loss 1.7257\n",
      "Epoch 1 Batch 2489 Loss 1.5987\n",
      "Epoch 1 Batch 2490 Loss 1.8518\n",
      "Epoch 1 Batch 2491 Loss 1.7456\n",
      "Epoch 1 Batch 2492 Loss 1.4013\n",
      "Epoch 1 Batch 2493 Loss 1.8361\n",
      "Epoch 1 Batch 2494 Loss 1.4304\n",
      "Epoch 1 Batch 2495 Loss 1.7715\n",
      "Epoch 1 Batch 2496 Loss 1.7433\n",
      "Epoch 1 Batch 2497 Loss 1.6181\n",
      "Epoch 1 Batch 2498 Loss 1.7378\n",
      "Epoch 1 Batch 2499 Loss 1.8006\n",
      "Epoch 1 Batch 2500 Loss 1.6958\n",
      "Epoch 1 Batch 2501 Loss 1.4834\n",
      "Epoch 1 Batch 2502 Loss 1.6726\n",
      "Epoch 1 Batch 2503 Loss 1.5736\n",
      "Epoch 1 Batch 2504 Loss 1.8254\n",
      "Epoch 1 Batch 2505 Loss 1.3030\n",
      "Epoch 1 Batch 2506 Loss 1.9417\n",
      "Epoch 1 Batch 2507 Loss 1.8911\n",
      "Epoch 1 Batch 2508 Loss 1.6166\n",
      "Epoch 1 Batch 2509 Loss 1.7083\n",
      "Epoch 1 Batch 2510 Loss 2.0293\n",
      "Epoch 1 Batch 2511 Loss 1.4885\n",
      "Epoch 1 Batch 2512 Loss 1.5372\n",
      "Epoch 1 Batch 2513 Loss 2.0168\n",
      "Epoch 1 Batch 2514 Loss 1.5238\n",
      "Epoch 1 Batch 2515 Loss 1.6827\n",
      "Epoch 1 Batch 2516 Loss 1.8575\n",
      "Epoch 1 Batch 2517 Loss 1.5155\n",
      "Epoch 1 Batch 2518 Loss 1.7816\n",
      "Epoch 1 Batch 2519 Loss 1.6113\n",
      "Epoch 1 Batch 2520 Loss 1.7447\n",
      "Epoch 1 Batch 2521 Loss 1.6839\n",
      "Epoch 1 Batch 2522 Loss 1.5017\n",
      "Epoch 1 Batch 2523 Loss 1.5353\n",
      "Epoch 1 Batch 2524 Loss 1.2937\n",
      "Epoch 1 Batch 2525 Loss 1.2866\n",
      "Epoch 1 Batch 2526 Loss 1.3919\n",
      "Epoch 1 Batch 2527 Loss 1.7022\n",
      "Epoch 1 Batch 2528 Loss 1.4173\n",
      "Epoch 1 Batch 2529 Loss 1.8493\n",
      "Epoch 1 Batch 2530 Loss 1.6251\n",
      "Epoch 1 Batch 2531 Loss 1.4042\n",
      "Epoch 1 Batch 2532 Loss 1.6974\n",
      "Epoch 1 Batch 2533 Loss 1.4723\n",
      "Epoch 1 Batch 2534 Loss 1.7178\n",
      "Epoch 1 Batch 2535 Loss 1.7423\n",
      "Epoch 1 Batch 2536 Loss 1.9702\n",
      "Epoch 1 Batch 2537 Loss 1.8462\n",
      "Epoch 1 Batch 2538 Loss 1.6452\n",
      "Epoch 1 Batch 2539 Loss 1.8603\n",
      "Epoch 1 Batch 2540 Loss 1.4714\n",
      "Epoch 1 Batch 2541 Loss 1.3000\n",
      "Epoch 1 Batch 2542 Loss 1.8752\n",
      "Epoch 1 Batch 2543 Loss 1.8440\n",
      "Epoch 1 Batch 2544 Loss 1.7684\n",
      "Epoch 1 Batch 2545 Loss 1.5875\n",
      "Epoch 1 Batch 2546 Loss 1.5628\n",
      "Epoch 1 Batch 2547 Loss 1.4089\n",
      "Epoch 1 Batch 2548 Loss 1.7076\n",
      "Epoch 1 Batch 2549 Loss 1.8174\n",
      "Epoch 1 Batch 2550 Loss 1.4978\n",
      "Epoch 1 Batch 2551 Loss 1.7501\n",
      "Epoch 1 Batch 2552 Loss 1.6630\n",
      "Epoch 1 Batch 2553 Loss 1.7264\n",
      "Epoch 1 Batch 2554 Loss 1.6199\n",
      "Epoch 1 Batch 2555 Loss 1.8553\n",
      "Epoch 1 Batch 2556 Loss 1.6763\n",
      "Epoch 1 Batch 2557 Loss 1.4618\n",
      "Epoch 1 Batch 2558 Loss 2.2329\n",
      "Epoch 1 Batch 2559 Loss 1.5847\n",
      "Epoch 1 Batch 2560 Loss 1.6435\n",
      "Epoch 1 Batch 2561 Loss 2.0603\n",
      "Epoch 1 Batch 2562 Loss 2.0604\n",
      "Epoch 1 Batch 2563 Loss 1.8371\n",
      "Epoch 1 Batch 2564 Loss 1.7202\n",
      "Epoch 1 Batch 2565 Loss 1.4908\n",
      "Epoch 1 Batch 2566 Loss 1.8062\n",
      "Epoch 1 Batch 2567 Loss 1.5431\n",
      "Epoch 1 Batch 2568 Loss 1.0625\n",
      "Epoch 1 Batch 2569 Loss 1.9783\n",
      "Epoch 1 Batch 2570 Loss 1.7081\n",
      "Epoch 1 Batch 2571 Loss 1.7052\n",
      "Epoch 1 Batch 2572 Loss 2.0233\n",
      "Epoch 1 Batch 2573 Loss 1.5956\n",
      "Epoch 1 Batch 2574 Loss 1.4027\n",
      "Epoch 1 Batch 2575 Loss 1.7758\n",
      "Epoch 1 Batch 2576 Loss 1.5027\n",
      "Epoch 1 Batch 2577 Loss 1.3790\n",
      "Epoch 1 Batch 2578 Loss 1.4881\n",
      "Epoch 1 Batch 2579 Loss 1.9881\n",
      "Epoch 1 Batch 2580 Loss 1.8470\n",
      "Epoch 1 Batch 2581 Loss 1.6899\n",
      "Epoch 1 Batch 2582 Loss 1.7060\n",
      "Epoch 1 Batch 2583 Loss 1.4806\n",
      "Epoch 1 Batch 2584 Loss 1.4710\n",
      "Epoch 1 Batch 2585 Loss 1.7424\n",
      "Epoch 1 Batch 2586 Loss 1.6219\n",
      "Epoch 1 Batch 2587 Loss 1.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [31:43<2:06:55, 1903.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 2588 Loss 1.6616\n",
      "Epoch 1 Loss 2.0747\n",
      "Time taken for 1 epoch 1903.8640513420105 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4060\n",
      "Epoch 2 Batch 1 Loss 1.5046\n",
      "Epoch 2 Batch 2 Loss 1.7824\n",
      "Epoch 2 Batch 3 Loss 1.6180\n",
      "Epoch 2 Batch 4 Loss 1.3900\n",
      "Epoch 2 Batch 5 Loss 1.5274\n",
      "Epoch 2 Batch 6 Loss 1.4689\n",
      "Epoch 2 Batch 7 Loss 1.6016\n",
      "Epoch 2 Batch 8 Loss 1.7601\n",
      "Epoch 2 Batch 9 Loss 1.5479\n",
      "Epoch 2 Batch 10 Loss 1.5457\n",
      "Epoch 2 Batch 11 Loss 1.4731\n",
      "Epoch 2 Batch 12 Loss 1.5464\n",
      "Epoch 2 Batch 13 Loss 1.5668\n",
      "Epoch 2 Batch 14 Loss 1.2727\n",
      "Epoch 2 Batch 15 Loss 1.9397\n",
      "Epoch 2 Batch 16 Loss 1.5340\n",
      "Epoch 2 Batch 17 Loss 1.8146\n",
      "Epoch 2 Batch 18 Loss 1.5237\n",
      "Epoch 2 Batch 19 Loss 1.4616\n",
      "Epoch 2 Batch 20 Loss 1.4876\n",
      "Epoch 2 Batch 21 Loss 1.8566\n",
      "Epoch 2 Batch 22 Loss 1.4997\n",
      "Epoch 2 Batch 23 Loss 1.4830\n",
      "Epoch 2 Batch 24 Loss 1.6625\n",
      "Epoch 2 Batch 25 Loss 1.7048\n",
      "Epoch 2 Batch 26 Loss 1.6521\n",
      "Epoch 2 Batch 27 Loss 1.4231\n",
      "Epoch 2 Batch 28 Loss 1.5939\n",
      "Epoch 2 Batch 29 Loss 1.5836\n",
      "Epoch 2 Batch 30 Loss 1.5453\n",
      "Epoch 2 Batch 31 Loss 1.6951\n",
      "Epoch 2 Batch 32 Loss 1.5902\n",
      "Epoch 2 Batch 33 Loss 1.7341\n",
      "Epoch 2 Batch 34 Loss 1.5908\n",
      "Epoch 2 Batch 35 Loss 1.7407\n",
      "Epoch 2 Batch 36 Loss 1.5717\n",
      "Epoch 2 Batch 37 Loss 1.5800\n",
      "Epoch 2 Batch 38 Loss 1.3950\n",
      "Epoch 2 Batch 39 Loss 1.8736\n",
      "Epoch 2 Batch 40 Loss 1.2978\n",
      "Epoch 2 Batch 41 Loss 1.6566\n",
      "Epoch 2 Batch 42 Loss 1.4551\n",
      "Epoch 2 Batch 43 Loss 1.5308\n",
      "Epoch 2 Batch 44 Loss 1.7196\n",
      "Epoch 2 Batch 45 Loss 1.2369\n",
      "Epoch 2 Batch 46 Loss 1.6889\n",
      "Epoch 2 Batch 47 Loss 1.3483\n",
      "Epoch 2 Batch 48 Loss 1.5071\n",
      "Epoch 2 Batch 49 Loss 1.7139\n",
      "Epoch 2 Batch 50 Loss 1.4838\n",
      "Epoch 2 Batch 51 Loss 1.6934\n",
      "Epoch 2 Batch 52 Loss 1.6978\n",
      "Epoch 2 Batch 53 Loss 1.2935\n",
      "Epoch 2 Batch 54 Loss 1.7729\n",
      "Epoch 2 Batch 55 Loss 1.3774\n",
      "Epoch 2 Batch 56 Loss 1.4661\n",
      "Epoch 2 Batch 57 Loss 1.5433\n",
      "Epoch 2 Batch 58 Loss 1.6087\n",
      "Epoch 2 Batch 59 Loss 1.5161\n",
      "Epoch 2 Batch 60 Loss 1.7957\n",
      "Epoch 2 Batch 61 Loss 1.4281\n",
      "Epoch 2 Batch 62 Loss 1.6094\n",
      "Epoch 2 Batch 63 Loss 1.6070\n",
      "Epoch 2 Batch 64 Loss 1.7479\n",
      "Epoch 2 Batch 65 Loss 1.2357\n",
      "Epoch 2 Batch 66 Loss 1.5558\n",
      "Epoch 2 Batch 67 Loss 1.3824\n",
      "Epoch 2 Batch 68 Loss 1.7697\n",
      "Epoch 2 Batch 69 Loss 1.9189\n",
      "Epoch 2 Batch 70 Loss 1.4828\n",
      "Epoch 2 Batch 71 Loss 1.6428\n",
      "Epoch 2 Batch 72 Loss 1.3993\n",
      "Epoch 2 Batch 73 Loss 1.5378\n",
      "Epoch 2 Batch 74 Loss 1.5070\n",
      "Epoch 2 Batch 75 Loss 1.5004\n",
      "Epoch 2 Batch 76 Loss 1.3362\n",
      "Epoch 2 Batch 77 Loss 1.6226\n",
      "Epoch 2 Batch 78 Loss 1.5705\n",
      "Epoch 2 Batch 79 Loss 2.0315\n",
      "Epoch 2 Batch 80 Loss 1.4831\n",
      "Epoch 2 Batch 81 Loss 1.4449\n",
      "Epoch 2 Batch 82 Loss 1.7041\n",
      "Epoch 2 Batch 83 Loss 1.7700\n",
      "Epoch 2 Batch 84 Loss 1.4458\n",
      "Epoch 2 Batch 85 Loss 1.4620\n",
      "Epoch 2 Batch 86 Loss 1.5691\n",
      "Epoch 2 Batch 87 Loss 1.5306\n",
      "Epoch 2 Batch 88 Loss 1.8730\n",
      "Epoch 2 Batch 89 Loss 1.7022\n",
      "Epoch 2 Batch 90 Loss 1.5319\n",
      "Epoch 2 Batch 91 Loss 1.4788\n",
      "Epoch 2 Batch 92 Loss 1.3533\n",
      "Epoch 2 Batch 93 Loss 1.7801\n",
      "Epoch 2 Batch 94 Loss 1.7558\n",
      "Epoch 2 Batch 95 Loss 1.4920\n",
      "Epoch 2 Batch 96 Loss 1.4498\n",
      "Epoch 2 Batch 97 Loss 1.5896\n",
      "Epoch 2 Batch 98 Loss 1.6224\n",
      "Epoch 2 Batch 99 Loss 1.6470\n",
      "Epoch 2 Batch 100 Loss 1.7712\n",
      "Epoch 2 Batch 101 Loss 1.8616\n",
      "Epoch 2 Batch 102 Loss 1.4267\n",
      "Epoch 2 Batch 103 Loss 1.5419\n",
      "Epoch 2 Batch 104 Loss 1.4309\n",
      "Epoch 2 Batch 105 Loss 1.5824\n",
      "Epoch 2 Batch 106 Loss 1.2112\n",
      "Epoch 2 Batch 107 Loss 1.8156\n",
      "Epoch 2 Batch 108 Loss 1.6510\n",
      "Epoch 2 Batch 109 Loss 1.8880\n",
      "Epoch 2 Batch 110 Loss 1.4651\n",
      "Epoch 2 Batch 111 Loss 1.5484\n",
      "Epoch 2 Batch 112 Loss 1.6463\n",
      "Epoch 2 Batch 113 Loss 1.9026\n",
      "Epoch 2 Batch 114 Loss 1.5074\n",
      "Epoch 2 Batch 115 Loss 1.6263\n",
      "Epoch 2 Batch 116 Loss 1.5517\n",
      "Epoch 2 Batch 117 Loss 1.5336\n",
      "Epoch 2 Batch 118 Loss 1.7689\n",
      "Epoch 2 Batch 119 Loss 1.5595\n",
      "Epoch 2 Batch 120 Loss 1.5223\n",
      "Epoch 2 Batch 121 Loss 1.6849\n",
      "Epoch 2 Batch 122 Loss 1.6550\n",
      "Epoch 2 Batch 123 Loss 1.3963\n",
      "Epoch 2 Batch 124 Loss 1.4334\n",
      "Epoch 2 Batch 125 Loss 1.6630\n",
      "Epoch 2 Batch 126 Loss 1.3966\n",
      "Epoch 2 Batch 127 Loss 1.6241\n",
      "Epoch 2 Batch 128 Loss 1.5070\n",
      "Epoch 2 Batch 129 Loss 1.3253\n",
      "Epoch 2 Batch 130 Loss 1.6605\n",
      "Epoch 2 Batch 131 Loss 1.6227\n",
      "Epoch 2 Batch 132 Loss 1.7457\n",
      "Epoch 2 Batch 133 Loss 1.7417\n",
      "Epoch 2 Batch 134 Loss 1.5612\n",
      "Epoch 2 Batch 135 Loss 1.6207\n",
      "Epoch 2 Batch 136 Loss 1.6659\n",
      "Epoch 2 Batch 137 Loss 1.4306\n",
      "Epoch 2 Batch 138 Loss 1.3581\n",
      "Epoch 2 Batch 139 Loss 1.8468\n",
      "Epoch 2 Batch 140 Loss 1.6660\n",
      "Epoch 2 Batch 141 Loss 1.9198\n",
      "Epoch 2 Batch 142 Loss 1.8474\n",
      "Epoch 2 Batch 143 Loss 2.0365\n",
      "Epoch 2 Batch 144 Loss 1.7743\n",
      "Epoch 2 Batch 145 Loss 1.6385\n",
      "Epoch 2 Batch 146 Loss 1.4239\n",
      "Epoch 2 Batch 147 Loss 1.5815\n",
      "Epoch 2 Batch 148 Loss 1.7652\n",
      "Epoch 2 Batch 149 Loss 1.5037\n",
      "Epoch 2 Batch 150 Loss 1.6921\n",
      "Epoch 2 Batch 151 Loss 1.4261\n",
      "Epoch 2 Batch 152 Loss 1.7100\n",
      "Epoch 2 Batch 153 Loss 1.4906\n",
      "Epoch 2 Batch 154 Loss 1.1995\n",
      "Epoch 2 Batch 155 Loss 1.6585\n",
      "Epoch 2 Batch 156 Loss 1.5013\n",
      "Epoch 2 Batch 157 Loss 1.5124\n",
      "Epoch 2 Batch 158 Loss 1.4261\n",
      "Epoch 2 Batch 159 Loss 1.2975\n",
      "Epoch 2 Batch 160 Loss 1.8948\n",
      "Epoch 2 Batch 161 Loss 1.5139\n",
      "Epoch 2 Batch 162 Loss 1.6667\n",
      "Epoch 2 Batch 163 Loss 1.3926\n",
      "Epoch 2 Batch 164 Loss 1.6157\n",
      "Epoch 2 Batch 165 Loss 1.4755\n",
      "Epoch 2 Batch 166 Loss 1.5266\n",
      "Epoch 2 Batch 167 Loss 1.4907\n",
      "Epoch 2 Batch 168 Loss 1.5079\n",
      "Epoch 2 Batch 169 Loss 1.4521\n",
      "Epoch 2 Batch 170 Loss 1.6341\n",
      "Epoch 2 Batch 171 Loss 1.4566\n",
      "Epoch 2 Batch 172 Loss 1.4530\n",
      "Epoch 2 Batch 173 Loss 1.6933\n",
      "Epoch 2 Batch 174 Loss 1.7589\n",
      "Epoch 2 Batch 175 Loss 1.6057\n",
      "Epoch 2 Batch 176 Loss 1.6486\n",
      "Epoch 2 Batch 177 Loss 1.7812\n",
      "Epoch 2 Batch 178 Loss 1.5013\n",
      "Epoch 2 Batch 179 Loss 1.3143\n",
      "Epoch 2 Batch 180 Loss 1.8595\n",
      "Epoch 2 Batch 181 Loss 1.4977\n",
      "Epoch 2 Batch 182 Loss 1.6204\n",
      "Epoch 2 Batch 183 Loss 1.6767\n",
      "Epoch 2 Batch 184 Loss 1.6133\n",
      "Epoch 2 Batch 185 Loss 1.4898\n",
      "Epoch 2 Batch 186 Loss 1.8643\n",
      "Epoch 2 Batch 187 Loss 1.3883\n",
      "Epoch 2 Batch 188 Loss 1.4664\n",
      "Epoch 2 Batch 189 Loss 1.4511\n",
      "Epoch 2 Batch 190 Loss 1.6456\n",
      "Epoch 2 Batch 191 Loss 1.5016\n",
      "Epoch 2 Batch 192 Loss 1.8513\n",
      "Epoch 2 Batch 193 Loss 1.5941\n",
      "Epoch 2 Batch 194 Loss 1.6722\n",
      "Epoch 2 Batch 195 Loss 1.5922\n",
      "Epoch 2 Batch 196 Loss 1.4910\n",
      "Epoch 2 Batch 197 Loss 1.4300\n",
      "Epoch 2 Batch 198 Loss 1.7287\n",
      "Epoch 2 Batch 199 Loss 1.4152\n",
      "Epoch 2 Batch 200 Loss 1.6094\n",
      "Epoch 2 Batch 201 Loss 1.5832\n",
      "Epoch 2 Batch 202 Loss 1.5013\n",
      "Epoch 2 Batch 203 Loss 1.7583\n",
      "Epoch 2 Batch 204 Loss 1.5075\n",
      "Epoch 2 Batch 205 Loss 1.6956\n",
      "Epoch 2 Batch 206 Loss 1.3577\n",
      "Epoch 2 Batch 207 Loss 1.3218\n",
      "Epoch 2 Batch 208 Loss 1.4414\n",
      "Epoch 2 Batch 209 Loss 1.8474\n",
      "Epoch 2 Batch 210 Loss 1.4583\n",
      "Epoch 2 Batch 211 Loss 1.4759\n",
      "Epoch 2 Batch 212 Loss 1.5431\n",
      "Epoch 2 Batch 213 Loss 1.6127\n",
      "Epoch 2 Batch 214 Loss 1.4652\n",
      "Epoch 2 Batch 215 Loss 1.5878\n",
      "Epoch 2 Batch 216 Loss 1.5166\n",
      "Epoch 2 Batch 217 Loss 1.7228\n",
      "Epoch 2 Batch 218 Loss 1.5420\n",
      "Epoch 2 Batch 219 Loss 1.7581\n",
      "Epoch 2 Batch 220 Loss 1.6306\n",
      "Epoch 2 Batch 221 Loss 1.5580\n",
      "Epoch 2 Batch 222 Loss 1.5083\n",
      "Epoch 2 Batch 223 Loss 1.6860\n",
      "Epoch 2 Batch 224 Loss 1.5149\n",
      "Epoch 2 Batch 225 Loss 1.4030\n",
      "Epoch 2 Batch 226 Loss 1.6329\n",
      "Epoch 2 Batch 227 Loss 1.5806\n",
      "Epoch 2 Batch 228 Loss 1.5308\n",
      "Epoch 2 Batch 229 Loss 1.8016\n",
      "Epoch 2 Batch 230 Loss 1.5355\n",
      "Epoch 2 Batch 231 Loss 1.6372\n",
      "Epoch 2 Batch 232 Loss 1.3618\n",
      "Epoch 2 Batch 233 Loss 1.7079\n",
      "Epoch 2 Batch 234 Loss 1.8132\n",
      "Epoch 2 Batch 235 Loss 1.5135\n",
      "Epoch 2 Batch 236 Loss 1.4841\n",
      "Epoch 2 Batch 237 Loss 1.5618\n",
      "Epoch 2 Batch 238 Loss 1.8401\n",
      "Epoch 2 Batch 239 Loss 1.2633\n",
      "Epoch 2 Batch 240 Loss 1.8049\n",
      "Epoch 2 Batch 241 Loss 1.8813\n",
      "Epoch 2 Batch 242 Loss 1.4949\n",
      "Epoch 2 Batch 243 Loss 1.3311\n",
      "Epoch 2 Batch 244 Loss 1.6743\n",
      "Epoch 2 Batch 245 Loss 1.8026\n",
      "Epoch 2 Batch 246 Loss 1.6831\n",
      "Epoch 2 Batch 247 Loss 1.8234\n",
      "Epoch 2 Batch 248 Loss 1.4403\n",
      "Epoch 2 Batch 249 Loss 1.4470\n",
      "Epoch 2 Batch 250 Loss 1.7619\n",
      "Epoch 2 Batch 251 Loss 1.3838\n",
      "Epoch 2 Batch 252 Loss 1.3952\n",
      "Epoch 2 Batch 253 Loss 1.6945\n",
      "Epoch 2 Batch 254 Loss 1.5048\n",
      "Epoch 2 Batch 255 Loss 1.6874\n",
      "Epoch 2 Batch 256 Loss 1.4578\n",
      "Epoch 2 Batch 257 Loss 1.8380\n",
      "Epoch 2 Batch 258 Loss 1.6237\n",
      "Epoch 2 Batch 259 Loss 1.2032\n",
      "Epoch 2 Batch 260 Loss 1.7244\n",
      "Epoch 2 Batch 261 Loss 1.4318\n",
      "Epoch 2 Batch 262 Loss 1.1629\n",
      "Epoch 2 Batch 263 Loss 1.5163\n",
      "Epoch 2 Batch 264 Loss 1.7893\n",
      "Epoch 2 Batch 265 Loss 1.3981\n",
      "Epoch 2 Batch 266 Loss 1.4891\n",
      "Epoch 2 Batch 267 Loss 1.5896\n",
      "Epoch 2 Batch 268 Loss 1.5278\n",
      "Epoch 2 Batch 269 Loss 1.9018\n",
      "Epoch 2 Batch 270 Loss 1.4693\n",
      "Epoch 2 Batch 271 Loss 1.6556\n",
      "Epoch 2 Batch 272 Loss 1.9502\n",
      "Epoch 2 Batch 273 Loss 1.4114\n",
      "Epoch 2 Batch 274 Loss 1.6838\n",
      "Epoch 2 Batch 275 Loss 1.1843\n",
      "Epoch 2 Batch 276 Loss 1.5786\n",
      "Epoch 2 Batch 277 Loss 1.6493\n",
      "Epoch 2 Batch 278 Loss 1.6565\n",
      "Epoch 2 Batch 279 Loss 1.5332\n",
      "Epoch 2 Batch 280 Loss 1.5503\n",
      "Epoch 2 Batch 281 Loss 1.5859\n",
      "Epoch 2 Batch 282 Loss 1.5100\n",
      "Epoch 2 Batch 283 Loss 1.1838\n",
      "Epoch 2 Batch 284 Loss 1.8821\n",
      "Epoch 2 Batch 285 Loss 1.2892\n",
      "Epoch 2 Batch 286 Loss 1.3312\n",
      "Epoch 2 Batch 287 Loss 1.3689\n",
      "Epoch 2 Batch 288 Loss 2.0045\n",
      "Epoch 2 Batch 289 Loss 1.7028\n",
      "Epoch 2 Batch 290 Loss 1.4171\n",
      "Epoch 2 Batch 291 Loss 1.7073\n",
      "Epoch 2 Batch 292 Loss 1.5266\n",
      "Epoch 2 Batch 293 Loss 1.7666\n",
      "Epoch 2 Batch 294 Loss 1.5712\n",
      "Epoch 2 Batch 295 Loss 1.2365\n",
      "Epoch 2 Batch 296 Loss 1.4820\n",
      "Epoch 2 Batch 297 Loss 1.6658\n",
      "Epoch 2 Batch 298 Loss 1.5344\n",
      "Epoch 2 Batch 299 Loss 1.7021\n",
      "Epoch 2 Batch 300 Loss 1.6780\n",
      "Epoch 2 Batch 301 Loss 1.5581\n",
      "Epoch 2 Batch 302 Loss 1.2064\n",
      "Epoch 2 Batch 303 Loss 1.5189\n",
      "Epoch 2 Batch 304 Loss 1.6886\n",
      "Epoch 2 Batch 305 Loss 1.4089\n",
      "Epoch 2 Batch 306 Loss 1.7672\n",
      "Epoch 2 Batch 307 Loss 1.7520\n",
      "Epoch 2 Batch 308 Loss 1.5034\n",
      "Epoch 2 Batch 309 Loss 1.8420\n",
      "Epoch 2 Batch 310 Loss 1.4698\n",
      "Epoch 2 Batch 311 Loss 1.5683\n",
      "Epoch 2 Batch 312 Loss 1.5970\n",
      "Epoch 2 Batch 313 Loss 1.4914\n",
      "Epoch 2 Batch 314 Loss 1.5293\n",
      "Epoch 2 Batch 315 Loss 1.4903\n",
      "Epoch 2 Batch 316 Loss 1.8272\n",
      "Epoch 2 Batch 317 Loss 1.3918\n",
      "Epoch 2 Batch 318 Loss 1.4612\n",
      "Epoch 2 Batch 319 Loss 1.7435\n",
      "Epoch 2 Batch 320 Loss 1.5629\n",
      "Epoch 2 Batch 321 Loss 1.3503\n",
      "Epoch 2 Batch 322 Loss 1.5122\n",
      "Epoch 2 Batch 323 Loss 1.5429\n",
      "Epoch 2 Batch 324 Loss 1.3403\n",
      "Epoch 2 Batch 325 Loss 1.4175\n",
      "Epoch 2 Batch 326 Loss 2.0034\n",
      "Epoch 2 Batch 327 Loss 1.6418\n",
      "Epoch 2 Batch 328 Loss 1.6303\n",
      "Epoch 2 Batch 329 Loss 1.2183\n",
      "Epoch 2 Batch 330 Loss 1.5457\n",
      "Epoch 2 Batch 331 Loss 1.5282\n",
      "Epoch 2 Batch 332 Loss 1.7847\n",
      "Epoch 2 Batch 333 Loss 1.5412\n",
      "Epoch 2 Batch 334 Loss 1.2721\n",
      "Epoch 2 Batch 335 Loss 1.4495\n",
      "Epoch 2 Batch 336 Loss 1.7039\n",
      "Epoch 2 Batch 337 Loss 1.3893\n",
      "Epoch 2 Batch 338 Loss 1.3295\n",
      "Epoch 2 Batch 339 Loss 1.4880\n",
      "Epoch 2 Batch 340 Loss 1.7383\n",
      "Epoch 2 Batch 341 Loss 1.4250\n",
      "Epoch 2 Batch 342 Loss 1.5255\n",
      "Epoch 2 Batch 343 Loss 1.4882\n",
      "Epoch 2 Batch 344 Loss 1.5304\n",
      "Epoch 2 Batch 345 Loss 1.2608\n",
      "Epoch 2 Batch 346 Loss 1.4791\n",
      "Epoch 2 Batch 347 Loss 1.5783\n",
      "Epoch 2 Batch 348 Loss 1.5796\n",
      "Epoch 2 Batch 349 Loss 1.8447\n",
      "Epoch 2 Batch 350 Loss 1.6902\n",
      "Epoch 2 Batch 351 Loss 1.7339\n",
      "Epoch 2 Batch 352 Loss 1.5706\n",
      "Epoch 2 Batch 353 Loss 2.0261\n",
      "Epoch 2 Batch 354 Loss 1.3148\n",
      "Epoch 2 Batch 355 Loss 1.8954\n",
      "Epoch 2 Batch 356 Loss 1.7192\n",
      "Epoch 2 Batch 357 Loss 2.0719\n",
      "Epoch 2 Batch 358 Loss 1.9908\n",
      "Epoch 2 Batch 359 Loss 1.4147\n",
      "Epoch 2 Batch 360 Loss 1.3395\n",
      "Epoch 2 Batch 361 Loss 1.8987\n",
      "Epoch 2 Batch 362 Loss 1.4628\n",
      "Epoch 2 Batch 363 Loss 1.4636\n",
      "Epoch 2 Batch 364 Loss 1.5385\n",
      "Epoch 2 Batch 365 Loss 1.4064\n",
      "Epoch 2 Batch 366 Loss 1.4905\n",
      "Epoch 2 Batch 367 Loss 1.4733\n",
      "Epoch 2 Batch 368 Loss 1.5639\n",
      "Epoch 2 Batch 369 Loss 1.4121\n",
      "Epoch 2 Batch 370 Loss 1.3864\n",
      "Epoch 2 Batch 371 Loss 1.8465\n",
      "Epoch 2 Batch 372 Loss 1.3217\n",
      "Epoch 2 Batch 373 Loss 1.3361\n",
      "Epoch 2 Batch 374 Loss 1.3120\n",
      "Epoch 2 Batch 375 Loss 1.5629\n",
      "Epoch 2 Batch 376 Loss 1.1658\n",
      "Epoch 2 Batch 377 Loss 1.5795\n",
      "Epoch 2 Batch 378 Loss 1.4324\n",
      "Epoch 2 Batch 379 Loss 1.4814\n",
      "Epoch 2 Batch 380 Loss 1.5260\n",
      "Epoch 2 Batch 381 Loss 1.6835\n",
      "Epoch 2 Batch 382 Loss 1.4563\n",
      "Epoch 2 Batch 383 Loss 1.2355\n",
      "Epoch 2 Batch 384 Loss 1.6697\n",
      "Epoch 2 Batch 385 Loss 1.6664\n",
      "Epoch 2 Batch 386 Loss 1.4301\n",
      "Epoch 2 Batch 387 Loss 1.7471\n",
      "Epoch 2 Batch 388 Loss 1.7284\n",
      "Epoch 2 Batch 389 Loss 1.7317\n",
      "Epoch 2 Batch 390 Loss 1.5549\n",
      "Epoch 2 Batch 391 Loss 1.8290\n",
      "Epoch 2 Batch 392 Loss 1.3161\n",
      "Epoch 2 Batch 393 Loss 1.5877\n",
      "Epoch 2 Batch 394 Loss 1.5513\n",
      "Epoch 2 Batch 395 Loss 1.6457\n",
      "Epoch 2 Batch 396 Loss 1.3347\n",
      "Epoch 2 Batch 397 Loss 1.5806\n",
      "Epoch 2 Batch 398 Loss 1.4044\n",
      "Epoch 2 Batch 399 Loss 1.9889\n",
      "Epoch 2 Batch 400 Loss 1.5453\n",
      "Epoch 2 Batch 401 Loss 1.5362\n",
      "Epoch 2 Batch 402 Loss 1.4908\n",
      "Epoch 2 Batch 403 Loss 1.8807\n",
      "Epoch 2 Batch 404 Loss 1.2562\n",
      "Epoch 2 Batch 405 Loss 1.3066\n",
      "Epoch 2 Batch 406 Loss 1.7504\n",
      "Epoch 2 Batch 407 Loss 1.6634\n",
      "Epoch 2 Batch 408 Loss 1.6081\n",
      "Epoch 2 Batch 409 Loss 1.6092\n",
      "Epoch 2 Batch 410 Loss 1.5098\n",
      "Epoch 2 Batch 411 Loss 1.4056\n",
      "Epoch 2 Batch 412 Loss 1.3002\n",
      "Epoch 2 Batch 413 Loss 1.5466\n",
      "Epoch 2 Batch 414 Loss 1.7225\n",
      "Epoch 2 Batch 415 Loss 1.5573\n",
      "Epoch 2 Batch 416 Loss 1.6054\n",
      "Epoch 2 Batch 417 Loss 1.8517\n",
      "Epoch 2 Batch 418 Loss 1.9654\n",
      "Epoch 2 Batch 419 Loss 1.2641\n",
      "Epoch 2 Batch 420 Loss 1.5629\n",
      "Epoch 2 Batch 421 Loss 1.6253\n",
      "Epoch 2 Batch 422 Loss 1.6416\n",
      "Epoch 2 Batch 423 Loss 1.5021\n",
      "Epoch 2 Batch 424 Loss 1.4788\n",
      "Epoch 2 Batch 425 Loss 1.6485\n",
      "Epoch 2 Batch 426 Loss 1.6125\n",
      "Epoch 2 Batch 427 Loss 1.6413\n",
      "Epoch 2 Batch 428 Loss 1.3666\n",
      "Epoch 2 Batch 429 Loss 1.3650\n",
      "Epoch 2 Batch 430 Loss 1.5320\n",
      "Epoch 2 Batch 431 Loss 1.3701\n",
      "Epoch 2 Batch 432 Loss 1.4232\n",
      "Epoch 2 Batch 433 Loss 1.2945\n",
      "Epoch 2 Batch 434 Loss 1.4421\n",
      "Epoch 2 Batch 435 Loss 1.3547\n",
      "Epoch 2 Batch 436 Loss 1.7607\n",
      "Epoch 2 Batch 437 Loss 1.6065\n",
      "Epoch 2 Batch 438 Loss 1.7168\n",
      "Epoch 2 Batch 439 Loss 1.6281\n",
      "Epoch 2 Batch 440 Loss 1.2489\n",
      "Epoch 2 Batch 441 Loss 1.6333\n",
      "Epoch 2 Batch 442 Loss 1.7694\n",
      "Epoch 2 Batch 443 Loss 1.6257\n",
      "Epoch 2 Batch 444 Loss 1.5791\n",
      "Epoch 2 Batch 445 Loss 1.5270\n",
      "Epoch 2 Batch 446 Loss 1.8641\n",
      "Epoch 2 Batch 447 Loss 1.5216\n",
      "Epoch 2 Batch 448 Loss 1.6688\n",
      "Epoch 2 Batch 449 Loss 1.4252\n",
      "Epoch 2 Batch 450 Loss 1.5816\n",
      "Epoch 2 Batch 451 Loss 1.5351\n",
      "Epoch 2 Batch 452 Loss 1.4585\n",
      "Epoch 2 Batch 453 Loss 1.5278\n",
      "Epoch 2 Batch 454 Loss 1.7616\n",
      "Epoch 2 Batch 455 Loss 1.5196\n",
      "Epoch 2 Batch 456 Loss 1.6458\n",
      "Epoch 2 Batch 457 Loss 1.7061\n",
      "Epoch 2 Batch 458 Loss 1.6287\n",
      "Epoch 2 Batch 459 Loss 1.6952\n",
      "Epoch 2 Batch 460 Loss 1.4436\n",
      "Epoch 2 Batch 461 Loss 1.6779\n",
      "Epoch 2 Batch 462 Loss 1.4800\n",
      "Epoch 2 Batch 463 Loss 1.7282\n",
      "Epoch 2 Batch 464 Loss 1.4289\n",
      "Epoch 2 Batch 465 Loss 1.8121\n",
      "Epoch 2 Batch 466 Loss 1.6977\n",
      "Epoch 2 Batch 467 Loss 1.8001\n",
      "Epoch 2 Batch 468 Loss 1.4741\n",
      "Epoch 2 Batch 469 Loss 1.3994\n",
      "Epoch 2 Batch 470 Loss 1.4608\n",
      "Epoch 2 Batch 471 Loss 1.6370\n",
      "Epoch 2 Batch 472 Loss 1.4056\n",
      "Epoch 2 Batch 473 Loss 1.3832\n",
      "Epoch 2 Batch 474 Loss 1.4573\n",
      "Epoch 2 Batch 475 Loss 1.6703\n",
      "Epoch 2 Batch 476 Loss 1.5250\n",
      "Epoch 2 Batch 477 Loss 1.6589\n",
      "Epoch 2 Batch 478 Loss 1.2954\n",
      "Epoch 2 Batch 479 Loss 1.3971\n",
      "Epoch 2 Batch 480 Loss 1.5979\n",
      "Epoch 2 Batch 481 Loss 1.5083\n",
      "Epoch 2 Batch 482 Loss 1.4410\n",
      "Epoch 2 Batch 483 Loss 1.3584\n",
      "Epoch 2 Batch 484 Loss 1.8761\n",
      "Epoch 2 Batch 485 Loss 1.7813\n",
      "Epoch 2 Batch 486 Loss 1.3589\n",
      "Epoch 2 Batch 487 Loss 1.6079\n",
      "Epoch 2 Batch 488 Loss 1.7271\n",
      "Epoch 2 Batch 489 Loss 1.6233\n",
      "Epoch 2 Batch 490 Loss 1.3873\n",
      "Epoch 2 Batch 491 Loss 1.3050\n",
      "Epoch 2 Batch 492 Loss 1.6711\n",
      "Epoch 2 Batch 493 Loss 1.3714\n",
      "Epoch 2 Batch 494 Loss 1.7966\n",
      "Epoch 2 Batch 495 Loss 1.3408\n",
      "Epoch 2 Batch 496 Loss 1.5329\n",
      "Epoch 2 Batch 497 Loss 1.4715\n",
      "Epoch 2 Batch 498 Loss 1.8272\n",
      "Epoch 2 Batch 499 Loss 1.4735\n",
      "Epoch 2 Batch 500 Loss 1.5775\n",
      "Epoch 2 Batch 501 Loss 1.5817\n",
      "Epoch 2 Batch 502 Loss 1.6107\n",
      "Epoch 2 Batch 503 Loss 1.3393\n",
      "Epoch 2 Batch 504 Loss 1.5455\n",
      "Epoch 2 Batch 505 Loss 1.4954\n",
      "Epoch 2 Batch 506 Loss 1.3112\n",
      "Epoch 2 Batch 507 Loss 1.6075\n",
      "Epoch 2 Batch 508 Loss 1.5280\n",
      "Epoch 2 Batch 509 Loss 1.6516\n",
      "Epoch 2 Batch 510 Loss 1.4175\n",
      "Epoch 2 Batch 511 Loss 1.5542\n",
      "Epoch 2 Batch 512 Loss 1.9284\n",
      "Epoch 2 Batch 513 Loss 1.3008\n",
      "Epoch 2 Batch 514 Loss 2.0387\n",
      "Epoch 2 Batch 515 Loss 1.2996\n",
      "Epoch 2 Batch 516 Loss 1.9409\n",
      "Epoch 2 Batch 517 Loss 1.4986\n",
      "Epoch 2 Batch 518 Loss 1.6571\n",
      "Epoch 2 Batch 519 Loss 1.7462\n",
      "Epoch 2 Batch 520 Loss 1.4658\n",
      "Epoch 2 Batch 521 Loss 1.7905\n",
      "Epoch 2 Batch 522 Loss 1.4998\n",
      "Epoch 2 Batch 523 Loss 2.0771\n",
      "Epoch 2 Batch 524 Loss 1.6651\n",
      "Epoch 2 Batch 525 Loss 1.6183\n",
      "Epoch 2 Batch 526 Loss 1.6883\n",
      "Epoch 2 Batch 527 Loss 1.5219\n",
      "Epoch 2 Batch 528 Loss 1.3378\n",
      "Epoch 2 Batch 529 Loss 2.0732\n",
      "Epoch 2 Batch 530 Loss 1.6232\n",
      "Epoch 2 Batch 531 Loss 1.4408\n",
      "Epoch 2 Batch 532 Loss 1.6843\n",
      "Epoch 2 Batch 533 Loss 1.6879\n",
      "Epoch 2 Batch 534 Loss 1.5225\n",
      "Epoch 2 Batch 535 Loss 1.9019\n",
      "Epoch 2 Batch 536 Loss 1.8954\n",
      "Epoch 2 Batch 537 Loss 1.3283\n",
      "Epoch 2 Batch 538 Loss 1.4673\n",
      "Epoch 2 Batch 539 Loss 1.6991\n",
      "Epoch 2 Batch 540 Loss 1.5187\n",
      "Epoch 2 Batch 541 Loss 1.5899\n",
      "Epoch 2 Batch 542 Loss 1.4212\n",
      "Epoch 2 Batch 543 Loss 1.4278\n",
      "Epoch 2 Batch 544 Loss 1.9792\n",
      "Epoch 2 Batch 545 Loss 1.4224\n",
      "Epoch 2 Batch 546 Loss 1.3685\n",
      "Epoch 2 Batch 547 Loss 1.5129\n",
      "Epoch 2 Batch 548 Loss 1.3859\n",
      "Epoch 2 Batch 549 Loss 1.6105\n",
      "Epoch 2 Batch 550 Loss 1.3176\n",
      "Epoch 2 Batch 551 Loss 1.6927\n",
      "Epoch 2 Batch 552 Loss 1.5566\n",
      "Epoch 2 Batch 553 Loss 1.3534\n",
      "Epoch 2 Batch 554 Loss 1.5886\n",
      "Epoch 2 Batch 555 Loss 1.6317\n",
      "Epoch 2 Batch 556 Loss 1.6263\n",
      "Epoch 2 Batch 557 Loss 1.5762\n",
      "Epoch 2 Batch 558 Loss 1.4718\n",
      "Epoch 2 Batch 559 Loss 1.5314\n",
      "Epoch 2 Batch 560 Loss 1.3014\n",
      "Epoch 2 Batch 561 Loss 1.6332\n",
      "Epoch 2 Batch 562 Loss 1.5176\n",
      "Epoch 2 Batch 563 Loss 1.4166\n",
      "Epoch 2 Batch 564 Loss 1.9385\n",
      "Epoch 2 Batch 565 Loss 1.4649\n",
      "Epoch 2 Batch 566 Loss 1.5771\n",
      "Epoch 2 Batch 567 Loss 1.9756\n",
      "Epoch 2 Batch 568 Loss 1.7053\n",
      "Epoch 2 Batch 569 Loss 1.5179\n",
      "Epoch 2 Batch 570 Loss 1.4841\n",
      "Epoch 2 Batch 571 Loss 1.5166\n",
      "Epoch 2 Batch 572 Loss 1.4346\n",
      "Epoch 2 Batch 573 Loss 2.0105\n",
      "Epoch 2 Batch 574 Loss 1.7519\n",
      "Epoch 2 Batch 575 Loss 1.4104\n",
      "Epoch 2 Batch 576 Loss 1.4822\n",
      "Epoch 2 Batch 577 Loss 1.5575\n",
      "Epoch 2 Batch 578 Loss 1.6176\n",
      "Epoch 2 Batch 579 Loss 1.5488\n",
      "Epoch 2 Batch 580 Loss 1.6676\n",
      "Epoch 2 Batch 581 Loss 1.9191\n",
      "Epoch 2 Batch 582 Loss 1.7531\n",
      "Epoch 2 Batch 583 Loss 1.6673\n",
      "Epoch 2 Batch 584 Loss 1.5134\n",
      "Epoch 2 Batch 585 Loss 1.5374\n",
      "Epoch 2 Batch 586 Loss 1.6884\n",
      "Epoch 2 Batch 587 Loss 1.3908\n",
      "Epoch 2 Batch 588 Loss 1.7016\n",
      "Epoch 2 Batch 589 Loss 1.5761\n",
      "Epoch 2 Batch 590 Loss 1.4144\n",
      "Epoch 2 Batch 591 Loss 1.5569\n",
      "Epoch 2 Batch 592 Loss 1.5869\n",
      "Epoch 2 Batch 593 Loss 1.6348\n",
      "Epoch 2 Batch 594 Loss 1.4715\n",
      "Epoch 2 Batch 595 Loss 1.4164\n",
      "Epoch 2 Batch 596 Loss 1.3563\n",
      "Epoch 2 Batch 597 Loss 1.5954\n",
      "Epoch 2 Batch 598 Loss 1.7912\n",
      "Epoch 2 Batch 599 Loss 1.6729\n",
      "Epoch 2 Batch 600 Loss 1.5406\n",
      "Epoch 2 Batch 601 Loss 1.6105\n",
      "Epoch 2 Batch 602 Loss 1.5630\n",
      "Epoch 2 Batch 603 Loss 1.9869\n",
      "Epoch 2 Batch 604 Loss 1.4926\n",
      "Epoch 2 Batch 605 Loss 2.1455\n",
      "Epoch 2 Batch 606 Loss 1.4248\n",
      "Epoch 2 Batch 607 Loss 1.6910\n",
      "Epoch 2 Batch 608 Loss 2.0439\n",
      "Epoch 2 Batch 609 Loss 1.3827\n",
      "Epoch 2 Batch 610 Loss 1.8377\n",
      "Epoch 2 Batch 611 Loss 1.3709\n",
      "Epoch 2 Batch 612 Loss 1.2540\n",
      "Epoch 2 Batch 613 Loss 1.4913\n",
      "Epoch 2 Batch 614 Loss 1.2112\n",
      "Epoch 2 Batch 615 Loss 1.6854\n",
      "Epoch 2 Batch 616 Loss 1.9070\n",
      "Epoch 2 Batch 617 Loss 1.7734\n",
      "Epoch 2 Batch 618 Loss 1.6241\n",
      "Epoch 2 Batch 619 Loss 1.5576\n",
      "Epoch 2 Batch 620 Loss 1.4409\n",
      "Epoch 2 Batch 621 Loss 1.5795\n",
      "Epoch 2 Batch 622 Loss 1.5342\n",
      "Epoch 2 Batch 623 Loss 1.7379\n",
      "Epoch 2 Batch 624 Loss 1.6108\n",
      "Epoch 2 Batch 625 Loss 1.4776\n",
      "Epoch 2 Batch 626 Loss 1.6227\n",
      "Epoch 2 Batch 627 Loss 1.6212\n",
      "Epoch 2 Batch 628 Loss 1.3628\n",
      "Epoch 2 Batch 629 Loss 1.3101\n",
      "Epoch 2 Batch 630 Loss 1.2619\n",
      "Epoch 2 Batch 631 Loss 1.5787\n",
      "Epoch 2 Batch 632 Loss 1.9768\n",
      "Epoch 2 Batch 633 Loss 1.6390\n",
      "Epoch 2 Batch 634 Loss 1.3385\n",
      "Epoch 2 Batch 635 Loss 1.6711\n",
      "Epoch 2 Batch 636 Loss 1.4064\n",
      "Epoch 2 Batch 637 Loss 1.6936\n",
      "Epoch 2 Batch 638 Loss 1.7897\n",
      "Epoch 2 Batch 639 Loss 1.5242\n",
      "Epoch 2 Batch 640 Loss 1.8646\n",
      "Epoch 2 Batch 641 Loss 1.3577\n",
      "Epoch 2 Batch 642 Loss 1.7039\n",
      "Epoch 2 Batch 643 Loss 1.4353\n",
      "Epoch 2 Batch 644 Loss 1.6914\n",
      "Epoch 2 Batch 645 Loss 1.5992\n",
      "Epoch 2 Batch 646 Loss 1.5346\n",
      "Epoch 2 Batch 647 Loss 1.8099\n",
      "Epoch 2 Batch 648 Loss 1.5433\n",
      "Epoch 2 Batch 649 Loss 1.7121\n",
      "Epoch 2 Batch 650 Loss 1.8959\n",
      "Epoch 2 Batch 651 Loss 1.7982\n",
      "Epoch 2 Batch 652 Loss 1.2323\n",
      "Epoch 2 Batch 653 Loss 1.7145\n",
      "Epoch 2 Batch 654 Loss 1.5606\n",
      "Epoch 2 Batch 655 Loss 1.6772\n",
      "Epoch 2 Batch 656 Loss 1.2465\n",
      "Epoch 2 Batch 657 Loss 1.2862\n",
      "Epoch 2 Batch 658 Loss 1.7308\n",
      "Epoch 2 Batch 659 Loss 1.7451\n",
      "Epoch 2 Batch 660 Loss 1.3672\n",
      "Epoch 2 Batch 661 Loss 1.6264\n",
      "Epoch 2 Batch 662 Loss 1.4955\n",
      "Epoch 2 Batch 663 Loss 1.4750\n",
      "Epoch 2 Batch 664 Loss 1.9103\n",
      "Epoch 2 Batch 665 Loss 1.4629\n",
      "Epoch 2 Batch 666 Loss 1.3127\n",
      "Epoch 2 Batch 667 Loss 1.3898\n",
      "Epoch 2 Batch 668 Loss 1.7030\n",
      "Epoch 2 Batch 669 Loss 1.6171\n",
      "Epoch 2 Batch 670 Loss 1.4539\n",
      "Epoch 2 Batch 671 Loss 1.4146\n",
      "Epoch 2 Batch 672 Loss 1.4068\n",
      "Epoch 2 Batch 673 Loss 1.2309\n",
      "Epoch 2 Batch 674 Loss 1.4506\n",
      "Epoch 2 Batch 675 Loss 1.0810\n",
      "Epoch 2 Batch 676 Loss 1.5420\n",
      "Epoch 2 Batch 677 Loss 1.5936\n",
      "Epoch 2 Batch 678 Loss 1.7286\n",
      "Epoch 2 Batch 679 Loss 1.5317\n",
      "Epoch 2 Batch 680 Loss 1.4988\n",
      "Epoch 2 Batch 681 Loss 1.2343\n",
      "Epoch 2 Batch 682 Loss 1.5566\n",
      "Epoch 2 Batch 683 Loss 1.6053\n",
      "Epoch 2 Batch 684 Loss 1.6109\n",
      "Epoch 2 Batch 685 Loss 1.6480\n",
      "Epoch 2 Batch 686 Loss 1.4259\n",
      "Epoch 2 Batch 687 Loss 1.7364\n",
      "Epoch 2 Batch 688 Loss 1.6623\n",
      "Epoch 2 Batch 689 Loss 1.6641\n",
      "Epoch 2 Batch 690 Loss 1.5934\n",
      "Epoch 2 Batch 691 Loss 1.6575\n",
      "Epoch 2 Batch 692 Loss 1.3489\n",
      "Epoch 2 Batch 693 Loss 1.4285\n",
      "Epoch 2 Batch 694 Loss 1.5601\n",
      "Epoch 2 Batch 695 Loss 1.6357\n",
      "Epoch 2 Batch 696 Loss 1.3972\n",
      "Epoch 2 Batch 697 Loss 1.5005\n",
      "Epoch 2 Batch 698 Loss 1.6366\n",
      "Epoch 2 Batch 699 Loss 1.3672\n",
      "Epoch 2 Batch 700 Loss 1.4724\n",
      "Epoch 2 Batch 701 Loss 1.3456\n",
      "Epoch 2 Batch 702 Loss 1.7543\n",
      "Epoch 2 Batch 703 Loss 1.7061\n",
      "Epoch 2 Batch 704 Loss 1.3739\n",
      "Epoch 2 Batch 705 Loss 1.5191\n",
      "Epoch 2 Batch 706 Loss 1.4959\n",
      "Epoch 2 Batch 707 Loss 1.3224\n",
      "Epoch 2 Batch 708 Loss 1.2410\n",
      "Epoch 2 Batch 709 Loss 1.5148\n",
      "Epoch 2 Batch 710 Loss 1.5055\n",
      "Epoch 2 Batch 711 Loss 1.6203\n",
      "Epoch 2 Batch 712 Loss 1.5853\n",
      "Epoch 2 Batch 713 Loss 1.7363\n",
      "Epoch 2 Batch 714 Loss 1.4717\n",
      "Epoch 2 Batch 715 Loss 1.5080\n",
      "Epoch 2 Batch 716 Loss 1.8269\n",
      "Epoch 2 Batch 717 Loss 1.7175\n",
      "Epoch 2 Batch 718 Loss 1.4423\n",
      "Epoch 2 Batch 719 Loss 1.6258\n",
      "Epoch 2 Batch 720 Loss 1.5381\n",
      "Epoch 2 Batch 721 Loss 1.8563\n",
      "Epoch 2 Batch 722 Loss 1.7402\n",
      "Epoch 2 Batch 723 Loss 1.6253\n",
      "Epoch 2 Batch 724 Loss 1.8301\n",
      "Epoch 2 Batch 725 Loss 1.4779\n",
      "Epoch 2 Batch 726 Loss 1.3534\n",
      "Epoch 2 Batch 727 Loss 1.4753\n",
      "Epoch 2 Batch 728 Loss 1.7132\n",
      "Epoch 2 Batch 729 Loss 1.3095\n",
      "Epoch 2 Batch 730 Loss 1.7250\n",
      "Epoch 2 Batch 731 Loss 1.5011\n",
      "Epoch 2 Batch 732 Loss 1.8852\n",
      "Epoch 2 Batch 733 Loss 1.7418\n",
      "Epoch 2 Batch 734 Loss 1.4953\n",
      "Epoch 2 Batch 735 Loss 1.4382\n",
      "Epoch 2 Batch 736 Loss 1.8442\n",
      "Epoch 2 Batch 737 Loss 1.5764\n",
      "Epoch 2 Batch 738 Loss 1.6113\n",
      "Epoch 2 Batch 739 Loss 1.4811\n",
      "Epoch 2 Batch 740 Loss 1.3422\n",
      "Epoch 2 Batch 741 Loss 1.2492\n",
      "Epoch 2 Batch 742 Loss 1.2770\n",
      "Epoch 2 Batch 743 Loss 1.4627\n",
      "Epoch 2 Batch 744 Loss 1.5899\n",
      "Epoch 2 Batch 745 Loss 1.6982\n",
      "Epoch 2 Batch 746 Loss 1.3777\n",
      "Epoch 2 Batch 747 Loss 1.7023\n",
      "Epoch 2 Batch 748 Loss 1.6671\n",
      "Epoch 2 Batch 749 Loss 1.3570\n",
      "Epoch 2 Batch 750 Loss 1.8039\n",
      "Epoch 2 Batch 751 Loss 1.6215\n",
      "Epoch 2 Batch 752 Loss 1.4177\n",
      "Epoch 2 Batch 753 Loss 1.2693\n",
      "Epoch 2 Batch 754 Loss 1.6675\n",
      "Epoch 2 Batch 755 Loss 1.3198\n",
      "Epoch 2 Batch 756 Loss 1.3424\n",
      "Epoch 2 Batch 757 Loss 1.6653\n",
      "Epoch 2 Batch 758 Loss 1.5396\n",
      "Epoch 2 Batch 759 Loss 1.7887\n",
      "Epoch 2 Batch 760 Loss 1.4624\n",
      "Epoch 2 Batch 761 Loss 1.6083\n",
      "Epoch 2 Batch 762 Loss 1.7117\n",
      "Epoch 2 Batch 763 Loss 1.4260\n",
      "Epoch 2 Batch 764 Loss 1.2906\n",
      "Epoch 2 Batch 765 Loss 1.5565\n",
      "Epoch 2 Batch 766 Loss 1.5362\n",
      "Epoch 2 Batch 767 Loss 1.6700\n",
      "Epoch 2 Batch 768 Loss 1.3736\n",
      "Epoch 2 Batch 769 Loss 1.4808\n",
      "Epoch 2 Batch 770 Loss 1.6211\n",
      "Epoch 2 Batch 771 Loss 1.4227\n",
      "Epoch 2 Batch 772 Loss 1.4413\n",
      "Epoch 2 Batch 773 Loss 1.5187\n",
      "Epoch 2 Batch 774 Loss 1.8506\n",
      "Epoch 2 Batch 775 Loss 1.5441\n",
      "Epoch 2 Batch 776 Loss 1.4774\n",
      "Epoch 2 Batch 777 Loss 1.5536\n",
      "Epoch 2 Batch 778 Loss 1.5130\n",
      "Epoch 2 Batch 779 Loss 1.1710\n",
      "Epoch 2 Batch 780 Loss 1.2550\n",
      "Epoch 2 Batch 781 Loss 1.5788\n",
      "Epoch 2 Batch 782 Loss 1.4541\n",
      "Epoch 2 Batch 783 Loss 1.3407\n",
      "Epoch 2 Batch 784 Loss 1.6533\n",
      "Epoch 2 Batch 785 Loss 1.4846\n",
      "Epoch 2 Batch 786 Loss 1.4270\n",
      "Epoch 2 Batch 787 Loss 1.9636\n",
      "Epoch 2 Batch 788 Loss 1.4280\n",
      "Epoch 2 Batch 789 Loss 1.4927\n",
      "Epoch 2 Batch 790 Loss 1.8038\n",
      "Epoch 2 Batch 791 Loss 1.1101\n",
      "Epoch 2 Batch 792 Loss 1.6655\n",
      "Epoch 2 Batch 793 Loss 1.7134\n",
      "Epoch 2 Batch 794 Loss 1.6407\n",
      "Epoch 2 Batch 795 Loss 1.4952\n",
      "Epoch 2 Batch 796 Loss 1.7020\n",
      "Epoch 2 Batch 797 Loss 1.2073\n",
      "Epoch 2 Batch 798 Loss 1.5184\n",
      "Epoch 2 Batch 799 Loss 1.3026\n",
      "Epoch 2 Batch 800 Loss 1.2527\n",
      "Epoch 2 Batch 801 Loss 1.3433\n",
      "Epoch 2 Batch 802 Loss 1.4079\n",
      "Epoch 2 Batch 803 Loss 1.0008\n",
      "Epoch 2 Batch 804 Loss 1.8091\n",
      "Epoch 2 Batch 805 Loss 1.6138\n",
      "Epoch 2 Batch 806 Loss 1.7611\n",
      "Epoch 2 Batch 807 Loss 1.5337\n",
      "Epoch 2 Batch 808 Loss 1.4035\n",
      "Epoch 2 Batch 809 Loss 1.4498\n",
      "Epoch 2 Batch 810 Loss 1.9039\n",
      "Epoch 2 Batch 811 Loss 1.4010\n",
      "Epoch 2 Batch 812 Loss 1.6010\n",
      "Epoch 2 Batch 813 Loss 1.5397\n",
      "Epoch 2 Batch 814 Loss 1.6570\n",
      "Epoch 2 Batch 815 Loss 1.3794\n",
      "Epoch 2 Batch 816 Loss 1.6745\n",
      "Epoch 2 Batch 817 Loss 1.5963\n",
      "Epoch 2 Batch 818 Loss 1.6441\n",
      "Epoch 2 Batch 819 Loss 1.5040\n",
      "Epoch 2 Batch 820 Loss 1.6753\n",
      "Epoch 2 Batch 821 Loss 1.6434\n",
      "Epoch 2 Batch 822 Loss 1.7272\n",
      "Epoch 2 Batch 823 Loss 1.5005\n",
      "Epoch 2 Batch 824 Loss 1.5230\n",
      "Epoch 2 Batch 825 Loss 1.9376\n",
      "Epoch 2 Batch 826 Loss 1.7984\n",
      "Epoch 2 Batch 827 Loss 1.8596\n",
      "Epoch 2 Batch 828 Loss 1.4956\n",
      "Epoch 2 Batch 829 Loss 1.2099\n",
      "Epoch 2 Batch 830 Loss 1.2506\n",
      "Epoch 2 Batch 831 Loss 1.5062\n",
      "Epoch 2 Batch 832 Loss 1.5402\n",
      "Epoch 2 Batch 833 Loss 1.4190\n",
      "Epoch 2 Batch 834 Loss 1.4445\n",
      "Epoch 2 Batch 835 Loss 1.5369\n",
      "Epoch 2 Batch 836 Loss 1.5968\n",
      "Epoch 2 Batch 837 Loss 1.2089\n",
      "Epoch 2 Batch 838 Loss 1.5451\n",
      "Epoch 2 Batch 839 Loss 1.6463\n",
      "Epoch 2 Batch 840 Loss 1.4920\n",
      "Epoch 2 Batch 841 Loss 1.2660\n",
      "Epoch 2 Batch 842 Loss 1.3519\n",
      "Epoch 2 Batch 843 Loss 1.4678\n",
      "Epoch 2 Batch 844 Loss 1.5906\n",
      "Epoch 2 Batch 845 Loss 1.5367\n",
      "Epoch 2 Batch 846 Loss 1.7096\n",
      "Epoch 2 Batch 847 Loss 1.4651\n",
      "Epoch 2 Batch 848 Loss 1.3062\n",
      "Epoch 2 Batch 849 Loss 1.7963\n",
      "Epoch 2 Batch 850 Loss 1.4122\n",
      "Epoch 2 Batch 851 Loss 1.6992\n",
      "Epoch 2 Batch 852 Loss 1.4202\n",
      "Epoch 2 Batch 853 Loss 1.7479\n",
      "Epoch 2 Batch 854 Loss 1.7641\n",
      "Epoch 2 Batch 855 Loss 1.6408\n",
      "Epoch 2 Batch 856 Loss 1.4618\n",
      "Epoch 2 Batch 857 Loss 1.4538\n",
      "Epoch 2 Batch 858 Loss 1.4481\n",
      "Epoch 2 Batch 859 Loss 1.5921\n",
      "Epoch 2 Batch 860 Loss 1.8732\n",
      "Epoch 2 Batch 861 Loss 1.6191\n",
      "Epoch 2 Batch 862 Loss 1.5684\n",
      "Epoch 2 Batch 863 Loss 1.7661\n",
      "Epoch 2 Batch 864 Loss 1.5763\n",
      "Epoch 2 Batch 865 Loss 1.4160\n",
      "Epoch 2 Batch 866 Loss 1.4396\n",
      "Epoch 2 Batch 867 Loss 1.6266\n",
      "Epoch 2 Batch 868 Loss 1.2985\n",
      "Epoch 2 Batch 869 Loss 1.5270\n",
      "Epoch 2 Batch 870 Loss 1.8169\n",
      "Epoch 2 Batch 871 Loss 1.3239\n",
      "Epoch 2 Batch 872 Loss 1.7871\n",
      "Epoch 2 Batch 873 Loss 1.4925\n",
      "Epoch 2 Batch 874 Loss 1.3943\n",
      "Epoch 2 Batch 875 Loss 1.3059\n",
      "Epoch 2 Batch 876 Loss 1.5298\n",
      "Epoch 2 Batch 877 Loss 1.1712\n",
      "Epoch 2 Batch 878 Loss 1.3636\n",
      "Epoch 2 Batch 879 Loss 1.6716\n",
      "Epoch 2 Batch 880 Loss 1.4451\n",
      "Epoch 2 Batch 881 Loss 1.2388\n",
      "Epoch 2 Batch 882 Loss 1.3314\n",
      "Epoch 2 Batch 883 Loss 1.6223\n",
      "Epoch 2 Batch 884 Loss 1.4273\n",
      "Epoch 2 Batch 885 Loss 1.3532\n",
      "Epoch 2 Batch 886 Loss 1.4837\n",
      "Epoch 2 Batch 887 Loss 1.7210\n",
      "Epoch 2 Batch 888 Loss 1.2411\n",
      "Epoch 2 Batch 889 Loss 1.7904\n",
      "Epoch 2 Batch 890 Loss 1.6950\n",
      "Epoch 2 Batch 891 Loss 1.6511\n",
      "Epoch 2 Batch 892 Loss 1.5267\n",
      "Epoch 2 Batch 893 Loss 1.3008\n",
      "Epoch 2 Batch 894 Loss 1.6532\n",
      "Epoch 2 Batch 895 Loss 1.6509\n",
      "Epoch 2 Batch 896 Loss 1.3058\n",
      "Epoch 2 Batch 897 Loss 1.2806\n",
      "Epoch 2 Batch 898 Loss 1.6229\n",
      "Epoch 2 Batch 899 Loss 1.3102\n",
      "Epoch 2 Batch 900 Loss 1.3310\n",
      "Epoch 2 Batch 901 Loss 1.5078\n",
      "Epoch 2 Batch 902 Loss 1.7777\n",
      "Epoch 2 Batch 903 Loss 1.1841\n",
      "Epoch 2 Batch 904 Loss 1.5078\n",
      "Epoch 2 Batch 905 Loss 1.5977\n",
      "Epoch 2 Batch 906 Loss 1.2724\n",
      "Epoch 2 Batch 907 Loss 1.9146\n",
      "Epoch 2 Batch 908 Loss 1.6668\n",
      "Epoch 2 Batch 909 Loss 1.3505\n",
      "Epoch 2 Batch 910 Loss 1.6830\n",
      "Epoch 2 Batch 911 Loss 1.7247\n",
      "Epoch 2 Batch 912 Loss 1.3458\n",
      "Epoch 2 Batch 913 Loss 1.5878\n",
      "Epoch 2 Batch 914 Loss 1.1344\n",
      "Epoch 2 Batch 915 Loss 1.6942\n",
      "Epoch 2 Batch 916 Loss 1.5199\n",
      "Epoch 2 Batch 917 Loss 1.5092\n",
      "Epoch 2 Batch 918 Loss 1.6385\n",
      "Epoch 2 Batch 919 Loss 1.7537\n",
      "Epoch 2 Batch 920 Loss 1.1611\n",
      "Epoch 2 Batch 921 Loss 1.5026\n",
      "Epoch 2 Batch 922 Loss 1.6619\n",
      "Epoch 2 Batch 923 Loss 1.4647\n",
      "Epoch 2 Batch 924 Loss 1.7685\n",
      "Epoch 2 Batch 925 Loss 1.3436\n",
      "Epoch 2 Batch 926 Loss 1.2958\n",
      "Epoch 2 Batch 927 Loss 1.6792\n",
      "Epoch 2 Batch 928 Loss 1.3161\n",
      "Epoch 2 Batch 929 Loss 1.6155\n",
      "Epoch 2 Batch 930 Loss 1.8860\n",
      "Epoch 2 Batch 931 Loss 1.7688\n",
      "Epoch 2 Batch 932 Loss 1.7147\n",
      "Epoch 2 Batch 933 Loss 1.5343\n",
      "Epoch 2 Batch 934 Loss 1.6716\n",
      "Epoch 2 Batch 935 Loss 1.5263\n",
      "Epoch 2 Batch 936 Loss 1.7571\n",
      "Epoch 2 Batch 937 Loss 1.4719\n",
      "Epoch 2 Batch 938 Loss 1.1875\n",
      "Epoch 2 Batch 939 Loss 1.4973\n",
      "Epoch 2 Batch 940 Loss 1.5937\n",
      "Epoch 2 Batch 941 Loss 1.8646\n",
      "Epoch 2 Batch 942 Loss 1.5449\n",
      "Epoch 2 Batch 943 Loss 1.3432\n",
      "Epoch 2 Batch 944 Loss 1.7436\n",
      "Epoch 2 Batch 945 Loss 1.7090\n",
      "Epoch 2 Batch 946 Loss 1.5269\n",
      "Epoch 2 Batch 947 Loss 1.7982\n",
      "Epoch 2 Batch 948 Loss 1.5381\n",
      "Epoch 2 Batch 949 Loss 1.6090\n",
      "Epoch 2 Batch 950 Loss 1.6667\n",
      "Epoch 2 Batch 951 Loss 1.3474\n",
      "Epoch 2 Batch 952 Loss 1.2854\n",
      "Epoch 2 Batch 953 Loss 1.8355\n",
      "Epoch 2 Batch 954 Loss 1.2834\n",
      "Epoch 2 Batch 955 Loss 1.6441\n",
      "Epoch 2 Batch 956 Loss 1.4814\n",
      "Epoch 2 Batch 957 Loss 1.3611\n",
      "Epoch 2 Batch 958 Loss 1.7799\n",
      "Epoch 2 Batch 959 Loss 1.5093\n",
      "Epoch 2 Batch 960 Loss 1.8649\n",
      "Epoch 2 Batch 961 Loss 1.4689\n",
      "Epoch 2 Batch 962 Loss 1.6843\n",
      "Epoch 2 Batch 963 Loss 1.6086\n",
      "Epoch 2 Batch 964 Loss 1.4703\n",
      "Epoch 2 Batch 965 Loss 1.2151\n",
      "Epoch 2 Batch 966 Loss 1.6191\n",
      "Epoch 2 Batch 967 Loss 1.4078\n",
      "Epoch 2 Batch 968 Loss 1.6719\n",
      "Epoch 2 Batch 969 Loss 1.2750\n",
      "Epoch 2 Batch 970 Loss 1.6290\n",
      "Epoch 2 Batch 971 Loss 1.8635\n",
      "Epoch 2 Batch 972 Loss 1.2355\n",
      "Epoch 2 Batch 973 Loss 1.7066\n",
      "Epoch 2 Batch 974 Loss 1.5250\n",
      "Epoch 2 Batch 975 Loss 1.3704\n",
      "Epoch 2 Batch 976 Loss 1.2907\n",
      "Epoch 2 Batch 977 Loss 1.4514\n",
      "Epoch 2 Batch 978 Loss 1.6931\n",
      "Epoch 2 Batch 979 Loss 1.8900\n",
      "Epoch 2 Batch 980 Loss 1.3467\n",
      "Epoch 2 Batch 981 Loss 1.2553\n",
      "Epoch 2 Batch 982 Loss 1.7564\n",
      "Epoch 2 Batch 983 Loss 1.9552\n",
      "Epoch 2 Batch 984 Loss 1.7683\n",
      "Epoch 2 Batch 985 Loss 1.3277\n",
      "Epoch 2 Batch 986 Loss 1.5736\n",
      "Epoch 2 Batch 987 Loss 1.6268\n",
      "Epoch 2 Batch 988 Loss 1.5957\n",
      "Epoch 2 Batch 989 Loss 1.7475\n",
      "Epoch 2 Batch 990 Loss 1.5840\n",
      "Epoch 2 Batch 991 Loss 1.4341\n",
      "Epoch 2 Batch 992 Loss 1.6709\n",
      "Epoch 2 Batch 993 Loss 1.6815\n",
      "Epoch 2 Batch 994 Loss 1.3737\n",
      "Epoch 2 Batch 995 Loss 1.3344\n",
      "Epoch 2 Batch 996 Loss 1.5757\n",
      "Epoch 2 Batch 997 Loss 1.4978\n",
      "Epoch 2 Batch 998 Loss 1.2641\n",
      "Epoch 2 Batch 999 Loss 1.6721\n",
      "Epoch 2 Batch 1000 Loss 1.4625\n",
      "Epoch 2 Batch 1001 Loss 1.3927\n",
      "Epoch 2 Batch 1002 Loss 1.4656\n",
      "Epoch 2 Batch 1003 Loss 1.2993\n",
      "Epoch 2 Batch 1004 Loss 1.5125\n",
      "Epoch 2 Batch 1005 Loss 1.7120\n",
      "Epoch 2 Batch 1006 Loss 1.6985\n",
      "Epoch 2 Batch 1007 Loss 1.5039\n",
      "Epoch 2 Batch 1008 Loss 1.4766\n",
      "Epoch 2 Batch 1009 Loss 1.5155\n",
      "Epoch 2 Batch 1010 Loss 1.6867\n",
      "Epoch 2 Batch 1011 Loss 1.4674\n",
      "Epoch 2 Batch 1012 Loss 1.7153\n",
      "Epoch 2 Batch 1013 Loss 1.5477\n",
      "Epoch 2 Batch 1014 Loss 1.5115\n",
      "Epoch 2 Batch 1015 Loss 1.2094\n",
      "Epoch 2 Batch 1016 Loss 1.2428\n",
      "Epoch 2 Batch 1017 Loss 1.1754\n",
      "Epoch 2 Batch 1018 Loss 1.5694\n",
      "Epoch 2 Batch 1019 Loss 1.8692\n",
      "Epoch 2 Batch 1020 Loss 1.7001\n",
      "Epoch 2 Batch 1021 Loss 1.4131\n",
      "Epoch 2 Batch 1022 Loss 1.5801\n",
      "Epoch 2 Batch 1023 Loss 1.6834\n",
      "Epoch 2 Batch 1024 Loss 1.8447\n",
      "Epoch 2 Batch 1025 Loss 1.6002\n",
      "Epoch 2 Batch 1026 Loss 1.6711\n",
      "Epoch 2 Batch 1027 Loss 1.3598\n",
      "Epoch 2 Batch 1028 Loss 1.7056\n",
      "Epoch 2 Batch 1029 Loss 1.6399\n",
      "Epoch 2 Batch 1030 Loss 1.6311\n",
      "Epoch 2 Batch 1031 Loss 1.5834\n",
      "Epoch 2 Batch 1032 Loss 1.3287\n",
      "Epoch 2 Batch 1033 Loss 1.2594\n",
      "Epoch 2 Batch 1034 Loss 1.5004\n",
      "Epoch 2 Batch 1035 Loss 1.5691\n",
      "Epoch 2 Batch 1036 Loss 1.6972\n",
      "Epoch 2 Batch 1037 Loss 1.7750\n",
      "Epoch 2 Batch 1038 Loss 1.4188\n",
      "Epoch 2 Batch 1039 Loss 1.6464\n",
      "Epoch 2 Batch 1040 Loss 1.4848\n",
      "Epoch 2 Batch 1041 Loss 1.6340\n",
      "Epoch 2 Batch 1042 Loss 1.4820\n",
      "Epoch 2 Batch 1043 Loss 1.4118\n",
      "Epoch 2 Batch 1044 Loss 1.5610\n",
      "Epoch 2 Batch 1045 Loss 1.4445\n",
      "Epoch 2 Batch 1046 Loss 1.6723\n",
      "Epoch 2 Batch 1047 Loss 1.6307\n",
      "Epoch 2 Batch 1048 Loss 1.5168\n",
      "Epoch 2 Batch 1049 Loss 1.1863\n",
      "Epoch 2 Batch 1050 Loss 1.2918\n",
      "Epoch 2 Batch 1051 Loss 1.5960\n",
      "Epoch 2 Batch 1052 Loss 1.5723\n",
      "Epoch 2 Batch 1053 Loss 1.7040\n",
      "Epoch 2 Batch 1054 Loss 1.5614\n",
      "Epoch 2 Batch 1055 Loss 1.5069\n",
      "Epoch 2 Batch 1056 Loss 1.4962\n",
      "Epoch 2 Batch 1057 Loss 1.4895\n",
      "Epoch 2 Batch 1058 Loss 1.3022\n",
      "Epoch 2 Batch 1059 Loss 1.2779\n",
      "Epoch 2 Batch 1060 Loss 1.3542\n",
      "Epoch 2 Batch 1061 Loss 1.3341\n",
      "Epoch 2 Batch 1062 Loss 1.4273\n",
      "Epoch 2 Batch 1063 Loss 1.4059\n",
      "Epoch 2 Batch 1064 Loss 1.5313\n",
      "Epoch 2 Batch 1065 Loss 1.0468\n",
      "Epoch 2 Batch 1066 Loss 1.3771\n",
      "Epoch 2 Batch 1067 Loss 1.3100\n",
      "Epoch 2 Batch 1068 Loss 1.4675\n",
      "Epoch 2 Batch 1069 Loss 1.3144\n",
      "Epoch 2 Batch 1070 Loss 1.4334\n",
      "Epoch 2 Batch 1071 Loss 1.2501\n",
      "Epoch 2 Batch 1072 Loss 1.6028\n",
      "Epoch 2 Batch 1073 Loss 1.6265\n",
      "Epoch 2 Batch 1074 Loss 1.3766\n",
      "Epoch 2 Batch 1075 Loss 1.5179\n",
      "Epoch 2 Batch 1076 Loss 1.4980\n",
      "Epoch 2 Batch 1077 Loss 1.6611\n",
      "Epoch 2 Batch 1078 Loss 1.8015\n",
      "Epoch 2 Batch 1079 Loss 1.6543\n",
      "Epoch 2 Batch 1080 Loss 1.6468\n",
      "Epoch 2 Batch 1081 Loss 1.7093\n",
      "Epoch 2 Batch 1082 Loss 1.3939\n",
      "Epoch 2 Batch 1083 Loss 1.3420\n",
      "Epoch 2 Batch 1084 Loss 1.7843\n",
      "Epoch 2 Batch 1085 Loss 1.4022\n",
      "Epoch 2 Batch 1086 Loss 1.4463\n",
      "Epoch 2 Batch 1087 Loss 1.3681\n",
      "Epoch 2 Batch 1088 Loss 1.6245\n",
      "Epoch 2 Batch 1089 Loss 1.3025\n",
      "Epoch 2 Batch 1090 Loss 1.7712\n",
      "Epoch 2 Batch 1091 Loss 1.4601\n",
      "Epoch 2 Batch 1092 Loss 1.6545\n",
      "Epoch 2 Batch 1093 Loss 1.2703\n",
      "Epoch 2 Batch 1094 Loss 1.3896\n",
      "Epoch 2 Batch 1095 Loss 1.5909\n",
      "Epoch 2 Batch 1096 Loss 1.6326\n",
      "Epoch 2 Batch 1097 Loss 1.4866\n",
      "Epoch 2 Batch 1098 Loss 1.2762\n",
      "Epoch 2 Batch 1099 Loss 1.5439\n",
      "Epoch 2 Batch 1100 Loss 1.5200\n",
      "Epoch 2 Batch 1101 Loss 1.4287\n",
      "Epoch 2 Batch 1102 Loss 1.8450\n",
      "Epoch 2 Batch 1103 Loss 1.5507\n",
      "Epoch 2 Batch 1104 Loss 1.4706\n",
      "Epoch 2 Batch 1105 Loss 1.2870\n",
      "Epoch 2 Batch 1106 Loss 1.5239\n",
      "Epoch 2 Batch 1107 Loss 1.5454\n",
      "Epoch 2 Batch 1108 Loss 1.6239\n",
      "Epoch 2 Batch 1109 Loss 1.6324\n",
      "Epoch 2 Batch 1110 Loss 1.7717\n",
      "Epoch 2 Batch 1111 Loss 1.4254\n",
      "Epoch 2 Batch 1112 Loss 1.6590\n",
      "Epoch 2 Batch 1113 Loss 1.7271\n",
      "Epoch 2 Batch 1114 Loss 1.5183\n",
      "Epoch 2 Batch 1115 Loss 1.7029\n",
      "Epoch 2 Batch 1116 Loss 1.3876\n",
      "Epoch 2 Batch 1117 Loss 1.4014\n",
      "Epoch 2 Batch 1118 Loss 1.4713\n",
      "Epoch 2 Batch 1119 Loss 1.3586\n",
      "Epoch 2 Batch 1120 Loss 1.4605\n",
      "Epoch 2 Batch 1121 Loss 1.2570\n",
      "Epoch 2 Batch 1122 Loss 1.4410\n",
      "Epoch 2 Batch 1123 Loss 1.4829\n",
      "Epoch 2 Batch 1124 Loss 1.3695\n",
      "Epoch 2 Batch 1125 Loss 1.5810\n",
      "Epoch 2 Batch 1126 Loss 1.6258\n",
      "Epoch 2 Batch 1127 Loss 1.3663\n",
      "Epoch 2 Batch 1128 Loss 1.3270\n",
      "Epoch 2 Batch 1129 Loss 1.4346\n",
      "Epoch 2 Batch 1130 Loss 1.7186\n",
      "Epoch 2 Batch 1131 Loss 1.6918\n",
      "Epoch 2 Batch 1132 Loss 1.3114\n",
      "Epoch 2 Batch 1133 Loss 1.3164\n",
      "Epoch 2 Batch 1134 Loss 1.2821\n",
      "Epoch 2 Batch 1135 Loss 1.5038\n",
      "Epoch 2 Batch 1136 Loss 1.2802\n",
      "Epoch 2 Batch 1137 Loss 1.2498\n",
      "Epoch 2 Batch 1138 Loss 1.5801\n",
      "Epoch 2 Batch 1139 Loss 2.0127\n",
      "Epoch 2 Batch 1140 Loss 1.5719\n",
      "Epoch 2 Batch 1141 Loss 1.4807\n",
      "Epoch 2 Batch 1142 Loss 1.4114\n",
      "Epoch 2 Batch 1143 Loss 1.8784\n",
      "Epoch 2 Batch 1144 Loss 1.3175\n",
      "Epoch 2 Batch 1145 Loss 2.0212\n",
      "Epoch 2 Batch 1146 Loss 1.3175\n",
      "Epoch 2 Batch 1147 Loss 1.6177\n",
      "Epoch 2 Batch 1148 Loss 1.6211\n",
      "Epoch 2 Batch 1149 Loss 1.6597\n",
      "Epoch 2 Batch 1150 Loss 1.3964\n",
      "Epoch 2 Batch 1151 Loss 1.4255\n",
      "Epoch 2 Batch 1152 Loss 1.4271\n",
      "Epoch 2 Batch 1153 Loss 1.5391\n",
      "Epoch 2 Batch 1154 Loss 1.8035\n",
      "Epoch 2 Batch 1155 Loss 1.0433\n",
      "Epoch 2 Batch 1156 Loss 1.6280\n",
      "Epoch 2 Batch 1157 Loss 1.5124\n",
      "Epoch 2 Batch 1158 Loss 1.4938\n",
      "Epoch 2 Batch 1159 Loss 1.5327\n",
      "Epoch 2 Batch 1160 Loss 1.8699\n",
      "Epoch 2 Batch 1161 Loss 1.5463\n",
      "Epoch 2 Batch 1162 Loss 1.5266\n",
      "Epoch 2 Batch 1163 Loss 1.4682\n",
      "Epoch 2 Batch 1164 Loss 1.5730\n",
      "Epoch 2 Batch 1165 Loss 1.3021\n",
      "Epoch 2 Batch 1166 Loss 1.5962\n",
      "Epoch 2 Batch 1167 Loss 1.3260\n",
      "Epoch 2 Batch 1168 Loss 1.7681\n",
      "Epoch 2 Batch 1169 Loss 1.5775\n",
      "Epoch 2 Batch 1170 Loss 1.8578\n",
      "Epoch 2 Batch 1171 Loss 1.4326\n",
      "Epoch 2 Batch 1172 Loss 1.2353\n",
      "Epoch 2 Batch 1173 Loss 1.3903\n",
      "Epoch 2 Batch 1174 Loss 1.7010\n",
      "Epoch 2 Batch 1175 Loss 1.3022\n",
      "Epoch 2 Batch 1176 Loss 1.5363\n",
      "Epoch 2 Batch 1177 Loss 1.6147\n",
      "Epoch 2 Batch 1178 Loss 1.9280\n",
      "Epoch 2 Batch 1179 Loss 1.2704\n",
      "Epoch 2 Batch 1180 Loss 1.7121\n",
      "Epoch 2 Batch 1181 Loss 1.5397\n",
      "Epoch 2 Batch 1182 Loss 1.1787\n",
      "Epoch 2 Batch 1183 Loss 1.5675\n",
      "Epoch 2 Batch 1184 Loss 1.5140\n",
      "Epoch 2 Batch 1185 Loss 1.5478\n",
      "Epoch 2 Batch 1186 Loss 1.4724\n",
      "Epoch 2 Batch 1187 Loss 1.7726\n",
      "Epoch 2 Batch 1188 Loss 1.4128\n",
      "Epoch 2 Batch 1189 Loss 1.9640\n",
      "Epoch 2 Batch 1190 Loss 1.6959\n",
      "Epoch 2 Batch 1191 Loss 1.2619\n",
      "Epoch 2 Batch 1192 Loss 1.4371\n",
      "Epoch 2 Batch 1193 Loss 1.6179\n",
      "Epoch 2 Batch 1194 Loss 1.5891\n",
      "Epoch 2 Batch 1195 Loss 1.5404\n",
      "Epoch 2 Batch 1196 Loss 1.8011\n",
      "Epoch 2 Batch 1197 Loss 1.4320\n",
      "Epoch 2 Batch 1198 Loss 1.0953\n",
      "Epoch 2 Batch 1199 Loss 1.7083\n",
      "Epoch 2 Batch 1200 Loss 1.3402\n",
      "Epoch 2 Batch 1201 Loss 1.6356\n",
      "Epoch 2 Batch 1202 Loss 1.1335\n",
      "Epoch 2 Batch 1203 Loss 1.5362\n",
      "Epoch 2 Batch 1204 Loss 1.5221\n",
      "Epoch 2 Batch 1205 Loss 1.6919\n",
      "Epoch 2 Batch 1206 Loss 1.3579\n",
      "Epoch 2 Batch 1207 Loss 1.3781\n",
      "Epoch 2 Batch 1208 Loss 1.4684\n",
      "Epoch 2 Batch 1209 Loss 1.5613\n",
      "Epoch 2 Batch 1210 Loss 1.6325\n",
      "Epoch 2 Batch 1211 Loss 1.6717\n",
      "Epoch 2 Batch 1212 Loss 1.5836\n",
      "Epoch 2 Batch 1213 Loss 1.6622\n",
      "Epoch 2 Batch 1214 Loss 1.3406\n",
      "Epoch 2 Batch 1215 Loss 1.3100\n",
      "Epoch 2 Batch 1216 Loss 1.5896\n",
      "Epoch 2 Batch 1217 Loss 1.4974\n",
      "Epoch 2 Batch 1218 Loss 1.6886\n",
      "Epoch 2 Batch 1219 Loss 1.5238\n",
      "Epoch 2 Batch 1220 Loss 1.2025\n",
      "Epoch 2 Batch 1221 Loss 1.1886\n",
      "Epoch 2 Batch 1222 Loss 1.3437\n",
      "Epoch 2 Batch 1223 Loss 1.7410\n",
      "Epoch 2 Batch 1224 Loss 1.5213\n",
      "Epoch 2 Batch 1225 Loss 1.3717\n",
      "Epoch 2 Batch 1226 Loss 1.5367\n",
      "Epoch 2 Batch 1227 Loss 1.7456\n",
      "Epoch 2 Batch 1228 Loss 1.5147\n",
      "Epoch 2 Batch 1229 Loss 1.5789\n",
      "Epoch 2 Batch 1230 Loss 1.1921\n",
      "Epoch 2 Batch 1231 Loss 1.6299\n",
      "Epoch 2 Batch 1232 Loss 1.4227\n",
      "Epoch 2 Batch 1233 Loss 1.4478\n",
      "Epoch 2 Batch 1234 Loss 1.4227\n",
      "Epoch 2 Batch 1235 Loss 1.4033\n",
      "Epoch 2 Batch 1236 Loss 1.4186\n",
      "Epoch 2 Batch 1237 Loss 1.4735\n",
      "Epoch 2 Batch 1238 Loss 1.4632\n",
      "Epoch 2 Batch 1239 Loss 1.3891\n",
      "Epoch 2 Batch 1240 Loss 1.7917\n",
      "Epoch 2 Batch 1241 Loss 1.4589\n",
      "Epoch 2 Batch 1242 Loss 1.5094\n",
      "Epoch 2 Batch 1243 Loss 1.7848\n",
      "Epoch 2 Batch 1244 Loss 1.5720\n",
      "Epoch 2 Batch 1245 Loss 1.6688\n",
      "Epoch 2 Batch 1246 Loss 1.7435\n",
      "Epoch 2 Batch 1247 Loss 1.3202\n",
      "Epoch 2 Batch 1248 Loss 1.5140\n",
      "Epoch 2 Batch 1249 Loss 1.4771\n",
      "Epoch 2 Batch 1250 Loss 1.6194\n",
      "Epoch 2 Batch 1251 Loss 1.3207\n",
      "Epoch 2 Batch 1252 Loss 1.8501\n",
      "Epoch 2 Batch 1253 Loss 1.2602\n",
      "Epoch 2 Batch 1254 Loss 1.5057\n",
      "Epoch 2 Batch 1255 Loss 1.4189\n",
      "Epoch 2 Batch 1256 Loss 1.6436\n",
      "Epoch 2 Batch 1257 Loss 1.4127\n",
      "Epoch 2 Batch 1258 Loss 1.3976\n",
      "Epoch 2 Batch 1259 Loss 1.6106\n",
      "Epoch 2 Batch 1260 Loss 1.5112\n",
      "Epoch 2 Batch 1261 Loss 1.8465\n",
      "Epoch 2 Batch 1262 Loss 1.4630\n",
      "Epoch 2 Batch 1263 Loss 1.4745\n",
      "Epoch 2 Batch 1264 Loss 1.3056\n",
      "Epoch 2 Batch 1265 Loss 1.9929\n",
      "Epoch 2 Batch 1266 Loss 1.6252\n",
      "Epoch 2 Batch 1267 Loss 1.5090\n",
      "Epoch 2 Batch 1268 Loss 1.6829\n",
      "Epoch 2 Batch 1269 Loss 1.8557\n",
      "Epoch 2 Batch 1270 Loss 1.7347\n",
      "Epoch 2 Batch 1271 Loss 1.3892\n",
      "Epoch 2 Batch 1272 Loss 1.7184\n",
      "Epoch 2 Batch 1273 Loss 1.4642\n",
      "Epoch 2 Batch 1274 Loss 1.3870\n",
      "Epoch 2 Batch 1275 Loss 1.4826\n",
      "Epoch 2 Batch 1276 Loss 1.7646\n",
      "Epoch 2 Batch 1277 Loss 1.5019\n",
      "Epoch 2 Batch 1278 Loss 1.5574\n",
      "Epoch 2 Batch 1279 Loss 1.5838\n",
      "Epoch 2 Batch 1280 Loss 1.2464\n",
      "Epoch 2 Batch 1281 Loss 1.4015\n",
      "Epoch 2 Batch 1282 Loss 1.5825\n",
      "Epoch 2 Batch 1283 Loss 1.5399\n",
      "Epoch 2 Batch 1284 Loss 1.7204\n",
      "Epoch 2 Batch 1285 Loss 1.7306\n",
      "Epoch 2 Batch 1286 Loss 1.6249\n",
      "Epoch 2 Batch 1287 Loss 1.2522\n",
      "Epoch 2 Batch 1288 Loss 1.2730\n",
      "Epoch 2 Batch 1289 Loss 1.5508\n",
      "Epoch 2 Batch 1290 Loss 1.6653\n",
      "Epoch 2 Batch 1291 Loss 1.5077\n",
      "Epoch 2 Batch 1292 Loss 1.3925\n",
      "Epoch 2 Batch 1293 Loss 1.5446\n",
      "Epoch 2 Batch 1294 Loss 1.3808\n",
      "Epoch 2 Batch 1295 Loss 1.6345\n",
      "Epoch 2 Batch 1296 Loss 1.7747\n",
      "Epoch 2 Batch 1297 Loss 1.5194\n",
      "Epoch 2 Batch 1298 Loss 1.6385\n",
      "Epoch 2 Batch 1299 Loss 1.2757\n",
      "Epoch 2 Batch 1300 Loss 1.7854\n",
      "Epoch 2 Batch 1301 Loss 1.3026\n",
      "Epoch 2 Batch 1302 Loss 1.4774\n",
      "Epoch 2 Batch 1303 Loss 1.5871\n",
      "Epoch 2 Batch 1304 Loss 1.8021\n",
      "Epoch 2 Batch 1305 Loss 1.5139\n",
      "Epoch 2 Batch 1306 Loss 1.6703\n",
      "Epoch 2 Batch 1307 Loss 1.7436\n",
      "Epoch 2 Batch 1308 Loss 1.4150\n",
      "Epoch 2 Batch 1309 Loss 1.5595\n",
      "Epoch 2 Batch 1310 Loss 1.5485\n",
      "Epoch 2 Batch 1311 Loss 1.5759\n",
      "Epoch 2 Batch 1312 Loss 1.2059\n",
      "Epoch 2 Batch 1313 Loss 1.2837\n",
      "Epoch 2 Batch 1314 Loss 1.5066\n",
      "Epoch 2 Batch 1315 Loss 1.5100\n",
      "Epoch 2 Batch 1316 Loss 1.3977\n",
      "Epoch 2 Batch 1317 Loss 1.3575\n",
      "Epoch 2 Batch 1318 Loss 1.1845\n",
      "Epoch 2 Batch 1319 Loss 1.4669\n",
      "Epoch 2 Batch 1320 Loss 1.6568\n",
      "Epoch 2 Batch 1321 Loss 1.4492\n",
      "Epoch 2 Batch 1322 Loss 1.6681\n",
      "Epoch 2 Batch 1323 Loss 1.7092\n",
      "Epoch 2 Batch 1324 Loss 1.5496\n",
      "Epoch 2 Batch 1325 Loss 1.2085\n",
      "Epoch 2 Batch 1326 Loss 1.5913\n",
      "Epoch 2 Batch 1327 Loss 1.3036\n",
      "Epoch 2 Batch 1328 Loss 1.4992\n",
      "Epoch 2 Batch 1329 Loss 1.5333\n",
      "Epoch 2 Batch 1330 Loss 1.4014\n",
      "Epoch 2 Batch 1331 Loss 1.5864\n",
      "Epoch 2 Batch 1332 Loss 1.7915\n",
      "Epoch 2 Batch 1333 Loss 1.8013\n",
      "Epoch 2 Batch 1334 Loss 1.5437\n",
      "Epoch 2 Batch 1335 Loss 1.3046\n",
      "Epoch 2 Batch 1336 Loss 1.8458\n",
      "Epoch 2 Batch 1337 Loss 1.4606\n",
      "Epoch 2 Batch 1338 Loss 1.3598\n",
      "Epoch 2 Batch 1339 Loss 1.3443\n",
      "Epoch 2 Batch 1340 Loss 1.4299\n",
      "Epoch 2 Batch 1341 Loss 1.4890\n",
      "Epoch 2 Batch 1342 Loss 1.8481\n",
      "Epoch 2 Batch 1343 Loss 1.6558\n",
      "Epoch 2 Batch 1344 Loss 1.9386\n",
      "Epoch 2 Batch 1345 Loss 1.7975\n",
      "Epoch 2 Batch 1346 Loss 1.7996\n",
      "Epoch 2 Batch 1347 Loss 1.5528\n",
      "Epoch 2 Batch 1348 Loss 1.4377\n",
      "Epoch 2 Batch 1349 Loss 1.5161\n",
      "Epoch 2 Batch 1350 Loss 1.6744\n",
      "Epoch 2 Batch 1351 Loss 1.5405\n",
      "Epoch 2 Batch 1352 Loss 1.7804\n",
      "Epoch 2 Batch 1353 Loss 1.8424\n",
      "Epoch 2 Batch 1354 Loss 1.4825\n",
      "Epoch 2 Batch 1355 Loss 1.4671\n",
      "Epoch 2 Batch 1356 Loss 1.5957\n",
      "Epoch 2 Batch 1357 Loss 1.4445\n",
      "Epoch 2 Batch 1358 Loss 1.3334\n",
      "Epoch 2 Batch 1359 Loss 1.8290\n",
      "Epoch 2 Batch 1360 Loss 1.2936\n",
      "Epoch 2 Batch 1361 Loss 1.2679\n",
      "Epoch 2 Batch 1362 Loss 1.8457\n",
      "Epoch 2 Batch 1363 Loss 1.5233\n",
      "Epoch 2 Batch 1364 Loss 1.5828\n",
      "Epoch 2 Batch 1365 Loss 1.5450\n",
      "Epoch 2 Batch 1366 Loss 1.3435\n",
      "Epoch 2 Batch 1367 Loss 1.7035\n",
      "Epoch 2 Batch 1368 Loss 1.2616\n",
      "Epoch 2 Batch 1369 Loss 1.7212\n",
      "Epoch 2 Batch 1370 Loss 1.1942\n",
      "Epoch 2 Batch 1371 Loss 1.4986\n",
      "Epoch 2 Batch 1372 Loss 1.8479\n",
      "Epoch 2 Batch 1373 Loss 1.7009\n",
      "Epoch 2 Batch 1374 Loss 1.5914\n",
      "Epoch 2 Batch 1375 Loss 1.6154\n",
      "Epoch 2 Batch 1376 Loss 1.2595\n",
      "Epoch 2 Batch 1377 Loss 1.4321\n",
      "Epoch 2 Batch 1378 Loss 1.5633\n",
      "Epoch 2 Batch 1379 Loss 1.3989\n",
      "Epoch 2 Batch 1380 Loss 1.1381\n",
      "Epoch 2 Batch 1381 Loss 1.4227\n",
      "Epoch 2 Batch 1382 Loss 1.3415\n",
      "Epoch 2 Batch 1383 Loss 1.5098\n",
      "Epoch 2 Batch 1384 Loss 1.2052\n",
      "Epoch 2 Batch 1385 Loss 1.5734\n",
      "Epoch 2 Batch 1386 Loss 1.3541\n",
      "Epoch 2 Batch 1387 Loss 1.4893\n",
      "Epoch 2 Batch 1388 Loss 1.3167\n",
      "Epoch 2 Batch 1389 Loss 1.6757\n",
      "Epoch 2 Batch 1390 Loss 1.3579\n",
      "Epoch 2 Batch 1391 Loss 1.4878\n",
      "Epoch 2 Batch 1392 Loss 1.6910\n",
      "Epoch 2 Batch 1393 Loss 1.4125\n",
      "Epoch 2 Batch 1394 Loss 1.5516\n",
      "Epoch 2 Batch 1395 Loss 1.4125\n",
      "Epoch 2 Batch 1396 Loss 1.2989\n",
      "Epoch 2 Batch 1397 Loss 1.5432\n",
      "Epoch 2 Batch 1398 Loss 1.4617\n",
      "Epoch 2 Batch 1399 Loss 1.4691\n",
      "Epoch 2 Batch 1400 Loss 1.2450\n",
      "Epoch 2 Batch 1401 Loss 1.5163\n",
      "Epoch 2 Batch 1402 Loss 1.3678\n",
      "Epoch 2 Batch 1403 Loss 1.3043\n",
      "Epoch 2 Batch 1404 Loss 1.2098\n",
      "Epoch 2 Batch 1405 Loss 1.6095\n",
      "Epoch 2 Batch 1406 Loss 1.7115\n",
      "Epoch 2 Batch 1407 Loss 1.5031\n",
      "Epoch 2 Batch 1408 Loss 1.3846\n",
      "Epoch 2 Batch 1409 Loss 1.4092\n",
      "Epoch 2 Batch 1410 Loss 1.6130\n",
      "Epoch 2 Batch 1411 Loss 1.4797\n",
      "Epoch 2 Batch 1412 Loss 1.4318\n",
      "Epoch 2 Batch 1413 Loss 1.8241\n",
      "Epoch 2 Batch 1414 Loss 1.5434\n",
      "Epoch 2 Batch 1415 Loss 1.7282\n",
      "Epoch 2 Batch 1416 Loss 1.6632\n",
      "Epoch 2 Batch 1417 Loss 1.7282\n",
      "Epoch 2 Batch 1418 Loss 1.6012\n",
      "Epoch 2 Batch 1419 Loss 1.7050\n",
      "Epoch 2 Batch 1420 Loss 1.8551\n",
      "Epoch 2 Batch 1421 Loss 1.3842\n",
      "Epoch 2 Batch 1422 Loss 1.7421\n",
      "Epoch 2 Batch 1423 Loss 1.4862\n",
      "Epoch 2 Batch 1424 Loss 1.4987\n",
      "Epoch 2 Batch 1425 Loss 1.4562\n",
      "Epoch 2 Batch 1426 Loss 1.8128\n",
      "Epoch 2 Batch 1427 Loss 1.5466\n",
      "Epoch 2 Batch 1428 Loss 1.6174\n",
      "Epoch 2 Batch 1429 Loss 1.2367\n",
      "Epoch 2 Batch 1430 Loss 1.8623\n",
      "Epoch 2 Batch 1431 Loss 1.5083\n",
      "Epoch 2 Batch 1432 Loss 1.4596\n",
      "Epoch 2 Batch 1433 Loss 1.4091\n",
      "Epoch 2 Batch 1434 Loss 1.3667\n",
      "Epoch 2 Batch 1435 Loss 1.9131\n",
      "Epoch 2 Batch 1436 Loss 1.4744\n",
      "Epoch 2 Batch 1437 Loss 1.6097\n",
      "Epoch 2 Batch 1438 Loss 1.5729\n",
      "Epoch 2 Batch 1439 Loss 1.2454\n",
      "Epoch 2 Batch 1440 Loss 1.6393\n",
      "Epoch 2 Batch 1441 Loss 1.5256\n",
      "Epoch 2 Batch 1442 Loss 1.5746\n",
      "Epoch 2 Batch 1443 Loss 1.4215\n",
      "Epoch 2 Batch 1444 Loss 1.3744\n",
      "Epoch 2 Batch 1445 Loss 1.6576\n",
      "Epoch 2 Batch 1446 Loss 1.3288\n",
      "Epoch 2 Batch 1447 Loss 1.3852\n",
      "Epoch 2 Batch 1448 Loss 1.4714\n",
      "Epoch 2 Batch 1449 Loss 1.1396\n",
      "Epoch 2 Batch 1450 Loss 1.4404\n",
      "Epoch 2 Batch 1451 Loss 1.5413\n",
      "Epoch 2 Batch 1452 Loss 1.6646\n",
      "Epoch 2 Batch 1453 Loss 1.4647\n",
      "Epoch 2 Batch 1454 Loss 1.3416\n",
      "Epoch 2 Batch 1455 Loss 1.4496\n",
      "Epoch 2 Batch 1456 Loss 1.5522\n",
      "Epoch 2 Batch 1457 Loss 1.6158\n",
      "Epoch 2 Batch 1458 Loss 1.9317\n",
      "Epoch 2 Batch 1459 Loss 1.8238\n",
      "Epoch 2 Batch 1460 Loss 1.7704\n",
      "Epoch 2 Batch 1461 Loss 1.1750\n",
      "Epoch 2 Batch 1462 Loss 1.5292\n",
      "Epoch 2 Batch 1463 Loss 1.3761\n",
      "Epoch 2 Batch 1464 Loss 1.6055\n",
      "Epoch 2 Batch 1465 Loss 1.5406\n",
      "Epoch 2 Batch 1466 Loss 1.9633\n",
      "Epoch 2 Batch 1467 Loss 1.3332\n",
      "Epoch 2 Batch 1468 Loss 1.3939\n",
      "Epoch 2 Batch 1469 Loss 1.1204\n",
      "Epoch 2 Batch 1470 Loss 1.4761\n",
      "Epoch 2 Batch 1471 Loss 1.4782\n",
      "Epoch 2 Batch 1472 Loss 1.6466\n",
      "Epoch 2 Batch 1473 Loss 1.4513\n",
      "Epoch 2 Batch 1474 Loss 1.5906\n",
      "Epoch 2 Batch 1475 Loss 1.5143\n",
      "Epoch 2 Batch 1476 Loss 1.3812\n",
      "Epoch 2 Batch 1477 Loss 1.7069\n",
      "Epoch 2 Batch 1478 Loss 1.5371\n",
      "Epoch 2 Batch 1479 Loss 1.5126\n",
      "Epoch 2 Batch 1480 Loss 1.4207\n",
      "Epoch 2 Batch 1481 Loss 1.3555\n",
      "Epoch 2 Batch 1482 Loss 1.6453\n",
      "Epoch 2 Batch 1483 Loss 1.5890\n",
      "Epoch 2 Batch 1484 Loss 1.8186\n",
      "Epoch 2 Batch 1485 Loss 1.9007\n",
      "Epoch 2 Batch 1486 Loss 1.3753\n",
      "Epoch 2 Batch 1487 Loss 1.2454\n",
      "Epoch 2 Batch 1488 Loss 1.6925\n",
      "Epoch 2 Batch 1489 Loss 1.8971\n",
      "Epoch 2 Batch 1490 Loss 1.5505\n",
      "Epoch 2 Batch 1491 Loss 1.5783\n",
      "Epoch 2 Batch 1492 Loss 1.3028\n",
      "Epoch 2 Batch 1493 Loss 1.6448\n",
      "Epoch 2 Batch 1494 Loss 1.6470\n",
      "Epoch 2 Batch 1495 Loss 1.5655\n",
      "Epoch 2 Batch 1496 Loss 1.3484\n",
      "Epoch 2 Batch 1497 Loss 1.6292\n",
      "Epoch 2 Batch 1498 Loss 1.9110\n",
      "Epoch 2 Batch 1499 Loss 1.4818\n",
      "Epoch 2 Batch 1500 Loss 1.8589\n",
      "Epoch 2 Batch 1501 Loss 1.5254\n",
      "Epoch 2 Batch 1502 Loss 1.1614\n",
      "Epoch 2 Batch 1503 Loss 1.4443\n",
      "Epoch 2 Batch 1504 Loss 1.2983\n",
      "Epoch 2 Batch 1505 Loss 1.6317\n",
      "Epoch 2 Batch 1506 Loss 1.3087\n",
      "Epoch 2 Batch 1507 Loss 1.3895\n",
      "Epoch 2 Batch 1508 Loss 2.1499\n",
      "Epoch 2 Batch 1509 Loss 1.5077\n",
      "Epoch 2 Batch 1510 Loss 1.3716\n",
      "Epoch 2 Batch 1511 Loss 1.7379\n",
      "Epoch 2 Batch 1512 Loss 1.3008\n",
      "Epoch 2 Batch 1513 Loss 1.6741\n",
      "Epoch 2 Batch 1514 Loss 1.0470\n",
      "Epoch 2 Batch 1515 Loss 1.4036\n",
      "Epoch 2 Batch 1516 Loss 1.8407\n",
      "Epoch 2 Batch 1517 Loss 1.2293\n",
      "Epoch 2 Batch 1518 Loss 1.7095\n",
      "Epoch 2 Batch 1519 Loss 1.7741\n",
      "Epoch 2 Batch 1520 Loss 1.6948\n",
      "Epoch 2 Batch 1521 Loss 1.4490\n",
      "Epoch 2 Batch 1522 Loss 1.8316\n",
      "Epoch 2 Batch 1523 Loss 1.6742\n",
      "Epoch 2 Batch 1524 Loss 1.4867\n",
      "Epoch 2 Batch 1525 Loss 1.6333\n",
      "Epoch 2 Batch 1526 Loss 1.6832\n",
      "Epoch 2 Batch 1527 Loss 1.2648\n",
      "Epoch 2 Batch 1528 Loss 1.6214\n",
      "Epoch 2 Batch 1529 Loss 1.3637\n",
      "Epoch 2 Batch 1530 Loss 1.2154\n",
      "Epoch 2 Batch 1531 Loss 1.6267\n",
      "Epoch 2 Batch 1532 Loss 1.2836\n",
      "Epoch 2 Batch 1533 Loss 1.5777\n",
      "Epoch 2 Batch 1534 Loss 1.3810\n",
      "Epoch 2 Batch 1535 Loss 1.5741\n",
      "Epoch 2 Batch 1536 Loss 1.4278\n",
      "Epoch 2 Batch 1537 Loss 1.1481\n",
      "Epoch 2 Batch 1538 Loss 1.2839\n",
      "Epoch 2 Batch 1539 Loss 1.7750\n",
      "Epoch 2 Batch 1540 Loss 1.5365\n",
      "Epoch 2 Batch 1541 Loss 1.2622\n",
      "Epoch 2 Batch 1542 Loss 1.4360\n",
      "Epoch 2 Batch 1543 Loss 1.3896\n",
      "Epoch 2 Batch 1544 Loss 1.4827\n",
      "Epoch 2 Batch 1545 Loss 1.7055\n",
      "Epoch 2 Batch 1546 Loss 1.7388\n",
      "Epoch 2 Batch 1547 Loss 1.5591\n",
      "Epoch 2 Batch 1548 Loss 1.8397\n",
      "Epoch 2 Batch 1549 Loss 1.3952\n",
      "Epoch 2 Batch 1550 Loss 1.5400\n",
      "Epoch 2 Batch 1551 Loss 1.4580\n",
      "Epoch 2 Batch 1552 Loss 1.5462\n",
      "Epoch 2 Batch 1553 Loss 1.3269\n",
      "Epoch 2 Batch 1554 Loss 1.3356\n",
      "Epoch 2 Batch 1555 Loss 1.4246\n",
      "Epoch 2 Batch 1556 Loss 1.6316\n",
      "Epoch 2 Batch 1557 Loss 1.4033\n",
      "Epoch 2 Batch 1558 Loss 1.6028\n",
      "Epoch 2 Batch 1559 Loss 1.7155\n",
      "Epoch 2 Batch 1560 Loss 1.6555\n",
      "Epoch 2 Batch 1561 Loss 1.4913\n",
      "Epoch 2 Batch 1562 Loss 1.3939\n",
      "Epoch 2 Batch 1563 Loss 1.0761\n",
      "Epoch 2 Batch 1564 Loss 1.7079\n",
      "Epoch 2 Batch 1565 Loss 1.5019\n",
      "Epoch 2 Batch 1566 Loss 1.3384\n",
      "Epoch 2 Batch 1567 Loss 1.1798\n",
      "Epoch 2 Batch 1568 Loss 2.0302\n",
      "Epoch 2 Batch 1569 Loss 1.6041\n",
      "Epoch 2 Batch 1570 Loss 1.3031\n",
      "Epoch 2 Batch 1571 Loss 1.3023\n",
      "Epoch 2 Batch 1572 Loss 1.2534\n",
      "Epoch 2 Batch 1573 Loss 1.5833\n",
      "Epoch 2 Batch 1574 Loss 1.4177\n",
      "Epoch 2 Batch 1575 Loss 1.3716\n",
      "Epoch 2 Batch 1576 Loss 1.6480\n",
      "Epoch 2 Batch 1577 Loss 1.4140\n",
      "Epoch 2 Batch 1578 Loss 1.5352\n",
      "Epoch 2 Batch 1579 Loss 1.4938\n",
      "Epoch 2 Batch 1580 Loss 1.7397\n",
      "Epoch 2 Batch 1581 Loss 1.4448\n",
      "Epoch 2 Batch 1582 Loss 1.5012\n",
      "Epoch 2 Batch 1583 Loss 1.3801\n",
      "Epoch 2 Batch 1584 Loss 1.4309\n",
      "Epoch 2 Batch 1585 Loss 1.5798\n",
      "Epoch 2 Batch 1586 Loss 1.7215\n",
      "Epoch 2 Batch 1587 Loss 1.7493\n",
      "Epoch 2 Batch 1588 Loss 1.6719\n",
      "Epoch 2 Batch 1589 Loss 1.6024\n",
      "Epoch 2 Batch 1590 Loss 1.6048\n",
      "Epoch 2 Batch 1591 Loss 1.5592\n",
      "Epoch 2 Batch 1592 Loss 1.5691\n",
      "Epoch 2 Batch 1593 Loss 1.2447\n",
      "Epoch 2 Batch 1594 Loss 1.3637\n",
      "Epoch 2 Batch 1595 Loss 1.4175\n",
      "Epoch 2 Batch 1596 Loss 1.5809\n",
      "Epoch 2 Batch 1597 Loss 1.6696\n",
      "Epoch 2 Batch 1598 Loss 1.1678\n",
      "Epoch 2 Batch 1599 Loss 1.3577\n",
      "Epoch 2 Batch 1600 Loss 1.4424\n",
      "Epoch 2 Batch 1601 Loss 1.6483\n",
      "Epoch 2 Batch 1602 Loss 1.2962\n",
      "Epoch 2 Batch 1603 Loss 1.2527\n",
      "Epoch 2 Batch 1604 Loss 1.5227\n",
      "Epoch 2 Batch 1605 Loss 1.6538\n",
      "Epoch 2 Batch 1606 Loss 1.6388\n",
      "Epoch 2 Batch 1607 Loss 1.6661\n",
      "Epoch 2 Batch 1608 Loss 1.4549\n",
      "Epoch 2 Batch 1609 Loss 1.2238\n",
      "Epoch 2 Batch 1610 Loss 1.6074\n",
      "Epoch 2 Batch 1611 Loss 1.7722\n",
      "Epoch 2 Batch 1612 Loss 1.4976\n",
      "Epoch 2 Batch 1613 Loss 1.6946\n",
      "Epoch 2 Batch 1614 Loss 1.2896\n",
      "Epoch 2 Batch 1615 Loss 1.6004\n",
      "Epoch 2 Batch 1616 Loss 1.5421\n",
      "Epoch 2 Batch 1617 Loss 1.4946\n",
      "Epoch 2 Batch 1618 Loss 1.1901\n",
      "Epoch 2 Batch 1619 Loss 1.5257\n",
      "Epoch 2 Batch 1620 Loss 1.3413\n",
      "Epoch 2 Batch 1621 Loss 1.4943\n",
      "Epoch 2 Batch 1622 Loss 1.3505\n",
      "Epoch 2 Batch 1623 Loss 1.6546\n",
      "Epoch 2 Batch 1624 Loss 1.5392\n",
      "Epoch 2 Batch 1625 Loss 1.4461\n",
      "Epoch 2 Batch 1626 Loss 1.1413\n",
      "Epoch 2 Batch 1627 Loss 1.4397\n",
      "Epoch 2 Batch 1628 Loss 1.4078\n",
      "Epoch 2 Batch 1629 Loss 1.3300\n",
      "Epoch 2 Batch 1630 Loss 1.6376\n",
      "Epoch 2 Batch 1631 Loss 1.5064\n",
      "Epoch 2 Batch 1632 Loss 1.8716\n",
      "Epoch 2 Batch 1633 Loss 1.2003\n",
      "Epoch 2 Batch 1634 Loss 1.2237\n",
      "Epoch 2 Batch 1635 Loss 1.5828\n",
      "Epoch 2 Batch 1636 Loss 1.5196\n",
      "Epoch 2 Batch 1637 Loss 1.5325\n",
      "Epoch 2 Batch 1638 Loss 1.2312\n",
      "Epoch 2 Batch 1639 Loss 1.5825\n",
      "Epoch 2 Batch 1640 Loss 1.5590\n",
      "Epoch 2 Batch 1641 Loss 1.2369\n",
      "Epoch 2 Batch 1642 Loss 1.4706\n",
      "Epoch 2 Batch 1643 Loss 1.7298\n",
      "Epoch 2 Batch 1644 Loss 1.5160\n",
      "Epoch 2 Batch 1645 Loss 1.6420\n",
      "Epoch 2 Batch 1646 Loss 1.3421\n",
      "Epoch 2 Batch 1647 Loss 1.5101\n",
      "Epoch 2 Batch 1648 Loss 1.3859\n",
      "Epoch 2 Batch 1649 Loss 1.4586\n",
      "Epoch 2 Batch 1650 Loss 1.5326\n",
      "Epoch 2 Batch 1651 Loss 1.4088\n",
      "Epoch 2 Batch 1652 Loss 1.3944\n",
      "Epoch 2 Batch 1653 Loss 1.4601\n",
      "Epoch 2 Batch 1654 Loss 1.5949\n",
      "Epoch 2 Batch 1655 Loss 1.9381\n",
      "Epoch 2 Batch 1656 Loss 1.5188\n",
      "Epoch 2 Batch 1657 Loss 1.4852\n",
      "Epoch 2 Batch 1658 Loss 1.3748\n",
      "Epoch 2 Batch 1659 Loss 1.4335\n",
      "Epoch 2 Batch 1660 Loss 1.6026\n",
      "Epoch 2 Batch 1661 Loss 1.3544\n",
      "Epoch 2 Batch 1662 Loss 1.5029\n",
      "Epoch 2 Batch 1663 Loss 1.0623\n",
      "Epoch 2 Batch 1664 Loss 1.0681\n",
      "Epoch 2 Batch 1665 Loss 1.4060\n",
      "Epoch 2 Batch 1666 Loss 1.5118\n",
      "Epoch 2 Batch 1667 Loss 1.2720\n",
      "Epoch 2 Batch 1668 Loss 1.5997\n",
      "Epoch 2 Batch 1669 Loss 1.2435\n",
      "Epoch 2 Batch 1670 Loss 1.4961\n",
      "Epoch 2 Batch 1671 Loss 1.7994\n",
      "Epoch 2 Batch 1672 Loss 1.5394\n",
      "Epoch 2 Batch 1673 Loss 1.6521\n",
      "Epoch 2 Batch 1674 Loss 1.3121\n",
      "Epoch 2 Batch 1675 Loss 1.7651\n",
      "Epoch 2 Batch 1676 Loss 1.7234\n",
      "Epoch 2 Batch 1677 Loss 1.4347\n",
      "Epoch 2 Batch 1678 Loss 1.4913\n",
      "Epoch 2 Batch 1679 Loss 1.6858\n",
      "Epoch 2 Batch 1680 Loss 1.3105\n",
      "Epoch 2 Batch 1681 Loss 1.5199\n",
      "Epoch 2 Batch 1682 Loss 1.4414\n",
      "Epoch 2 Batch 1683 Loss 1.3266\n",
      "Epoch 2 Batch 1684 Loss 1.6148\n",
      "Epoch 2 Batch 1685 Loss 1.2514\n",
      "Epoch 2 Batch 1686 Loss 1.5217\n",
      "Epoch 2 Batch 1687 Loss 1.4263\n",
      "Epoch 2 Batch 1688 Loss 1.2601\n",
      "Epoch 2 Batch 1689 Loss 1.3857\n",
      "Epoch 2 Batch 1690 Loss 1.4587\n",
      "Epoch 2 Batch 1691 Loss 1.3625\n",
      "Epoch 2 Batch 1692 Loss 1.7362\n",
      "Epoch 2 Batch 1693 Loss 1.7981\n",
      "Epoch 2 Batch 1694 Loss 1.5830\n",
      "Epoch 2 Batch 1695 Loss 1.5562\n",
      "Epoch 2 Batch 1696 Loss 1.3840\n",
      "Epoch 2 Batch 1697 Loss 1.2800\n",
      "Epoch 2 Batch 1698 Loss 1.5938\n",
      "Epoch 2 Batch 1699 Loss 1.5875\n",
      "Epoch 2 Batch 1700 Loss 1.4367\n",
      "Epoch 2 Batch 1701 Loss 1.4943\n",
      "Epoch 2 Batch 1702 Loss 1.4060\n",
      "Epoch 2 Batch 1703 Loss 1.2381\n",
      "Epoch 2 Batch 1704 Loss 1.5217\n",
      "Epoch 2 Batch 1705 Loss 1.3969\n",
      "Epoch 2 Batch 1706 Loss 1.3943\n",
      "Epoch 2 Batch 1707 Loss 1.1208\n",
      "Epoch 2 Batch 1708 Loss 1.4564\n",
      "Epoch 2 Batch 1709 Loss 1.5776\n",
      "Epoch 2 Batch 1710 Loss 1.5171\n",
      "Epoch 2 Batch 1711 Loss 1.8862\n",
      "Epoch 2 Batch 1712 Loss 1.3999\n",
      "Epoch 2 Batch 1713 Loss 1.5949\n",
      "Epoch 2 Batch 1714 Loss 1.4032\n",
      "Epoch 2 Batch 1715 Loss 1.8656\n",
      "Epoch 2 Batch 1716 Loss 1.3455\n",
      "Epoch 2 Batch 1717 Loss 1.3399\n",
      "Epoch 2 Batch 1718 Loss 1.6302\n",
      "Epoch 2 Batch 1719 Loss 1.3807\n",
      "Epoch 2 Batch 1720 Loss 1.5263\n",
      "Epoch 2 Batch 1721 Loss 1.4573\n",
      "Epoch 2 Batch 1722 Loss 1.4537\n",
      "Epoch 2 Batch 1723 Loss 1.3507\n",
      "Epoch 2 Batch 1724 Loss 1.2899\n",
      "Epoch 2 Batch 1725 Loss 1.9121\n",
      "Epoch 2 Batch 1726 Loss 1.2513\n",
      "Epoch 2 Batch 1727 Loss 1.4424\n",
      "Epoch 2 Batch 1728 Loss 1.3572\n",
      "Epoch 2 Batch 1729 Loss 1.4454\n",
      "Epoch 2 Batch 1730 Loss 1.4797\n",
      "Epoch 2 Batch 1731 Loss 1.5237\n",
      "Epoch 2 Batch 1732 Loss 1.5303\n",
      "Epoch 2 Batch 1733 Loss 1.5805\n",
      "Epoch 2 Batch 1734 Loss 1.3356\n",
      "Epoch 2 Batch 1735 Loss 1.4429\n",
      "Epoch 2 Batch 1736 Loss 1.3363\n",
      "Epoch 2 Batch 1737 Loss 1.3458\n",
      "Epoch 2 Batch 1738 Loss 1.2381\n",
      "Epoch 2 Batch 1739 Loss 1.8275\n",
      "Epoch 2 Batch 1740 Loss 1.5638\n",
      "Epoch 2 Batch 1741 Loss 1.1973\n",
      "Epoch 2 Batch 1742 Loss 1.4607\n",
      "Epoch 2 Batch 1743 Loss 1.5978\n",
      "Epoch 2 Batch 1744 Loss 1.1955\n",
      "Epoch 2 Batch 1745 Loss 1.6066\n",
      "Epoch 2 Batch 1746 Loss 1.4568\n",
      "Epoch 2 Batch 1747 Loss 1.6620\n",
      "Epoch 2 Batch 1748 Loss 1.2567\n",
      "Epoch 2 Batch 1749 Loss 1.4652\n",
      "Epoch 2 Batch 1750 Loss 1.4456\n",
      "Epoch 2 Batch 1751 Loss 1.6506\n",
      "Epoch 2 Batch 1752 Loss 1.7243\n",
      "Epoch 2 Batch 1753 Loss 1.4866\n",
      "Epoch 2 Batch 1754 Loss 1.9241\n",
      "Epoch 2 Batch 1755 Loss 1.3230\n",
      "Epoch 2 Batch 1756 Loss 1.8288\n",
      "Epoch 2 Batch 1757 Loss 1.5441\n",
      "Epoch 2 Batch 1758 Loss 1.5833\n",
      "Epoch 2 Batch 1759 Loss 1.3424\n",
      "Epoch 2 Batch 1760 Loss 1.8196\n",
      "Epoch 2 Batch 1761 Loss 1.4809\n",
      "Epoch 2 Batch 1762 Loss 1.6141\n",
      "Epoch 2 Batch 1763 Loss 1.5734\n",
      "Epoch 2 Batch 1764 Loss 1.6886\n",
      "Epoch 2 Batch 1765 Loss 1.8434\n",
      "Epoch 2 Batch 1766 Loss 1.4793\n",
      "Epoch 2 Batch 1767 Loss 1.3711\n",
      "Epoch 2 Batch 1768 Loss 1.7678\n",
      "Epoch 2 Batch 1769 Loss 1.5530\n",
      "Epoch 2 Batch 1770 Loss 1.4051\n",
      "Epoch 2 Batch 1771 Loss 1.6812\n",
      "Epoch 2 Batch 1772 Loss 1.4820\n",
      "Epoch 2 Batch 1773 Loss 1.4296\n",
      "Epoch 2 Batch 1774 Loss 1.5061\n",
      "Epoch 2 Batch 1775 Loss 1.6276\n",
      "Epoch 2 Batch 1776 Loss 1.6652\n",
      "Epoch 2 Batch 1777 Loss 1.4504\n",
      "Epoch 2 Batch 1778 Loss 1.4836\n",
      "Epoch 2 Batch 1779 Loss 1.3925\n",
      "Epoch 2 Batch 1780 Loss 1.3398\n",
      "Epoch 2 Batch 1781 Loss 1.1407\n",
      "Epoch 2 Batch 1782 Loss 1.5858\n",
      "Epoch 2 Batch 1783 Loss 1.8632\n",
      "Epoch 2 Batch 1784 Loss 1.5197\n",
      "Epoch 2 Batch 1785 Loss 1.4094\n",
      "Epoch 2 Batch 1786 Loss 1.7975\n",
      "Epoch 2 Batch 1787 Loss 1.2330\n",
      "Epoch 2 Batch 1788 Loss 1.8532\n",
      "Epoch 2 Batch 1789 Loss 1.3882\n",
      "Epoch 2 Batch 1790 Loss 1.7667\n",
      "Epoch 2 Batch 1791 Loss 1.3612\n",
      "Epoch 2 Batch 1792 Loss 1.3519\n",
      "Epoch 2 Batch 1793 Loss 1.9645\n",
      "Epoch 2 Batch 1794 Loss 1.5992\n",
      "Epoch 2 Batch 1795 Loss 1.6948\n",
      "Epoch 2 Batch 1796 Loss 1.1976\n",
      "Epoch 2 Batch 1797 Loss 1.5720\n",
      "Epoch 2 Batch 1798 Loss 1.2259\n",
      "Epoch 2 Batch 1799 Loss 1.4615\n",
      "Epoch 2 Batch 1800 Loss 1.1651\n",
      "Epoch 2 Batch 1801 Loss 1.1072\n",
      "Epoch 2 Batch 1802 Loss 1.3793\n",
      "Epoch 2 Batch 1803 Loss 1.3937\n",
      "Epoch 2 Batch 1804 Loss 1.2676\n",
      "Epoch 2 Batch 1805 Loss 1.4419\n",
      "Epoch 2 Batch 1806 Loss 1.2901\n",
      "Epoch 2 Batch 1807 Loss 1.5031\n",
      "Epoch 2 Batch 1808 Loss 1.3728\n",
      "Epoch 2 Batch 1809 Loss 1.2821\n",
      "Epoch 2 Batch 1810 Loss 1.4561\n",
      "Epoch 2 Batch 1811 Loss 1.6216\n",
      "Epoch 2 Batch 1812 Loss 1.6259\n",
      "Epoch 2 Batch 1813 Loss 1.2744\n",
      "Epoch 2 Batch 1814 Loss 1.1966\n",
      "Epoch 2 Batch 1815 Loss 1.3414\n",
      "Epoch 2 Batch 1816 Loss 1.4305\n",
      "Epoch 2 Batch 1817 Loss 1.4334\n",
      "Epoch 2 Batch 1818 Loss 1.6755\n",
      "Epoch 2 Batch 1819 Loss 1.6950\n",
      "Epoch 2 Batch 1820 Loss 1.7927\n",
      "Epoch 2 Batch 1821 Loss 1.7854\n",
      "Epoch 2 Batch 1822 Loss 1.7433\n",
      "Epoch 2 Batch 1823 Loss 1.5731\n",
      "Epoch 2 Batch 1824 Loss 1.7183\n",
      "Epoch 2 Batch 1825 Loss 1.3128\n",
      "Epoch 2 Batch 1826 Loss 1.6775\n",
      "Epoch 2 Batch 1827 Loss 1.4184\n",
      "Epoch 2 Batch 1828 Loss 1.3506\n",
      "Epoch 2 Batch 1829 Loss 1.7696\n",
      "Epoch 2 Batch 1830 Loss 1.4843\n",
      "Epoch 2 Batch 1831 Loss 1.6068\n",
      "Epoch 2 Batch 1832 Loss 1.2420\n",
      "Epoch 2 Batch 1833 Loss 1.4160\n",
      "Epoch 2 Batch 1834 Loss 1.3632\n",
      "Epoch 2 Batch 1835 Loss 1.4128\n",
      "Epoch 2 Batch 1836 Loss 1.4668\n",
      "Epoch 2 Batch 1837 Loss 1.4146\n",
      "Epoch 2 Batch 1838 Loss 1.5727\n",
      "Epoch 2 Batch 1839 Loss 1.6707\n",
      "Epoch 2 Batch 1840 Loss 1.4574\n",
      "Epoch 2 Batch 1841 Loss 1.1279\n",
      "Epoch 2 Batch 1842 Loss 1.7912\n",
      "Epoch 2 Batch 1843 Loss 1.3406\n",
      "Epoch 2 Batch 1844 Loss 1.4739\n",
      "Epoch 2 Batch 1845 Loss 1.5415\n",
      "Epoch 2 Batch 1846 Loss 1.4908\n",
      "Epoch 2 Batch 1847 Loss 1.4281\n",
      "Epoch 2 Batch 1848 Loss 1.3248\n",
      "Epoch 2 Batch 1849 Loss 1.5375\n",
      "Epoch 2 Batch 1850 Loss 1.3532\n",
      "Epoch 2 Batch 1851 Loss 1.1913\n",
      "Epoch 2 Batch 1852 Loss 1.5846\n",
      "Epoch 2 Batch 1853 Loss 1.5517\n",
      "Epoch 2 Batch 1854 Loss 1.3961\n",
      "Epoch 2 Batch 1855 Loss 1.7753\n",
      "Epoch 2 Batch 1856 Loss 1.2075\n",
      "Epoch 2 Batch 1857 Loss 1.3334\n",
      "Epoch 2 Batch 1858 Loss 1.1308\n",
      "Epoch 2 Batch 1859 Loss 1.5344\n",
      "Epoch 2 Batch 1860 Loss 1.5239\n",
      "Epoch 2 Batch 1861 Loss 1.4985\n",
      "Epoch 2 Batch 1862 Loss 1.3582\n",
      "Epoch 2 Batch 1863 Loss 1.3883\n",
      "Epoch 2 Batch 1864 Loss 1.2959\n",
      "Epoch 2 Batch 1865 Loss 1.3451\n",
      "Epoch 2 Batch 1866 Loss 1.6893\n",
      "Epoch 2 Batch 1867 Loss 1.5702\n",
      "Epoch 2 Batch 1868 Loss 1.5152\n",
      "Epoch 2 Batch 1869 Loss 1.6248\n",
      "Epoch 2 Batch 1870 Loss 1.4447\n",
      "Epoch 2 Batch 1871 Loss 1.6099\n",
      "Epoch 2 Batch 1872 Loss 1.5815\n",
      "Epoch 2 Batch 1873 Loss 1.6901\n",
      "Epoch 2 Batch 1874 Loss 1.3146\n",
      "Epoch 2 Batch 1875 Loss 1.5718\n",
      "Epoch 2 Batch 1876 Loss 1.3194\n",
      "Epoch 2 Batch 1877 Loss 1.4376\n",
      "Epoch 2 Batch 1878 Loss 1.7445\n",
      "Epoch 2 Batch 1879 Loss 1.5916\n",
      "Epoch 2 Batch 1880 Loss 1.7535\n",
      "Epoch 2 Batch 1881 Loss 1.5912\n",
      "Epoch 2 Batch 1882 Loss 1.6912\n",
      "Epoch 2 Batch 1883 Loss 1.3492\n",
      "Epoch 2 Batch 1884 Loss 1.5382\n",
      "Epoch 2 Batch 1885 Loss 1.2720\n",
      "Epoch 2 Batch 1886 Loss 1.4767\n",
      "Epoch 2 Batch 1887 Loss 1.7514\n",
      "Epoch 2 Batch 1888 Loss 1.6904\n",
      "Epoch 2 Batch 1889 Loss 1.4479\n",
      "Epoch 2 Batch 1890 Loss 1.7256\n",
      "Epoch 2 Batch 1891 Loss 1.6160\n",
      "Epoch 2 Batch 1892 Loss 1.6349\n",
      "Epoch 2 Batch 1893 Loss 1.0789\n",
      "Epoch 2 Batch 1894 Loss 1.3779\n",
      "Epoch 2 Batch 1895 Loss 1.5991\n",
      "Epoch 2 Batch 1896 Loss 1.6344\n",
      "Epoch 2 Batch 1897 Loss 1.7074\n",
      "Epoch 2 Batch 1898 Loss 1.5606\n",
      "Epoch 2 Batch 1899 Loss 1.5778\n",
      "Epoch 2 Batch 1900 Loss 1.2765\n",
      "Epoch 2 Batch 1901 Loss 1.5442\n",
      "Epoch 2 Batch 1902 Loss 1.4637\n",
      "Epoch 2 Batch 1903 Loss 1.3423\n",
      "Epoch 2 Batch 1904 Loss 1.3848\n",
      "Epoch 2 Batch 1905 Loss 1.2106\n",
      "Epoch 2 Batch 1906 Loss 1.5498\n",
      "Epoch 2 Batch 1907 Loss 1.3012\n",
      "Epoch 2 Batch 1908 Loss 1.8131\n",
      "Epoch 2 Batch 1909 Loss 1.3436\n",
      "Epoch 2 Batch 1910 Loss 1.7417\n",
      "Epoch 2 Batch 1911 Loss 1.4036\n",
      "Epoch 2 Batch 1912 Loss 1.5381\n",
      "Epoch 2 Batch 1913 Loss 1.6021\n",
      "Epoch 2 Batch 1914 Loss 1.3135\n",
      "Epoch 2 Batch 1915 Loss 1.5378\n",
      "Epoch 2 Batch 1916 Loss 1.4803\n",
      "Epoch 2 Batch 1917 Loss 1.2905\n",
      "Epoch 2 Batch 1918 Loss 1.4874\n",
      "Epoch 2 Batch 1919 Loss 1.5125\n",
      "Epoch 2 Batch 1920 Loss 1.2678\n",
      "Epoch 2 Batch 1921 Loss 1.5446\n",
      "Epoch 2 Batch 1922 Loss 1.7061\n",
      "Epoch 2 Batch 1923 Loss 1.3729\n",
      "Epoch 2 Batch 1924 Loss 1.5221\n",
      "Epoch 2 Batch 1925 Loss 1.3765\n",
      "Epoch 2 Batch 1926 Loss 1.2983\n",
      "Epoch 2 Batch 1927 Loss 1.7616\n",
      "Epoch 2 Batch 1928 Loss 1.2906\n",
      "Epoch 2 Batch 1929 Loss 1.5377\n",
      "Epoch 2 Batch 1930 Loss 1.2943\n",
      "Epoch 2 Batch 1931 Loss 1.4228\n",
      "Epoch 2 Batch 1932 Loss 1.5882\n",
      "Epoch 2 Batch 1933 Loss 1.3800\n",
      "Epoch 2 Batch 1934 Loss 1.5247\n",
      "Epoch 2 Batch 1935 Loss 1.4192\n",
      "Epoch 2 Batch 1936 Loss 1.8176\n",
      "Epoch 2 Batch 1937 Loss 1.4047\n",
      "Epoch 2 Batch 1938 Loss 1.6255\n",
      "Epoch 2 Batch 1939 Loss 1.5163\n",
      "Epoch 2 Batch 1940 Loss 1.5418\n",
      "Epoch 2 Batch 1941 Loss 1.4826\n",
      "Epoch 2 Batch 1942 Loss 1.7129\n",
      "Epoch 2 Batch 1943 Loss 1.5115\n",
      "Epoch 2 Batch 1944 Loss 1.2532\n",
      "Epoch 2 Batch 1945 Loss 1.4669\n",
      "Epoch 2 Batch 1946 Loss 1.3520\n",
      "Epoch 2 Batch 1947 Loss 1.5372\n",
      "Epoch 2 Batch 1948 Loss 1.2535\n",
      "Epoch 2 Batch 1949 Loss 1.6173\n",
      "Epoch 2 Batch 1950 Loss 1.5222\n",
      "Epoch 2 Batch 1951 Loss 1.5596\n",
      "Epoch 2 Batch 1952 Loss 1.3524\n",
      "Epoch 2 Batch 1953 Loss 1.3692\n",
      "Epoch 2 Batch 1954 Loss 1.5995\n",
      "Epoch 2 Batch 1955 Loss 1.4952\n",
      "Epoch 2 Batch 1956 Loss 1.3983\n",
      "Epoch 2 Batch 1957 Loss 1.2321\n",
      "Epoch 2 Batch 1958 Loss 1.2021\n",
      "Epoch 2 Batch 1959 Loss 1.3111\n",
      "Epoch 2 Batch 1960 Loss 1.5743\n",
      "Epoch 2 Batch 1961 Loss 1.3795\n",
      "Epoch 2 Batch 1962 Loss 1.8182\n",
      "Epoch 2 Batch 1963 Loss 1.5582\n",
      "Epoch 2 Batch 1964 Loss 1.5313\n",
      "Epoch 2 Batch 1965 Loss 1.4837\n",
      "Epoch 2 Batch 1966 Loss 1.6027\n",
      "Epoch 2 Batch 1967 Loss 1.7876\n",
      "Epoch 2 Batch 1968 Loss 1.5457\n",
      "Epoch 2 Batch 1969 Loss 1.5303\n",
      "Epoch 2 Batch 1970 Loss 1.2431\n",
      "Epoch 2 Batch 1971 Loss 1.6121\n",
      "Epoch 2 Batch 1972 Loss 1.4160\n",
      "Epoch 2 Batch 1973 Loss 1.3443\n",
      "Epoch 2 Batch 1974 Loss 1.2569\n",
      "Epoch 2 Batch 1975 Loss 1.5919\n",
      "Epoch 2 Batch 1976 Loss 1.5397\n",
      "Epoch 2 Batch 1977 Loss 1.3922\n",
      "Epoch 2 Batch 1978 Loss 1.5213\n",
      "Epoch 2 Batch 1979 Loss 1.4710\n",
      "Epoch 2 Batch 1980 Loss 1.1861\n",
      "Epoch 2 Batch 1981 Loss 1.3195\n",
      "Epoch 2 Batch 1982 Loss 1.5168\n",
      "Epoch 2 Batch 1983 Loss 1.7061\n",
      "Epoch 2 Batch 1984 Loss 1.3874\n",
      "Epoch 2 Batch 1985 Loss 1.3505\n",
      "Epoch 2 Batch 1986 Loss 1.6496\n",
      "Epoch 2 Batch 1987 Loss 1.5764\n",
      "Epoch 2 Batch 1988 Loss 1.2950\n",
      "Epoch 2 Batch 1989 Loss 1.5791\n",
      "Epoch 2 Batch 1990 Loss 1.4192\n",
      "Epoch 2 Batch 1991 Loss 1.1896\n",
      "Epoch 2 Batch 1992 Loss 1.4458\n",
      "Epoch 2 Batch 1993 Loss 1.4659\n",
      "Epoch 2 Batch 1994 Loss 1.3443\n",
      "Epoch 2 Batch 1995 Loss 1.2695\n",
      "Epoch 2 Batch 1996 Loss 1.6780\n",
      "Epoch 2 Batch 1997 Loss 1.4739\n",
      "Epoch 2 Batch 1998 Loss 1.4943\n",
      "Epoch 2 Batch 1999 Loss 1.3237\n",
      "Epoch 2 Batch 2000 Loss 1.1606\n",
      "Epoch 2 Batch 2001 Loss 1.2737\n",
      "Epoch 2 Batch 2002 Loss 1.4211\n",
      "Epoch 2 Batch 2003 Loss 1.3825\n",
      "Epoch 2 Batch 2004 Loss 1.6373\n",
      "Epoch 2 Batch 2005 Loss 1.7108\n",
      "Epoch 2 Batch 2006 Loss 1.2691\n",
      "Epoch 2 Batch 2007 Loss 1.5336\n",
      "Epoch 2 Batch 2008 Loss 1.3270\n",
      "Epoch 2 Batch 2009 Loss 1.6120\n",
      "Epoch 2 Batch 2010 Loss 1.2017\n",
      "Epoch 2 Batch 2011 Loss 1.5455\n",
      "Epoch 2 Batch 2012 Loss 1.1847\n",
      "Epoch 2 Batch 2013 Loss 1.8944\n",
      "Epoch 2 Batch 2014 Loss 1.6107\n",
      "Epoch 2 Batch 2015 Loss 1.3398\n",
      "Epoch 2 Batch 2016 Loss 1.3763\n",
      "Epoch 2 Batch 2017 Loss 1.8301\n",
      "Epoch 2 Batch 2018 Loss 1.2969\n",
      "Epoch 2 Batch 2019 Loss 1.6517\n",
      "Epoch 2 Batch 2020 Loss 1.4608\n",
      "Epoch 2 Batch 2021 Loss 1.1923\n",
      "Epoch 2 Batch 2022 Loss 1.4957\n",
      "Epoch 2 Batch 2023 Loss 1.9984\n",
      "Epoch 2 Batch 2024 Loss 1.7993\n",
      "Epoch 2 Batch 2025 Loss 1.3960\n",
      "Epoch 2 Batch 2026 Loss 1.2617\n",
      "Epoch 2 Batch 2027 Loss 1.5137\n",
      "Epoch 2 Batch 2028 Loss 1.3051\n",
      "Epoch 2 Batch 2029 Loss 1.2154\n",
      "Epoch 2 Batch 2030 Loss 1.5611\n",
      "Epoch 2 Batch 2031 Loss 1.4390\n",
      "Epoch 2 Batch 2032 Loss 1.3548\n",
      "Epoch 2 Batch 2033 Loss 1.5609\n",
      "Epoch 2 Batch 2034 Loss 1.3092\n",
      "Epoch 2 Batch 2035 Loss 1.5543\n",
      "Epoch 2 Batch 2036 Loss 1.7302\n",
      "Epoch 2 Batch 2037 Loss 1.6550\n",
      "Epoch 2 Batch 2038 Loss 1.5862\n",
      "Epoch 2 Batch 2039 Loss 1.5467\n",
      "Epoch 2 Batch 2040 Loss 1.2698\n",
      "Epoch 2 Batch 2041 Loss 1.6828\n",
      "Epoch 2 Batch 2042 Loss 1.2981\n",
      "Epoch 2 Batch 2043 Loss 1.4302\n",
      "Epoch 2 Batch 2044 Loss 1.5311\n",
      "Epoch 2 Batch 2045 Loss 1.4335\n",
      "Epoch 2 Batch 2046 Loss 1.4742\n",
      "Epoch 2 Batch 2047 Loss 1.3620\n",
      "Epoch 2 Batch 2048 Loss 1.1782\n",
      "Epoch 2 Batch 2049 Loss 1.4134\n",
      "Epoch 2 Batch 2050 Loss 1.3317\n",
      "Epoch 2 Batch 2051 Loss 1.8747\n",
      "Epoch 2 Batch 2052 Loss 1.3155\n",
      "Epoch 2 Batch 2053 Loss 1.5249\n",
      "Epoch 2 Batch 2054 Loss 1.5728\n",
      "Epoch 2 Batch 2055 Loss 1.7866\n",
      "Epoch 2 Batch 2056 Loss 1.4833\n",
      "Epoch 2 Batch 2057 Loss 1.6546\n",
      "Epoch 2 Batch 2058 Loss 1.3208\n",
      "Epoch 2 Batch 2059 Loss 1.7224\n",
      "Epoch 2 Batch 2060 Loss 1.5638\n",
      "Epoch 2 Batch 2061 Loss 1.2911\n",
      "Epoch 2 Batch 2062 Loss 1.5838\n",
      "Epoch 2 Batch 2063 Loss 1.3508\n",
      "Epoch 2 Batch 2064 Loss 1.2453\n",
      "Epoch 2 Batch 2065 Loss 1.2916\n",
      "Epoch 2 Batch 2066 Loss 1.2865\n",
      "Epoch 2 Batch 2067 Loss 1.5334\n",
      "Epoch 2 Batch 2068 Loss 1.3133\n",
      "Epoch 2 Batch 2069 Loss 1.2379\n",
      "Epoch 2 Batch 2070 Loss 1.4456\n",
      "Epoch 2 Batch 2071 Loss 1.4236\n",
      "Epoch 2 Batch 2072 Loss 1.4873\n",
      "Epoch 2 Batch 2073 Loss 1.2683\n",
      "Epoch 2 Batch 2074 Loss 1.4810\n",
      "Epoch 2 Batch 2075 Loss 1.3527\n",
      "Epoch 2 Batch 2076 Loss 1.3862\n",
      "Epoch 2 Batch 2077 Loss 1.3725\n",
      "Epoch 2 Batch 2078 Loss 1.4510\n",
      "Epoch 2 Batch 2079 Loss 1.4140\n",
      "Epoch 2 Batch 2080 Loss 1.4079\n",
      "Epoch 2 Batch 2081 Loss 1.5244\n",
      "Epoch 2 Batch 2082 Loss 1.5929\n",
      "Epoch 2 Batch 2083 Loss 1.8024\n",
      "Epoch 2 Batch 2084 Loss 1.7945\n",
      "Epoch 2 Batch 2085 Loss 1.4337\n",
      "Epoch 2 Batch 2086 Loss 1.4478\n",
      "Epoch 2 Batch 2087 Loss 1.4952\n",
      "Epoch 2 Batch 2088 Loss 1.1210\n",
      "Epoch 2 Batch 2089 Loss 1.3344\n",
      "Epoch 2 Batch 2090 Loss 1.3744\n",
      "Epoch 2 Batch 2091 Loss 1.6066\n",
      "Epoch 2 Batch 2092 Loss 1.4668\n",
      "Epoch 2 Batch 2093 Loss 1.6776\n",
      "Epoch 2 Batch 2094 Loss 1.5869\n",
      "Epoch 2 Batch 2095 Loss 1.4620\n",
      "Epoch 2 Batch 2096 Loss 1.7161\n",
      "Epoch 2 Batch 2097 Loss 1.2243\n",
      "Epoch 2 Batch 2098 Loss 1.5384\n",
      "Epoch 2 Batch 2099 Loss 1.5024\n",
      "Epoch 2 Batch 2100 Loss 1.5308\n",
      "Epoch 2 Batch 2101 Loss 1.6694\n",
      "Epoch 2 Batch 2102 Loss 1.6913\n",
      "Epoch 2 Batch 2103 Loss 1.3555\n",
      "Epoch 2 Batch 2104 Loss 1.5536\n",
      "Epoch 2 Batch 2105 Loss 1.4434\n",
      "Epoch 2 Batch 2106 Loss 1.8944\n",
      "Epoch 2 Batch 2107 Loss 1.3314\n",
      "Epoch 2 Batch 2108 Loss 1.2744\n",
      "Epoch 2 Batch 2109 Loss 1.3465\n",
      "Epoch 2 Batch 2110 Loss 1.6679\n",
      "Epoch 2 Batch 2111 Loss 1.2471\n",
      "Epoch 2 Batch 2112 Loss 1.3060\n",
      "Epoch 2 Batch 2113 Loss 1.2733\n",
      "Epoch 2 Batch 2114 Loss 1.5621\n",
      "Epoch 2 Batch 2115 Loss 1.5049\n",
      "Epoch 2 Batch 2116 Loss 1.1207\n",
      "Epoch 2 Batch 2117 Loss 1.6594\n",
      "Epoch 2 Batch 2118 Loss 1.4763\n",
      "Epoch 2 Batch 2119 Loss 1.3378\n",
      "Epoch 2 Batch 2120 Loss 1.3524\n",
      "Epoch 2 Batch 2121 Loss 1.5949\n",
      "Epoch 2 Batch 2122 Loss 1.8964\n",
      "Epoch 2 Batch 2123 Loss 1.4166\n",
      "Epoch 2 Batch 2124 Loss 1.6504\n",
      "Epoch 2 Batch 2125 Loss 1.6703\n",
      "Epoch 2 Batch 2126 Loss 1.6551\n",
      "Epoch 2 Batch 2127 Loss 1.5800\n",
      "Epoch 2 Batch 2128 Loss 1.6103\n",
      "Epoch 2 Batch 2129 Loss 1.5502\n",
      "Epoch 2 Batch 2130 Loss 1.2446\n",
      "Epoch 2 Batch 2131 Loss 1.5831\n",
      "Epoch 2 Batch 2132 Loss 1.4605\n",
      "Epoch 2 Batch 2133 Loss 1.2923\n",
      "Epoch 2 Batch 2134 Loss 1.2423\n",
      "Epoch 2 Batch 2135 Loss 1.5130\n",
      "Epoch 2 Batch 2136 Loss 1.3069\n",
      "Epoch 2 Batch 2137 Loss 1.3817\n",
      "Epoch 2 Batch 2138 Loss 1.3531\n",
      "Epoch 2 Batch 2139 Loss 1.5085\n",
      "Epoch 2 Batch 2140 Loss 1.3684\n",
      "Epoch 2 Batch 2141 Loss 1.2135\n",
      "Epoch 2 Batch 2142 Loss 1.5246\n",
      "Epoch 2 Batch 2143 Loss 1.1527\n",
      "Epoch 2 Batch 2144 Loss 1.6838\n",
      "Epoch 2 Batch 2145 Loss 1.3162\n",
      "Epoch 2 Batch 2146 Loss 1.7814\n",
      "Epoch 2 Batch 2147 Loss 1.8437\n",
      "Epoch 2 Batch 2148 Loss 1.3390\n",
      "Epoch 2 Batch 2149 Loss 1.3262\n",
      "Epoch 2 Batch 2150 Loss 1.6435\n",
      "Epoch 2 Batch 2151 Loss 1.4365\n",
      "Epoch 2 Batch 2152 Loss 1.3236\n",
      "Epoch 2 Batch 2153 Loss 1.7602\n",
      "Epoch 2 Batch 2154 Loss 1.3185\n",
      "Epoch 2 Batch 2155 Loss 1.4523\n",
      "Epoch 2 Batch 2156 Loss 1.9248\n",
      "Epoch 2 Batch 2157 Loss 1.5558\n",
      "Epoch 2 Batch 2158 Loss 1.7443\n",
      "Epoch 2 Batch 2159 Loss 1.4546\n",
      "Epoch 2 Batch 2160 Loss 1.5288\n",
      "Epoch 2 Batch 2161 Loss 1.4595\n",
      "Epoch 2 Batch 2162 Loss 1.3906\n",
      "Epoch 2 Batch 2163 Loss 1.2969\n",
      "Epoch 2 Batch 2164 Loss 1.5081\n",
      "Epoch 2 Batch 2165 Loss 1.4792\n",
      "Epoch 2 Batch 2166 Loss 1.5580\n",
      "Epoch 2 Batch 2167 Loss 1.3957\n",
      "Epoch 2 Batch 2168 Loss 1.6261\n",
      "Epoch 2 Batch 2169 Loss 1.7126\n",
      "Epoch 2 Batch 2170 Loss 1.4772\n",
      "Epoch 2 Batch 2171 Loss 1.9043\n",
      "Epoch 2 Batch 2172 Loss 1.3264\n",
      "Epoch 2 Batch 2173 Loss 1.3799\n",
      "Epoch 2 Batch 2174 Loss 1.2637\n",
      "Epoch 2 Batch 2175 Loss 1.8414\n",
      "Epoch 2 Batch 2176 Loss 1.4503\n",
      "Epoch 2 Batch 2177 Loss 1.3645\n",
      "Epoch 2 Batch 2178 Loss 1.2517\n",
      "Epoch 2 Batch 2179 Loss 1.4343\n",
      "Epoch 2 Batch 2180 Loss 1.4311\n",
      "Epoch 2 Batch 2181 Loss 1.1163\n",
      "Epoch 2 Batch 2182 Loss 1.5444\n",
      "Epoch 2 Batch 2183 Loss 1.5236\n",
      "Epoch 2 Batch 2184 Loss 1.3390\n",
      "Epoch 2 Batch 2185 Loss 1.1659\n",
      "Epoch 2 Batch 2186 Loss 1.3321\n",
      "Epoch 2 Batch 2187 Loss 1.2069\n",
      "Epoch 2 Batch 2188 Loss 1.6047\n",
      "Epoch 2 Batch 2189 Loss 1.6542\n",
      "Epoch 2 Batch 2190 Loss 1.5197\n",
      "Epoch 2 Batch 2191 Loss 1.3817\n",
      "Epoch 2 Batch 2192 Loss 1.2142\n",
      "Epoch 2 Batch 2193 Loss 1.5479\n",
      "Epoch 2 Batch 2194 Loss 1.1236\n",
      "Epoch 2 Batch 2195 Loss 1.3685\n",
      "Epoch 2 Batch 2196 Loss 1.5311\n",
      "Epoch 2 Batch 2197 Loss 1.6281\n",
      "Epoch 2 Batch 2198 Loss 1.2736\n",
      "Epoch 2 Batch 2199 Loss 1.5071\n",
      "Epoch 2 Batch 2200 Loss 1.3507\n",
      "Epoch 2 Batch 2201 Loss 1.7790\n",
      "Epoch 2 Batch 2202 Loss 1.3487\n",
      "Epoch 2 Batch 2203 Loss 1.4481\n",
      "Epoch 2 Batch 2204 Loss 1.3652\n",
      "Epoch 2 Batch 2205 Loss 1.4293\n",
      "Epoch 2 Batch 2206 Loss 1.6835\n",
      "Epoch 2 Batch 2207 Loss 1.2996\n",
      "Epoch 2 Batch 2208 Loss 1.7460\n",
      "Epoch 2 Batch 2209 Loss 1.9091\n",
      "Epoch 2 Batch 2210 Loss 1.1835\n",
      "Epoch 2 Batch 2211 Loss 1.4356\n",
      "Epoch 2 Batch 2212 Loss 1.4422\n",
      "Epoch 2 Batch 2213 Loss 1.3367\n",
      "Epoch 2 Batch 2214 Loss 1.3766\n",
      "Epoch 2 Batch 2215 Loss 1.7285\n",
      "Epoch 2 Batch 2216 Loss 1.2664\n",
      "Epoch 2 Batch 2217 Loss 1.3749\n",
      "Epoch 2 Batch 2218 Loss 1.2133\n",
      "Epoch 2 Batch 2219 Loss 1.5762\n",
      "Epoch 2 Batch 2220 Loss 1.3242\n",
      "Epoch 2 Batch 2221 Loss 1.4945\n",
      "Epoch 2 Batch 2222 Loss 1.6216\n",
      "Epoch 2 Batch 2223 Loss 1.4090\n",
      "Epoch 2 Batch 2224 Loss 1.1284\n",
      "Epoch 2 Batch 2225 Loss 1.5191\n",
      "Epoch 2 Batch 2226 Loss 1.5387\n",
      "Epoch 2 Batch 2227 Loss 1.8315\n",
      "Epoch 2 Batch 2228 Loss 1.5848\n",
      "Epoch 2 Batch 2229 Loss 1.0958\n",
      "Epoch 2 Batch 2230 Loss 1.4696\n",
      "Epoch 2 Batch 2231 Loss 1.3283\n",
      "Epoch 2 Batch 2232 Loss 1.1971\n",
      "Epoch 2 Batch 2233 Loss 1.2742\n",
      "Epoch 2 Batch 2234 Loss 1.6889\n",
      "Epoch 2 Batch 2235 Loss 1.4544\n",
      "Epoch 2 Batch 2236 Loss 1.7790\n",
      "Epoch 2 Batch 2237 Loss 1.2610\n",
      "Epoch 2 Batch 2238 Loss 1.4044\n",
      "Epoch 2 Batch 2239 Loss 1.3650\n",
      "Epoch 2 Batch 2240 Loss 1.3854\n",
      "Epoch 2 Batch 2241 Loss 1.1904\n",
      "Epoch 2 Batch 2242 Loss 1.6871\n",
      "Epoch 2 Batch 2243 Loss 1.4020\n",
      "Epoch 2 Batch 2244 Loss 1.4544\n",
      "Epoch 2 Batch 2245 Loss 1.3378\n",
      "Epoch 2 Batch 2246 Loss 1.5883\n",
      "Epoch 2 Batch 2247 Loss 1.6869\n",
      "Epoch 2 Batch 2248 Loss 1.2269\n",
      "Epoch 2 Batch 2249 Loss 1.3381\n",
      "Epoch 2 Batch 2250 Loss 1.7095\n",
      "Epoch 2 Batch 2251 Loss 1.3922\n",
      "Epoch 2 Batch 2252 Loss 1.5706\n",
      "Epoch 2 Batch 2253 Loss 1.4000\n",
      "Epoch 2 Batch 2254 Loss 1.1077\n",
      "Epoch 2 Batch 2255 Loss 1.5861\n",
      "Epoch 2 Batch 2256 Loss 1.5556\n",
      "Epoch 2 Batch 2257 Loss 1.3337\n",
      "Epoch 2 Batch 2258 Loss 1.3059\n",
      "Epoch 2 Batch 2259 Loss 1.7260\n",
      "Epoch 2 Batch 2260 Loss 1.3491\n",
      "Epoch 2 Batch 2261 Loss 1.6071\n",
      "Epoch 2 Batch 2262 Loss 1.3583\n",
      "Epoch 2 Batch 2263 Loss 1.4870\n",
      "Epoch 2 Batch 2264 Loss 1.3590\n",
      "Epoch 2 Batch 2265 Loss 1.6381\n",
      "Epoch 2 Batch 2266 Loss 1.3631\n",
      "Epoch 2 Batch 2267 Loss 1.6580\n",
      "Epoch 2 Batch 2268 Loss 1.6128\n",
      "Epoch 2 Batch 2269 Loss 1.6881\n",
      "Epoch 2 Batch 2270 Loss 1.4859\n",
      "Epoch 2 Batch 2271 Loss 1.5188\n",
      "Epoch 2 Batch 2272 Loss 1.4899\n",
      "Epoch 2 Batch 2273 Loss 1.3321\n",
      "Epoch 2 Batch 2274 Loss 1.3169\n",
      "Epoch 2 Batch 2275 Loss 1.4507\n",
      "Epoch 2 Batch 2276 Loss 1.1859\n",
      "Epoch 2 Batch 2277 Loss 1.4089\n",
      "Epoch 2 Batch 2278 Loss 1.7504\n",
      "Epoch 2 Batch 2279 Loss 1.7408\n",
      "Epoch 2 Batch 2280 Loss 1.6331\n",
      "Epoch 2 Batch 2281 Loss 1.3366\n",
      "Epoch 2 Batch 2282 Loss 1.7103\n",
      "Epoch 2 Batch 2283 Loss 1.5068\n",
      "Epoch 2 Batch 2284 Loss 1.2818\n",
      "Epoch 2 Batch 2285 Loss 1.3591\n",
      "Epoch 2 Batch 2286 Loss 1.5885\n",
      "Epoch 2 Batch 2287 Loss 1.1411\n",
      "Epoch 2 Batch 2288 Loss 1.7916\n",
      "Epoch 2 Batch 2289 Loss 1.5559\n",
      "Epoch 2 Batch 2290 Loss 1.3397\n",
      "Epoch 2 Batch 2291 Loss 1.3922\n",
      "Epoch 2 Batch 2292 Loss 1.5732\n",
      "Epoch 2 Batch 2293 Loss 1.2050\n",
      "Epoch 2 Batch 2294 Loss 1.7420\n",
      "Epoch 2 Batch 2295 Loss 1.9307\n",
      "Epoch 2 Batch 2296 Loss 1.4983\n",
      "Epoch 2 Batch 2297 Loss 1.5996\n",
      "Epoch 2 Batch 2298 Loss 1.4872\n",
      "Epoch 2 Batch 2299 Loss 1.1669\n",
      "Epoch 2 Batch 2300 Loss 1.5374\n",
      "Epoch 2 Batch 2301 Loss 1.3813\n",
      "Epoch 2 Batch 2302 Loss 1.5642\n",
      "Epoch 2 Batch 2303 Loss 1.5695\n",
      "Epoch 2 Batch 2304 Loss 1.6542\n",
      "Epoch 2 Batch 2305 Loss 1.6702\n",
      "Epoch 2 Batch 2306 Loss 1.4792\n",
      "Epoch 2 Batch 2307 Loss 1.8181\n",
      "Epoch 2 Batch 2308 Loss 1.5590\n",
      "Epoch 2 Batch 2309 Loss 1.3428\n",
      "Epoch 2 Batch 2310 Loss 1.4711\n",
      "Epoch 2 Batch 2311 Loss 1.4199\n",
      "Epoch 2 Batch 2312 Loss 1.2185\n",
      "Epoch 2 Batch 2313 Loss 1.8165\n",
      "Epoch 2 Batch 2314 Loss 1.4605\n",
      "Epoch 2 Batch 2315 Loss 1.3647\n",
      "Epoch 2 Batch 2316 Loss 1.7751\n",
      "Epoch 2 Batch 2317 Loss 1.5888\n",
      "Epoch 2 Batch 2318 Loss 1.2245\n",
      "Epoch 2 Batch 2319 Loss 2.1011\n",
      "Epoch 2 Batch 2320 Loss 1.4011\n",
      "Epoch 2 Batch 2321 Loss 1.3528\n",
      "Epoch 2 Batch 2322 Loss 1.4910\n",
      "Epoch 2 Batch 2323 Loss 1.1712\n",
      "Epoch 2 Batch 2324 Loss 1.7872\n",
      "Epoch 2 Batch 2325 Loss 1.2348\n",
      "Epoch 2 Batch 2326 Loss 1.4271\n",
      "Epoch 2 Batch 2327 Loss 1.5234\n",
      "Epoch 2 Batch 2328 Loss 1.4564\n",
      "Epoch 2 Batch 2329 Loss 1.5467\n",
      "Epoch 2 Batch 2330 Loss 1.3004\n",
      "Epoch 2 Batch 2331 Loss 1.3664\n",
      "Epoch 2 Batch 2332 Loss 1.2640\n",
      "Epoch 2 Batch 2333 Loss 1.6165\n",
      "Epoch 2 Batch 2334 Loss 1.1314\n",
      "Epoch 2 Batch 2335 Loss 1.2331\n",
      "Epoch 2 Batch 2336 Loss 1.4070\n",
      "Epoch 2 Batch 2337 Loss 1.5153\n",
      "Epoch 2 Batch 2338 Loss 1.2393\n",
      "Epoch 2 Batch 2339 Loss 1.3429\n",
      "Epoch 2 Batch 2340 Loss 1.5987\n",
      "Epoch 2 Batch 2341 Loss 1.2071\n",
      "Epoch 2 Batch 2342 Loss 1.4713\n",
      "Epoch 2 Batch 2343 Loss 1.2592\n",
      "Epoch 2 Batch 2344 Loss 1.4871\n",
      "Epoch 2 Batch 2345 Loss 1.3188\n",
      "Epoch 2 Batch 2346 Loss 1.2815\n",
      "Epoch 2 Batch 2347 Loss 1.1396\n",
      "Epoch 2 Batch 2348 Loss 1.3301\n",
      "Epoch 2 Batch 2349 Loss 1.3943\n",
      "Epoch 2 Batch 2350 Loss 1.4577\n",
      "Epoch 2 Batch 2351 Loss 1.8672\n",
      "Epoch 2 Batch 2352 Loss 1.3645\n",
      "Epoch 2 Batch 2353 Loss 1.2625\n",
      "Epoch 2 Batch 2354 Loss 1.9171\n",
      "Epoch 2 Batch 2355 Loss 1.5061\n",
      "Epoch 2 Batch 2356 Loss 1.5269\n",
      "Epoch 2 Batch 2357 Loss 1.4625\n",
      "Epoch 2 Batch 2358 Loss 1.2732\n",
      "Epoch 2 Batch 2359 Loss 1.1842\n",
      "Epoch 2 Batch 2360 Loss 1.4964\n",
      "Epoch 2 Batch 2361 Loss 1.6765\n",
      "Epoch 2 Batch 2362 Loss 1.2935\n",
      "Epoch 2 Batch 2363 Loss 1.5670\n",
      "Epoch 2 Batch 2364 Loss 1.3772\n",
      "Epoch 2 Batch 2365 Loss 1.6462\n",
      "Epoch 2 Batch 2366 Loss 1.4427\n",
      "Epoch 2 Batch 2367 Loss 1.6702\n",
      "Epoch 2 Batch 2368 Loss 1.3512\n",
      "Epoch 2 Batch 2369 Loss 1.3026\n",
      "Epoch 2 Batch 2370 Loss 1.3037\n",
      "Epoch 2 Batch 2371 Loss 1.4403\n",
      "Epoch 2 Batch 2372 Loss 1.9219\n",
      "Epoch 2 Batch 2373 Loss 1.6010\n",
      "Epoch 2 Batch 2374 Loss 1.6909\n",
      "Epoch 2 Batch 2375 Loss 1.5160\n",
      "Epoch 2 Batch 2376 Loss 1.3758\n",
      "Epoch 2 Batch 2377 Loss 1.2503\n",
      "Epoch 2 Batch 2378 Loss 1.1219\n",
      "Epoch 2 Batch 2379 Loss 1.9026\n",
      "Epoch 2 Batch 2380 Loss 1.6354\n",
      "Epoch 2 Batch 2381 Loss 1.1948\n",
      "Epoch 2 Batch 2382 Loss 1.3740\n",
      "Epoch 2 Batch 2383 Loss 1.3243\n",
      "Epoch 2 Batch 2384 Loss 1.6463\n",
      "Epoch 2 Batch 2385 Loss 1.6458\n",
      "Epoch 2 Batch 2386 Loss 1.6682\n",
      "Epoch 2 Batch 2387 Loss 1.7887\n",
      "Epoch 2 Batch 2388 Loss 1.1882\n",
      "Epoch 2 Batch 2389 Loss 1.0619\n",
      "Epoch 2 Batch 2390 Loss 1.3708\n",
      "Epoch 2 Batch 2391 Loss 1.4420\n",
      "Epoch 2 Batch 2392 Loss 1.5789\n",
      "Epoch 2 Batch 2393 Loss 1.5448\n",
      "Epoch 2 Batch 2394 Loss 1.2215\n",
      "Epoch 2 Batch 2395 Loss 1.6344\n",
      "Epoch 2 Batch 2396 Loss 1.5610\n",
      "Epoch 2 Batch 2397 Loss 1.4994\n",
      "Epoch 2 Batch 2398 Loss 1.5108\n",
      "Epoch 2 Batch 2399 Loss 1.4394\n",
      "Epoch 2 Batch 2400 Loss 1.7028\n",
      "Epoch 2 Batch 2401 Loss 1.3407\n",
      "Epoch 2 Batch 2402 Loss 1.6240\n",
      "Epoch 2 Batch 2403 Loss 1.5826\n",
      "Epoch 2 Batch 2404 Loss 1.3148\n",
      "Epoch 2 Batch 2405 Loss 1.5825\n",
      "Epoch 2 Batch 2406 Loss 1.3033\n",
      "Epoch 2 Batch 2407 Loss 1.7383\n",
      "Epoch 2 Batch 2408 Loss 1.2944\n",
      "Epoch 2 Batch 2409 Loss 1.2932\n",
      "Epoch 2 Batch 2410 Loss 1.6401\n",
      "Epoch 2 Batch 2411 Loss 1.2533\n",
      "Epoch 2 Batch 2412 Loss 1.2559\n",
      "Epoch 2 Batch 2413 Loss 1.3390\n",
      "Epoch 2 Batch 2414 Loss 1.4602\n",
      "Epoch 2 Batch 2415 Loss 1.6161\n",
      "Epoch 2 Batch 2416 Loss 1.3544\n",
      "Epoch 2 Batch 2417 Loss 1.0759\n",
      "Epoch 2 Batch 2418 Loss 0.9767\n",
      "Epoch 2 Batch 2419 Loss 1.4846\n",
      "Epoch 2 Batch 2420 Loss 1.6967\n",
      "Epoch 2 Batch 2421 Loss 1.5839\n",
      "Epoch 2 Batch 2422 Loss 1.7411\n",
      "Epoch 2 Batch 2423 Loss 1.5090\n",
      "Epoch 2 Batch 2424 Loss 1.6504\n",
      "Epoch 2 Batch 2425 Loss 1.4092\n",
      "Epoch 2 Batch 2426 Loss 1.1440\n",
      "Epoch 2 Batch 2427 Loss 1.2407\n",
      "Epoch 2 Batch 2428 Loss 1.3214\n",
      "Epoch 2 Batch 2429 Loss 1.4438\n",
      "Epoch 2 Batch 2430 Loss 1.3629\n",
      "Epoch 2 Batch 2431 Loss 1.6233\n",
      "Epoch 2 Batch 2432 Loss 1.5745\n",
      "Epoch 2 Batch 2433 Loss 1.2905\n",
      "Epoch 2 Batch 2434 Loss 1.3593\n",
      "Epoch 2 Batch 2435 Loss 1.3035\n",
      "Epoch 2 Batch 2436 Loss 1.3150\n",
      "Epoch 2 Batch 2437 Loss 1.3944\n",
      "Epoch 2 Batch 2438 Loss 1.2225\n",
      "Epoch 2 Batch 2439 Loss 1.1802\n",
      "Epoch 2 Batch 2440 Loss 1.3089\n",
      "Epoch 2 Batch 2441 Loss 1.6496\n",
      "Epoch 2 Batch 2442 Loss 1.2692\n",
      "Epoch 2 Batch 2443 Loss 1.3605\n",
      "Epoch 2 Batch 2444 Loss 1.6540\n",
      "Epoch 2 Batch 2445 Loss 1.4868\n",
      "Epoch 2 Batch 2446 Loss 1.1665\n",
      "Epoch 2 Batch 2447 Loss 1.3453\n",
      "Epoch 2 Batch 2448 Loss 1.6882\n",
      "Epoch 2 Batch 2449 Loss 1.5556\n",
      "Epoch 2 Batch 2450 Loss 1.4703\n",
      "Epoch 2 Batch 2451 Loss 1.2154\n",
      "Epoch 2 Batch 2452 Loss 1.8790\n",
      "Epoch 2 Batch 2453 Loss 1.5997\n",
      "Epoch 2 Batch 2454 Loss 1.3419\n",
      "Epoch 2 Batch 2455 Loss 1.6740\n",
      "Epoch 2 Batch 2456 Loss 1.0936\n",
      "Epoch 2 Batch 2457 Loss 1.3596\n",
      "Epoch 2 Batch 2458 Loss 1.5978\n",
      "Epoch 2 Batch 2459 Loss 1.1592\n",
      "Epoch 2 Batch 2460 Loss 1.9075\n",
      "Epoch 2 Batch 2461 Loss 1.3428\n",
      "Epoch 2 Batch 2462 Loss 1.4248\n",
      "Epoch 2 Batch 2463 Loss 1.6023\n",
      "Epoch 2 Batch 2464 Loss 1.5734\n",
      "Epoch 2 Batch 2465 Loss 1.5596\n",
      "Epoch 2 Batch 2466 Loss 1.5618\n",
      "Epoch 2 Batch 2467 Loss 1.7480\n",
      "Epoch 2 Batch 2468 Loss 1.0408\n",
      "Epoch 2 Batch 2469 Loss 1.2916\n",
      "Epoch 2 Batch 2470 Loss 1.3706\n",
      "Epoch 2 Batch 2471 Loss 1.7000\n",
      "Epoch 2 Batch 2472 Loss 1.2666\n",
      "Epoch 2 Batch 2473 Loss 1.6874\n",
      "Epoch 2 Batch 2474 Loss 1.3667\n",
      "Epoch 2 Batch 2475 Loss 1.4572\n",
      "Epoch 2 Batch 2476 Loss 1.3990\n",
      "Epoch 2 Batch 2477 Loss 1.4729\n",
      "Epoch 2 Batch 2478 Loss 1.5675\n",
      "Epoch 2 Batch 2479 Loss 1.2637\n",
      "Epoch 2 Batch 2480 Loss 1.4087\n",
      "Epoch 2 Batch 2481 Loss 1.3311\n",
      "Epoch 2 Batch 2482 Loss 1.4270\n",
      "Epoch 2 Batch 2483 Loss 1.3123\n",
      "Epoch 2 Batch 2484 Loss 1.2697\n",
      "Epoch 2 Batch 2485 Loss 1.4415\n",
      "Epoch 2 Batch 2486 Loss 1.4532\n",
      "Epoch 2 Batch 2487 Loss 1.3488\n",
      "Epoch 2 Batch 2488 Loss 1.7650\n",
      "Epoch 2 Batch 2489 Loss 1.6072\n",
      "Epoch 2 Batch 2490 Loss 1.2562\n",
      "Epoch 2 Batch 2491 Loss 1.3848\n",
      "Epoch 2 Batch 2492 Loss 1.3026\n",
      "Epoch 2 Batch 2493 Loss 1.2553\n",
      "Epoch 2 Batch 2494 Loss 1.2526\n",
      "Epoch 2 Batch 2495 Loss 1.3795\n",
      "Epoch 2 Batch 2496 Loss 1.2342\n",
      "Epoch 2 Batch 2497 Loss 1.5240\n",
      "Epoch 2 Batch 2498 Loss 1.5993\n",
      "Epoch 2 Batch 2499 Loss 1.3120\n",
      "Epoch 2 Batch 2500 Loss 1.2791\n",
      "Epoch 2 Batch 2501 Loss 1.5948\n",
      "Epoch 2 Batch 2502 Loss 1.8142\n",
      "Epoch 2 Batch 2503 Loss 1.1547\n",
      "Epoch 2 Batch 2504 Loss 1.5333\n",
      "Epoch 2 Batch 2505 Loss 1.2842\n",
      "Epoch 2 Batch 2506 Loss 1.4586\n",
      "Epoch 2 Batch 2507 Loss 1.5034\n",
      "Epoch 2 Batch 2508 Loss 1.5900\n",
      "Epoch 2 Batch 2509 Loss 1.3609\n",
      "Epoch 2 Batch 2510 Loss 1.2945\n",
      "Epoch 2 Batch 2511 Loss 1.5554\n",
      "Epoch 2 Batch 2512 Loss 1.4049\n",
      "Epoch 2 Batch 2513 Loss 1.3892\n",
      "Epoch 2 Batch 2514 Loss 1.6841\n",
      "Epoch 2 Batch 2515 Loss 1.4561\n",
      "Epoch 2 Batch 2516 Loss 1.6332\n",
      "Epoch 2 Batch 2517 Loss 1.3339\n",
      "Epoch 2 Batch 2518 Loss 1.6671\n",
      "Epoch 2 Batch 2519 Loss 1.4084\n",
      "Epoch 2 Batch 2520 Loss 1.3626\n",
      "Epoch 2 Batch 2521 Loss 1.6149\n",
      "Epoch 2 Batch 2522 Loss 1.7783\n",
      "Epoch 2 Batch 2523 Loss 1.2731\n",
      "Epoch 2 Batch 2524 Loss 1.5755\n",
      "Epoch 2 Batch 2525 Loss 1.3576\n",
      "Epoch 2 Batch 2526 Loss 1.1253\n",
      "Epoch 2 Batch 2527 Loss 1.3078\n",
      "Epoch 2 Batch 2528 Loss 1.6434\n",
      "Epoch 2 Batch 2529 Loss 1.2327\n",
      "Epoch 2 Batch 2530 Loss 1.7381\n",
      "Epoch 2 Batch 2531 Loss 1.5251\n",
      "Epoch 2 Batch 2532 Loss 1.3624\n",
      "Epoch 2 Batch 2533 Loss 1.3485\n",
      "Epoch 2 Batch 2534 Loss 1.6351\n",
      "Epoch 2 Batch 2535 Loss 1.2352\n",
      "Epoch 2 Batch 2536 Loss 1.3952\n",
      "Epoch 2 Batch 2537 Loss 1.1262\n",
      "Epoch 2 Batch 2538 Loss 1.5593\n",
      "Epoch 2 Batch 2539 Loss 1.6677\n",
      "Epoch 2 Batch 2540 Loss 1.3943\n",
      "Epoch 2 Batch 2541 Loss 1.5200\n",
      "Epoch 2 Batch 2542 Loss 1.3014\n",
      "Epoch 2 Batch 2543 Loss 1.2441\n",
      "Epoch 2 Batch 2544 Loss 1.4918\n",
      "Epoch 2 Batch 2545 Loss 1.2162\n",
      "Epoch 2 Batch 2546 Loss 1.3992\n",
      "Epoch 2 Batch 2547 Loss 1.5719\n",
      "Epoch 2 Batch 2548 Loss 1.5551\n",
      "Epoch 2 Batch 2549 Loss 1.4961\n",
      "Epoch 2 Batch 2550 Loss 1.6229\n",
      "Epoch 2 Batch 2551 Loss 1.4478\n",
      "Epoch 2 Batch 2552 Loss 0.9129\n",
      "Epoch 2 Batch 2553 Loss 1.5104\n",
      "Epoch 2 Batch 2554 Loss 1.2466\n",
      "Epoch 2 Batch 2555 Loss 1.3890\n",
      "Epoch 2 Batch 2556 Loss 1.4138\n",
      "Epoch 2 Batch 2557 Loss 1.3745\n",
      "Epoch 2 Batch 2558 Loss 1.6858\n",
      "Epoch 2 Batch 2559 Loss 1.4069\n",
      "Epoch 2 Batch 2560 Loss 1.4369\n",
      "Epoch 2 Batch 2561 Loss 1.3320\n",
      "Epoch 2 Batch 2562 Loss 1.6617\n",
      "Epoch 2 Batch 2563 Loss 1.2562\n",
      "Epoch 2 Batch 2564 Loss 1.4759\n",
      "Epoch 2 Batch 2565 Loss 1.3974\n",
      "Epoch 2 Batch 2566 Loss 1.5081\n",
      "Epoch 2 Batch 2567 Loss 1.3469\n",
      "Epoch 2 Batch 2568 Loss 1.7246\n",
      "Epoch 2 Batch 2569 Loss 1.4637\n",
      "Epoch 2 Batch 2570 Loss 1.3440\n",
      "Epoch 2 Batch 2571 Loss 1.4326\n",
      "Epoch 2 Batch 2572 Loss 1.3166\n",
      "Epoch 2 Batch 2573 Loss 1.2983\n",
      "Epoch 2 Batch 2574 Loss 1.1978\n",
      "Epoch 2 Batch 2575 Loss 1.4660\n",
      "Epoch 2 Batch 2576 Loss 1.4934\n",
      "Epoch 2 Batch 2577 Loss 1.5278\n",
      "Epoch 2 Batch 2578 Loss 1.0606\n",
      "Epoch 2 Batch 2579 Loss 1.3665\n",
      "Epoch 2 Batch 2580 Loss 1.2951\n",
      "Epoch 2 Batch 2581 Loss 1.5804\n",
      "Epoch 2 Batch 2582 Loss 1.4169\n",
      "Epoch 2 Batch 2583 Loss 1.6073\n",
      "Epoch 2 Batch 2584 Loss 1.7489\n",
      "Epoch 2 Batch 2585 Loss 1.4698\n",
      "Epoch 2 Batch 2586 Loss 1.3280\n",
      "Epoch 2 Batch 2587 Loss 1.3203\n",
      "Epoch 2 Batch 2588 Loss 1.3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [1:04:18<1:35:57, 1919.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 2 at /mnt/pycharm_class04/data/checkpoints/training_checkpoints_seq2seq/ckpt/ckpt-1\n",
      "Epoch 2 Loss 1.5155\n",
      "Time taken for 1 epoch 1954.4530375003815 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2169\n",
      "Epoch 3 Batch 1 Loss 1.0667\n",
      "Epoch 3 Batch 2 Loss 1.2031\n",
      "Epoch 3 Batch 3 Loss 1.3107\n",
      "Epoch 3 Batch 4 Loss 1.5746\n",
      "Epoch 3 Batch 5 Loss 1.5899\n",
      "Epoch 3 Batch 6 Loss 1.1630\n",
      "Epoch 3 Batch 7 Loss 1.1998\n",
      "Epoch 3 Batch 8 Loss 1.3554\n",
      "Epoch 3 Batch 9 Loss 1.2274\n",
      "Epoch 3 Batch 10 Loss 1.3043\n",
      "Epoch 3 Batch 11 Loss 1.3836\n",
      "Epoch 3 Batch 12 Loss 1.4799\n",
      "Epoch 3 Batch 13 Loss 1.6130\n",
      "Epoch 3 Batch 14 Loss 1.3504\n",
      "Epoch 3 Batch 15 Loss 1.3933\n",
      "Epoch 3 Batch 16 Loss 1.2044\n",
      "Epoch 3 Batch 17 Loss 1.4773\n",
      "Epoch 3 Batch 18 Loss 1.1132\n",
      "Epoch 3 Batch 19 Loss 1.3533\n",
      "Epoch 3 Batch 20 Loss 1.3622\n",
      "Epoch 3 Batch 21 Loss 1.0566\n",
      "Epoch 3 Batch 22 Loss 1.4304\n",
      "Epoch 3 Batch 23 Loss 1.4004\n",
      "Epoch 3 Batch 24 Loss 1.4267\n",
      "Epoch 3 Batch 25 Loss 1.1999\n",
      "Epoch 3 Batch 26 Loss 1.3855\n",
      "Epoch 3 Batch 27 Loss 1.4620\n",
      "Epoch 3 Batch 28 Loss 1.3563\n",
      "Epoch 3 Batch 29 Loss 1.3398\n",
      "Epoch 3 Batch 30 Loss 1.2844\n",
      "Epoch 3 Batch 31 Loss 1.1372\n",
      "Epoch 3 Batch 32 Loss 1.3116\n",
      "Epoch 3 Batch 33 Loss 1.3815\n",
      "Epoch 3 Batch 34 Loss 1.3837\n",
      "Epoch 3 Batch 35 Loss 1.6981\n",
      "Epoch 3 Batch 36 Loss 1.3366\n",
      "Epoch 3 Batch 37 Loss 1.2692\n",
      "Epoch 3 Batch 38 Loss 1.2100\n",
      "Epoch 3 Batch 39 Loss 1.4679\n",
      "Epoch 3 Batch 40 Loss 1.4195\n",
      "Epoch 3 Batch 41 Loss 1.4816\n",
      "Epoch 3 Batch 42 Loss 1.4539\n",
      "Epoch 3 Batch 43 Loss 1.3058\n",
      "Epoch 3 Batch 44 Loss 1.4935\n",
      "Epoch 3 Batch 45 Loss 1.4927\n",
      "Epoch 3 Batch 46 Loss 1.4853\n",
      "Epoch 3 Batch 47 Loss 0.9846\n",
      "Epoch 3 Batch 48 Loss 1.2044\n",
      "Epoch 3 Batch 49 Loss 1.2471\n",
      "Epoch 3 Batch 50 Loss 1.3368\n",
      "Epoch 3 Batch 51 Loss 1.3522\n",
      "Epoch 3 Batch 52 Loss 1.7343\n",
      "Epoch 3 Batch 53 Loss 1.4279\n",
      "Epoch 3 Batch 54 Loss 1.4498\n",
      "Epoch 3 Batch 55 Loss 1.3049\n",
      "Epoch 3 Batch 56 Loss 1.4890\n",
      "Epoch 3 Batch 57 Loss 1.6773\n",
      "Epoch 3 Batch 58 Loss 1.2244\n",
      "Epoch 3 Batch 59 Loss 1.3443\n",
      "Epoch 3 Batch 60 Loss 1.2433\n",
      "Epoch 3 Batch 61 Loss 1.3988\n",
      "Epoch 3 Batch 62 Loss 1.8750\n",
      "Epoch 3 Batch 63 Loss 1.1878\n",
      "Epoch 3 Batch 64 Loss 1.5318\n",
      "Epoch 3 Batch 65 Loss 1.4086\n",
      "Epoch 3 Batch 66 Loss 1.5119\n",
      "Epoch 3 Batch 67 Loss 1.4772\n",
      "Epoch 3 Batch 68 Loss 1.4436\n",
      "Epoch 3 Batch 69 Loss 1.1326\n",
      "Epoch 3 Batch 70 Loss 1.1064\n",
      "Epoch 3 Batch 71 Loss 1.4074\n",
      "Epoch 3 Batch 72 Loss 1.2072\n",
      "Epoch 3 Batch 73 Loss 1.4639\n",
      "Epoch 3 Batch 74 Loss 1.3388\n",
      "Epoch 3 Batch 75 Loss 1.3087\n",
      "Epoch 3 Batch 76 Loss 1.3197\n",
      "Epoch 3 Batch 77 Loss 1.2295\n",
      "Epoch 3 Batch 78 Loss 1.4537\n",
      "Epoch 3 Batch 79 Loss 1.3818\n",
      "Epoch 3 Batch 80 Loss 1.1682\n",
      "Epoch 3 Batch 81 Loss 1.6869\n",
      "Epoch 3 Batch 82 Loss 1.4835\n",
      "Epoch 3 Batch 83 Loss 1.6017\n",
      "Epoch 3 Batch 84 Loss 1.2445\n",
      "Epoch 3 Batch 85 Loss 1.2443\n",
      "Epoch 3 Batch 86 Loss 1.0396\n",
      "Epoch 3 Batch 87 Loss 1.5984\n",
      "Epoch 3 Batch 88 Loss 1.3139\n",
      "Epoch 3 Batch 89 Loss 1.1845\n",
      "Epoch 3 Batch 90 Loss 1.2590\n",
      "Epoch 3 Batch 91 Loss 1.6237\n",
      "Epoch 3 Batch 92 Loss 1.3828\n",
      "Epoch 3 Batch 93 Loss 1.4308\n",
      "Epoch 3 Batch 94 Loss 1.6941\n",
      "Epoch 3 Batch 95 Loss 1.6202\n",
      "Epoch 3 Batch 96 Loss 1.5953\n",
      "Epoch 3 Batch 97 Loss 1.5038\n",
      "Epoch 3 Batch 98 Loss 1.3756\n",
      "Epoch 3 Batch 99 Loss 1.3919\n",
      "Epoch 3 Batch 100 Loss 1.3749\n",
      "Epoch 3 Batch 101 Loss 1.2407\n",
      "Epoch 3 Batch 102 Loss 1.3422\n",
      "Epoch 3 Batch 103 Loss 1.4700\n",
      "Epoch 3 Batch 104 Loss 1.2551\n",
      "Epoch 3 Batch 105 Loss 1.0284\n",
      "Epoch 3 Batch 106 Loss 1.5700\n",
      "Epoch 3 Batch 107 Loss 1.2292\n",
      "Epoch 3 Batch 108 Loss 1.3325\n",
      "Epoch 3 Batch 109 Loss 1.8037\n",
      "Epoch 3 Batch 110 Loss 1.2859\n",
      "Epoch 3 Batch 111 Loss 1.2446\n",
      "Epoch 3 Batch 112 Loss 1.5398\n",
      "Epoch 3 Batch 113 Loss 1.1795\n",
      "Epoch 3 Batch 114 Loss 1.4173\n",
      "Epoch 3 Batch 115 Loss 1.3982\n",
      "Epoch 3 Batch 116 Loss 1.5955\n",
      "Epoch 3 Batch 117 Loss 1.3562\n",
      "Epoch 3 Batch 118 Loss 1.8153\n",
      "Epoch 3 Batch 119 Loss 1.4025\n",
      "Epoch 3 Batch 120 Loss 1.3281\n",
      "Epoch 3 Batch 121 Loss 1.2601\n",
      "Epoch 3 Batch 122 Loss 1.3506\n",
      "Epoch 3 Batch 123 Loss 1.3164\n",
      "Epoch 3 Batch 124 Loss 1.5452\n",
      "Epoch 3 Batch 125 Loss 1.4073\n",
      "Epoch 3 Batch 126 Loss 1.5860\n",
      "Epoch 3 Batch 127 Loss 1.3269\n",
      "Epoch 3 Batch 128 Loss 1.5366\n",
      "Epoch 3 Batch 129 Loss 1.4877\n",
      "Epoch 3 Batch 130 Loss 0.9900\n",
      "Epoch 3 Batch 131 Loss 1.5118\n",
      "Epoch 3 Batch 132 Loss 1.7340\n",
      "Epoch 3 Batch 133 Loss 1.5912\n",
      "Epoch 3 Batch 134 Loss 1.0527\n",
      "Epoch 3 Batch 135 Loss 1.5751\n",
      "Epoch 3 Batch 136 Loss 1.3261\n",
      "Epoch 3 Batch 137 Loss 1.6479\n",
      "Epoch 3 Batch 138 Loss 1.2906\n",
      "Epoch 3 Batch 139 Loss 1.0117\n",
      "Epoch 3 Batch 140 Loss 1.2996\n",
      "Epoch 3 Batch 141 Loss 1.2259\n",
      "Epoch 3 Batch 142 Loss 1.5987\n",
      "Epoch 3 Batch 143 Loss 1.4248\n",
      "Epoch 3 Batch 144 Loss 1.3050\n",
      "Epoch 3 Batch 145 Loss 1.3969\n",
      "Epoch 3 Batch 146 Loss 1.3214\n",
      "Epoch 3 Batch 147 Loss 1.1282\n",
      "Epoch 3 Batch 148 Loss 1.4395\n",
      "Epoch 3 Batch 149 Loss 1.4672\n",
      "Epoch 3 Batch 150 Loss 1.3512\n",
      "Epoch 3 Batch 151 Loss 1.6061\n",
      "Epoch 3 Batch 152 Loss 1.3035\n",
      "Epoch 3 Batch 153 Loss 1.1435\n",
      "Epoch 3 Batch 154 Loss 1.3051\n",
      "Epoch 3 Batch 155 Loss 1.1370\n",
      "Epoch 3 Batch 156 Loss 1.3333\n",
      "Epoch 3 Batch 157 Loss 1.3348\n",
      "Epoch 3 Batch 158 Loss 1.3763\n",
      "Epoch 3 Batch 159 Loss 1.1817\n",
      "Epoch 3 Batch 160 Loss 1.1335\n",
      "Epoch 3 Batch 161 Loss 1.2121\n",
      "Epoch 3 Batch 162 Loss 1.2528\n",
      "Epoch 3 Batch 163 Loss 1.2131\n",
      "Epoch 3 Batch 164 Loss 1.4874\n",
      "Epoch 3 Batch 165 Loss 1.5678\n",
      "Epoch 3 Batch 166 Loss 1.1362\n",
      "Epoch 3 Batch 167 Loss 1.2348\n",
      "Epoch 3 Batch 168 Loss 1.4242\n",
      "Epoch 3 Batch 169 Loss 1.3597\n",
      "Epoch 3 Batch 170 Loss 1.4407\n",
      "Epoch 3 Batch 171 Loss 1.1252\n",
      "Epoch 3 Batch 172 Loss 1.6175\n",
      "Epoch 3 Batch 173 Loss 1.1171\n",
      "Epoch 3 Batch 174 Loss 1.4494\n",
      "Epoch 3 Batch 175 Loss 1.6485\n",
      "Epoch 3 Batch 176 Loss 1.2052\n",
      "Epoch 3 Batch 177 Loss 1.0215\n",
      "Epoch 3 Batch 178 Loss 1.3831\n",
      "Epoch 3 Batch 179 Loss 1.1322\n",
      "Epoch 3 Batch 180 Loss 1.5460\n",
      "Epoch 3 Batch 181 Loss 1.2979\n",
      "Epoch 3 Batch 182 Loss 1.1974\n",
      "Epoch 3 Batch 183 Loss 1.4125\n",
      "Epoch 3 Batch 184 Loss 1.3923\n",
      "Epoch 3 Batch 185 Loss 1.2049\n",
      "Epoch 3 Batch 186 Loss 1.6279\n",
      "Epoch 3 Batch 187 Loss 1.2665\n",
      "Epoch 3 Batch 188 Loss 1.3831\n",
      "Epoch 3 Batch 189 Loss 1.4152\n",
      "Epoch 3 Batch 190 Loss 1.2851\n",
      "Epoch 3 Batch 191 Loss 1.2502\n",
      "Epoch 3 Batch 192 Loss 1.5823\n",
      "Epoch 3 Batch 193 Loss 1.4625\n",
      "Epoch 3 Batch 194 Loss 1.3246\n",
      "Epoch 3 Batch 195 Loss 1.2388\n",
      "Epoch 3 Batch 196 Loss 1.4131\n",
      "Epoch 3 Batch 197 Loss 1.6262\n",
      "Epoch 3 Batch 198 Loss 1.7664\n",
      "Epoch 3 Batch 199 Loss 1.3680\n",
      "Epoch 3 Batch 200 Loss 1.2201\n",
      "Epoch 3 Batch 201 Loss 1.5966\n",
      "Epoch 3 Batch 202 Loss 1.3412\n",
      "Epoch 3 Batch 203 Loss 1.4292\n",
      "Epoch 3 Batch 204 Loss 1.4207\n",
      "Epoch 3 Batch 205 Loss 1.5460\n",
      "Epoch 3 Batch 206 Loss 1.6661\n",
      "Epoch 3 Batch 207 Loss 1.4823\n",
      "Epoch 3 Batch 208 Loss 1.3265\n",
      "Epoch 3 Batch 209 Loss 1.1895\n",
      "Epoch 3 Batch 210 Loss 1.2510\n",
      "Epoch 3 Batch 211 Loss 1.3924\n",
      "Epoch 3 Batch 212 Loss 1.1958\n",
      "Epoch 3 Batch 213 Loss 1.2039\n",
      "Epoch 3 Batch 214 Loss 1.7814\n",
      "Epoch 3 Batch 215 Loss 1.4809\n",
      "Epoch 3 Batch 216 Loss 1.2290\n",
      "Epoch 3 Batch 217 Loss 1.0310\n",
      "Epoch 3 Batch 218 Loss 1.3024\n",
      "Epoch 3 Batch 219 Loss 1.2952\n",
      "Epoch 3 Batch 220 Loss 1.6109\n",
      "Epoch 3 Batch 221 Loss 1.0748\n",
      "Epoch 3 Batch 222 Loss 1.5204\n",
      "Epoch 3 Batch 223 Loss 1.4342\n",
      "Epoch 3 Batch 224 Loss 1.3270\n",
      "Epoch 3 Batch 225 Loss 1.3700\n",
      "Epoch 3 Batch 226 Loss 1.0644\n",
      "Epoch 3 Batch 227 Loss 1.1725\n",
      "Epoch 3 Batch 228 Loss 1.4862\n",
      "Epoch 3 Batch 229 Loss 1.3125\n",
      "Epoch 3 Batch 230 Loss 1.6214\n",
      "Epoch 3 Batch 231 Loss 1.5310\n",
      "Epoch 3 Batch 232 Loss 1.3228\n",
      "Epoch 3 Batch 233 Loss 1.3944\n",
      "Epoch 3 Batch 234 Loss 1.3507\n",
      "Epoch 3 Batch 235 Loss 1.5537\n",
      "Epoch 3 Batch 236 Loss 1.3406\n",
      "Epoch 3 Batch 237 Loss 1.3791\n",
      "Epoch 3 Batch 238 Loss 1.3360\n",
      "Epoch 3 Batch 239 Loss 1.1621\n",
      "Epoch 3 Batch 240 Loss 1.3165\n",
      "Epoch 3 Batch 241 Loss 1.4152\n",
      "Epoch 3 Batch 242 Loss 1.3188\n",
      "Epoch 3 Batch 243 Loss 1.4529\n",
      "Epoch 3 Batch 244 Loss 1.4823\n",
      "Epoch 3 Batch 245 Loss 1.2200\n",
      "Epoch 3 Batch 246 Loss 1.2732\n",
      "Epoch 3 Batch 247 Loss 1.3945\n",
      "Epoch 3 Batch 248 Loss 1.5109\n",
      "Epoch 3 Batch 249 Loss 1.3080\n",
      "Epoch 3 Batch 250 Loss 1.1566\n",
      "Epoch 3 Batch 251 Loss 1.4595\n",
      "Epoch 3 Batch 252 Loss 1.4096\n",
      "Epoch 3 Batch 253 Loss 1.2606\n",
      "Epoch 3 Batch 254 Loss 1.6417\n",
      "Epoch 3 Batch 255 Loss 1.5304\n",
      "Epoch 3 Batch 256 Loss 1.3453\n",
      "Epoch 3 Batch 257 Loss 1.2422\n",
      "Epoch 3 Batch 258 Loss 1.1284\n",
      "Epoch 3 Batch 259 Loss 1.1888\n",
      "Epoch 3 Batch 260 Loss 1.1765\n",
      "Epoch 3 Batch 261 Loss 1.4199\n",
      "Epoch 3 Batch 262 Loss 0.9989\n",
      "Epoch 3 Batch 263 Loss 1.5159\n",
      "Epoch 3 Batch 264 Loss 1.5253\n",
      "Epoch 3 Batch 265 Loss 1.2735\n",
      "Epoch 3 Batch 266 Loss 1.6180\n",
      "Epoch 3 Batch 267 Loss 1.6056\n",
      "Epoch 3 Batch 268 Loss 1.2226\n",
      "Epoch 3 Batch 269 Loss 1.1997\n",
      "Epoch 3 Batch 270 Loss 1.3055\n",
      "Epoch 3 Batch 271 Loss 1.0169\n",
      "Epoch 3 Batch 272 Loss 1.1431\n",
      "Epoch 3 Batch 273 Loss 1.2053\n",
      "Epoch 3 Batch 274 Loss 1.5047\n",
      "Epoch 3 Batch 275 Loss 1.4077\n",
      "Epoch 3 Batch 276 Loss 0.8516\n",
      "Epoch 3 Batch 277 Loss 1.4044\n",
      "Epoch 3 Batch 278 Loss 1.3337\n",
      "Epoch 3 Batch 279 Loss 1.2417\n",
      "Epoch 3 Batch 280 Loss 1.1783\n",
      "Epoch 3 Batch 281 Loss 1.1096\n",
      "Epoch 3 Batch 282 Loss 1.1147\n",
      "Epoch 3 Batch 283 Loss 1.4245\n",
      "Epoch 3 Batch 284 Loss 1.3059\n",
      "Epoch 3 Batch 285 Loss 1.2671\n",
      "Epoch 3 Batch 286 Loss 1.1683\n",
      "Epoch 3 Batch 287 Loss 1.3922\n",
      "Epoch 3 Batch 288 Loss 1.3309\n",
      "Epoch 3 Batch 289 Loss 1.2133\n",
      "Epoch 3 Batch 290 Loss 1.6169\n",
      "Epoch 3 Batch 291 Loss 1.3782\n",
      "Epoch 3 Batch 292 Loss 1.2079\n",
      "Epoch 3 Batch 293 Loss 1.2272\n",
      "Epoch 3 Batch 294 Loss 1.5285\n",
      "Epoch 3 Batch 295 Loss 1.0900\n",
      "Epoch 3 Batch 296 Loss 1.4200\n",
      "Epoch 3 Batch 297 Loss 1.2563\n",
      "Epoch 3 Batch 298 Loss 1.3016\n",
      "Epoch 3 Batch 299 Loss 1.3452\n",
      "Epoch 3 Batch 300 Loss 1.2720\n",
      "Epoch 3 Batch 301 Loss 1.2083\n",
      "Epoch 3 Batch 302 Loss 1.4849\n",
      "Epoch 3 Batch 303 Loss 1.1575\n",
      "Epoch 3 Batch 304 Loss 1.2297\n",
      "Epoch 3 Batch 305 Loss 1.3551\n",
      "Epoch 3 Batch 306 Loss 1.1967\n",
      "Epoch 3 Batch 307 Loss 1.5013\n",
      "Epoch 3 Batch 308 Loss 1.3096\n",
      "Epoch 3 Batch 309 Loss 1.2341\n",
      "Epoch 3 Batch 310 Loss 1.3638\n",
      "Epoch 3 Batch 311 Loss 1.3284\n",
      "Epoch 3 Batch 312 Loss 1.0823\n",
      "Epoch 3 Batch 313 Loss 1.2503\n",
      "Epoch 3 Batch 314 Loss 1.1615\n",
      "Epoch 3 Batch 315 Loss 1.3769\n",
      "Epoch 3 Batch 316 Loss 1.1541\n",
      "Epoch 3 Batch 317 Loss 1.3099\n",
      "Epoch 3 Batch 318 Loss 1.3674\n",
      "Epoch 3 Batch 319 Loss 1.2703\n",
      "Epoch 3 Batch 320 Loss 1.3907\n",
      "Epoch 3 Batch 321 Loss 1.2708\n",
      "Epoch 3 Batch 322 Loss 1.2713\n",
      "Epoch 3 Batch 323 Loss 1.5373\n",
      "Epoch 3 Batch 324 Loss 1.3000\n",
      "Epoch 3 Batch 325 Loss 1.3366\n",
      "Epoch 3 Batch 326 Loss 1.5105\n",
      "Epoch 3 Batch 327 Loss 1.3966\n",
      "Epoch 3 Batch 328 Loss 1.1410\n",
      "Epoch 3 Batch 329 Loss 1.2891\n",
      "Epoch 3 Batch 330 Loss 1.1243\n",
      "Epoch 3 Batch 331 Loss 1.2441\n",
      "Epoch 3 Batch 332 Loss 1.4969\n",
      "Epoch 3 Batch 333 Loss 1.4943\n",
      "Epoch 3 Batch 334 Loss 1.1405\n",
      "Epoch 3 Batch 335 Loss 1.2609\n",
      "Epoch 3 Batch 336 Loss 1.5967\n",
      "Epoch 3 Batch 337 Loss 1.2844\n",
      "Epoch 3 Batch 338 Loss 1.3530\n",
      "Epoch 3 Batch 339 Loss 1.3368\n",
      "Epoch 3 Batch 340 Loss 1.4542\n",
      "Epoch 3 Batch 341 Loss 1.2338\n",
      "Epoch 3 Batch 342 Loss 1.7551\n",
      "Epoch 3 Batch 343 Loss 1.1188\n",
      "Epoch 3 Batch 344 Loss 1.4935\n",
      "Epoch 3 Batch 345 Loss 1.5417\n",
      "Epoch 3 Batch 346 Loss 1.4172\n",
      "Epoch 3 Batch 347 Loss 1.3413\n",
      "Epoch 3 Batch 348 Loss 1.4912\n",
      "Epoch 3 Batch 349 Loss 1.2686\n",
      "Epoch 3 Batch 350 Loss 1.3063\n",
      "Epoch 3 Batch 351 Loss 1.0957\n",
      "Epoch 3 Batch 352 Loss 1.0750\n",
      "Epoch 3 Batch 353 Loss 1.3448\n",
      "Epoch 3 Batch 354 Loss 1.5874\n",
      "Epoch 3 Batch 355 Loss 1.5350\n",
      "Epoch 3 Batch 356 Loss 1.5675\n",
      "Epoch 3 Batch 357 Loss 1.2423\n",
      "Epoch 3 Batch 358 Loss 1.6831\n",
      "Epoch 3 Batch 359 Loss 1.4300\n",
      "Epoch 3 Batch 360 Loss 1.2782\n",
      "Epoch 3 Batch 361 Loss 1.3291\n",
      "Epoch 3 Batch 362 Loss 1.5730\n",
      "Epoch 3 Batch 363 Loss 1.3652\n",
      "Epoch 3 Batch 364 Loss 1.4826\n",
      "Epoch 3 Batch 365 Loss 1.3898\n",
      "Epoch 3 Batch 366 Loss 1.3062\n",
      "Epoch 3 Batch 367 Loss 1.4674\n",
      "Epoch 3 Batch 368 Loss 1.1609\n",
      "Epoch 3 Batch 369 Loss 1.3266\n",
      "Epoch 3 Batch 370 Loss 1.4372\n",
      "Epoch 3 Batch 371 Loss 1.4369\n",
      "Epoch 3 Batch 372 Loss 1.0754\n",
      "Epoch 3 Batch 373 Loss 1.4299\n",
      "Epoch 3 Batch 374 Loss 1.1548\n",
      "Epoch 3 Batch 375 Loss 1.1772\n",
      "Epoch 3 Batch 376 Loss 1.5160\n",
      "Epoch 3 Batch 377 Loss 1.2729\n",
      "Epoch 3 Batch 378 Loss 1.7377\n",
      "Epoch 3 Batch 379 Loss 1.0301\n",
      "Epoch 3 Batch 380 Loss 0.8717\n",
      "Epoch 3 Batch 381 Loss 1.3079\n",
      "Epoch 3 Batch 382 Loss 1.2661\n",
      "Epoch 3 Batch 383 Loss 1.3019\n",
      "Epoch 3 Batch 384 Loss 1.4320\n",
      "Epoch 3 Batch 385 Loss 1.1767\n",
      "Epoch 3 Batch 386 Loss 1.5076\n",
      "Epoch 3 Batch 387 Loss 0.9372\n",
      "Epoch 3 Batch 388 Loss 1.2719\n",
      "Epoch 3 Batch 389 Loss 1.3114\n",
      "Epoch 3 Batch 390 Loss 1.4488\n",
      "Epoch 3 Batch 391 Loss 1.3068\n",
      "Epoch 3 Batch 392 Loss 1.1246\n",
      "Epoch 3 Batch 393 Loss 1.4720\n",
      "Epoch 3 Batch 394 Loss 1.5758\n",
      "Epoch 3 Batch 395 Loss 1.2922\n",
      "Epoch 3 Batch 396 Loss 1.1287\n",
      "Epoch 3 Batch 397 Loss 1.2508\n",
      "Epoch 3 Batch 398 Loss 1.3345\n",
      "Epoch 3 Batch 399 Loss 1.5010\n",
      "Epoch 3 Batch 400 Loss 1.6380\n",
      "Epoch 3 Batch 401 Loss 1.5319\n",
      "Epoch 3 Batch 402 Loss 1.5325\n",
      "Epoch 3 Batch 403 Loss 1.3452\n",
      "Epoch 3 Batch 404 Loss 1.3349\n",
      "Epoch 3 Batch 405 Loss 1.2817\n",
      "Epoch 3 Batch 406 Loss 1.3798\n",
      "Epoch 3 Batch 407 Loss 1.0784\n",
      "Epoch 3 Batch 408 Loss 1.5538\n",
      "Epoch 3 Batch 409 Loss 1.4266\n",
      "Epoch 3 Batch 410 Loss 1.2198\n",
      "Epoch 3 Batch 411 Loss 1.6857\n",
      "Epoch 3 Batch 412 Loss 1.4853\n",
      "Epoch 3 Batch 413 Loss 1.2627\n",
      "Epoch 3 Batch 414 Loss 1.4320\n",
      "Epoch 3 Batch 415 Loss 1.3313\n",
      "Epoch 3 Batch 416 Loss 1.5369\n",
      "Epoch 3 Batch 417 Loss 1.0874\n",
      "Epoch 3 Batch 418 Loss 1.2952\n",
      "Epoch 3 Batch 419 Loss 1.5372\n",
      "Epoch 3 Batch 420 Loss 1.3881\n",
      "Epoch 3 Batch 421 Loss 1.2276\n",
      "Epoch 3 Batch 422 Loss 1.5687\n",
      "Epoch 3 Batch 423 Loss 1.1817\n",
      "Epoch 3 Batch 424 Loss 1.1104\n",
      "Epoch 3 Batch 425 Loss 1.3155\n",
      "Epoch 3 Batch 426 Loss 1.2063\n",
      "Epoch 3 Batch 427 Loss 1.2049\n",
      "Epoch 3 Batch 428 Loss 1.3701\n",
      "Epoch 3 Batch 429 Loss 1.1686\n",
      "Epoch 3 Batch 430 Loss 1.1121\n",
      "Epoch 3 Batch 431 Loss 1.4407\n",
      "Epoch 3 Batch 432 Loss 1.6397\n",
      "Epoch 3 Batch 433 Loss 1.2614\n",
      "Epoch 3 Batch 434 Loss 1.1318\n",
      "Epoch 3 Batch 435 Loss 1.7439\n",
      "Epoch 3 Batch 436 Loss 1.5228\n",
      "Epoch 3 Batch 437 Loss 1.4932\n",
      "Epoch 3 Batch 438 Loss 1.1168\n",
      "Epoch 3 Batch 439 Loss 1.3472\n",
      "Epoch 3 Batch 440 Loss 1.6661\n",
      "Epoch 3 Batch 441 Loss 1.2440\n",
      "Epoch 3 Batch 442 Loss 1.1408\n",
      "Epoch 3 Batch 443 Loss 1.3540\n",
      "Epoch 3 Batch 444 Loss 1.1751\n",
      "Epoch 3 Batch 445 Loss 1.6159\n",
      "Epoch 3 Batch 446 Loss 1.3699\n",
      "Epoch 3 Batch 447 Loss 1.3037\n",
      "Epoch 3 Batch 448 Loss 1.2942\n",
      "Epoch 3 Batch 449 Loss 1.2137\n",
      "Epoch 3 Batch 450 Loss 1.3298\n",
      "Epoch 3 Batch 451 Loss 1.3511\n",
      "Epoch 3 Batch 452 Loss 1.4489\n",
      "Epoch 3 Batch 453 Loss 0.9656\n",
      "Epoch 3 Batch 454 Loss 1.6338\n",
      "Epoch 3 Batch 455 Loss 1.4114\n",
      "Epoch 3 Batch 456 Loss 1.2744\n",
      "Epoch 3 Batch 457 Loss 1.2089\n",
      "Epoch 3 Batch 458 Loss 1.2734\n",
      "Epoch 3 Batch 459 Loss 1.5079\n",
      "Epoch 3 Batch 460 Loss 1.2983\n",
      "Epoch 3 Batch 461 Loss 1.3319\n",
      "Epoch 3 Batch 462 Loss 1.2122\n",
      "Epoch 3 Batch 463 Loss 1.2884\n",
      "Epoch 3 Batch 464 Loss 1.4021\n",
      "Epoch 3 Batch 465 Loss 1.5796\n",
      "Epoch 3 Batch 466 Loss 1.3251\n",
      "Epoch 3 Batch 467 Loss 1.1166\n",
      "Epoch 3 Batch 468 Loss 1.4992\n",
      "Epoch 3 Batch 469 Loss 1.2542\n",
      "Epoch 3 Batch 470 Loss 1.4033\n",
      "Epoch 3 Batch 471 Loss 1.5187\n",
      "Epoch 3 Batch 472 Loss 1.7559\n",
      "Epoch 3 Batch 473 Loss 1.4629\n",
      "Epoch 3 Batch 474 Loss 1.4249\n",
      "Epoch 3 Batch 475 Loss 1.6377\n",
      "Epoch 3 Batch 476 Loss 1.4183\n",
      "Epoch 3 Batch 477 Loss 1.1129\n",
      "Epoch 3 Batch 478 Loss 1.4809\n",
      "Epoch 3 Batch 479 Loss 1.5753\n",
      "Epoch 3 Batch 480 Loss 0.9668\n",
      "Epoch 3 Batch 481 Loss 1.4318\n",
      "Epoch 3 Batch 482 Loss 1.4407\n",
      "Epoch 3 Batch 483 Loss 1.4761\n",
      "Epoch 3 Batch 484 Loss 1.2073\n",
      "Epoch 3 Batch 485 Loss 1.3869\n",
      "Epoch 3 Batch 486 Loss 1.1959\n",
      "Epoch 3 Batch 487 Loss 1.3605\n",
      "Epoch 3 Batch 488 Loss 1.1919\n",
      "Epoch 3 Batch 489 Loss 1.6203\n",
      "Epoch 3 Batch 490 Loss 1.7727\n",
      "Epoch 3 Batch 491 Loss 1.4326\n",
      "Epoch 3 Batch 492 Loss 1.5703\n",
      "Epoch 3 Batch 493 Loss 1.4899\n",
      "Epoch 3 Batch 494 Loss 1.4021\n",
      "Epoch 3 Batch 495 Loss 1.6310\n",
      "Epoch 3 Batch 496 Loss 1.3208\n",
      "Epoch 3 Batch 497 Loss 1.0140\n",
      "Epoch 3 Batch 498 Loss 1.3019\n",
      "Epoch 3 Batch 499 Loss 1.1227\n",
      "Epoch 3 Batch 500 Loss 1.2395\n",
      "Epoch 3 Batch 501 Loss 1.0936\n",
      "Epoch 3 Batch 502 Loss 1.4271\n",
      "Epoch 3 Batch 503 Loss 1.2166\n",
      "Epoch 3 Batch 504 Loss 1.2413\n",
      "Epoch 3 Batch 505 Loss 1.1850\n",
      "Epoch 3 Batch 506 Loss 1.0104\n",
      "Epoch 3 Batch 507 Loss 1.4688\n",
      "Epoch 3 Batch 508 Loss 1.5142\n",
      "Epoch 3 Batch 509 Loss 1.4189\n",
      "Epoch 3 Batch 510 Loss 1.4195\n",
      "Epoch 3 Batch 511 Loss 1.6098\n",
      "Epoch 3 Batch 512 Loss 1.3365\n",
      "Epoch 3 Batch 513 Loss 1.3350\n",
      "Epoch 3 Batch 514 Loss 1.2951\n",
      "Epoch 3 Batch 515 Loss 1.4410\n",
      "Epoch 3 Batch 516 Loss 1.2614\n",
      "Epoch 3 Batch 517 Loss 1.5220\n",
      "Epoch 3 Batch 518 Loss 1.2499\n",
      "Epoch 3 Batch 519 Loss 1.2554\n",
      "Epoch 3 Batch 520 Loss 1.4412\n",
      "Epoch 3 Batch 521 Loss 1.3489\n",
      "Epoch 3 Batch 522 Loss 1.1139\n",
      "Epoch 3 Batch 523 Loss 1.6011\n",
      "Epoch 3 Batch 524 Loss 1.1040\n",
      "Epoch 3 Batch 525 Loss 1.3165\n",
      "Epoch 3 Batch 526 Loss 1.4673\n",
      "Epoch 3 Batch 527 Loss 1.3177\n",
      "Epoch 3 Batch 528 Loss 1.2526\n",
      "Epoch 3 Batch 529 Loss 1.4104\n",
      "Epoch 3 Batch 530 Loss 1.3679\n",
      "Epoch 3 Batch 531 Loss 1.3913\n",
      "Epoch 3 Batch 532 Loss 1.5305\n",
      "Epoch 3 Batch 533 Loss 1.3672\n",
      "Epoch 3 Batch 534 Loss 1.1883\n",
      "Epoch 3 Batch 535 Loss 1.1930\n",
      "Epoch 3 Batch 536 Loss 1.3790\n",
      "Epoch 3 Batch 537 Loss 1.4809\n",
      "Epoch 3 Batch 538 Loss 1.5933\n",
      "Epoch 3 Batch 539 Loss 1.0896\n",
      "Epoch 3 Batch 540 Loss 1.6033\n",
      "Epoch 3 Batch 541 Loss 1.3261\n",
      "Epoch 3 Batch 542 Loss 1.4082\n",
      "Epoch 3 Batch 543 Loss 1.2826\n",
      "Epoch 3 Batch 544 Loss 1.3345\n",
      "Epoch 3 Batch 545 Loss 1.2955\n",
      "Epoch 3 Batch 546 Loss 1.4035\n",
      "Epoch 3 Batch 547 Loss 1.5434\n",
      "Epoch 3 Batch 548 Loss 1.3446\n",
      "Epoch 3 Batch 549 Loss 1.3556\n",
      "Epoch 3 Batch 550 Loss 1.2478\n",
      "Epoch 3 Batch 551 Loss 1.2028\n",
      "Epoch 3 Batch 552 Loss 1.5629\n",
      "Epoch 3 Batch 553 Loss 1.2292\n",
      "Epoch 3 Batch 554 Loss 1.2529\n",
      "Epoch 3 Batch 555 Loss 1.2779\n",
      "Epoch 3 Batch 556 Loss 1.4878\n",
      "Epoch 3 Batch 557 Loss 1.2042\n",
      "Epoch 3 Batch 558 Loss 1.1715\n",
      "Epoch 3 Batch 559 Loss 1.4501\n",
      "Epoch 3 Batch 560 Loss 1.2356\n",
      "Epoch 3 Batch 561 Loss 1.0378\n",
      "Epoch 3 Batch 562 Loss 1.3962\n",
      "Epoch 3 Batch 563 Loss 1.2348\n",
      "Epoch 3 Batch 564 Loss 1.1869\n",
      "Epoch 3 Batch 565 Loss 1.4539\n",
      "Epoch 3 Batch 566 Loss 1.2212\n",
      "Epoch 3 Batch 567 Loss 1.6972\n",
      "Epoch 3 Batch 568 Loss 1.1791\n",
      "Epoch 3 Batch 569 Loss 1.7209\n",
      "Epoch 3 Batch 570 Loss 1.5427\n",
      "Epoch 3 Batch 571 Loss 1.5284\n",
      "Epoch 3 Batch 572 Loss 1.3939\n",
      "Epoch 3 Batch 573 Loss 1.3670\n",
      "Epoch 3 Batch 574 Loss 1.1698\n",
      "Epoch 3 Batch 575 Loss 1.2655\n",
      "Epoch 3 Batch 576 Loss 1.6207\n",
      "Epoch 3 Batch 577 Loss 1.7504\n",
      "Epoch 3 Batch 578 Loss 1.4195\n",
      "Epoch 3 Batch 579 Loss 1.2632\n",
      "Epoch 3 Batch 580 Loss 1.3862\n",
      "Epoch 3 Batch 581 Loss 1.4100\n",
      "Epoch 3 Batch 582 Loss 1.3257\n",
      "Epoch 3 Batch 583 Loss 1.0753\n",
      "Epoch 3 Batch 584 Loss 1.4713\n",
      "Epoch 3 Batch 585 Loss 1.1992\n",
      "Epoch 3 Batch 586 Loss 1.7312\n",
      "Epoch 3 Batch 587 Loss 1.2466\n",
      "Epoch 3 Batch 588 Loss 1.4775\n",
      "Epoch 3 Batch 589 Loss 1.4301\n",
      "Epoch 3 Batch 590 Loss 1.1824\n",
      "Epoch 3 Batch 591 Loss 1.2731\n",
      "Epoch 3 Batch 592 Loss 1.4023\n",
      "Epoch 3 Batch 593 Loss 1.4012\n",
      "Epoch 3 Batch 594 Loss 1.4199\n",
      "Epoch 3 Batch 595 Loss 1.0187\n",
      "Epoch 3 Batch 596 Loss 1.2603\n",
      "Epoch 3 Batch 597 Loss 1.2872\n",
      "Epoch 3 Batch 598 Loss 1.1669\n",
      "Epoch 3 Batch 599 Loss 1.4388\n",
      "Epoch 3 Batch 600 Loss 1.4330\n",
      "Epoch 3 Batch 601 Loss 1.1202\n",
      "Epoch 3 Batch 602 Loss 1.1110\n",
      "Epoch 3 Batch 603 Loss 1.4149\n",
      "Epoch 3 Batch 604 Loss 1.3023\n",
      "Epoch 3 Batch 605 Loss 0.9875\n",
      "Epoch 3 Batch 606 Loss 1.1551\n",
      "Epoch 3 Batch 607 Loss 1.0882\n",
      "Epoch 3 Batch 608 Loss 1.3481\n",
      "Epoch 3 Batch 609 Loss 1.4496\n",
      "Epoch 3 Batch 610 Loss 1.5952\n",
      "Epoch 3 Batch 611 Loss 1.3589\n",
      "Epoch 3 Batch 612 Loss 1.2373\n",
      "Epoch 3 Batch 613 Loss 1.3953\n",
      "Epoch 3 Batch 614 Loss 1.3544\n",
      "Epoch 3 Batch 615 Loss 1.1023\n",
      "Epoch 3 Batch 616 Loss 1.7547\n",
      "Epoch 3 Batch 617 Loss 1.1866\n",
      "Epoch 3 Batch 618 Loss 1.0643\n",
      "Epoch 3 Batch 619 Loss 1.2159\n",
      "Epoch 3 Batch 620 Loss 1.1831\n",
      "Epoch 3 Batch 621 Loss 1.1481\n",
      "Epoch 3 Batch 622 Loss 1.1600\n",
      "Epoch 3 Batch 623 Loss 1.2305\n",
      "Epoch 3 Batch 624 Loss 1.3558\n",
      "Epoch 3 Batch 625 Loss 1.2233\n",
      "Epoch 3 Batch 626 Loss 1.0962\n",
      "Epoch 3 Batch 627 Loss 1.1253\n",
      "Epoch 3 Batch 628 Loss 1.3209\n",
      "Epoch 3 Batch 629 Loss 1.2169\n",
      "Epoch 3 Batch 630 Loss 1.4383\n",
      "Epoch 3 Batch 631 Loss 1.1360\n",
      "Epoch 3 Batch 632 Loss 1.4013\n",
      "Epoch 3 Batch 633 Loss 1.4853\n",
      "Epoch 3 Batch 634 Loss 0.9233\n",
      "Epoch 3 Batch 635 Loss 1.1275\n",
      "Epoch 3 Batch 636 Loss 1.3866\n",
      "Epoch 3 Batch 637 Loss 1.4506\n",
      "Epoch 3 Batch 638 Loss 1.5657\n",
      "Epoch 3 Batch 639 Loss 1.3421\n",
      "Epoch 3 Batch 640 Loss 1.1986\n",
      "Epoch 3 Batch 641 Loss 1.3685\n",
      "Epoch 3 Batch 642 Loss 1.5090\n",
      "Epoch 3 Batch 643 Loss 1.4102\n",
      "Epoch 3 Batch 644 Loss 1.4117\n",
      "Epoch 3 Batch 645 Loss 1.5240\n",
      "Epoch 3 Batch 646 Loss 1.3243\n",
      "Epoch 3 Batch 647 Loss 1.4428\n",
      "Epoch 3 Batch 648 Loss 1.3440\n",
      "Epoch 3 Batch 649 Loss 1.3602\n",
      "Epoch 3 Batch 650 Loss 1.4914\n",
      "Epoch 3 Batch 651 Loss 1.5022\n",
      "Epoch 3 Batch 652 Loss 1.2560\n",
      "Epoch 3 Batch 653 Loss 1.4489\n",
      "Epoch 3 Batch 654 Loss 1.3006\n",
      "Epoch 3 Batch 655 Loss 1.3506\n",
      "Epoch 3 Batch 656 Loss 1.4829\n",
      "Epoch 3 Batch 657 Loss 1.5064\n",
      "Epoch 3 Batch 658 Loss 1.4669\n",
      "Epoch 3 Batch 659 Loss 1.5414\n",
      "Epoch 3 Batch 660 Loss 1.2942\n",
      "Epoch 3 Batch 661 Loss 1.0786\n",
      "Epoch 3 Batch 662 Loss 1.2455\n",
      "Epoch 3 Batch 663 Loss 1.3600\n",
      "Epoch 3 Batch 664 Loss 1.2492\n",
      "Epoch 3 Batch 665 Loss 1.1008\n",
      "Epoch 3 Batch 666 Loss 1.4038\n",
      "Epoch 3 Batch 667 Loss 1.2968\n",
      "Epoch 3 Batch 668 Loss 1.2427\n",
      "Epoch 3 Batch 669 Loss 1.6577\n",
      "Epoch 3 Batch 670 Loss 1.7200\n",
      "Epoch 3 Batch 671 Loss 1.4528\n",
      "Epoch 3 Batch 672 Loss 1.4266\n",
      "Epoch 3 Batch 673 Loss 1.3501\n",
      "Epoch 3 Batch 674 Loss 1.2668\n",
      "Epoch 3 Batch 675 Loss 1.4912\n",
      "Epoch 3 Batch 676 Loss 1.4524\n",
      "Epoch 3 Batch 677 Loss 1.1480\n",
      "Epoch 3 Batch 678 Loss 1.0960\n",
      "Epoch 3 Batch 679 Loss 1.3973\n",
      "Epoch 3 Batch 680 Loss 1.1132\n",
      "Epoch 3 Batch 681 Loss 1.1877\n",
      "Epoch 3 Batch 682 Loss 1.1400\n",
      "Epoch 3 Batch 683 Loss 1.2092\n",
      "Epoch 3 Batch 684 Loss 1.2947\n",
      "Epoch 3 Batch 685 Loss 1.1261\n",
      "Epoch 3 Batch 686 Loss 1.6439\n",
      "Epoch 3 Batch 687 Loss 1.4061\n",
      "Epoch 3 Batch 688 Loss 1.4417\n",
      "Epoch 3 Batch 689 Loss 1.2783\n",
      "Epoch 3 Batch 690 Loss 1.2221\n",
      "Epoch 3 Batch 691 Loss 1.5037\n",
      "Epoch 3 Batch 692 Loss 1.2757\n",
      "Epoch 3 Batch 693 Loss 1.3543\n",
      "Epoch 3 Batch 694 Loss 1.6173\n",
      "Epoch 3 Batch 695 Loss 1.5859\n",
      "Epoch 3 Batch 696 Loss 1.3723\n",
      "Epoch 3 Batch 697 Loss 1.0330\n",
      "Epoch 3 Batch 698 Loss 1.4216\n",
      "Epoch 3 Batch 699 Loss 1.1527\n",
      "Epoch 3 Batch 700 Loss 1.2544\n",
      "Epoch 3 Batch 701 Loss 1.5672\n",
      "Epoch 3 Batch 702 Loss 1.4306\n",
      "Epoch 3 Batch 703 Loss 1.4231\n",
      "Epoch 3 Batch 704 Loss 1.1318\n",
      "Epoch 3 Batch 705 Loss 1.6850\n",
      "Epoch 3 Batch 706 Loss 1.1160\n",
      "Epoch 3 Batch 707 Loss 1.4970\n",
      "Epoch 3 Batch 708 Loss 1.1440\n",
      "Epoch 3 Batch 709 Loss 1.1645\n",
      "Epoch 3 Batch 710 Loss 1.4327\n",
      "Epoch 3 Batch 711 Loss 1.4292\n",
      "Epoch 3 Batch 712 Loss 1.2259\n",
      "Epoch 3 Batch 713 Loss 1.2352\n",
      "Epoch 3 Batch 714 Loss 1.0141\n",
      "Epoch 3 Batch 715 Loss 1.1107\n",
      "Epoch 3 Batch 716 Loss 1.1573\n",
      "Epoch 3 Batch 717 Loss 1.3103\n",
      "Epoch 3 Batch 718 Loss 1.5832\n",
      "Epoch 3 Batch 719 Loss 1.4428\n",
      "Epoch 3 Batch 720 Loss 1.3229\n",
      "Epoch 3 Batch 721 Loss 1.1326\n",
      "Epoch 3 Batch 722 Loss 1.4336\n",
      "Epoch 3 Batch 723 Loss 1.2039\n",
      "Epoch 3 Batch 724 Loss 1.4215\n",
      "Epoch 3 Batch 725 Loss 1.5932\n",
      "Epoch 3 Batch 726 Loss 1.2279\n",
      "Epoch 3 Batch 727 Loss 1.5247\n",
      "Epoch 3 Batch 728 Loss 1.3508\n",
      "Epoch 3 Batch 729 Loss 1.3684\n",
      "Epoch 3 Batch 730 Loss 1.3124\n",
      "Epoch 3 Batch 731 Loss 1.3642\n",
      "Epoch 3 Batch 732 Loss 1.5437\n",
      "Epoch 3 Batch 733 Loss 1.1847\n",
      "Epoch 3 Batch 734 Loss 1.6162\n",
      "Epoch 3 Batch 735 Loss 1.5075\n",
      "Epoch 3 Batch 736 Loss 1.5420\n",
      "Epoch 3 Batch 737 Loss 1.7938\n",
      "Epoch 3 Batch 738 Loss 1.4467\n",
      "Epoch 3 Batch 739 Loss 1.3884\n",
      "Epoch 3 Batch 740 Loss 1.4423\n",
      "Epoch 3 Batch 741 Loss 1.3412\n",
      "Epoch 3 Batch 742 Loss 1.5484\n",
      "Epoch 3 Batch 743 Loss 1.2507\n",
      "Epoch 3 Batch 744 Loss 1.1726\n",
      "Epoch 3 Batch 745 Loss 1.3041\n",
      "Epoch 3 Batch 746 Loss 1.4601\n",
      "Epoch 3 Batch 747 Loss 1.1348\n",
      "Epoch 3 Batch 748 Loss 1.2521\n",
      "Epoch 3 Batch 749 Loss 1.2183\n",
      "Epoch 3 Batch 750 Loss 1.4801\n",
      "Epoch 3 Batch 751 Loss 1.3216\n",
      "Epoch 3 Batch 752 Loss 1.2662\n",
      "Epoch 3 Batch 753 Loss 1.3253\n",
      "Epoch 3 Batch 754 Loss 1.3566\n",
      "Epoch 3 Batch 755 Loss 1.0237\n",
      "Epoch 3 Batch 756 Loss 1.1558\n",
      "Epoch 3 Batch 757 Loss 1.8726\n",
      "Epoch 3 Batch 758 Loss 1.5703\n",
      "Epoch 3 Batch 759 Loss 1.5699\n",
      "Epoch 3 Batch 760 Loss 1.1119\n",
      "Epoch 3 Batch 761 Loss 1.1528\n",
      "Epoch 3 Batch 762 Loss 1.4513\n",
      "Epoch 3 Batch 763 Loss 1.3006\n",
      "Epoch 3 Batch 764 Loss 1.3846\n",
      "Epoch 3 Batch 765 Loss 0.9390\n",
      "Epoch 3 Batch 766 Loss 1.0682\n",
      "Epoch 3 Batch 767 Loss 1.4650\n",
      "Epoch 3 Batch 768 Loss 1.2975\n",
      "Epoch 3 Batch 769 Loss 0.9780\n",
      "Epoch 3 Batch 770 Loss 1.4734\n",
      "Epoch 3 Batch 771 Loss 1.3627\n",
      "Epoch 3 Batch 772 Loss 1.3113\n",
      "Epoch 3 Batch 773 Loss 1.4358\n",
      "Epoch 3 Batch 774 Loss 1.5807\n",
      "Epoch 3 Batch 775 Loss 1.3347\n",
      "Epoch 3 Batch 776 Loss 1.0997\n",
      "Epoch 3 Batch 777 Loss 1.3705\n",
      "Epoch 3 Batch 778 Loss 1.5051\n",
      "Epoch 3 Batch 779 Loss 1.4404\n",
      "Epoch 3 Batch 780 Loss 1.1490\n",
      "Epoch 3 Batch 781 Loss 1.3771\n",
      "Epoch 3 Batch 782 Loss 1.3799\n",
      "Epoch 3 Batch 783 Loss 1.1223\n",
      "Epoch 3 Batch 784 Loss 1.6236\n",
      "Epoch 3 Batch 785 Loss 1.2093\n",
      "Epoch 3 Batch 786 Loss 1.2269\n",
      "Epoch 3 Batch 787 Loss 1.5403\n",
      "Epoch 3 Batch 788 Loss 1.4439\n",
      "Epoch 3 Batch 789 Loss 1.3759\n",
      "Epoch 3 Batch 790 Loss 1.4704\n",
      "Epoch 3 Batch 791 Loss 1.2822\n",
      "Epoch 3 Batch 792 Loss 1.6154\n",
      "Epoch 3 Batch 793 Loss 1.4552\n",
      "Epoch 3 Batch 794 Loss 1.5273\n",
      "Epoch 3 Batch 795 Loss 1.2224\n",
      "Epoch 3 Batch 796 Loss 1.2676\n",
      "Epoch 3 Batch 797 Loss 1.4569\n",
      "Epoch 3 Batch 798 Loss 1.0812\n",
      "Epoch 3 Batch 799 Loss 1.5083\n",
      "Epoch 3 Batch 800 Loss 1.3645\n",
      "Epoch 3 Batch 801 Loss 1.7487\n",
      "Epoch 3 Batch 802 Loss 1.5261\n",
      "Epoch 3 Batch 803 Loss 1.2328\n",
      "Epoch 3 Batch 804 Loss 1.4419\n",
      "Epoch 3 Batch 805 Loss 1.1733\n",
      "Epoch 3 Batch 806 Loss 1.0621\n",
      "Epoch 3 Batch 807 Loss 1.2508\n",
      "Epoch 3 Batch 808 Loss 1.2716\n",
      "Epoch 3 Batch 809 Loss 1.4383\n",
      "Epoch 3 Batch 810 Loss 1.5068\n",
      "Epoch 3 Batch 811 Loss 1.2572\n",
      "Epoch 3 Batch 812 Loss 1.3740\n",
      "Epoch 3 Batch 813 Loss 1.3069\n",
      "Epoch 3 Batch 814 Loss 1.2496\n",
      "Epoch 3 Batch 815 Loss 1.1368\n",
      "Epoch 3 Batch 816 Loss 1.5963\n",
      "Epoch 3 Batch 817 Loss 1.1744\n",
      "Epoch 3 Batch 818 Loss 1.3158\n",
      "Epoch 3 Batch 819 Loss 1.2533\n",
      "Epoch 3 Batch 820 Loss 1.5637\n",
      "Epoch 3 Batch 821 Loss 1.0948\n",
      "Epoch 3 Batch 822 Loss 1.1747\n",
      "Epoch 3 Batch 823 Loss 1.3093\n",
      "Epoch 3 Batch 824 Loss 1.3675\n",
      "Epoch 3 Batch 825 Loss 1.2845\n",
      "Epoch 3 Batch 826 Loss 1.3802\n",
      "Epoch 3 Batch 827 Loss 1.0627\n",
      "Epoch 3 Batch 828 Loss 1.6509\n",
      "Epoch 3 Batch 829 Loss 1.2402\n",
      "Epoch 3 Batch 830 Loss 1.5905\n",
      "Epoch 3 Batch 831 Loss 1.2120\n",
      "Epoch 3 Batch 832 Loss 1.4574\n",
      "Epoch 3 Batch 833 Loss 1.2780\n",
      "Epoch 3 Batch 834 Loss 1.4406\n",
      "Epoch 3 Batch 835 Loss 1.5484\n",
      "Epoch 3 Batch 836 Loss 1.2308\n",
      "Epoch 3 Batch 837 Loss 1.3426\n",
      "Epoch 3 Batch 838 Loss 1.3988\n",
      "Epoch 3 Batch 839 Loss 1.1595\n",
      "Epoch 3 Batch 840 Loss 1.1532\n",
      "Epoch 3 Batch 841 Loss 1.3458\n",
      "Epoch 3 Batch 842 Loss 1.3508\n",
      "Epoch 3 Batch 843 Loss 1.1995\n",
      "Epoch 3 Batch 844 Loss 1.2859\n",
      "Epoch 3 Batch 845 Loss 1.2597\n",
      "Epoch 3 Batch 846 Loss 1.0631\n",
      "Epoch 3 Batch 847 Loss 1.2043\n",
      "Epoch 3 Batch 848 Loss 1.3091\n",
      "Epoch 3 Batch 849 Loss 1.6330\n",
      "Epoch 3 Batch 850 Loss 1.2293\n",
      "Epoch 3 Batch 851 Loss 1.1401\n",
      "Epoch 3 Batch 852 Loss 1.3618\n",
      "Epoch 3 Batch 853 Loss 0.8980\n",
      "Epoch 3 Batch 854 Loss 1.4115\n",
      "Epoch 3 Batch 855 Loss 1.3725\n",
      "Epoch 3 Batch 856 Loss 1.2750\n",
      "Epoch 3 Batch 857 Loss 1.1445\n",
      "Epoch 3 Batch 858 Loss 1.6183\n",
      "Epoch 3 Batch 859 Loss 1.4215\n",
      "Epoch 3 Batch 860 Loss 1.2729\n",
      "Epoch 3 Batch 861 Loss 1.4998\n",
      "Epoch 3 Batch 862 Loss 0.9853\n",
      "Epoch 3 Batch 863 Loss 1.3888\n",
      "Epoch 3 Batch 864 Loss 1.0398\n",
      "Epoch 3 Batch 865 Loss 1.1837\n",
      "Epoch 3 Batch 866 Loss 1.5376\n",
      "Epoch 3 Batch 867 Loss 1.2893\n",
      "Epoch 3 Batch 868 Loss 1.2772\n",
      "Epoch 3 Batch 869 Loss 1.0000\n",
      "Epoch 3 Batch 870 Loss 1.1906\n",
      "Epoch 3 Batch 871 Loss 1.1702\n",
      "Epoch 3 Batch 872 Loss 1.4007\n",
      "Epoch 3 Batch 873 Loss 1.1807\n",
      "Epoch 3 Batch 874 Loss 1.4565\n",
      "Epoch 3 Batch 875 Loss 1.5843\n",
      "Epoch 3 Batch 876 Loss 1.7018\n",
      "Epoch 3 Batch 877 Loss 1.4574\n",
      "Epoch 3 Batch 878 Loss 1.1962\n",
      "Epoch 3 Batch 879 Loss 1.4374\n",
      "Epoch 3 Batch 880 Loss 1.4938\n",
      "Epoch 3 Batch 881 Loss 1.1385\n",
      "Epoch 3 Batch 882 Loss 1.2489\n",
      "Epoch 3 Batch 883 Loss 1.2686\n",
      "Epoch 3 Batch 884 Loss 1.1599\n",
      "Epoch 3 Batch 885 Loss 1.4575\n",
      "Epoch 3 Batch 886 Loss 1.2298\n",
      "Epoch 3 Batch 887 Loss 1.1774\n",
      "Epoch 3 Batch 888 Loss 1.1029\n",
      "Epoch 3 Batch 889 Loss 1.5142\n",
      "Epoch 3 Batch 890 Loss 1.3605\n",
      "Epoch 3 Batch 891 Loss 1.4317\n",
      "Epoch 3 Batch 892 Loss 1.4305\n",
      "Epoch 3 Batch 893 Loss 1.2608\n",
      "Epoch 3 Batch 894 Loss 1.4881\n",
      "Epoch 3 Batch 895 Loss 1.2571\n",
      "Epoch 3 Batch 896 Loss 1.3074\n",
      "Epoch 3 Batch 897 Loss 1.1340\n",
      "Epoch 3 Batch 898 Loss 1.1570\n",
      "Epoch 3 Batch 899 Loss 1.1444\n",
      "Epoch 3 Batch 900 Loss 1.0974\n",
      "Epoch 3 Batch 901 Loss 1.6069\n",
      "Epoch 3 Batch 902 Loss 1.3756\n",
      "Epoch 3 Batch 903 Loss 1.3919\n",
      "Epoch 3 Batch 904 Loss 1.2205\n",
      "Epoch 3 Batch 905 Loss 1.3573\n",
      "Epoch 3 Batch 906 Loss 1.1976\n",
      "Epoch 3 Batch 907 Loss 1.0813\n",
      "Epoch 3 Batch 908 Loss 1.2214\n",
      "Epoch 3 Batch 909 Loss 1.4108\n",
      "Epoch 3 Batch 910 Loss 1.2970\n",
      "Epoch 3 Batch 911 Loss 1.4707\n",
      "Epoch 3 Batch 912 Loss 1.3862\n",
      "Epoch 3 Batch 913 Loss 1.1731\n",
      "Epoch 3 Batch 914 Loss 1.3547\n",
      "Epoch 3 Batch 915 Loss 1.2175\n",
      "Epoch 3 Batch 916 Loss 1.4140\n",
      "Epoch 3 Batch 917 Loss 1.3080\n",
      "Epoch 3 Batch 918 Loss 1.4682\n",
      "Epoch 3 Batch 919 Loss 1.4741\n",
      "Epoch 3 Batch 920 Loss 1.0213\n",
      "Epoch 3 Batch 921 Loss 1.2625\n",
      "Epoch 3 Batch 922 Loss 1.3973\n",
      "Epoch 3 Batch 923 Loss 1.4709\n",
      "Epoch 3 Batch 924 Loss 1.4805\n",
      "Epoch 3 Batch 925 Loss 1.2728\n",
      "Epoch 3 Batch 926 Loss 1.3244\n",
      "Epoch 3 Batch 927 Loss 1.5181\n",
      "Epoch 3 Batch 928 Loss 1.2477\n",
      "Epoch 3 Batch 929 Loss 1.1995\n",
      "Epoch 3 Batch 930 Loss 1.2495\n",
      "Epoch 3 Batch 931 Loss 1.3368\n",
      "Epoch 3 Batch 932 Loss 1.1873\n",
      "Epoch 3 Batch 933 Loss 1.0576\n",
      "Epoch 3 Batch 934 Loss 1.2500\n",
      "Epoch 3 Batch 935 Loss 1.2554\n",
      "Epoch 3 Batch 936 Loss 1.3287\n",
      "Epoch 3 Batch 937 Loss 1.2807\n",
      "Epoch 3 Batch 938 Loss 1.2459\n",
      "Epoch 3 Batch 939 Loss 1.6432\n",
      "Epoch 3 Batch 940 Loss 1.3424\n",
      "Epoch 3 Batch 941 Loss 1.3042\n",
      "Epoch 3 Batch 942 Loss 1.7017\n",
      "Epoch 3 Batch 943 Loss 1.3054\n",
      "Epoch 3 Batch 944 Loss 1.4558\n",
      "Epoch 3 Batch 945 Loss 1.4835\n",
      "Epoch 3 Batch 946 Loss 1.5415\n",
      "Epoch 3 Batch 947 Loss 1.1631\n",
      "Epoch 3 Batch 948 Loss 1.0741\n",
      "Epoch 3 Batch 949 Loss 1.3964\n",
      "Epoch 3 Batch 950 Loss 1.2822\n",
      "Epoch 3 Batch 951 Loss 1.2960\n",
      "Epoch 3 Batch 952 Loss 1.3359\n",
      "Epoch 3 Batch 953 Loss 1.2817\n",
      "Epoch 3 Batch 954 Loss 1.2099\n",
      "Epoch 3 Batch 955 Loss 1.3893\n",
      "Epoch 3 Batch 956 Loss 1.2658\n",
      "Epoch 3 Batch 957 Loss 1.1112\n",
      "Epoch 3 Batch 958 Loss 1.2423\n",
      "Epoch 3 Batch 959 Loss 1.2848\n",
      "Epoch 3 Batch 960 Loss 1.3560\n",
      "Epoch 3 Batch 961 Loss 1.4506\n",
      "Epoch 3 Batch 962 Loss 1.5740\n",
      "Epoch 3 Batch 963 Loss 1.4388\n",
      "Epoch 3 Batch 964 Loss 1.3087\n",
      "Epoch 3 Batch 965 Loss 1.4378\n",
      "Epoch 3 Batch 966 Loss 1.1588\n",
      "Epoch 3 Batch 967 Loss 1.2887\n",
      "Epoch 3 Batch 968 Loss 1.3459\n",
      "Epoch 3 Batch 969 Loss 1.3738\n",
      "Epoch 3 Batch 970 Loss 1.1752\n",
      "Epoch 3 Batch 971 Loss 1.5342\n",
      "Epoch 3 Batch 972 Loss 1.3025\n",
      "Epoch 3 Batch 973 Loss 0.9473\n",
      "Epoch 3 Batch 974 Loss 1.2909\n",
      "Epoch 3 Batch 975 Loss 1.6473\n",
      "Epoch 3 Batch 976 Loss 1.3046\n",
      "Epoch 3 Batch 977 Loss 1.6542\n",
      "Epoch 3 Batch 978 Loss 1.1179\n",
      "Epoch 3 Batch 979 Loss 1.3995\n",
      "Epoch 3 Batch 980 Loss 1.3210\n",
      "Epoch 3 Batch 981 Loss 1.5229\n",
      "Epoch 3 Batch 982 Loss 1.5029\n",
      "Epoch 3 Batch 983 Loss 1.3895\n",
      "Epoch 3 Batch 984 Loss 1.2969\n",
      "Epoch 3 Batch 985 Loss 1.2250\n",
      "Epoch 3 Batch 986 Loss 0.9855\n",
      "Epoch 3 Batch 987 Loss 1.4118\n",
      "Epoch 3 Batch 988 Loss 1.5282\n",
      "Epoch 3 Batch 989 Loss 1.2087\n",
      "Epoch 3 Batch 990 Loss 1.1077\n",
      "Epoch 3 Batch 991 Loss 1.5588\n",
      "Epoch 3 Batch 992 Loss 1.2086\n",
      "Epoch 3 Batch 993 Loss 1.3307\n",
      "Epoch 3 Batch 994 Loss 0.9912\n",
      "Epoch 3 Batch 995 Loss 1.1777\n",
      "Epoch 3 Batch 996 Loss 1.0855\n",
      "Epoch 3 Batch 997 Loss 1.4759\n",
      "Epoch 3 Batch 998 Loss 1.5665\n",
      "Epoch 3 Batch 999 Loss 1.5340\n",
      "Epoch 3 Batch 1000 Loss 1.3764\n",
      "Epoch 3 Batch 1001 Loss 1.1459\n",
      "Epoch 3 Batch 1002 Loss 1.2238\n",
      "Epoch 3 Batch 1003 Loss 1.2476\n",
      "Epoch 3 Batch 1004 Loss 1.3220\n",
      "Epoch 3 Batch 1005 Loss 1.3331\n",
      "Epoch 3 Batch 1006 Loss 1.2490\n",
      "Epoch 3 Batch 1007 Loss 1.4182\n",
      "Epoch 3 Batch 1008 Loss 1.2267\n",
      "Epoch 3 Batch 1009 Loss 1.3568\n",
      "Epoch 3 Batch 1010 Loss 1.5876\n",
      "Epoch 3 Batch 1011 Loss 1.2651\n",
      "Epoch 3 Batch 1012 Loss 1.4481\n",
      "Epoch 3 Batch 1013 Loss 1.5256\n",
      "Epoch 3 Batch 1014 Loss 1.2371\n",
      "Epoch 3 Batch 1015 Loss 1.2769\n",
      "Epoch 3 Batch 1016 Loss 1.4729\n",
      "Epoch 3 Batch 1017 Loss 1.4530\n",
      "Epoch 3 Batch 1018 Loss 1.0965\n",
      "Epoch 3 Batch 1019 Loss 1.4459\n",
      "Epoch 3 Batch 1020 Loss 1.3297\n",
      "Epoch 3 Batch 1021 Loss 1.5023\n",
      "Epoch 3 Batch 1022 Loss 1.1388\n",
      "Epoch 3 Batch 1023 Loss 1.0995\n",
      "Epoch 3 Batch 1024 Loss 1.3410\n",
      "Epoch 3 Batch 1025 Loss 1.2454\n",
      "Epoch 3 Batch 1026 Loss 1.1097\n",
      "Epoch 3 Batch 1027 Loss 1.5198\n",
      "Epoch 3 Batch 1028 Loss 1.6172\n",
      "Epoch 3 Batch 1029 Loss 1.3933\n",
      "Epoch 3 Batch 1030 Loss 1.3618\n",
      "Epoch 3 Batch 1031 Loss 1.3126\n",
      "Epoch 3 Batch 1032 Loss 1.1317\n",
      "Epoch 3 Batch 1033 Loss 1.2853\n",
      "Epoch 3 Batch 1034 Loss 1.4449\n",
      "Epoch 3 Batch 1035 Loss 1.4724\n",
      "Epoch 3 Batch 1036 Loss 1.1463\n",
      "Epoch 3 Batch 1037 Loss 1.2539\n",
      "Epoch 3 Batch 1038 Loss 1.3411\n",
      "Epoch 3 Batch 1039 Loss 1.4321\n",
      "Epoch 3 Batch 1040 Loss 1.2268\n",
      "Epoch 3 Batch 1041 Loss 1.4312\n",
      "Epoch 3 Batch 1042 Loss 1.1675\n",
      "Epoch 3 Batch 1043 Loss 1.3478\n",
      "Epoch 3 Batch 1044 Loss 1.4849\n",
      "Epoch 3 Batch 1045 Loss 1.1217\n",
      "Epoch 3 Batch 1046 Loss 1.4203\n",
      "Epoch 3 Batch 1047 Loss 1.3776\n",
      "Epoch 3 Batch 1048 Loss 1.2872\n",
      "Epoch 3 Batch 1049 Loss 1.4889\n",
      "Epoch 3 Batch 1050 Loss 1.4123\n",
      "Epoch 3 Batch 1051 Loss 1.4955\n",
      "Epoch 3 Batch 1052 Loss 1.2145\n",
      "Epoch 3 Batch 1053 Loss 1.3136\n",
      "Epoch 3 Batch 1054 Loss 1.3742\n",
      "Epoch 3 Batch 1055 Loss 1.1441\n",
      "Epoch 3 Batch 1056 Loss 1.3769\n",
      "Epoch 3 Batch 1057 Loss 1.0675\n",
      "Epoch 3 Batch 1058 Loss 1.5050\n",
      "Epoch 3 Batch 1059 Loss 1.4514\n",
      "Epoch 3 Batch 1060 Loss 1.2873\n",
      "Epoch 3 Batch 1061 Loss 1.2837\n",
      "Epoch 3 Batch 1062 Loss 1.2192\n",
      "Epoch 3 Batch 1063 Loss 1.2041\n",
      "Epoch 3 Batch 1064 Loss 1.4264\n",
      "Epoch 3 Batch 1065 Loss 1.6885\n",
      "Epoch 3 Batch 1066 Loss 1.4776\n",
      "Epoch 3 Batch 1067 Loss 1.2434\n",
      "Epoch 3 Batch 1068 Loss 1.4206\n",
      "Epoch 3 Batch 1069 Loss 1.2488\n",
      "Epoch 3 Batch 1070 Loss 1.2105\n",
      "Epoch 3 Batch 1071 Loss 1.4191\n",
      "Epoch 3 Batch 1072 Loss 1.4121\n",
      "Epoch 3 Batch 1073 Loss 1.0935\n",
      "Epoch 3 Batch 1074 Loss 1.2268\n",
      "Epoch 3 Batch 1075 Loss 1.1121\n",
      "Epoch 3 Batch 1076 Loss 1.4000\n",
      "Epoch 3 Batch 1077 Loss 1.4174\n",
      "Epoch 3 Batch 1078 Loss 1.4445\n",
      "Epoch 3 Batch 1079 Loss 1.6255\n",
      "Epoch 3 Batch 1080 Loss 1.3078\n",
      "Epoch 3 Batch 1081 Loss 1.2785\n",
      "Epoch 3 Batch 1082 Loss 1.4419\n",
      "Epoch 3 Batch 1083 Loss 1.3696\n",
      "Epoch 3 Batch 1084 Loss 1.1624\n",
      "Epoch 3 Batch 1085 Loss 1.3364\n",
      "Epoch 3 Batch 1086 Loss 1.3200\n",
      "Epoch 3 Batch 1087 Loss 1.2353\n",
      "Epoch 3 Batch 1088 Loss 1.4220\n",
      "Epoch 3 Batch 1089 Loss 1.4890\n",
      "Epoch 3 Batch 1090 Loss 1.3959\n",
      "Epoch 3 Batch 1091 Loss 1.4871\n",
      "Epoch 3 Batch 1092 Loss 1.5422\n",
      "Epoch 3 Batch 1093 Loss 1.1383\n",
      "Epoch 3 Batch 1094 Loss 1.4408\n",
      "Epoch 3 Batch 1095 Loss 1.2680\n",
      "Epoch 3 Batch 1096 Loss 1.0965\n",
      "Epoch 3 Batch 1097 Loss 1.4172\n",
      "Epoch 3 Batch 1098 Loss 1.5594\n",
      "Epoch 3 Batch 1099 Loss 1.8000\n",
      "Epoch 3 Batch 1100 Loss 1.2805\n",
      "Epoch 3 Batch 1101 Loss 1.3515\n",
      "Epoch 3 Batch 1102 Loss 1.6864\n",
      "Epoch 3 Batch 1103 Loss 1.2393\n",
      "Epoch 3 Batch 1104 Loss 1.3763\n",
      "Epoch 3 Batch 1105 Loss 1.4524\n",
      "Epoch 3 Batch 1106 Loss 1.4461\n",
      "Epoch 3 Batch 1107 Loss 1.0643\n",
      "Epoch 3 Batch 1108 Loss 1.2765\n",
      "Epoch 3 Batch 1109 Loss 1.3339\n",
      "Epoch 3 Batch 1110 Loss 1.1408\n",
      "Epoch 3 Batch 1111 Loss 0.9484\n",
      "Epoch 3 Batch 1112 Loss 1.0515\n",
      "Epoch 3 Batch 1113 Loss 1.3444\n",
      "Epoch 3 Batch 1114 Loss 1.5189\n",
      "Epoch 3 Batch 1115 Loss 1.2213\n",
      "Epoch 3 Batch 1116 Loss 1.4162\n",
      "Epoch 3 Batch 1117 Loss 1.2389\n",
      "Epoch 3 Batch 1118 Loss 1.2811\n",
      "Epoch 3 Batch 1119 Loss 1.4425\n",
      "Epoch 3 Batch 1120 Loss 1.2599\n",
      "Epoch 3 Batch 1121 Loss 1.4512\n",
      "Epoch 3 Batch 1122 Loss 1.5447\n",
      "Epoch 3 Batch 1123 Loss 1.1989\n",
      "Epoch 3 Batch 1124 Loss 1.4193\n",
      "Epoch 3 Batch 1125 Loss 1.3964\n",
      "Epoch 3 Batch 1126 Loss 1.2512\n",
      "Epoch 3 Batch 1127 Loss 1.3040\n",
      "Epoch 3 Batch 1128 Loss 1.3066\n",
      "Epoch 3 Batch 1129 Loss 1.7081\n",
      "Epoch 3 Batch 1130 Loss 1.4130\n",
      "Epoch 3 Batch 1131 Loss 1.4872\n",
      "Epoch 3 Batch 1132 Loss 1.3807\n",
      "Epoch 3 Batch 1133 Loss 1.3413\n",
      "Epoch 3 Batch 1134 Loss 1.1740\n",
      "Epoch 3 Batch 1135 Loss 1.3136\n",
      "Epoch 3 Batch 1136 Loss 1.3219\n",
      "Epoch 3 Batch 1137 Loss 1.4998\n",
      "Epoch 3 Batch 1138 Loss 1.2673\n",
      "Epoch 3 Batch 1139 Loss 1.2180\n",
      "Epoch 3 Batch 1140 Loss 1.4814\n",
      "Epoch 3 Batch 1141 Loss 1.6228\n",
      "Epoch 3 Batch 1142 Loss 1.4217\n",
      "Epoch 3 Batch 1143 Loss 1.3158\n",
      "Epoch 3 Batch 1144 Loss 1.4193\n",
      "Epoch 3 Batch 1145 Loss 1.2164\n",
      "Epoch 3 Batch 1146 Loss 1.5407\n",
      "Epoch 3 Batch 1147 Loss 1.3256\n",
      "Epoch 3 Batch 1148 Loss 1.4337\n",
      "Epoch 3 Batch 1149 Loss 1.0271\n",
      "Epoch 3 Batch 1150 Loss 1.3553\n",
      "Epoch 3 Batch 1151 Loss 1.5265\n",
      "Epoch 3 Batch 1152 Loss 0.8299\n",
      "Epoch 3 Batch 1153 Loss 1.1390\n",
      "Epoch 3 Batch 1154 Loss 1.6571\n",
      "Epoch 3 Batch 1155 Loss 1.4554\n",
      "Epoch 3 Batch 1156 Loss 1.2754\n",
      "Epoch 3 Batch 1157 Loss 1.2180\n",
      "Epoch 3 Batch 1158 Loss 1.4745\n",
      "Epoch 3 Batch 1159 Loss 1.4155\n",
      "Epoch 3 Batch 1160 Loss 1.5816\n",
      "Epoch 3 Batch 1161 Loss 1.6327\n",
      "Epoch 3 Batch 1162 Loss 1.2824\n",
      "Epoch 3 Batch 1163 Loss 1.1715\n",
      "Epoch 3 Batch 1164 Loss 1.5039\n",
      "Epoch 3 Batch 1165 Loss 1.8094\n",
      "Epoch 3 Batch 1166 Loss 1.2275\n",
      "Epoch 3 Batch 1167 Loss 1.4100\n",
      "Epoch 3 Batch 1168 Loss 1.5407\n",
      "Epoch 3 Batch 1169 Loss 1.2052\n",
      "Epoch 3 Batch 1170 Loss 1.3746\n",
      "Epoch 3 Batch 1171 Loss 1.4517\n",
      "Epoch 3 Batch 1172 Loss 1.5979\n",
      "Epoch 3 Batch 1173 Loss 1.2666\n",
      "Epoch 3 Batch 1174 Loss 1.5682\n",
      "Epoch 3 Batch 1175 Loss 1.3254\n",
      "Epoch 3 Batch 1176 Loss 1.0983\n",
      "Epoch 3 Batch 1177 Loss 1.3333\n",
      "Epoch 3 Batch 1178 Loss 1.0714\n",
      "Epoch 3 Batch 1179 Loss 1.1865\n",
      "Epoch 3 Batch 1180 Loss 1.3826\n",
      "Epoch 3 Batch 1181 Loss 1.3833\n",
      "Epoch 3 Batch 1182 Loss 1.5364\n",
      "Epoch 3 Batch 1183 Loss 1.5565\n",
      "Epoch 3 Batch 1184 Loss 1.2772\n",
      "Epoch 3 Batch 1185 Loss 1.2239\n",
      "Epoch 3 Batch 1186 Loss 1.4977\n",
      "Epoch 3 Batch 1187 Loss 1.2053\n",
      "Epoch 3 Batch 1188 Loss 1.5598\n",
      "Epoch 3 Batch 1189 Loss 1.3616\n",
      "Epoch 3 Batch 1190 Loss 1.3107\n",
      "Epoch 3 Batch 1191 Loss 0.8968\n",
      "Epoch 3 Batch 1192 Loss 1.4421\n",
      "Epoch 3 Batch 1193 Loss 1.1945\n",
      "Epoch 3 Batch 1194 Loss 1.2846\n",
      "Epoch 3 Batch 1195 Loss 1.5744\n",
      "Epoch 3 Batch 1196 Loss 1.1942\n",
      "Epoch 3 Batch 1197 Loss 1.5341\n",
      "Epoch 3 Batch 1198 Loss 1.4273\n",
      "Epoch 3 Batch 1199 Loss 1.0821\n",
      "Epoch 3 Batch 1200 Loss 1.3320\n",
      "Epoch 3 Batch 1201 Loss 1.3544\n",
      "Epoch 3 Batch 1202 Loss 1.5607\n",
      "Epoch 3 Batch 1203 Loss 1.4225\n",
      "Epoch 3 Batch 1204 Loss 1.4525\n",
      "Epoch 3 Batch 1205 Loss 1.2406\n",
      "Epoch 3 Batch 1206 Loss 1.2238\n",
      "Epoch 3 Batch 1207 Loss 1.2556\n",
      "Epoch 3 Batch 1208 Loss 1.5117\n",
      "Epoch 3 Batch 1209 Loss 1.2024\n",
      "Epoch 3 Batch 1210 Loss 1.2119\n",
      "Epoch 3 Batch 1211 Loss 1.4607\n",
      "Epoch 3 Batch 1212 Loss 1.2253\n",
      "Epoch 3 Batch 1213 Loss 1.3751\n",
      "Epoch 3 Batch 1214 Loss 1.0569\n",
      "Epoch 3 Batch 1215 Loss 1.3798\n",
      "Epoch 3 Batch 1216 Loss 1.0321\n",
      "Epoch 3 Batch 1217 Loss 1.3248\n",
      "Epoch 3 Batch 1218 Loss 1.3837\n",
      "Epoch 3 Batch 1219 Loss 1.4298\n",
      "Epoch 3 Batch 1220 Loss 1.3006\n",
      "Epoch 3 Batch 1221 Loss 1.2950\n",
      "Epoch 3 Batch 1222 Loss 1.2332\n",
      "Epoch 3 Batch 1223 Loss 1.2794\n",
      "Epoch 3 Batch 1224 Loss 1.5311\n",
      "Epoch 3 Batch 1225 Loss 1.3682\n",
      "Epoch 3 Batch 1226 Loss 1.3617\n",
      "Epoch 3 Batch 1227 Loss 1.3237\n",
      "Epoch 3 Batch 1228 Loss 1.2340\n",
      "Epoch 3 Batch 1229 Loss 1.3551\n",
      "Epoch 3 Batch 1230 Loss 1.0222\n",
      "Epoch 3 Batch 1231 Loss 1.2680\n",
      "Epoch 3 Batch 1232 Loss 1.4229\n",
      "Epoch 3 Batch 1233 Loss 1.5620\n",
      "Epoch 3 Batch 1234 Loss 1.4656\n",
      "Epoch 3 Batch 1235 Loss 1.4390\n",
      "Epoch 3 Batch 1236 Loss 1.4840\n",
      "Epoch 3 Batch 1237 Loss 1.3657\n",
      "Epoch 3 Batch 1238 Loss 1.4043\n",
      "Epoch 3 Batch 1239 Loss 1.5602\n",
      "Epoch 3 Batch 1240 Loss 0.9770\n",
      "Epoch 3 Batch 1241 Loss 1.3121\n",
      "Epoch 3 Batch 1242 Loss 1.3990\n",
      "Epoch 3 Batch 1243 Loss 1.3133\n",
      "Epoch 3 Batch 1244 Loss 1.2040\n",
      "Epoch 3 Batch 1245 Loss 1.1260\n",
      "Epoch 3 Batch 1246 Loss 1.2506\n",
      "Epoch 3 Batch 1247 Loss 1.3776\n",
      "Epoch 3 Batch 1248 Loss 1.3648\n",
      "Epoch 3 Batch 1249 Loss 1.3960\n",
      "Epoch 3 Batch 1250 Loss 1.3210\n",
      "Epoch 3 Batch 1251 Loss 1.2561\n",
      "Epoch 3 Batch 1252 Loss 1.1754\n",
      "Epoch 3 Batch 1253 Loss 1.3141\n",
      "Epoch 3 Batch 1254 Loss 1.3080\n",
      "Epoch 3 Batch 1255 Loss 1.2912\n",
      "Epoch 3 Batch 1256 Loss 1.6920\n",
      "Epoch 3 Batch 1257 Loss 1.3855\n",
      "Epoch 3 Batch 1258 Loss 1.1227\n",
      "Epoch 3 Batch 1259 Loss 1.1905\n",
      "Epoch 3 Batch 1260 Loss 1.2478\n",
      "Epoch 3 Batch 1261 Loss 1.2436\n",
      "Epoch 3 Batch 1262 Loss 1.2033\n",
      "Epoch 3 Batch 1263 Loss 1.5637\n",
      "Epoch 3 Batch 1264 Loss 1.3185\n",
      "Epoch 3 Batch 1265 Loss 1.5625\n",
      "Epoch 3 Batch 1266 Loss 1.1022\n",
      "Epoch 3 Batch 1267 Loss 1.3011\n",
      "Epoch 3 Batch 1268 Loss 1.2836\n",
      "Epoch 3 Batch 1269 Loss 1.4352\n",
      "Epoch 3 Batch 1270 Loss 1.1413\n",
      "Epoch 3 Batch 1271 Loss 1.4966\n",
      "Epoch 3 Batch 1272 Loss 0.9038\n",
      "Epoch 3 Batch 1273 Loss 1.3295\n",
      "Epoch 3 Batch 1274 Loss 1.3196\n",
      "Epoch 3 Batch 1275 Loss 1.1586\n",
      "Epoch 3 Batch 1276 Loss 1.3407\n",
      "Epoch 3 Batch 1277 Loss 1.3258\n",
      "Epoch 3 Batch 1278 Loss 1.4556\n",
      "Epoch 3 Batch 1279 Loss 1.1772\n",
      "Epoch 3 Batch 1280 Loss 1.4607\n",
      "Epoch 3 Batch 1281 Loss 1.2922\n",
      "Epoch 3 Batch 1282 Loss 1.5217\n",
      "Epoch 3 Batch 1283 Loss 1.4040\n",
      "Epoch 3 Batch 1284 Loss 1.2953\n",
      "Epoch 3 Batch 1285 Loss 1.4788\n",
      "Epoch 3 Batch 1286 Loss 1.1734\n",
      "Epoch 3 Batch 1287 Loss 1.6592\n",
      "Epoch 3 Batch 1288 Loss 1.3724\n",
      "Epoch 3 Batch 1289 Loss 1.6302\n",
      "Epoch 3 Batch 1290 Loss 1.9582\n",
      "Epoch 3 Batch 1291 Loss 1.0689\n",
      "Epoch 3 Batch 1292 Loss 1.3087\n",
      "Epoch 3 Batch 1293 Loss 1.4473\n",
      "Epoch 3 Batch 1294 Loss 1.4845\n",
      "Epoch 3 Batch 1295 Loss 1.4801\n",
      "Epoch 3 Batch 1296 Loss 1.3273\n",
      "Epoch 3 Batch 1297 Loss 1.3188\n",
      "Epoch 3 Batch 1298 Loss 1.2633\n",
      "Epoch 3 Batch 1299 Loss 1.3724\n",
      "Epoch 3 Batch 1300 Loss 1.3269\n",
      "Epoch 3 Batch 1301 Loss 1.3069\n",
      "Epoch 3 Batch 1302 Loss 1.3221\n",
      "Epoch 3 Batch 1303 Loss 1.4898\n",
      "Epoch 3 Batch 1304 Loss 1.4245\n",
      "Epoch 3 Batch 1305 Loss 1.4234\n",
      "Epoch 3 Batch 1306 Loss 1.3233\n",
      "Epoch 3 Batch 1307 Loss 1.2065\n",
      "Epoch 3 Batch 1308 Loss 1.3953\n",
      "Epoch 3 Batch 1309 Loss 1.3957\n",
      "Epoch 3 Batch 1310 Loss 1.4332\n",
      "Epoch 3 Batch 1311 Loss 1.4454\n",
      "Epoch 3 Batch 1312 Loss 1.4167\n",
      "Epoch 3 Batch 1313 Loss 1.1573\n",
      "Epoch 3 Batch 1314 Loss 1.2788\n",
      "Epoch 3 Batch 1315 Loss 1.3925\n",
      "Epoch 3 Batch 1316 Loss 1.1021\n",
      "Epoch 3 Batch 1317 Loss 1.2135\n",
      "Epoch 3 Batch 1318 Loss 1.4305\n",
      "Epoch 3 Batch 1319 Loss 1.2923\n",
      "Epoch 3 Batch 1320 Loss 1.3540\n",
      "Epoch 3 Batch 1321 Loss 1.3579\n",
      "Epoch 3 Batch 1322 Loss 1.1330\n",
      "Epoch 3 Batch 1323 Loss 1.4937\n",
      "Epoch 3 Batch 1324 Loss 1.0581\n",
      "Epoch 3 Batch 1325 Loss 1.3593\n",
      "Epoch 3 Batch 1326 Loss 1.2617\n",
      "Epoch 3 Batch 1327 Loss 1.4477\n",
      "Epoch 3 Batch 1328 Loss 1.6321\n",
      "Epoch 3 Batch 1329 Loss 1.3409\n",
      "Epoch 3 Batch 1330 Loss 1.4106\n",
      "Epoch 3 Batch 1331 Loss 1.2407\n",
      "Epoch 3 Batch 1332 Loss 1.1869\n",
      "Epoch 3 Batch 1333 Loss 1.3905\n",
      "Epoch 3 Batch 1334 Loss 1.3066\n",
      "Epoch 3 Batch 1335 Loss 1.3060\n",
      "Epoch 3 Batch 1336 Loss 1.2621\n",
      "Epoch 3 Batch 1337 Loss 1.2858\n",
      "Epoch 3 Batch 1338 Loss 1.3492\n",
      "Epoch 3 Batch 1339 Loss 1.4734\n",
      "Epoch 3 Batch 1340 Loss 1.2605\n",
      "Epoch 3 Batch 1341 Loss 1.0079\n",
      "Epoch 3 Batch 1342 Loss 1.1477\n",
      "Epoch 3 Batch 1343 Loss 1.1223\n",
      "Epoch 3 Batch 1344 Loss 1.4887\n",
      "Epoch 3 Batch 1345 Loss 1.4424\n",
      "Epoch 3 Batch 1346 Loss 1.4151\n",
      "Epoch 3 Batch 1347 Loss 1.3616\n",
      "Epoch 3 Batch 1348 Loss 1.4549\n",
      "Epoch 3 Batch 1349 Loss 1.2555\n",
      "Epoch 3 Batch 1350 Loss 1.2899\n",
      "Epoch 3 Batch 1351 Loss 1.4470\n",
      "Epoch 3 Batch 1352 Loss 1.3077\n",
      "Epoch 3 Batch 1353 Loss 1.1239\n",
      "Epoch 3 Batch 1354 Loss 1.3940\n",
      "Epoch 3 Batch 1355 Loss 1.2030\n",
      "Epoch 3 Batch 1356 Loss 1.2992\n",
      "Epoch 3 Batch 1357 Loss 1.5152\n",
      "Epoch 3 Batch 1358 Loss 1.3571\n",
      "Epoch 3 Batch 1359 Loss 1.5296\n",
      "Epoch 3 Batch 1360 Loss 1.5148\n",
      "Epoch 3 Batch 1361 Loss 1.3055\n",
      "Epoch 3 Batch 1362 Loss 1.3787\n",
      "Epoch 3 Batch 1363 Loss 1.7456\n",
      "Epoch 3 Batch 1364 Loss 1.3087\n",
      "Epoch 3 Batch 1365 Loss 1.1940\n",
      "Epoch 3 Batch 1366 Loss 1.4804\n",
      "Epoch 3 Batch 1367 Loss 1.1609\n",
      "Epoch 3 Batch 1368 Loss 1.5550\n",
      "Epoch 3 Batch 1369 Loss 1.3599\n",
      "Epoch 3 Batch 1370 Loss 1.2986\n",
      "Epoch 3 Batch 1371 Loss 1.2349\n",
      "Epoch 3 Batch 1372 Loss 1.3413\n",
      "Epoch 3 Batch 1373 Loss 1.1149\n",
      "Epoch 3 Batch 1374 Loss 1.3492\n",
      "Epoch 3 Batch 1375 Loss 1.4061\n",
      "Epoch 3 Batch 1376 Loss 1.4757\n",
      "Epoch 3 Batch 1377 Loss 1.3284\n",
      "Epoch 3 Batch 1378 Loss 1.2516\n",
      "Epoch 3 Batch 1379 Loss 1.1740\n",
      "Epoch 3 Batch 1380 Loss 1.0558\n",
      "Epoch 3 Batch 1381 Loss 1.6218\n",
      "Epoch 3 Batch 1382 Loss 1.6231\n",
      "Epoch 3 Batch 1383 Loss 1.2925\n",
      "Epoch 3 Batch 1384 Loss 1.4089\n",
      "Epoch 3 Batch 1385 Loss 1.5564\n",
      "Epoch 3 Batch 1386 Loss 1.3328\n",
      "Epoch 3 Batch 1387 Loss 1.4620\n",
      "Epoch 3 Batch 1388 Loss 1.3564\n",
      "Epoch 3 Batch 1389 Loss 1.4928\n",
      "Epoch 3 Batch 1390 Loss 1.0392\n",
      "Epoch 3 Batch 1391 Loss 1.3059\n",
      "Epoch 3 Batch 1392 Loss 1.2218\n",
      "Epoch 3 Batch 1393 Loss 1.5072\n",
      "Epoch 3 Batch 1394 Loss 1.2777\n",
      "Epoch 3 Batch 1395 Loss 1.3162\n",
      "Epoch 3 Batch 1396 Loss 1.1327\n",
      "Epoch 3 Batch 1397 Loss 1.1459\n",
      "Epoch 3 Batch 1398 Loss 1.1480\n",
      "Epoch 3 Batch 1399 Loss 1.2756\n",
      "Epoch 3 Batch 1400 Loss 1.2927\n",
      "Epoch 3 Batch 1401 Loss 1.3894\n",
      "Epoch 3 Batch 1402 Loss 1.2749\n",
      "Epoch 3 Batch 1403 Loss 1.2544\n",
      "Epoch 3 Batch 1404 Loss 1.4756\n",
      "Epoch 3 Batch 1405 Loss 1.5168\n",
      "Epoch 3 Batch 1406 Loss 1.3394\n",
      "Epoch 3 Batch 1407 Loss 1.2837\n",
      "Epoch 3 Batch 1408 Loss 1.1872\n",
      "Epoch 3 Batch 1409 Loss 1.4003\n",
      "Epoch 3 Batch 1410 Loss 1.2585\n",
      "Epoch 3 Batch 1411 Loss 1.2646\n",
      "Epoch 3 Batch 1412 Loss 1.3550\n",
      "Epoch 3 Batch 1413 Loss 1.5153\n",
      "Epoch 3 Batch 1414 Loss 1.2290\n",
      "Epoch 3 Batch 1415 Loss 1.4533\n",
      "Epoch 3 Batch 1416 Loss 1.2355\n",
      "Epoch 3 Batch 1417 Loss 1.3484\n",
      "Epoch 3 Batch 1418 Loss 1.4027\n",
      "Epoch 3 Batch 1419 Loss 1.0662\n",
      "Epoch 3 Batch 1420 Loss 1.5096\n",
      "Epoch 3 Batch 1421 Loss 1.5191\n",
      "Epoch 3 Batch 1422 Loss 1.1010\n",
      "Epoch 3 Batch 1423 Loss 1.1636\n",
      "Epoch 3 Batch 1424 Loss 1.5958\n",
      "Epoch 3 Batch 1425 Loss 1.3139\n",
      "Epoch 3 Batch 1426 Loss 1.3588\n",
      "Epoch 3 Batch 1427 Loss 1.1621\n",
      "Epoch 3 Batch 1428 Loss 1.4598\n",
      "Epoch 3 Batch 1429 Loss 1.1343\n",
      "Epoch 3 Batch 1430 Loss 1.1567\n",
      "Epoch 3 Batch 1431 Loss 1.0065\n",
      "Epoch 3 Batch 1432 Loss 1.6270\n",
      "Epoch 3 Batch 1433 Loss 1.4740\n",
      "Epoch 3 Batch 1434 Loss 1.6240\n",
      "Epoch 3 Batch 1435 Loss 1.3270\n",
      "Epoch 3 Batch 1436 Loss 1.6058\n",
      "Epoch 3 Batch 1437 Loss 1.3177\n",
      "Epoch 3 Batch 1438 Loss 1.4928\n",
      "Epoch 3 Batch 1439 Loss 1.3046\n",
      "Epoch 3 Batch 1440 Loss 1.5504\n",
      "Epoch 3 Batch 1441 Loss 1.1423\n",
      "Epoch 3 Batch 1442 Loss 1.2165\n",
      "Epoch 3 Batch 1443 Loss 1.1696\n",
      "Epoch 3 Batch 1444 Loss 1.3340\n",
      "Epoch 3 Batch 1445 Loss 1.1282\n",
      "Epoch 3 Batch 1446 Loss 1.2950\n",
      "Epoch 3 Batch 1447 Loss 1.1983\n",
      "Epoch 3 Batch 1448 Loss 1.0926\n",
      "Epoch 3 Batch 1449 Loss 1.4989\n",
      "Epoch 3 Batch 1450 Loss 1.3727\n",
      "Epoch 3 Batch 1451 Loss 1.4572\n",
      "Epoch 3 Batch 1452 Loss 1.2359\n",
      "Epoch 3 Batch 1453 Loss 1.5212\n",
      "Epoch 3 Batch 1454 Loss 1.2440\n",
      "Epoch 3 Batch 1455 Loss 1.3026\n",
      "Epoch 3 Batch 1456 Loss 1.5118\n",
      "Epoch 3 Batch 1457 Loss 1.3999\n",
      "Epoch 3 Batch 1458 Loss 1.0938\n",
      "Epoch 3 Batch 1459 Loss 1.4749\n",
      "Epoch 3 Batch 1460 Loss 1.2699\n",
      "Epoch 3 Batch 1461 Loss 1.3011\n",
      "Epoch 3 Batch 1462 Loss 1.5126\n",
      "Epoch 3 Batch 1463 Loss 1.3760\n",
      "Epoch 3 Batch 1464 Loss 1.6853\n",
      "Epoch 3 Batch 1465 Loss 1.1818\n",
      "Epoch 3 Batch 1466 Loss 1.4418\n",
      "Epoch 3 Batch 1467 Loss 1.3764\n",
      "Epoch 3 Batch 1468 Loss 1.3587\n",
      "Epoch 3 Batch 1469 Loss 1.5353\n",
      "Epoch 3 Batch 1470 Loss 1.3712\n",
      "Epoch 3 Batch 1471 Loss 1.3466\n",
      "Epoch 3 Batch 1472 Loss 1.5761\n",
      "Epoch 3 Batch 1473 Loss 1.4642\n",
      "Epoch 3 Batch 1474 Loss 1.2713\n",
      "Epoch 3 Batch 1475 Loss 1.2256\n",
      "Epoch 3 Batch 1476 Loss 1.5608\n",
      "Epoch 3 Batch 1477 Loss 1.5205\n",
      "Epoch 3 Batch 1478 Loss 1.2920\n",
      "Epoch 3 Batch 1479 Loss 1.5201\n",
      "Epoch 3 Batch 1480 Loss 1.2182\n",
      "Epoch 3 Batch 1481 Loss 1.3638\n",
      "Epoch 3 Batch 1482 Loss 1.2429\n",
      "Epoch 3 Batch 1483 Loss 1.3348\n",
      "Epoch 3 Batch 1484 Loss 1.3080\n",
      "Epoch 3 Batch 1485 Loss 1.7800\n",
      "Epoch 3 Batch 1486 Loss 1.1791\n",
      "Epoch 3 Batch 1487 Loss 1.4596\n",
      "Epoch 3 Batch 1488 Loss 1.4102\n",
      "Epoch 3 Batch 1489 Loss 1.1656\n",
      "Epoch 3 Batch 1490 Loss 1.2931\n",
      "Epoch 3 Batch 1491 Loss 1.1629\n",
      "Epoch 3 Batch 1492 Loss 1.4589\n",
      "Epoch 3 Batch 1493 Loss 1.0812\n",
      "Epoch 3 Batch 1494 Loss 1.1897\n",
      "Epoch 3 Batch 1495 Loss 1.3661\n",
      "Epoch 3 Batch 1496 Loss 1.1437\n",
      "Epoch 3 Batch 1497 Loss 1.6314\n",
      "Epoch 3 Batch 1498 Loss 1.5656\n",
      "Epoch 3 Batch 1499 Loss 1.3260\n",
      "Epoch 3 Batch 1500 Loss 1.1635\n",
      "Epoch 3 Batch 1501 Loss 1.3205\n",
      "Epoch 3 Batch 1502 Loss 1.2429\n",
      "Epoch 3 Batch 1503 Loss 1.5361\n",
      "Epoch 3 Batch 1504 Loss 0.9857\n",
      "Epoch 3 Batch 1505 Loss 1.0643\n",
      "Epoch 3 Batch 1506 Loss 1.3653\n",
      "Epoch 3 Batch 1507 Loss 1.5120\n",
      "Epoch 3 Batch 1508 Loss 1.4406\n",
      "Epoch 3 Batch 1509 Loss 1.4816\n",
      "Epoch 3 Batch 1510 Loss 1.2613\n",
      "Epoch 3 Batch 1511 Loss 1.5949\n",
      "Epoch 3 Batch 1512 Loss 0.9582\n",
      "Epoch 3 Batch 1513 Loss 1.2205\n",
      "Epoch 3 Batch 1514 Loss 1.4071\n",
      "Epoch 3 Batch 1515 Loss 1.2644\n",
      "Epoch 3 Batch 1516 Loss 1.2884\n",
      "Epoch 3 Batch 1517 Loss 1.3221\n",
      "Epoch 3 Batch 1518 Loss 1.1257\n",
      "Epoch 3 Batch 1519 Loss 1.1846\n",
      "Epoch 3 Batch 1520 Loss 1.0211\n",
      "Epoch 3 Batch 1521 Loss 1.3099\n",
      "Epoch 3 Batch 1522 Loss 1.6461\n",
      "Epoch 3 Batch 1523 Loss 1.1847\n",
      "Epoch 3 Batch 1524 Loss 1.2609\n",
      "Epoch 3 Batch 1525 Loss 1.3479\n",
      "Epoch 3 Batch 1526 Loss 1.3946\n",
      "Epoch 3 Batch 1527 Loss 1.3618\n",
      "Epoch 3 Batch 1528 Loss 1.6320\n",
      "Epoch 3 Batch 1529 Loss 1.4788\n",
      "Epoch 3 Batch 1530 Loss 1.3737\n",
      "Epoch 3 Batch 1531 Loss 1.2160\n",
      "Epoch 3 Batch 1532 Loss 1.4598\n",
      "Epoch 3 Batch 1533 Loss 1.2384\n",
      "Epoch 3 Batch 1534 Loss 1.5307\n",
      "Epoch 3 Batch 1535 Loss 1.4671\n",
      "Epoch 3 Batch 1536 Loss 1.3734\n",
      "Epoch 3 Batch 1537 Loss 1.7184\n",
      "Epoch 3 Batch 1538 Loss 1.1824\n",
      "Epoch 3 Batch 1539 Loss 1.2001\n",
      "Epoch 3 Batch 1540 Loss 1.2458\n",
      "Epoch 3 Batch 1541 Loss 1.4481\n",
      "Epoch 3 Batch 1542 Loss 1.6280\n",
      "Epoch 3 Batch 1543 Loss 1.2090\n",
      "Epoch 3 Batch 1544 Loss 1.2846\n",
      "Epoch 3 Batch 1545 Loss 1.1896\n",
      "Epoch 3 Batch 1546 Loss 1.1667\n",
      "Epoch 3 Batch 1547 Loss 1.3217\n",
      "Epoch 3 Batch 1548 Loss 1.3031\n",
      "Epoch 3 Batch 1549 Loss 1.2632\n",
      "Epoch 3 Batch 1550 Loss 1.4805\n",
      "Epoch 3 Batch 1551 Loss 1.2951\n",
      "Epoch 3 Batch 1552 Loss 1.4294\n",
      "Epoch 3 Batch 1553 Loss 1.5987\n",
      "Epoch 3 Batch 1554 Loss 1.3902\n",
      "Epoch 3 Batch 1555 Loss 1.4316\n",
      "Epoch 3 Batch 1556 Loss 1.4964\n",
      "Epoch 3 Batch 1557 Loss 1.2012\n",
      "Epoch 3 Batch 1558 Loss 1.2168\n",
      "Epoch 3 Batch 1559 Loss 1.5139\n",
      "Epoch 3 Batch 1560 Loss 1.2160\n",
      "Epoch 3 Batch 1561 Loss 1.4536\n",
      "Epoch 3 Batch 1562 Loss 1.3674\n",
      "Epoch 3 Batch 1563 Loss 1.2369\n",
      "Epoch 3 Batch 1564 Loss 1.3097\n",
      "Epoch 3 Batch 1565 Loss 1.2298\n",
      "Epoch 3 Batch 1566 Loss 1.0152\n",
      "Epoch 3 Batch 1567 Loss 1.5162\n",
      "Epoch 3 Batch 1568 Loss 1.3773\n",
      "Epoch 3 Batch 1569 Loss 1.3777\n",
      "Epoch 3 Batch 1570 Loss 1.0804\n",
      "Epoch 3 Batch 1571 Loss 1.0433\n",
      "Epoch 3 Batch 1572 Loss 1.1744\n",
      "Epoch 3 Batch 1573 Loss 1.2214\n",
      "Epoch 3 Batch 1574 Loss 1.5235\n",
      "Epoch 3 Batch 1575 Loss 1.2102\n",
      "Epoch 3 Batch 1576 Loss 1.3534\n",
      "Epoch 3 Batch 1577 Loss 1.3909\n",
      "Epoch 3 Batch 1578 Loss 1.4085\n",
      "Epoch 3 Batch 1579 Loss 0.9941\n",
      "Epoch 3 Batch 1580 Loss 1.3110\n",
      "Epoch 3 Batch 1581 Loss 1.6125\n",
      "Epoch 3 Batch 1582 Loss 1.0551\n",
      "Epoch 3 Batch 1583 Loss 1.1266\n",
      "Epoch 3 Batch 1584 Loss 1.4068\n",
      "Epoch 3 Batch 1585 Loss 1.2222\n",
      "Epoch 3 Batch 1586 Loss 1.1346\n",
      "Epoch 3 Batch 1587 Loss 1.2813\n",
      "Epoch 3 Batch 1588 Loss 1.3690\n",
      "Epoch 3 Batch 1589 Loss 0.9209\n",
      "Epoch 3 Batch 1590 Loss 1.3310\n",
      "Epoch 3 Batch 1591 Loss 1.3897\n",
      "Epoch 3 Batch 1592 Loss 1.1657\n",
      "Epoch 3 Batch 1593 Loss 1.3298\n",
      "Epoch 3 Batch 1594 Loss 1.5721\n",
      "Epoch 3 Batch 1595 Loss 1.3146\n",
      "Epoch 3 Batch 1596 Loss 1.4316\n",
      "Epoch 3 Batch 1597 Loss 1.2728\n",
      "Epoch 3 Batch 1598 Loss 1.5349\n",
      "Epoch 3 Batch 1599 Loss 1.1137\n",
      "Epoch 3 Batch 1600 Loss 1.2857\n",
      "Epoch 3 Batch 1601 Loss 1.0115\n",
      "Epoch 3 Batch 1602 Loss 1.2161\n",
      "Epoch 3 Batch 1603 Loss 1.2081\n",
      "Epoch 3 Batch 1604 Loss 1.3639\n",
      "Epoch 3 Batch 1605 Loss 1.2827\n",
      "Epoch 3 Batch 1606 Loss 1.1901\n",
      "Epoch 3 Batch 1607 Loss 1.4730\n",
      "Epoch 3 Batch 1608 Loss 1.4603\n",
      "Epoch 3 Batch 1609 Loss 1.1525\n",
      "Epoch 3 Batch 1610 Loss 1.0671\n",
      "Epoch 3 Batch 1611 Loss 1.2859\n",
      "Epoch 3 Batch 1612 Loss 1.3018\n",
      "Epoch 3 Batch 1613 Loss 1.2042\n",
      "Epoch 3 Batch 1614 Loss 1.3845\n",
      "Epoch 3 Batch 1615 Loss 1.4047\n",
      "Epoch 3 Batch 1616 Loss 1.0812\n",
      "Epoch 3 Batch 1617 Loss 1.3561\n",
      "Epoch 3 Batch 1618 Loss 1.3657\n",
      "Epoch 3 Batch 1619 Loss 1.5521\n",
      "Epoch 3 Batch 1620 Loss 1.6388\n",
      "Epoch 3 Batch 1621 Loss 1.3370\n",
      "Epoch 3 Batch 1622 Loss 1.1407\n",
      "Epoch 3 Batch 1623 Loss 1.0479\n",
      "Epoch 3 Batch 1624 Loss 1.3260\n",
      "Epoch 3 Batch 1625 Loss 1.0451\n",
      "Epoch 3 Batch 1626 Loss 1.4926\n",
      "Epoch 3 Batch 1627 Loss 1.1154\n",
      "Epoch 3 Batch 1628 Loss 1.0801\n",
      "Epoch 3 Batch 1629 Loss 1.4253\n",
      "Epoch 3 Batch 1630 Loss 1.4537\n",
      "Epoch 3 Batch 1631 Loss 1.2101\n",
      "Epoch 3 Batch 1632 Loss 1.2598\n",
      "Epoch 3 Batch 1633 Loss 1.3338\n",
      "Epoch 3 Batch 1634 Loss 1.4250\n",
      "Epoch 3 Batch 1635 Loss 1.7569\n",
      "Epoch 3 Batch 1636 Loss 1.7657\n",
      "Epoch 3 Batch 1637 Loss 1.1563\n",
      "Epoch 3 Batch 1638 Loss 1.2903\n",
      "Epoch 3 Batch 1639 Loss 1.2713\n",
      "Epoch 3 Batch 1640 Loss 1.1744\n",
      "Epoch 3 Batch 1641 Loss 1.4932\n",
      "Epoch 3 Batch 1642 Loss 1.8178\n",
      "Epoch 3 Batch 1643 Loss 1.1783\n",
      "Epoch 3 Batch 1644 Loss 1.4974\n",
      "Epoch 3 Batch 1645 Loss 1.4258\n",
      "Epoch 3 Batch 1646 Loss 1.1771\n",
      "Epoch 3 Batch 1647 Loss 1.2882\n",
      "Epoch 3 Batch 1648 Loss 1.7205\n",
      "Epoch 3 Batch 1649 Loss 1.5350\n",
      "Epoch 3 Batch 1650 Loss 1.1904\n",
      "Epoch 3 Batch 1651 Loss 1.2310\n",
      "Epoch 3 Batch 1652 Loss 1.3336\n",
      "Epoch 3 Batch 1653 Loss 1.4912\n",
      "Epoch 3 Batch 1654 Loss 1.2779\n",
      "Epoch 3 Batch 1655 Loss 1.3072\n",
      "Epoch 3 Batch 1656 Loss 1.2825\n",
      "Epoch 3 Batch 1657 Loss 1.2022\n",
      "Epoch 3 Batch 1658 Loss 1.5289\n",
      "Epoch 3 Batch 1659 Loss 1.5500\n",
      "Epoch 3 Batch 1660 Loss 1.1254\n",
      "Epoch 3 Batch 1661 Loss 1.3990\n",
      "Epoch 3 Batch 1662 Loss 1.0572\n",
      "Epoch 3 Batch 1663 Loss 1.3883\n",
      "Epoch 3 Batch 1664 Loss 1.3653\n",
      "Epoch 3 Batch 1665 Loss 1.2742\n",
      "Epoch 3 Batch 1666 Loss 1.5475\n",
      "Epoch 3 Batch 1667 Loss 1.5014\n",
      "Epoch 3 Batch 1668 Loss 1.0060\n",
      "Epoch 3 Batch 1669 Loss 1.0483\n",
      "Epoch 3 Batch 1670 Loss 1.2829\n",
      "Epoch 3 Batch 1671 Loss 1.0802\n",
      "Epoch 3 Batch 1672 Loss 1.5992\n",
      "Epoch 3 Batch 1673 Loss 1.4196\n",
      "Epoch 3 Batch 1674 Loss 1.2758\n",
      "Epoch 3 Batch 1675 Loss 1.2185\n",
      "Epoch 3 Batch 1676 Loss 1.2791\n",
      "Epoch 3 Batch 1677 Loss 1.2787\n",
      "Epoch 3 Batch 1678 Loss 1.3660\n",
      "Epoch 3 Batch 1679 Loss 1.3727\n",
      "Epoch 3 Batch 1680 Loss 1.2721\n",
      "Epoch 3 Batch 1681 Loss 1.5039\n",
      "Epoch 3 Batch 1682 Loss 1.4106\n",
      "Epoch 3 Batch 1683 Loss 1.2623\n",
      "Epoch 3 Batch 1684 Loss 1.2874\n",
      "Epoch 3 Batch 1685 Loss 1.5845\n",
      "Epoch 3 Batch 1686 Loss 1.3065\n",
      "Epoch 3 Batch 1687 Loss 1.1808\n",
      "Epoch 3 Batch 1688 Loss 1.1987\n",
      "Epoch 3 Batch 1689 Loss 1.6118\n",
      "Epoch 3 Batch 1690 Loss 0.9598\n",
      "Epoch 3 Batch 1691 Loss 1.5486\n",
      "Epoch 3 Batch 1692 Loss 1.4254\n",
      "Epoch 3 Batch 1693 Loss 1.4732\n",
      "Epoch 3 Batch 1694 Loss 1.1792\n",
      "Epoch 3 Batch 1695 Loss 1.0641\n",
      "Epoch 3 Batch 1696 Loss 1.5944\n",
      "Epoch 3 Batch 1697 Loss 1.5078\n",
      "Epoch 3 Batch 1698 Loss 1.3816\n",
      "Epoch 3 Batch 1699 Loss 1.5493\n",
      "Epoch 3 Batch 1700 Loss 1.3729\n",
      "Epoch 3 Batch 1701 Loss 1.1277\n",
      "Epoch 3 Batch 1702 Loss 1.0869\n",
      "Epoch 3 Batch 1703 Loss 1.2103\n",
      "Epoch 3 Batch 1704 Loss 1.0583\n",
      "Epoch 3 Batch 1705 Loss 1.7344\n",
      "Epoch 3 Batch 1706 Loss 1.1791\n",
      "Epoch 3 Batch 1707 Loss 1.4258\n",
      "Epoch 3 Batch 1708 Loss 1.4938\n",
      "Epoch 3 Batch 1709 Loss 1.2518\n",
      "Epoch 3 Batch 1710 Loss 1.5495\n",
      "Epoch 3 Batch 1711 Loss 1.4153\n",
      "Epoch 3 Batch 1712 Loss 1.3603\n",
      "Epoch 3 Batch 1713 Loss 1.3217\n",
      "Epoch 3 Batch 1714 Loss 1.3832\n",
      "Epoch 3 Batch 1715 Loss 1.5730\n",
      "Epoch 3 Batch 1716 Loss 1.3615\n",
      "Epoch 3 Batch 1717 Loss 1.1638\n",
      "Epoch 3 Batch 1718 Loss 1.2944\n",
      "Epoch 3 Batch 1719 Loss 1.1190\n",
      "Epoch 3 Batch 1720 Loss 1.1838\n",
      "Epoch 3 Batch 1721 Loss 1.0869\n",
      "Epoch 3 Batch 1722 Loss 1.4201\n",
      "Epoch 3 Batch 1723 Loss 1.0440\n",
      "Epoch 3 Batch 1724 Loss 1.7601\n",
      "Epoch 3 Batch 1725 Loss 1.4625\n",
      "Epoch 3 Batch 1726 Loss 1.5677\n",
      "Epoch 3 Batch 1727 Loss 1.5230\n",
      "Epoch 3 Batch 1728 Loss 1.1151\n",
      "Epoch 3 Batch 1729 Loss 1.2926\n",
      "Epoch 3 Batch 1730 Loss 1.1103\n",
      "Epoch 3 Batch 1731 Loss 1.1907\n",
      "Epoch 3 Batch 1732 Loss 1.2643\n",
      "Epoch 3 Batch 1733 Loss 1.6197\n",
      "Epoch 3 Batch 1734 Loss 1.2293\n",
      "Epoch 3 Batch 1735 Loss 1.0445\n",
      "Epoch 3 Batch 1736 Loss 1.2831\n",
      "Epoch 3 Batch 1737 Loss 0.9183\n",
      "Epoch 3 Batch 1738 Loss 1.2835\n",
      "Epoch 3 Batch 1739 Loss 1.3176\n",
      "Epoch 3 Batch 1740 Loss 1.0704\n",
      "Epoch 3 Batch 1741 Loss 1.3065\n",
      "Epoch 3 Batch 1742 Loss 1.1367\n",
      "Epoch 3 Batch 1743 Loss 1.5344\n",
      "Epoch 3 Batch 1744 Loss 1.1008\n",
      "Epoch 3 Batch 1745 Loss 1.1743\n",
      "Epoch 3 Batch 1746 Loss 1.3100\n",
      "Epoch 3 Batch 1747 Loss 1.4176\n",
      "Epoch 3 Batch 1748 Loss 1.2001\n",
      "Epoch 3 Batch 1749 Loss 1.3366\n",
      "Epoch 3 Batch 1750 Loss 1.4532\n",
      "Epoch 3 Batch 1751 Loss 1.2597\n",
      "Epoch 3 Batch 1752 Loss 1.2827\n",
      "Epoch 3 Batch 1753 Loss 1.1602\n",
      "Epoch 3 Batch 1754 Loss 1.6043\n",
      "Epoch 3 Batch 1755 Loss 1.4030\n",
      "Epoch 3 Batch 1756 Loss 1.3523\n",
      "Epoch 3 Batch 1757 Loss 1.2936\n",
      "Epoch 3 Batch 1758 Loss 1.4793\n",
      "Epoch 3 Batch 1759 Loss 1.3096\n",
      "Epoch 3 Batch 1760 Loss 1.2895\n",
      "Epoch 3 Batch 1761 Loss 1.5279\n",
      "Epoch 3 Batch 1762 Loss 1.0093\n",
      "Epoch 3 Batch 1763 Loss 1.2278\n",
      "Epoch 3 Batch 1764 Loss 1.4341\n",
      "Epoch 3 Batch 1765 Loss 1.4106\n",
      "Epoch 3 Batch 1766 Loss 1.3089\n",
      "Epoch 3 Batch 1767 Loss 1.4688\n",
      "Epoch 3 Batch 1768 Loss 1.3080\n",
      "Epoch 3 Batch 1769 Loss 1.5739\n",
      "Epoch 3 Batch 1770 Loss 1.4307\n",
      "Epoch 3 Batch 1771 Loss 1.3250\n",
      "Epoch 3 Batch 1772 Loss 1.3578\n",
      "Epoch 3 Batch 1773 Loss 1.2387\n",
      "Epoch 3 Batch 1774 Loss 1.2868\n",
      "Epoch 3 Batch 1775 Loss 1.2125\n",
      "Epoch 3 Batch 1776 Loss 1.1741\n",
      "Epoch 3 Batch 1777 Loss 1.3535\n",
      "Epoch 3 Batch 1778 Loss 1.1828\n",
      "Epoch 3 Batch 1779 Loss 1.4015\n",
      "Epoch 3 Batch 1780 Loss 1.2865\n",
      "Epoch 3 Batch 1781 Loss 1.1827\n",
      "Epoch 3 Batch 1782 Loss 1.2353\n",
      "Epoch 3 Batch 1783 Loss 1.3673\n",
      "Epoch 3 Batch 1784 Loss 1.4575\n",
      "Epoch 3 Batch 1785 Loss 1.4080\n",
      "Epoch 3 Batch 1786 Loss 1.6387\n",
      "Epoch 3 Batch 1787 Loss 1.3012\n",
      "Epoch 3 Batch 1788 Loss 1.5038\n",
      "Epoch 3 Batch 1789 Loss 1.4090\n",
      "Epoch 3 Batch 1790 Loss 1.3899\n",
      "Epoch 3 Batch 1791 Loss 1.4376\n",
      "Epoch 3 Batch 1792 Loss 1.2532\n",
      "Epoch 3 Batch 1793 Loss 1.6069\n",
      "Epoch 3 Batch 1794 Loss 1.4548\n",
      "Epoch 3 Batch 1795 Loss 1.2527\n",
      "Epoch 3 Batch 1796 Loss 1.0683\n",
      "Epoch 3 Batch 1797 Loss 1.2411\n",
      "Epoch 3 Batch 1798 Loss 1.3125\n",
      "Epoch 3 Batch 1799 Loss 1.6100\n",
      "Epoch 3 Batch 1800 Loss 1.3088\n",
      "Epoch 3 Batch 1801 Loss 1.3039\n",
      "Epoch 3 Batch 1802 Loss 1.3837\n",
      "Epoch 3 Batch 1803 Loss 1.3436\n",
      "Epoch 3 Batch 1804 Loss 1.2141\n",
      "Epoch 3 Batch 1805 Loss 1.1695\n",
      "Epoch 3 Batch 1806 Loss 1.0546\n",
      "Epoch 3 Batch 1807 Loss 1.1260\n",
      "Epoch 3 Batch 1808 Loss 1.2159\n",
      "Epoch 3 Batch 1809 Loss 1.1519\n",
      "Epoch 3 Batch 1810 Loss 1.2628\n",
      "Epoch 3 Batch 1811 Loss 1.2426\n",
      "Epoch 3 Batch 1812 Loss 1.4403\n",
      "Epoch 3 Batch 1813 Loss 1.0692\n",
      "Epoch 3 Batch 1814 Loss 1.1601\n",
      "Epoch 3 Batch 1815 Loss 1.4084\n",
      "Epoch 3 Batch 1816 Loss 1.4491\n",
      "Epoch 3 Batch 1817 Loss 1.3398\n",
      "Epoch 3 Batch 1818 Loss 1.3440\n",
      "Epoch 3 Batch 1819 Loss 1.1680\n",
      "Epoch 3 Batch 1820 Loss 1.5514\n",
      "Epoch 3 Batch 1821 Loss 1.8283\n",
      "Epoch 3 Batch 1822 Loss 1.3432\n",
      "Epoch 3 Batch 1823 Loss 1.5421\n",
      "Epoch 3 Batch 1824 Loss 1.2865\n",
      "Epoch 3 Batch 1825 Loss 1.2184\n",
      "Epoch 3 Batch 1826 Loss 1.4257\n",
      "Epoch 3 Batch 1827 Loss 1.2868\n",
      "Epoch 3 Batch 1828 Loss 1.4526\n",
      "Epoch 3 Batch 1829 Loss 1.2110\n",
      "Epoch 3 Batch 1830 Loss 1.3046\n",
      "Epoch 3 Batch 1831 Loss 1.4491\n",
      "Epoch 3 Batch 1832 Loss 1.4413\n",
      "Epoch 3 Batch 1833 Loss 1.4585\n",
      "Epoch 3 Batch 1834 Loss 1.1653\n",
      "Epoch 3 Batch 1835 Loss 1.1275\n",
      "Epoch 3 Batch 1836 Loss 1.2364\n",
      "Epoch 3 Batch 1837 Loss 1.4563\n",
      "Epoch 3 Batch 1838 Loss 1.2470\n",
      "Epoch 3 Batch 1839 Loss 1.2307\n",
      "Epoch 3 Batch 1840 Loss 1.2548\n",
      "Epoch 3 Batch 1841 Loss 1.3161\n",
      "Epoch 3 Batch 1842 Loss 1.5284\n",
      "Epoch 3 Batch 1843 Loss 1.2416\n",
      "Epoch 3 Batch 1844 Loss 1.4596\n",
      "Epoch 3 Batch 1845 Loss 1.4168\n",
      "Epoch 3 Batch 1846 Loss 1.3184\n",
      "Epoch 3 Batch 1847 Loss 1.2032\n",
      "Epoch 3 Batch 1848 Loss 1.7043\n",
      "Epoch 3 Batch 1849 Loss 1.2825\n",
      "Epoch 3 Batch 1850 Loss 1.1628\n",
      "Epoch 3 Batch 1851 Loss 1.2726\n",
      "Epoch 3 Batch 1852 Loss 1.1628\n",
      "Epoch 3 Batch 1853 Loss 1.2915\n",
      "Epoch 3 Batch 1854 Loss 1.4337\n",
      "Epoch 3 Batch 1855 Loss 1.6402\n",
      "Epoch 3 Batch 1856 Loss 1.2606\n",
      "Epoch 3 Batch 1857 Loss 1.0389\n",
      "Epoch 3 Batch 1858 Loss 1.5204\n",
      "Epoch 3 Batch 1859 Loss 1.2116\n",
      "Epoch 3 Batch 1860 Loss 1.3488\n",
      "Epoch 3 Batch 1861 Loss 1.2248\n",
      "Epoch 3 Batch 1862 Loss 1.5087\n",
      "Epoch 3 Batch 1863 Loss 1.2442\n",
      "Epoch 3 Batch 1864 Loss 1.2043\n",
      "Epoch 3 Batch 1865 Loss 1.0339\n",
      "Epoch 3 Batch 1866 Loss 1.6722\n",
      "Epoch 3 Batch 1867 Loss 1.1855\n",
      "Epoch 3 Batch 1868 Loss 1.3619\n",
      "Epoch 3 Batch 1869 Loss 1.5587\n",
      "Epoch 3 Batch 1870 Loss 1.3863\n",
      "Epoch 3 Batch 1871 Loss 1.1256\n",
      "Epoch 3 Batch 1872 Loss 1.2203\n",
      "Epoch 3 Batch 1873 Loss 1.3421\n",
      "Epoch 3 Batch 1874 Loss 1.3918\n",
      "Epoch 3 Batch 1875 Loss 1.3855\n",
      "Epoch 3 Batch 1876 Loss 1.4295\n",
      "Epoch 3 Batch 1877 Loss 1.4452\n",
      "Epoch 3 Batch 1878 Loss 1.2532\n",
      "Epoch 3 Batch 1879 Loss 1.4576\n",
      "Epoch 3 Batch 1880 Loss 1.2665\n",
      "Epoch 3 Batch 1881 Loss 1.3396\n",
      "Epoch 3 Batch 1882 Loss 1.2158\n",
      "Epoch 3 Batch 1883 Loss 1.2412\n",
      "Epoch 3 Batch 1884 Loss 1.5393\n",
      "Epoch 3 Batch 1885 Loss 1.4149\n",
      "Epoch 3 Batch 1886 Loss 1.4740\n",
      "Epoch 3 Batch 1887 Loss 1.8956\n",
      "Epoch 3 Batch 1888 Loss 1.7204\n",
      "Epoch 3 Batch 1889 Loss 1.6210\n",
      "Epoch 3 Batch 1890 Loss 1.5334\n",
      "Epoch 3 Batch 1891 Loss 1.1341\n",
      "Epoch 3 Batch 1892 Loss 1.5201\n",
      "Epoch 3 Batch 1893 Loss 1.3951\n",
      "Epoch 3 Batch 1894 Loss 1.3511\n",
      "Epoch 3 Batch 1895 Loss 1.0735\n",
      "Epoch 3 Batch 1896 Loss 1.1342\n",
      "Epoch 3 Batch 1897 Loss 1.6462\n",
      "Epoch 3 Batch 1898 Loss 1.4437\n",
      "Epoch 3 Batch 1899 Loss 1.5371\n",
      "Epoch 3 Batch 1900 Loss 1.3123\n",
      "Epoch 3 Batch 1901 Loss 1.6286\n",
      "Epoch 3 Batch 1902 Loss 1.2687\n",
      "Epoch 3 Batch 1903 Loss 1.2768\n",
      "Epoch 3 Batch 1904 Loss 1.4357\n",
      "Epoch 3 Batch 1905 Loss 1.4375\n",
      "Epoch 3 Batch 1906 Loss 1.4141\n",
      "Epoch 3 Batch 1907 Loss 1.0102\n",
      "Epoch 3 Batch 1908 Loss 1.1785\n",
      "Epoch 3 Batch 1909 Loss 1.2181\n",
      "Epoch 3 Batch 1910 Loss 1.2776\n",
      "Epoch 3 Batch 1911 Loss 1.3849\n",
      "Epoch 3 Batch 1912 Loss 1.3387\n",
      "Epoch 3 Batch 1913 Loss 1.0514\n",
      "Epoch 3 Batch 1914 Loss 1.2829\n",
      "Epoch 3 Batch 1915 Loss 1.1447\n",
      "Epoch 3 Batch 1916 Loss 1.1947\n",
      "Epoch 3 Batch 1917 Loss 1.4494\n",
      "Epoch 3 Batch 1918 Loss 1.3946\n",
      "Epoch 3 Batch 1919 Loss 1.2089\n",
      "Epoch 3 Batch 1920 Loss 1.3018\n",
      "Epoch 3 Batch 1921 Loss 1.4285\n",
      "Epoch 3 Batch 1922 Loss 1.0811\n",
      "Epoch 3 Batch 1923 Loss 1.3424\n",
      "Epoch 3 Batch 1924 Loss 1.5382\n",
      "Epoch 3 Batch 1925 Loss 1.3646\n",
      "Epoch 3 Batch 1926 Loss 1.1061\n",
      "Epoch 3 Batch 1927 Loss 1.1712\n",
      "Epoch 3 Batch 1928 Loss 1.1468\n",
      "Epoch 3 Batch 1929 Loss 1.4452\n",
      "Epoch 3 Batch 1930 Loss 1.3238\n",
      "Epoch 3 Batch 1931 Loss 1.5469\n",
      "Epoch 3 Batch 1932 Loss 1.3998\n",
      "Epoch 3 Batch 1933 Loss 1.4142\n",
      "Epoch 3 Batch 1934 Loss 1.2256\n",
      "Epoch 3 Batch 1935 Loss 1.7616\n",
      "Epoch 3 Batch 1936 Loss 1.2934\n",
      "Epoch 3 Batch 1937 Loss 1.1165\n",
      "Epoch 3 Batch 1938 Loss 1.3659\n",
      "Epoch 3 Batch 1939 Loss 1.3000\n",
      "Epoch 3 Batch 1940 Loss 1.4103\n",
      "Epoch 3 Batch 1941 Loss 1.0757\n",
      "Epoch 3 Batch 1942 Loss 1.1746\n",
      "Epoch 3 Batch 1943 Loss 1.2928\n",
      "Epoch 3 Batch 1944 Loss 1.2664\n",
      "Epoch 3 Batch 1945 Loss 0.9452\n",
      "Epoch 3 Batch 1946 Loss 1.6856\n",
      "Epoch 3 Batch 1947 Loss 1.4564\n",
      "Epoch 3 Batch 1948 Loss 1.2438\n",
      "Epoch 3 Batch 1949 Loss 1.3343\n",
      "Epoch 3 Batch 1950 Loss 1.2412\n",
      "Epoch 3 Batch 1951 Loss 1.4380\n",
      "Epoch 3 Batch 1952 Loss 1.4524\n",
      "Epoch 3 Batch 1953 Loss 1.1680\n",
      "Epoch 3 Batch 1954 Loss 1.3684\n",
      "Epoch 3 Batch 1955 Loss 1.2336\n",
      "Epoch 3 Batch 1956 Loss 1.6437\n",
      "Epoch 3 Batch 1957 Loss 1.2295\n",
      "Epoch 3 Batch 1958 Loss 1.1470\n",
      "Epoch 3 Batch 1959 Loss 1.4386\n",
      "Epoch 3 Batch 1960 Loss 1.2365\n",
      "Epoch 3 Batch 1961 Loss 1.8274\n",
      "Epoch 3 Batch 1962 Loss 1.4915\n",
      "Epoch 3 Batch 1963 Loss 1.3958\n",
      "Epoch 3 Batch 1964 Loss 1.1891\n",
      "Epoch 3 Batch 1965 Loss 1.0919\n",
      "Epoch 3 Batch 1966 Loss 1.0899\n",
      "Epoch 3 Batch 1967 Loss 0.9733\n",
      "Epoch 3 Batch 1968 Loss 1.5455\n",
      "Epoch 3 Batch 1969 Loss 1.4087\n",
      "Epoch 3 Batch 1970 Loss 1.0260\n",
      "Epoch 3 Batch 1971 Loss 1.3762\n",
      "Epoch 3 Batch 1972 Loss 1.3898\n",
      "Epoch 3 Batch 1973 Loss 1.1932\n",
      "Epoch 3 Batch 1974 Loss 1.3268\n",
      "Epoch 3 Batch 1975 Loss 1.2649\n",
      "Epoch 3 Batch 1976 Loss 1.3840\n",
      "Epoch 3 Batch 1977 Loss 1.3741\n",
      "Epoch 3 Batch 1978 Loss 1.3473\n",
      "Epoch 3 Batch 1979 Loss 1.2213\n",
      "Epoch 3 Batch 1980 Loss 1.3724\n",
      "Epoch 3 Batch 1981 Loss 1.4574\n",
      "Epoch 3 Batch 1982 Loss 1.3873\n",
      "Epoch 3 Batch 1983 Loss 1.3950\n",
      "Epoch 3 Batch 1984 Loss 1.1605\n",
      "Epoch 3 Batch 1985 Loss 1.3004\n",
      "Epoch 3 Batch 1986 Loss 0.9866\n",
      "Epoch 3 Batch 1987 Loss 1.1690\n",
      "Epoch 3 Batch 1988 Loss 1.8045\n",
      "Epoch 3 Batch 1989 Loss 1.1943\n",
      "Epoch 3 Batch 1990 Loss 1.1115\n",
      "Epoch 3 Batch 1991 Loss 1.4634\n",
      "Epoch 3 Batch 1992 Loss 1.5567\n",
      "Epoch 3 Batch 1993 Loss 1.0912\n",
      "Epoch 3 Batch 1994 Loss 1.3691\n",
      "Epoch 3 Batch 1995 Loss 1.4389\n",
      "Epoch 3 Batch 1996 Loss 1.2446\n",
      "Epoch 3 Batch 1997 Loss 1.4283\n",
      "Epoch 3 Batch 1998 Loss 1.1528\n",
      "Epoch 3 Batch 1999 Loss 1.1435\n",
      "Epoch 3 Batch 2000 Loss 1.0984\n",
      "Epoch 3 Batch 2001 Loss 1.4789\n",
      "Epoch 3 Batch 2002 Loss 1.7123\n",
      "Epoch 3 Batch 2003 Loss 1.2407\n",
      "Epoch 3 Batch 2004 Loss 1.5446\n",
      "Epoch 3 Batch 2005 Loss 1.5020\n",
      "Epoch 3 Batch 2006 Loss 1.2304\n",
      "Epoch 3 Batch 2007 Loss 1.4759\n",
      "Epoch 3 Batch 2008 Loss 1.3166\n",
      "Epoch 3 Batch 2009 Loss 1.6590\n",
      "Epoch 3 Batch 2010 Loss 1.4354\n",
      "Epoch 3 Batch 2011 Loss 1.3450\n",
      "Epoch 3 Batch 2012 Loss 1.3769\n",
      "Epoch 3 Batch 2013 Loss 1.2016\n",
      "Epoch 3 Batch 2014 Loss 1.1767\n",
      "Epoch 3 Batch 2015 Loss 1.1451\n",
      "Epoch 3 Batch 2016 Loss 1.3072\n",
      "Epoch 3 Batch 2017 Loss 1.3148\n",
      "Epoch 3 Batch 2018 Loss 1.5229\n",
      "Epoch 3 Batch 2019 Loss 1.4450\n",
      "Epoch 3 Batch 2020 Loss 1.1252\n",
      "Epoch 3 Batch 2021 Loss 1.6116\n",
      "Epoch 3 Batch 2022 Loss 1.0731\n",
      "Epoch 3 Batch 2023 Loss 1.4191\n",
      "Epoch 3 Batch 2024 Loss 1.0884\n",
      "Epoch 3 Batch 2025 Loss 1.2336\n",
      "Epoch 3 Batch 2026 Loss 1.7289\n",
      "Epoch 3 Batch 2027 Loss 1.4467\n",
      "Epoch 3 Batch 2028 Loss 1.3288\n",
      "Epoch 3 Batch 2029 Loss 1.2138\n",
      "Epoch 3 Batch 2030 Loss 1.5925\n",
      "Epoch 3 Batch 2031 Loss 1.1151\n",
      "Epoch 3 Batch 2032 Loss 1.1566\n",
      "Epoch 3 Batch 2033 Loss 1.2663\n",
      "Epoch 3 Batch 2034 Loss 1.4652\n",
      "Epoch 3 Batch 2035 Loss 1.3610\n",
      "Epoch 3 Batch 2036 Loss 1.1735\n",
      "Epoch 3 Batch 2037 Loss 1.3700\n",
      "Epoch 3 Batch 2038 Loss 1.4159\n",
      "Epoch 3 Batch 2039 Loss 1.2226\n",
      "Epoch 3 Batch 2040 Loss 1.4143\n",
      "Epoch 3 Batch 2041 Loss 1.3631\n",
      "Epoch 3 Batch 2042 Loss 1.2354\n",
      "Epoch 3 Batch 2043 Loss 1.5449\n",
      "Epoch 3 Batch 2044 Loss 1.3619\n",
      "Epoch 3 Batch 2045 Loss 1.1256\n",
      "Epoch 3 Batch 2046 Loss 1.2578\n",
      "Epoch 3 Batch 2047 Loss 1.5154\n",
      "Epoch 3 Batch 2048 Loss 1.4129\n",
      "Epoch 3 Batch 2049 Loss 1.3120\n",
      "Epoch 3 Batch 2050 Loss 1.0029\n",
      "Epoch 3 Batch 2051 Loss 1.2071\n",
      "Epoch 3 Batch 2052 Loss 1.0617\n",
      "Epoch 3 Batch 2053 Loss 1.1095\n",
      "Epoch 3 Batch 2054 Loss 1.2493\n",
      "Epoch 3 Batch 2055 Loss 1.3925\n",
      "Epoch 3 Batch 2056 Loss 1.2119\n",
      "Epoch 3 Batch 2057 Loss 1.1335\n",
      "Epoch 3 Batch 2058 Loss 1.4204\n",
      "Epoch 3 Batch 2059 Loss 1.0232\n",
      "Epoch 3 Batch 2060 Loss 1.7852\n",
      "Epoch 3 Batch 2061 Loss 1.2000\n",
      "Epoch 3 Batch 2062 Loss 1.3860\n",
      "Epoch 3 Batch 2063 Loss 1.5133\n",
      "Epoch 3 Batch 2064 Loss 1.7386\n",
      "Epoch 3 Batch 2065 Loss 1.6134\n",
      "Epoch 3 Batch 2066 Loss 1.6816\n",
      "Epoch 3 Batch 2067 Loss 1.3390\n",
      "Epoch 3 Batch 2068 Loss 1.5096\n",
      "Epoch 3 Batch 2069 Loss 1.3424\n",
      "Epoch 3 Batch 2070 Loss 1.5180\n",
      "Epoch 3 Batch 2071 Loss 1.2576\n",
      "Epoch 3 Batch 2072 Loss 1.6237\n",
      "Epoch 3 Batch 2073 Loss 1.1255\n",
      "Epoch 3 Batch 2074 Loss 1.2425\n",
      "Epoch 3 Batch 2075 Loss 1.3624\n",
      "Epoch 3 Batch 2076 Loss 1.3438\n",
      "Epoch 3 Batch 2077 Loss 1.1976\n",
      "Epoch 3 Batch 2078 Loss 1.2317\n",
      "Epoch 3 Batch 2079 Loss 1.3669\n",
      "Epoch 3 Batch 2080 Loss 1.4846\n",
      "Epoch 3 Batch 2081 Loss 1.2586\n",
      "Epoch 3 Batch 2082 Loss 1.1084\n",
      "Epoch 3 Batch 2083 Loss 1.2005\n",
      "Epoch 3 Batch 2084 Loss 1.5305\n",
      "Epoch 3 Batch 2085 Loss 1.3373\n",
      "Epoch 3 Batch 2086 Loss 1.4512\n",
      "Epoch 3 Batch 2087 Loss 1.2336\n",
      "Epoch 3 Batch 2088 Loss 1.3461\n",
      "Epoch 3 Batch 2089 Loss 1.4048\n",
      "Epoch 3 Batch 2090 Loss 1.1485\n",
      "Epoch 3 Batch 2091 Loss 1.7075\n",
      "Epoch 3 Batch 2092 Loss 1.0953\n",
      "Epoch 3 Batch 2093 Loss 1.2622\n",
      "Epoch 3 Batch 2094 Loss 1.6070\n",
      "Epoch 3 Batch 2095 Loss 1.1968\n",
      "Epoch 3 Batch 2096 Loss 1.1187\n",
      "Epoch 3 Batch 2097 Loss 1.6830\n",
      "Epoch 3 Batch 2098 Loss 1.3771\n",
      "Epoch 3 Batch 2099 Loss 1.4346\n",
      "Epoch 3 Batch 2100 Loss 1.1269\n",
      "Epoch 3 Batch 2101 Loss 1.2206\n",
      "Epoch 3 Batch 2102 Loss 1.3400\n",
      "Epoch 3 Batch 2103 Loss 1.3895\n",
      "Epoch 3 Batch 2104 Loss 1.3792\n",
      "Epoch 3 Batch 2105 Loss 1.6017\n",
      "Epoch 3 Batch 2106 Loss 1.3864\n",
      "Epoch 3 Batch 2107 Loss 1.4272\n",
      "Epoch 3 Batch 2108 Loss 1.2615\n",
      "Epoch 3 Batch 2109 Loss 1.3806\n",
      "Epoch 3 Batch 2110 Loss 1.3815\n",
      "Epoch 3 Batch 2111 Loss 1.3429\n",
      "Epoch 3 Batch 2112 Loss 1.8933\n",
      "Epoch 3 Batch 2113 Loss 1.7210\n",
      "Epoch 3 Batch 2114 Loss 1.6953\n",
      "Epoch 3 Batch 2115 Loss 1.2235\n",
      "Epoch 3 Batch 2116 Loss 1.2724\n",
      "Epoch 3 Batch 2117 Loss 1.1490\n",
      "Epoch 3 Batch 2118 Loss 1.2603\n",
      "Epoch 3 Batch 2119 Loss 1.3677\n",
      "Epoch 3 Batch 2120 Loss 1.1745\n",
      "Epoch 3 Batch 2121 Loss 1.4385\n",
      "Epoch 3 Batch 2122 Loss 1.5712\n",
      "Epoch 3 Batch 2123 Loss 1.5032\n",
      "Epoch 3 Batch 2124 Loss 1.2768\n",
      "Epoch 3 Batch 2125 Loss 1.3586\n",
      "Epoch 3 Batch 2126 Loss 1.3073\n",
      "Epoch 3 Batch 2127 Loss 1.3724\n",
      "Epoch 3 Batch 2128 Loss 1.6913\n",
      "Epoch 3 Batch 2129 Loss 1.4531\n",
      "Epoch 3 Batch 2130 Loss 1.1315\n",
      "Epoch 3 Batch 2131 Loss 1.5087\n",
      "Epoch 3 Batch 2132 Loss 1.3576\n",
      "Epoch 3 Batch 2133 Loss 1.2339\n",
      "Epoch 3 Batch 2134 Loss 1.3316\n",
      "Epoch 3 Batch 2135 Loss 1.6198\n",
      "Epoch 3 Batch 2136 Loss 1.3006\n",
      "Epoch 3 Batch 2137 Loss 1.2047\n",
      "Epoch 3 Batch 2138 Loss 1.2781\n",
      "Epoch 3 Batch 2139 Loss 1.1426\n",
      "Epoch 3 Batch 2140 Loss 1.3023\n",
      "Epoch 3 Batch 2141 Loss 1.3421\n",
      "Epoch 3 Batch 2142 Loss 1.3144\n",
      "Epoch 3 Batch 2143 Loss 1.1567\n",
      "Epoch 3 Batch 2144 Loss 1.0905\n",
      "Epoch 3 Batch 2145 Loss 1.1222\n",
      "Epoch 3 Batch 2146 Loss 1.1806\n",
      "Epoch 3 Batch 2147 Loss 1.2106\n",
      "Epoch 3 Batch 2148 Loss 1.0403\n",
      "Epoch 3 Batch 2149 Loss 1.4349\n",
      "Epoch 3 Batch 2150 Loss 1.5771\n",
      "Epoch 3 Batch 2151 Loss 1.0958\n",
      "Epoch 3 Batch 2152 Loss 1.2882\n",
      "Epoch 3 Batch 2153 Loss 1.2049\n",
      "Epoch 3 Batch 2154 Loss 1.2238\n",
      "Epoch 3 Batch 2155 Loss 1.0159\n",
      "Epoch 3 Batch 2156 Loss 1.1512\n",
      "Epoch 3 Batch 2157 Loss 1.6402\n",
      "Epoch 3 Batch 2158 Loss 1.0848\n",
      "Epoch 3 Batch 2159 Loss 1.4957\n",
      "Epoch 3 Batch 2160 Loss 1.1718\n",
      "Epoch 3 Batch 2161 Loss 1.4519\n",
      "Epoch 3 Batch 2162 Loss 1.3330\n",
      "Epoch 3 Batch 2163 Loss 1.4369\n",
      "Epoch 3 Batch 2164 Loss 1.3717\n",
      "Epoch 3 Batch 2165 Loss 1.2501\n",
      "Epoch 3 Batch 2166 Loss 1.1798\n",
      "Epoch 3 Batch 2167 Loss 1.5800\n",
      "Epoch 3 Batch 2168 Loss 1.2734\n",
      "Epoch 3 Batch 2169 Loss 1.1574\n",
      "Epoch 3 Batch 2170 Loss 1.6632\n",
      "Epoch 3 Batch 2171 Loss 1.0453\n",
      "Epoch 3 Batch 2172 Loss 1.5538\n",
      "Epoch 3 Batch 2173 Loss 1.3868\n",
      "Epoch 3 Batch 2174 Loss 1.1503\n",
      "Epoch 3 Batch 2175 Loss 1.3119\n",
      "Epoch 3 Batch 2176 Loss 1.1106\n",
      "Epoch 3 Batch 2177 Loss 1.3324\n",
      "Epoch 3 Batch 2178 Loss 1.3671\n",
      "Epoch 3 Batch 2179 Loss 1.3112\n",
      "Epoch 3 Batch 2180 Loss 1.2266\n",
      "Epoch 3 Batch 2181 Loss 1.2619\n",
      "Epoch 3 Batch 2182 Loss 1.3884\n",
      "Epoch 3 Batch 2183 Loss 1.3998\n",
      "Epoch 3 Batch 2184 Loss 1.3466\n",
      "Epoch 3 Batch 2185 Loss 1.1924\n",
      "Epoch 3 Batch 2186 Loss 1.4623\n",
      "Epoch 3 Batch 2187 Loss 1.1295\n",
      "Epoch 3 Batch 2188 Loss 1.4746\n",
      "Epoch 3 Batch 2189 Loss 1.1417\n",
      "Epoch 3 Batch 2190 Loss 1.5664\n",
      "Epoch 3 Batch 2191 Loss 1.3595\n",
      "Epoch 3 Batch 2192 Loss 1.2238\n",
      "Epoch 3 Batch 2193 Loss 1.2640\n",
      "Epoch 3 Batch 2194 Loss 1.4338\n",
      "Epoch 3 Batch 2195 Loss 1.2236\n",
      "Epoch 3 Batch 2196 Loss 1.3369\n",
      "Epoch 3 Batch 2197 Loss 1.4474\n",
      "Epoch 3 Batch 2198 Loss 1.2657\n",
      "Epoch 3 Batch 2199 Loss 1.3310\n",
      "Epoch 3 Batch 2200 Loss 1.4925\n",
      "Epoch 3 Batch 2201 Loss 1.4842\n",
      "Epoch 3 Batch 2202 Loss 1.3997\n",
      "Epoch 3 Batch 2203 Loss 1.3937\n",
      "Epoch 3 Batch 2204 Loss 1.3957\n",
      "Epoch 3 Batch 2205 Loss 1.1616\n",
      "Epoch 3 Batch 2206 Loss 1.2993\n",
      "Epoch 3 Batch 2207 Loss 1.4717\n",
      "Epoch 3 Batch 2208 Loss 1.4211\n",
      "Epoch 3 Batch 2209 Loss 1.3741\n",
      "Epoch 3 Batch 2210 Loss 1.1348\n",
      "Epoch 3 Batch 2211 Loss 1.5842\n",
      "Epoch 3 Batch 2212 Loss 1.2434\n",
      "Epoch 3 Batch 2213 Loss 1.2053\n",
      "Epoch 3 Batch 2214 Loss 1.2908\n",
      "Epoch 3 Batch 2215 Loss 1.3468\n",
      "Epoch 3 Batch 2216 Loss 1.1080\n",
      "Epoch 3 Batch 2217 Loss 1.6427\n",
      "Epoch 3 Batch 2218 Loss 1.4999\n",
      "Epoch 3 Batch 2219 Loss 1.4845\n",
      "Epoch 3 Batch 2220 Loss 1.3463\n",
      "Epoch 3 Batch 2221 Loss 1.5232\n",
      "Epoch 3 Batch 2222 Loss 1.3727\n",
      "Epoch 3 Batch 2223 Loss 1.3844\n",
      "Epoch 3 Batch 2224 Loss 1.3312\n",
      "Epoch 3 Batch 2225 Loss 1.1345\n",
      "Epoch 3 Batch 2226 Loss 1.1374\n",
      "Epoch 3 Batch 2227 Loss 1.1455\n",
      "Epoch 3 Batch 2228 Loss 1.2209\n",
      "Epoch 3 Batch 2229 Loss 1.5013\n",
      "Epoch 3 Batch 2230 Loss 1.2925\n",
      "Epoch 3 Batch 2231 Loss 1.4191\n",
      "Epoch 3 Batch 2232 Loss 1.2529\n",
      "Epoch 3 Batch 2233 Loss 1.0110\n",
      "Epoch 3 Batch 2234 Loss 1.2324\n",
      "Epoch 3 Batch 2235 Loss 1.1750\n",
      "Epoch 3 Batch 2236 Loss 1.0956\n",
      "Epoch 3 Batch 2237 Loss 1.3375\n",
      "Epoch 3 Batch 2238 Loss 1.3271\n",
      "Epoch 3 Batch 2239 Loss 1.2502\n",
      "Epoch 3 Batch 2240 Loss 1.0401\n",
      "Epoch 3 Batch 2241 Loss 1.3136\n",
      "Epoch 3 Batch 2242 Loss 1.3911\n",
      "Epoch 3 Batch 2243 Loss 1.2231\n",
      "Epoch 3 Batch 2244 Loss 1.2501\n",
      "Epoch 3 Batch 2245 Loss 1.0228\n",
      "Epoch 3 Batch 2246 Loss 1.4849\n",
      "Epoch 3 Batch 2247 Loss 1.3672\n",
      "Epoch 3 Batch 2248 Loss 1.4351\n",
      "Epoch 3 Batch 2249 Loss 1.2420\n",
      "Epoch 3 Batch 2250 Loss 1.3882\n",
      "Epoch 3 Batch 2251 Loss 1.6303\n",
      "Epoch 3 Batch 2252 Loss 1.4850\n",
      "Epoch 3 Batch 2253 Loss 1.2023\n",
      "Epoch 3 Batch 2254 Loss 1.1598\n",
      "Epoch 3 Batch 2255 Loss 0.9393\n",
      "Epoch 3 Batch 2256 Loss 1.2875\n",
      "Epoch 3 Batch 2257 Loss 1.3531\n",
      "Epoch 3 Batch 2258 Loss 1.4066\n",
      "Epoch 3 Batch 2259 Loss 1.5812\n",
      "Epoch 3 Batch 2260 Loss 1.4266\n",
      "Epoch 3 Batch 2261 Loss 1.5082\n",
      "Epoch 3 Batch 2262 Loss 1.2306\n",
      "Epoch 3 Batch 2263 Loss 1.2834\n",
      "Epoch 3 Batch 2264 Loss 1.5171\n",
      "Epoch 3 Batch 2265 Loss 1.1025\n",
      "Epoch 3 Batch 2266 Loss 1.2982\n",
      "Epoch 3 Batch 2267 Loss 1.2071\n",
      "Epoch 3 Batch 2268 Loss 1.3321\n",
      "Epoch 3 Batch 2269 Loss 1.3406\n",
      "Epoch 3 Batch 2270 Loss 1.3554\n",
      "Epoch 3 Batch 2271 Loss 1.5185\n",
      "Epoch 3 Batch 2272 Loss 1.4437\n",
      "Epoch 3 Batch 2273 Loss 1.1314\n",
      "Epoch 3 Batch 2274 Loss 1.3688\n",
      "Epoch 3 Batch 2275 Loss 1.3689\n",
      "Epoch 3 Batch 2276 Loss 1.3710\n",
      "Epoch 3 Batch 2277 Loss 1.9299\n",
      "Epoch 3 Batch 2278 Loss 1.5745\n",
      "Epoch 3 Batch 2279 Loss 1.2977\n",
      "Epoch 3 Batch 2280 Loss 1.5979\n",
      "Epoch 3 Batch 2281 Loss 1.1778\n",
      "Epoch 3 Batch 2282 Loss 1.4157\n",
      "Epoch 3 Batch 2283 Loss 1.2872\n",
      "Epoch 3 Batch 2284 Loss 1.2938\n",
      "Epoch 3 Batch 2285 Loss 1.4150\n",
      "Epoch 3 Batch 2286 Loss 1.1151\n",
      "Epoch 3 Batch 2287 Loss 1.6623\n",
      "Epoch 3 Batch 2288 Loss 1.3866\n",
      "Epoch 3 Batch 2289 Loss 1.5332\n",
      "Epoch 3 Batch 2290 Loss 1.2022\n",
      "Epoch 3 Batch 2291 Loss 1.5194\n",
      "Epoch 3 Batch 2292 Loss 1.2782\n",
      "Epoch 3 Batch 2293 Loss 1.1271\n",
      "Epoch 3 Batch 2294 Loss 1.5311\n",
      "Epoch 3 Batch 2295 Loss 1.1330\n",
      "Epoch 3 Batch 2296 Loss 1.1601\n",
      "Epoch 3 Batch 2297 Loss 1.4402\n",
      "Epoch 3 Batch 2298 Loss 1.4457\n",
      "Epoch 3 Batch 2299 Loss 1.4132\n",
      "Epoch 3 Batch 2300 Loss 1.4873\n",
      "Epoch 3 Batch 2301 Loss 1.4794\n",
      "Epoch 3 Batch 2302 Loss 1.2921\n",
      "Epoch 3 Batch 2303 Loss 1.4561\n",
      "Epoch 3 Batch 2304 Loss 1.2679\n",
      "Epoch 3 Batch 2305 Loss 1.3813\n",
      "Epoch 3 Batch 2306 Loss 1.2498\n",
      "Epoch 3 Batch 2307 Loss 1.0978\n",
      "Epoch 3 Batch 2308 Loss 1.1276\n",
      "Epoch 3 Batch 2309 Loss 1.3627\n",
      "Epoch 3 Batch 2310 Loss 1.1128\n",
      "Epoch 3 Batch 2311 Loss 1.4175\n",
      "Epoch 3 Batch 2312 Loss 1.0569\n",
      "Epoch 3 Batch 2313 Loss 1.3168\n",
      "Epoch 3 Batch 2314 Loss 1.3094\n",
      "Epoch 3 Batch 2315 Loss 1.1013\n",
      "Epoch 3 Batch 2316 Loss 1.3128\n",
      "Epoch 3 Batch 2317 Loss 1.2480\n",
      "Epoch 3 Batch 2318 Loss 1.7531\n",
      "Epoch 3 Batch 2319 Loss 1.4996\n",
      "Epoch 3 Batch 2320 Loss 1.7679\n",
      "Epoch 3 Batch 2321 Loss 1.5163\n",
      "Epoch 3 Batch 2322 Loss 1.3024\n",
      "Epoch 3 Batch 2323 Loss 1.4160\n",
      "Epoch 3 Batch 2324 Loss 1.5494\n",
      "Epoch 3 Batch 2325 Loss 1.5804\n",
      "Epoch 3 Batch 2326 Loss 1.5549\n",
      "Epoch 3 Batch 2327 Loss 1.1031\n",
      "Epoch 3 Batch 2328 Loss 1.1557\n",
      "Epoch 3 Batch 2329 Loss 1.3937\n",
      "Epoch 3 Batch 2330 Loss 1.6249\n",
      "Epoch 3 Batch 2331 Loss 1.3561\n",
      "Epoch 3 Batch 2332 Loss 1.2625\n",
      "Epoch 3 Batch 2333 Loss 1.6138\n",
      "Epoch 3 Batch 2334 Loss 1.2477\n",
      "Epoch 3 Batch 2335 Loss 1.2400\n",
      "Epoch 3 Batch 2336 Loss 1.3231\n",
      "Epoch 3 Batch 2337 Loss 1.2057\n",
      "Epoch 3 Batch 2338 Loss 1.2367\n",
      "Epoch 3 Batch 2339 Loss 1.2892\n",
      "Epoch 3 Batch 2340 Loss 1.1000\n",
      "Epoch 3 Batch 2341 Loss 1.3140\n",
      "Epoch 3 Batch 2342 Loss 1.2828\n",
      "Epoch 3 Batch 2343 Loss 1.3451\n",
      "Epoch 3 Batch 2344 Loss 1.0993\n",
      "Epoch 3 Batch 2345 Loss 1.1463\n",
      "Epoch 3 Batch 2346 Loss 1.4727\n",
      "Epoch 3 Batch 2347 Loss 1.2084\n",
      "Epoch 3 Batch 2348 Loss 1.5139\n",
      "Epoch 3 Batch 2349 Loss 1.5723\n",
      "Epoch 3 Batch 2350 Loss 1.2041\n",
      "Epoch 3 Batch 2351 Loss 1.2609\n",
      "Epoch 3 Batch 2352 Loss 1.4487\n",
      "Epoch 3 Batch 2353 Loss 1.5352\n",
      "Epoch 3 Batch 2354 Loss 1.2742\n",
      "Epoch 3 Batch 2355 Loss 1.4372\n",
      "Epoch 3 Batch 2356 Loss 1.0670\n",
      "Epoch 3 Batch 2357 Loss 1.4034\n",
      "Epoch 3 Batch 2358 Loss 1.2842\n",
      "Epoch 3 Batch 2359 Loss 1.0357\n",
      "Epoch 3 Batch 2360 Loss 1.3598\n",
      "Epoch 3 Batch 2361 Loss 1.4085\n",
      "Epoch 3 Batch 2362 Loss 1.5148\n",
      "Epoch 3 Batch 2363 Loss 1.2393\n",
      "Epoch 3 Batch 2364 Loss 1.4591\n",
      "Epoch 3 Batch 2365 Loss 1.6425\n",
      "Epoch 3 Batch 2366 Loss 1.4293\n",
      "Epoch 3 Batch 2367 Loss 1.3148\n",
      "Epoch 3 Batch 2368 Loss 1.2886\n",
      "Epoch 3 Batch 2369 Loss 1.4966\n",
      "Epoch 3 Batch 2370 Loss 1.5184\n",
      "Epoch 3 Batch 2371 Loss 1.1708\n",
      "Epoch 3 Batch 2372 Loss 1.3187\n",
      "Epoch 3 Batch 2373 Loss 1.4665\n",
      "Epoch 3 Batch 2374 Loss 1.2089\n",
      "Epoch 3 Batch 2375 Loss 1.3055\n",
      "Epoch 3 Batch 2376 Loss 1.1066\n",
      "Epoch 3 Batch 2377 Loss 1.1569\n",
      "Epoch 3 Batch 2378 Loss 1.0547\n",
      "Epoch 3 Batch 2379 Loss 1.1846\n",
      "Epoch 3 Batch 2380 Loss 0.9894\n",
      "Epoch 3 Batch 2381 Loss 1.4385\n",
      "Epoch 3 Batch 2382 Loss 1.4478\n",
      "Epoch 3 Batch 2383 Loss 1.3181\n",
      "Epoch 3 Batch 2384 Loss 0.9101\n",
      "Epoch 3 Batch 2385 Loss 1.4557\n",
      "Epoch 3 Batch 2386 Loss 1.4430\n",
      "Epoch 3 Batch 2387 Loss 1.2942\n",
      "Epoch 3 Batch 2388 Loss 1.3015\n",
      "Epoch 3 Batch 2389 Loss 1.5752\n",
      "Epoch 3 Batch 2390 Loss 1.1363\n",
      "Epoch 3 Batch 2391 Loss 1.3402\n",
      "Epoch 3 Batch 2392 Loss 1.2609\n",
      "Epoch 3 Batch 2393 Loss 1.1977\n",
      "Epoch 3 Batch 2394 Loss 1.0864\n",
      "Epoch 3 Batch 2395 Loss 1.2383\n",
      "Epoch 3 Batch 2396 Loss 1.2357\n",
      "Epoch 3 Batch 2397 Loss 1.1627\n",
      "Epoch 3 Batch 2398 Loss 1.0475\n",
      "Epoch 3 Batch 2399 Loss 1.2190\n",
      "Epoch 3 Batch 2400 Loss 1.3136\n",
      "Epoch 3 Batch 2401 Loss 1.0690\n",
      "Epoch 3 Batch 2402 Loss 1.2711\n",
      "Epoch 3 Batch 2403 Loss 1.1459\n",
      "Epoch 3 Batch 2404 Loss 1.3264\n",
      "Epoch 3 Batch 2405 Loss 1.4152\n",
      "Epoch 3 Batch 2406 Loss 1.3493\n",
      "Epoch 3 Batch 2407 Loss 1.1947\n",
      "Epoch 3 Batch 2408 Loss 1.5505\n",
      "Epoch 3 Batch 2409 Loss 1.1822\n",
      "Epoch 3 Batch 2410 Loss 1.2744\n",
      "Epoch 3 Batch 2411 Loss 1.4098\n",
      "Epoch 3 Batch 2412 Loss 1.0901\n",
      "Epoch 3 Batch 2413 Loss 1.4977\n",
      "Epoch 3 Batch 2414 Loss 1.1755\n",
      "Epoch 3 Batch 2415 Loss 1.5314\n",
      "Epoch 3 Batch 2416 Loss 1.1354\n",
      "Epoch 3 Batch 2417 Loss 1.3178\n",
      "Epoch 3 Batch 2418 Loss 1.3897\n",
      "Epoch 3 Batch 2419 Loss 1.2048\n",
      "Epoch 3 Batch 2420 Loss 1.2692\n",
      "Epoch 3 Batch 2421 Loss 1.4040\n",
      "Epoch 3 Batch 2422 Loss 1.4896\n",
      "Epoch 3 Batch 2423 Loss 1.1404\n",
      "Epoch 3 Batch 2424 Loss 1.3889\n",
      "Epoch 3 Batch 2425 Loss 1.0159\n",
      "Epoch 3 Batch 2426 Loss 1.4239\n",
      "Epoch 3 Batch 2427 Loss 0.9712\n",
      "Epoch 3 Batch 2428 Loss 1.0747\n",
      "Epoch 3 Batch 2429 Loss 1.2164\n",
      "Epoch 3 Batch 2430 Loss 1.2200\n",
      "Epoch 3 Batch 2431 Loss 1.4138\n",
      "Epoch 3 Batch 2432 Loss 1.2380\n",
      "Epoch 3 Batch 2433 Loss 1.3758\n",
      "Epoch 3 Batch 2434 Loss 1.1222\n",
      "Epoch 3 Batch 2435 Loss 1.2332\n",
      "Epoch 3 Batch 2436 Loss 1.4069\n",
      "Epoch 3 Batch 2437 Loss 1.1682\n",
      "Epoch 3 Batch 2438 Loss 1.4239\n",
      "Epoch 3 Batch 2439 Loss 1.3806\n",
      "Epoch 3 Batch 2440 Loss 1.6888\n",
      "Epoch 3 Batch 2441 Loss 1.1950\n",
      "Epoch 3 Batch 2442 Loss 1.2893\n",
      "Epoch 3 Batch 2443 Loss 1.3199\n",
      "Epoch 3 Batch 2444 Loss 1.5404\n",
      "Epoch 3 Batch 2445 Loss 1.5971\n",
      "Epoch 3 Batch 2446 Loss 1.2840\n",
      "Epoch 3 Batch 2447 Loss 0.9491\n",
      "Epoch 3 Batch 2448 Loss 1.4319\n",
      "Epoch 3 Batch 2449 Loss 1.3255\n",
      "Epoch 3 Batch 2450 Loss 1.4260\n",
      "Epoch 3 Batch 2451 Loss 1.5520\n",
      "Epoch 3 Batch 2452 Loss 1.5756\n",
      "Epoch 3 Batch 2453 Loss 1.3405\n",
      "Epoch 3 Batch 2454 Loss 1.1225\n",
      "Epoch 3 Batch 2455 Loss 1.0731\n",
      "Epoch 3 Batch 2456 Loss 1.1077\n",
      "Epoch 3 Batch 2457 Loss 1.2109\n",
      "Epoch 3 Batch 2458 Loss 1.2727\n",
      "Epoch 3 Batch 2459 Loss 1.2670\n",
      "Epoch 3 Batch 2460 Loss 1.2497\n",
      "Epoch 3 Batch 2461 Loss 1.1863\n",
      "Epoch 3 Batch 2462 Loss 1.3675\n",
      "Epoch 3 Batch 2463 Loss 1.4514\n",
      "Epoch 3 Batch 2464 Loss 1.3633\n",
      "Epoch 3 Batch 2465 Loss 1.4049\n",
      "Epoch 3 Batch 2466 Loss 1.3732\n",
      "Epoch 3 Batch 2467 Loss 1.4710\n",
      "Epoch 3 Batch 2468 Loss 1.2038\n",
      "Epoch 3 Batch 2469 Loss 1.2519\n",
      "Epoch 3 Batch 2470 Loss 1.3182\n",
      "Epoch 3 Batch 2471 Loss 1.2783\n",
      "Epoch 3 Batch 2472 Loss 1.3549\n",
      "Epoch 3 Batch 2473 Loss 1.3300\n",
      "Epoch 3 Batch 2474 Loss 1.1458\n",
      "Epoch 3 Batch 2475 Loss 1.5599\n",
      "Epoch 3 Batch 2476 Loss 1.1191\n",
      "Epoch 3 Batch 2477 Loss 1.3950\n",
      "Epoch 3 Batch 2478 Loss 1.4064\n",
      "Epoch 3 Batch 2479 Loss 1.7473\n",
      "Epoch 3 Batch 2480 Loss 1.0630\n",
      "Epoch 3 Batch 2481 Loss 1.3668\n",
      "Epoch 3 Batch 2482 Loss 1.3301\n",
      "Epoch 3 Batch 2483 Loss 1.2058\n",
      "Epoch 3 Batch 2484 Loss 1.2927\n",
      "Epoch 3 Batch 2485 Loss 1.2469\n",
      "Epoch 3 Batch 2486 Loss 1.3650\n",
      "Epoch 3 Batch 2487 Loss 1.3717\n",
      "Epoch 3 Batch 2488 Loss 1.4079\n",
      "Epoch 3 Batch 2489 Loss 1.4534\n",
      "Epoch 3 Batch 2490 Loss 1.1693\n",
      "Epoch 3 Batch 2491 Loss 0.9707\n",
      "Epoch 3 Batch 2492 Loss 1.4619\n",
      "Epoch 3 Batch 2493 Loss 1.4636\n",
      "Epoch 3 Batch 2494 Loss 1.4375\n",
      "Epoch 3 Batch 2495 Loss 1.4470\n",
      "Epoch 3 Batch 2496 Loss 1.1190\n",
      "Epoch 3 Batch 2497 Loss 0.8816\n",
      "Epoch 3 Batch 2498 Loss 1.1925\n",
      "Epoch 3 Batch 2499 Loss 1.2796\n",
      "Epoch 3 Batch 2500 Loss 1.3742\n",
      "Epoch 3 Batch 2501 Loss 1.1275\n",
      "Epoch 3 Batch 2502 Loss 0.9943\n",
      "Epoch 3 Batch 2503 Loss 1.6450\n",
      "Epoch 3 Batch 2504 Loss 1.3717\n",
      "Epoch 3 Batch 2505 Loss 1.3482\n",
      "Epoch 3 Batch 2506 Loss 1.2245\n",
      "Epoch 3 Batch 2507 Loss 1.4210\n",
      "Epoch 3 Batch 2508 Loss 1.3635\n",
      "Epoch 3 Batch 2509 Loss 1.2213\n",
      "Epoch 3 Batch 2510 Loss 1.1498\n",
      "Epoch 3 Batch 2511 Loss 1.1267\n",
      "Epoch 3 Batch 2512 Loss 1.1516\n",
      "Epoch 3 Batch 2513 Loss 1.3703\n",
      "Epoch 3 Batch 2514 Loss 1.1873\n",
      "Epoch 3 Batch 2515 Loss 1.2150\n",
      "Epoch 3 Batch 2516 Loss 1.5778\n",
      "Epoch 3 Batch 2517 Loss 1.7825\n",
      "Epoch 3 Batch 2518 Loss 1.1068\n",
      "Epoch 3 Batch 2519 Loss 1.0926\n",
      "Epoch 3 Batch 2520 Loss 1.3228\n",
      "Epoch 3 Batch 2521 Loss 1.4290\n",
      "Epoch 3 Batch 2522 Loss 1.2566\n",
      "Epoch 3 Batch 2523 Loss 1.3958\n",
      "Epoch 3 Batch 2524 Loss 1.3880\n",
      "Epoch 3 Batch 2525 Loss 1.2791\n",
      "Epoch 3 Batch 2526 Loss 1.0354\n",
      "Epoch 3 Batch 2527 Loss 1.3126\n",
      "Epoch 3 Batch 2528 Loss 1.4049\n",
      "Epoch 3 Batch 2529 Loss 1.3568\n",
      "Epoch 3 Batch 2530 Loss 1.3774\n",
      "Epoch 3 Batch 2531 Loss 1.4465\n",
      "Epoch 3 Batch 2532 Loss 1.4481\n",
      "Epoch 3 Batch 2533 Loss 1.2632\n",
      "Epoch 3 Batch 2534 Loss 1.4680\n",
      "Epoch 3 Batch 2535 Loss 1.4908\n",
      "Epoch 3 Batch 2536 Loss 1.2727\n",
      "Epoch 3 Batch 2537 Loss 1.5008\n",
      "Epoch 3 Batch 2538 Loss 1.2780\n",
      "Epoch 3 Batch 2539 Loss 1.3260\n",
      "Epoch 3 Batch 2540 Loss 1.4461\n",
      "Epoch 3 Batch 2541 Loss 1.2014\n",
      "Epoch 3 Batch 2542 Loss 1.5238\n",
      "Epoch 3 Batch 2543 Loss 1.1288\n",
      "Epoch 3 Batch 2544 Loss 1.1950\n",
      "Epoch 3 Batch 2545 Loss 1.2315\n",
      "Epoch 3 Batch 2546 Loss 1.1564\n",
      "Epoch 3 Batch 2547 Loss 1.2331\n",
      "Epoch 3 Batch 2548 Loss 1.2219\n",
      "Epoch 3 Batch 2549 Loss 1.1755\n",
      "Epoch 3 Batch 2550 Loss 1.0721\n",
      "Epoch 3 Batch 2551 Loss 1.6856\n",
      "Epoch 3 Batch 2552 Loss 1.1063\n",
      "Epoch 3 Batch 2553 Loss 1.5061\n",
      "Epoch 3 Batch 2554 Loss 1.5077\n",
      "Epoch 3 Batch 2555 Loss 1.4776\n",
      "Epoch 3 Batch 2556 Loss 1.4266\n",
      "Epoch 3 Batch 2557 Loss 1.3836\n",
      "Epoch 3 Batch 2558 Loss 1.1291\n",
      "Epoch 3 Batch 2559 Loss 1.2286\n",
      "Epoch 3 Batch 2560 Loss 1.3551\n",
      "Epoch 3 Batch 2561 Loss 0.9396\n",
      "Epoch 3 Batch 2562 Loss 1.1835\n",
      "Epoch 3 Batch 2563 Loss 1.2602\n",
      "Epoch 3 Batch 2564 Loss 1.4231\n",
      "Epoch 3 Batch 2565 Loss 1.1940\n",
      "Epoch 3 Batch 2566 Loss 1.4423\n",
      "Epoch 3 Batch 2567 Loss 1.1819\n",
      "Epoch 3 Batch 2568 Loss 1.2018\n",
      "Epoch 3 Batch 2569 Loss 1.4230\n",
      "Epoch 3 Batch 2570 Loss 1.3525\n",
      "Epoch 3 Batch 2571 Loss 1.4258\n",
      "Epoch 3 Batch 2572 Loss 1.2296\n",
      "Epoch 3 Batch 2573 Loss 1.2878\n",
      "Epoch 3 Batch 2574 Loss 1.2819\n",
      "Epoch 3 Batch 2575 Loss 1.4770\n",
      "Epoch 3 Batch 2576 Loss 1.1493\n",
      "Epoch 3 Batch 2577 Loss 1.1317\n",
      "Epoch 3 Batch 2578 Loss 1.2258\n",
      "Epoch 3 Batch 2579 Loss 1.0303\n",
      "Epoch 3 Batch 2580 Loss 1.1527\n",
      "Epoch 3 Batch 2581 Loss 1.4932\n",
      "Epoch 3 Batch 2582 Loss 1.6321\n",
      "Epoch 3 Batch 2583 Loss 1.4719\n",
      "Epoch 3 Batch 2584 Loss 1.2923\n",
      "Epoch 3 Batch 2585 Loss 1.3293\n",
      "Epoch 3 Batch 2586 Loss 1.2147\n",
      "Epoch 3 Batch 2587 Loss 1.2506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:36:39<1:04:11, 1925.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Batch 2588 Loss 1.5767\n",
      "Epoch 3 Loss 1.3355\n",
      "Time taken for 1 epoch 1940.880223274231 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0888\n",
      "Epoch 4 Batch 1 Loss 1.2566\n",
      "Epoch 4 Batch 2 Loss 1.1330\n",
      "Epoch 4 Batch 3 Loss 1.0478\n",
      "Epoch 4 Batch 4 Loss 1.0408\n",
      "Epoch 4 Batch 5 Loss 1.1647\n",
      "Epoch 4 Batch 6 Loss 1.0679\n",
      "Epoch 4 Batch 7 Loss 1.3774\n",
      "Epoch 4 Batch 8 Loss 1.4561\n",
      "Epoch 4 Batch 9 Loss 1.2125\n",
      "Epoch 4 Batch 10 Loss 1.2542\n",
      "Epoch 4 Batch 11 Loss 1.1805\n",
      "Epoch 4 Batch 12 Loss 1.2381\n",
      "Epoch 4 Batch 13 Loss 1.1656\n",
      "Epoch 4 Batch 14 Loss 1.2581\n",
      "Epoch 4 Batch 15 Loss 1.0329\n",
      "Epoch 4 Batch 16 Loss 1.4202\n",
      "Epoch 4 Batch 17 Loss 1.1183\n",
      "Epoch 4 Batch 18 Loss 1.4189\n",
      "Epoch 4 Batch 19 Loss 1.1495\n",
      "Epoch 4 Batch 20 Loss 1.4130\n",
      "Epoch 4 Batch 21 Loss 1.3404\n",
      "Epoch 4 Batch 22 Loss 1.3915\n",
      "Epoch 4 Batch 23 Loss 1.3354\n",
      "Epoch 4 Batch 24 Loss 1.5257\n",
      "Epoch 4 Batch 25 Loss 1.2257\n",
      "Epoch 4 Batch 26 Loss 1.0224\n",
      "Epoch 4 Batch 27 Loss 1.1834\n",
      "Epoch 4 Batch 28 Loss 1.1778\n",
      "Epoch 4 Batch 29 Loss 0.9617\n",
      "Epoch 4 Batch 30 Loss 1.1500\n",
      "Epoch 4 Batch 31 Loss 0.9952\n",
      "Epoch 4 Batch 32 Loss 1.5361\n",
      "Epoch 4 Batch 33 Loss 0.9849\n",
      "Epoch 4 Batch 34 Loss 1.2326\n",
      "Epoch 4 Batch 35 Loss 1.0672\n",
      "Epoch 4 Batch 36 Loss 1.0080\n",
      "Epoch 4 Batch 37 Loss 1.2749\n",
      "Epoch 4 Batch 38 Loss 1.5284\n",
      "Epoch 4 Batch 39 Loss 1.0273\n",
      "Epoch 4 Batch 40 Loss 1.6987\n",
      "Epoch 4 Batch 41 Loss 1.2825\n",
      "Epoch 4 Batch 42 Loss 1.1579\n",
      "Epoch 4 Batch 43 Loss 1.3495\n",
      "Epoch 4 Batch 44 Loss 1.4416\n",
      "Epoch 4 Batch 45 Loss 1.4273\n",
      "Epoch 4 Batch 46 Loss 1.3891\n",
      "Epoch 4 Batch 47 Loss 0.9219\n",
      "Epoch 4 Batch 48 Loss 1.1851\n",
      "Epoch 4 Batch 49 Loss 1.3548\n",
      "Epoch 4 Batch 50 Loss 0.9901\n",
      "Epoch 4 Batch 51 Loss 0.8754\n",
      "Epoch 4 Batch 52 Loss 1.4490\n",
      "Epoch 4 Batch 53 Loss 0.8316\n",
      "Epoch 4 Batch 54 Loss 1.4210\n",
      "Epoch 4 Batch 55 Loss 1.3607\n",
      "Epoch 4 Batch 56 Loss 1.4066\n",
      "Epoch 4 Batch 57 Loss 1.0490\n",
      "Epoch 4 Batch 58 Loss 1.5424\n",
      "Epoch 4 Batch 59 Loss 1.7257\n",
      "Epoch 4 Batch 60 Loss 0.9971\n",
      "Epoch 4 Batch 61 Loss 1.0252\n",
      "Epoch 4 Batch 62 Loss 1.0126\n",
      "Epoch 4 Batch 63 Loss 1.2992\n",
      "Epoch 4 Batch 64 Loss 1.2678\n",
      "Epoch 4 Batch 65 Loss 1.2181\n",
      "Epoch 4 Batch 66 Loss 1.2740\n",
      "Epoch 4 Batch 67 Loss 1.3419\n",
      "Epoch 4 Batch 68 Loss 1.3416\n",
      "Epoch 4 Batch 69 Loss 1.2564\n",
      "Epoch 4 Batch 70 Loss 1.1112\n",
      "Epoch 4 Batch 71 Loss 1.0667\n",
      "Epoch 4 Batch 72 Loss 1.1786\n",
      "Epoch 4 Batch 73 Loss 1.2350\n",
      "Epoch 4 Batch 74 Loss 1.1176\n",
      "Epoch 4 Batch 75 Loss 1.0891\n",
      "Epoch 4 Batch 76 Loss 1.1521\n",
      "Epoch 4 Batch 77 Loss 1.3360\n",
      "Epoch 4 Batch 78 Loss 1.1393\n",
      "Epoch 4 Batch 79 Loss 1.1402\n",
      "Epoch 4 Batch 80 Loss 1.2584\n",
      "Epoch 4 Batch 81 Loss 1.3238\n",
      "Epoch 4 Batch 82 Loss 1.2502\n",
      "Epoch 4 Batch 83 Loss 1.1179\n",
      "Epoch 4 Batch 84 Loss 0.8738\n",
      "Epoch 4 Batch 85 Loss 1.2335\n",
      "Epoch 4 Batch 86 Loss 1.0275\n",
      "Epoch 4 Batch 87 Loss 1.3263\n",
      "Epoch 4 Batch 88 Loss 1.3434\n",
      "Epoch 4 Batch 89 Loss 1.1179\n",
      "Epoch 4 Batch 90 Loss 1.0752\n",
      "Epoch 4 Batch 91 Loss 1.1337\n",
      "Epoch 4 Batch 92 Loss 1.3063\n",
      "Epoch 4 Batch 93 Loss 1.1871\n",
      "Epoch 4 Batch 94 Loss 0.9947\n",
      "Epoch 4 Batch 95 Loss 1.1891\n",
      "Epoch 4 Batch 96 Loss 1.0979\n",
      "Epoch 4 Batch 97 Loss 1.2178\n",
      "Epoch 4 Batch 98 Loss 1.0828\n",
      "Epoch 4 Batch 99 Loss 1.3094\n",
      "Epoch 4 Batch 100 Loss 1.3151\n",
      "Epoch 4 Batch 101 Loss 1.3162\n",
      "Epoch 4 Batch 102 Loss 1.0297\n",
      "Epoch 4 Batch 103 Loss 1.2481\n",
      "Epoch 4 Batch 104 Loss 1.1876\n",
      "Epoch 4 Batch 105 Loss 1.3154\n",
      "Epoch 4 Batch 106 Loss 1.3771\n",
      "Epoch 4 Batch 107 Loss 1.1563\n",
      "Epoch 4 Batch 108 Loss 1.0290\n",
      "Epoch 4 Batch 109 Loss 0.8795\n",
      "Epoch 4 Batch 110 Loss 1.4357\n",
      "Epoch 4 Batch 111 Loss 1.4164\n",
      "Epoch 4 Batch 112 Loss 1.2863\n",
      "Epoch 4 Batch 113 Loss 1.2844\n",
      "Epoch 4 Batch 114 Loss 1.3040\n",
      "Epoch 4 Batch 115 Loss 1.0623\n",
      "Epoch 4 Batch 116 Loss 1.3802\n",
      "Epoch 4 Batch 117 Loss 1.0607\n",
      "Epoch 4 Batch 118 Loss 1.0124\n",
      "Epoch 4 Batch 119 Loss 1.2262\n",
      "Epoch 4 Batch 120 Loss 1.2506\n",
      "Epoch 4 Batch 121 Loss 1.0132\n",
      "Epoch 4 Batch 122 Loss 1.2115\n",
      "Epoch 4 Batch 123 Loss 1.3856\n",
      "Epoch 4 Batch 124 Loss 1.4316\n",
      "Epoch 4 Batch 125 Loss 1.4928\n",
      "Epoch 4 Batch 126 Loss 1.1180\n",
      "Epoch 4 Batch 127 Loss 1.3045\n",
      "Epoch 4 Batch 128 Loss 1.2588\n",
      "Epoch 4 Batch 129 Loss 1.1506\n",
      "Epoch 4 Batch 130 Loss 1.3141\n",
      "Epoch 4 Batch 131 Loss 0.9205\n",
      "Epoch 4 Batch 132 Loss 1.1914\n",
      "Epoch 4 Batch 133 Loss 1.0753\n",
      "Epoch 4 Batch 134 Loss 1.0798\n",
      "Epoch 4 Batch 135 Loss 1.1481\n",
      "Epoch 4 Batch 136 Loss 1.1290\n",
      "Epoch 4 Batch 137 Loss 1.3715\n",
      "Epoch 4 Batch 138 Loss 1.3177\n",
      "Epoch 4 Batch 139 Loss 1.3939\n",
      "Epoch 4 Batch 140 Loss 1.5646\n",
      "Epoch 4 Batch 141 Loss 1.0956\n",
      "Epoch 4 Batch 142 Loss 1.2790\n",
      "Epoch 4 Batch 143 Loss 1.3279\n",
      "Epoch 4 Batch 144 Loss 1.4026\n",
      "Epoch 4 Batch 145 Loss 1.3107\n",
      "Epoch 4 Batch 146 Loss 1.5275\n",
      "Epoch 4 Batch 147 Loss 1.3375\n",
      "Epoch 4 Batch 148 Loss 0.9246\n",
      "Epoch 4 Batch 149 Loss 1.3568\n",
      "Epoch 4 Batch 150 Loss 1.2366\n",
      "Epoch 4 Batch 151 Loss 1.2829\n",
      "Epoch 4 Batch 152 Loss 1.1013\n",
      "Epoch 4 Batch 153 Loss 1.2266\n",
      "Epoch 4 Batch 154 Loss 1.3171\n",
      "Epoch 4 Batch 155 Loss 1.2217\n",
      "Epoch 4 Batch 156 Loss 1.3174\n",
      "Epoch 4 Batch 157 Loss 1.2594\n",
      "Epoch 4 Batch 158 Loss 1.2246\n",
      "Epoch 4 Batch 159 Loss 1.3535\n",
      "Epoch 4 Batch 160 Loss 1.1841\n",
      "Epoch 4 Batch 161 Loss 0.9740\n",
      "Epoch 4 Batch 162 Loss 1.0908\n",
      "Epoch 4 Batch 163 Loss 1.1415\n",
      "Epoch 4 Batch 164 Loss 1.5954\n",
      "Epoch 4 Batch 165 Loss 1.1979\n",
      "Epoch 4 Batch 166 Loss 0.9376\n",
      "Epoch 4 Batch 167 Loss 1.3417\n",
      "Epoch 4 Batch 168 Loss 1.3004\n",
      "Epoch 4 Batch 169 Loss 1.1343\n",
      "Epoch 4 Batch 170 Loss 1.3978\n",
      "Epoch 4 Batch 171 Loss 1.1434\n",
      "Epoch 4 Batch 172 Loss 1.5295\n",
      "Epoch 4 Batch 173 Loss 1.3643\n",
      "Epoch 4 Batch 174 Loss 0.9065\n",
      "Epoch 4 Batch 175 Loss 0.9328\n",
      "Epoch 4 Batch 176 Loss 1.2806\n",
      "Epoch 4 Batch 177 Loss 1.1511\n",
      "Epoch 4 Batch 178 Loss 1.1536\n",
      "Epoch 4 Batch 179 Loss 0.9324\n",
      "Epoch 4 Batch 180 Loss 0.9338\n",
      "Epoch 4 Batch 181 Loss 1.4241\n",
      "Epoch 4 Batch 182 Loss 1.2297\n",
      "Epoch 4 Batch 183 Loss 0.9426\n",
      "Epoch 4 Batch 184 Loss 1.2259\n",
      "Epoch 4 Batch 185 Loss 1.5066\n",
      "Epoch 4 Batch 186 Loss 1.3065\n",
      "Epoch 4 Batch 187 Loss 1.1809\n",
      "Epoch 4 Batch 188 Loss 1.2359\n",
      "Epoch 4 Batch 189 Loss 1.1287\n",
      "Epoch 4 Batch 190 Loss 1.4916\n",
      "Epoch 4 Batch 191 Loss 1.5482\n",
      "Epoch 4 Batch 192 Loss 1.2067\n",
      "Epoch 4 Batch 193 Loss 1.2869\n",
      "Epoch 4 Batch 194 Loss 0.9871\n",
      "Epoch 4 Batch 195 Loss 1.2040\n",
      "Epoch 4 Batch 196 Loss 1.3023\n",
      "Epoch 4 Batch 197 Loss 1.3710\n",
      "Epoch 4 Batch 198 Loss 1.3555\n",
      "Epoch 4 Batch 199 Loss 1.1872\n",
      "Epoch 4 Batch 200 Loss 1.0942\n",
      "Epoch 4 Batch 201 Loss 1.5083\n",
      "Epoch 4 Batch 202 Loss 1.0677\n",
      "Epoch 4 Batch 203 Loss 0.9313\n",
      "Epoch 4 Batch 204 Loss 1.4307\n",
      "Epoch 4 Batch 205 Loss 1.0700\n",
      "Epoch 4 Batch 206 Loss 1.1751\n",
      "Epoch 4 Batch 207 Loss 1.4144\n",
      "Epoch 4 Batch 208 Loss 1.2336\n",
      "Epoch 4 Batch 209 Loss 0.7873\n",
      "Epoch 4 Batch 210 Loss 1.0128\n",
      "Epoch 4 Batch 211 Loss 1.0464\n",
      "Epoch 4 Batch 212 Loss 1.4066\n",
      "Epoch 4 Batch 213 Loss 1.0635\n",
      "Epoch 4 Batch 214 Loss 1.2505\n",
      "Epoch 4 Batch 215 Loss 1.4779\n",
      "Epoch 4 Batch 216 Loss 1.2331\n",
      "Epoch 4 Batch 217 Loss 1.2368\n",
      "Epoch 4 Batch 218 Loss 1.3250\n",
      "Epoch 4 Batch 219 Loss 1.0819\n",
      "Epoch 4 Batch 220 Loss 1.0223\n",
      "Epoch 4 Batch 221 Loss 1.0680\n",
      "Epoch 4 Batch 222 Loss 1.4810\n",
      "Epoch 4 Batch 223 Loss 1.3669\n",
      "Epoch 4 Batch 224 Loss 1.2331\n",
      "Epoch 4 Batch 225 Loss 1.3845\n",
      "Epoch 4 Batch 226 Loss 1.0209\n",
      "Epoch 4 Batch 227 Loss 1.0693\n",
      "Epoch 4 Batch 228 Loss 1.0928\n",
      "Epoch 4 Batch 229 Loss 1.0009\n",
      "Epoch 4 Batch 230 Loss 1.1648\n",
      "Epoch 4 Batch 231 Loss 1.3429\n",
      "Epoch 4 Batch 232 Loss 1.2354\n",
      "Epoch 4 Batch 233 Loss 1.0729\n",
      "Epoch 4 Batch 234 Loss 1.1376\n",
      "Epoch 4 Batch 235 Loss 1.0707\n",
      "Epoch 4 Batch 236 Loss 1.3053\n",
      "Epoch 4 Batch 237 Loss 1.2961\n",
      "Epoch 4 Batch 238 Loss 1.5392\n",
      "Epoch 4 Batch 239 Loss 1.1601\n",
      "Epoch 4 Batch 240 Loss 1.0280\n",
      "Epoch 4 Batch 241 Loss 1.1964\n",
      "Epoch 4 Batch 242 Loss 1.3905\n",
      "Epoch 4 Batch 243 Loss 1.2678\n",
      "Epoch 4 Batch 244 Loss 1.2560\n",
      "Epoch 4 Batch 245 Loss 1.1391\n",
      "Epoch 4 Batch 246 Loss 1.2723\n",
      "Epoch 4 Batch 247 Loss 1.0901\n",
      "Epoch 4 Batch 248 Loss 1.4430\n",
      "Epoch 4 Batch 249 Loss 1.2571\n",
      "Epoch 4 Batch 250 Loss 0.8224\n",
      "Epoch 4 Batch 251 Loss 1.2158\n",
      "Epoch 4 Batch 252 Loss 0.9258\n",
      "Epoch 4 Batch 253 Loss 0.9463\n",
      "Epoch 4 Batch 254 Loss 1.3202\n",
      "Epoch 4 Batch 255 Loss 1.2003\n",
      "Epoch 4 Batch 256 Loss 1.1891\n",
      "Epoch 4 Batch 257 Loss 1.3883\n",
      "Epoch 4 Batch 258 Loss 1.1510\n",
      "Epoch 4 Batch 259 Loss 1.1437\n",
      "Epoch 4 Batch 260 Loss 1.3306\n",
      "Epoch 4 Batch 261 Loss 1.3376\n",
      "Epoch 4 Batch 262 Loss 1.4109\n",
      "Epoch 4 Batch 263 Loss 1.1430\n",
      "Epoch 4 Batch 264 Loss 1.1695\n",
      "Epoch 4 Batch 265 Loss 1.2610\n",
      "Epoch 4 Batch 266 Loss 1.2046\n",
      "Epoch 4 Batch 267 Loss 1.0834\n",
      "Epoch 4 Batch 268 Loss 1.1027\n",
      "Epoch 4 Batch 269 Loss 1.2948\n",
      "Epoch 4 Batch 270 Loss 1.1739\n",
      "Epoch 4 Batch 271 Loss 1.0162\n",
      "Epoch 4 Batch 272 Loss 1.0494\n",
      "Epoch 4 Batch 273 Loss 1.3301\n",
      "Epoch 4 Batch 274 Loss 1.2822\n",
      "Epoch 4 Batch 275 Loss 1.2595\n",
      "Epoch 4 Batch 276 Loss 1.0828\n",
      "Epoch 4 Batch 277 Loss 1.3729\n",
      "Epoch 4 Batch 278 Loss 1.1618\n",
      "Epoch 4 Batch 279 Loss 1.1262\n",
      "Epoch 4 Batch 280 Loss 1.3136\n",
      "Epoch 4 Batch 281 Loss 0.8124\n",
      "Epoch 4 Batch 282 Loss 1.5379\n",
      "Epoch 4 Batch 283 Loss 1.5159\n",
      "Epoch 4 Batch 284 Loss 1.2466\n",
      "Epoch 4 Batch 285 Loss 1.3773\n",
      "Epoch 4 Batch 286 Loss 1.4516\n",
      "Epoch 4 Batch 287 Loss 1.3510\n",
      "Epoch 4 Batch 288 Loss 1.2651\n",
      "Epoch 4 Batch 289 Loss 1.1799\n",
      "Epoch 4 Batch 290 Loss 1.1811\n",
      "Epoch 4 Batch 291 Loss 0.9458\n",
      "Epoch 4 Batch 292 Loss 1.2477\n",
      "Epoch 4 Batch 293 Loss 1.1506\n",
      "Epoch 4 Batch 294 Loss 1.2620\n",
      "Epoch 4 Batch 295 Loss 1.3919\n",
      "Epoch 4 Batch 296 Loss 1.2673\n",
      "Epoch 4 Batch 297 Loss 0.9771\n",
      "Epoch 4 Batch 298 Loss 1.3351\n",
      "Epoch 4 Batch 299 Loss 1.1792\n",
      "Epoch 4 Batch 300 Loss 0.9483\n",
      "Epoch 4 Batch 301 Loss 1.4100\n",
      "Epoch 4 Batch 302 Loss 0.9185\n",
      "Epoch 4 Batch 303 Loss 1.4600\n",
      "Epoch 4 Batch 304 Loss 1.0447\n",
      "Epoch 4 Batch 305 Loss 1.2976\n",
      "Epoch 4 Batch 306 Loss 1.4486\n",
      "Epoch 4 Batch 307 Loss 0.9054\n",
      "Epoch 4 Batch 308 Loss 1.2487\n",
      "Epoch 4 Batch 309 Loss 1.2244\n",
      "Epoch 4 Batch 310 Loss 1.2331\n",
      "Epoch 4 Batch 311 Loss 1.2189\n",
      "Epoch 4 Batch 312 Loss 1.6190\n",
      "Epoch 4 Batch 313 Loss 1.2538\n",
      "Epoch 4 Batch 314 Loss 1.2593\n",
      "Epoch 4 Batch 315 Loss 1.2437\n",
      "Epoch 4 Batch 316 Loss 1.1381\n",
      "Epoch 4 Batch 317 Loss 1.3731\n",
      "Epoch 4 Batch 318 Loss 1.3701\n",
      "Epoch 4 Batch 319 Loss 1.4757\n",
      "Epoch 4 Batch 320 Loss 1.0190\n",
      "Epoch 4 Batch 321 Loss 1.2188\n",
      "Epoch 4 Batch 322 Loss 0.9925\n",
      "Epoch 4 Batch 323 Loss 1.1989\n",
      "Epoch 4 Batch 324 Loss 0.9570\n",
      "Epoch 4 Batch 325 Loss 1.1189\n",
      "Epoch 4 Batch 326 Loss 0.8725\n",
      "Epoch 4 Batch 327 Loss 1.2879\n",
      "Epoch 4 Batch 328 Loss 1.0763\n",
      "Epoch 4 Batch 329 Loss 1.2020\n",
      "Epoch 4 Batch 330 Loss 1.1221\n",
      "Epoch 4 Batch 331 Loss 1.5370\n",
      "Epoch 4 Batch 332 Loss 1.2246\n",
      "Epoch 4 Batch 333 Loss 1.4594\n",
      "Epoch 4 Batch 334 Loss 1.2005\n",
      "Epoch 4 Batch 335 Loss 1.2474\n",
      "Epoch 4 Batch 336 Loss 1.3000\n",
      "Epoch 4 Batch 337 Loss 1.2387\n",
      "Epoch 4 Batch 338 Loss 1.1756\n",
      "Epoch 4 Batch 339 Loss 1.1800\n",
      "Epoch 4 Batch 340 Loss 1.2470\n",
      "Epoch 4 Batch 341 Loss 1.1757\n",
      "Epoch 4 Batch 342 Loss 1.2366\n",
      "Epoch 4 Batch 343 Loss 1.2833\n",
      "Epoch 4 Batch 344 Loss 1.2538\n",
      "Epoch 4 Batch 345 Loss 1.2132\n",
      "Epoch 4 Batch 346 Loss 1.1973\n",
      "Epoch 4 Batch 347 Loss 1.2309\n",
      "Epoch 4 Batch 348 Loss 1.1511\n",
      "Epoch 4 Batch 349 Loss 1.4273\n",
      "Epoch 4 Batch 350 Loss 1.1275\n",
      "Epoch 4 Batch 351 Loss 1.3605\n",
      "Epoch 4 Batch 352 Loss 1.2128\n",
      "Epoch 4 Batch 353 Loss 1.0718\n",
      "Epoch 4 Batch 354 Loss 1.0890\n",
      "Epoch 4 Batch 355 Loss 1.3530\n",
      "Epoch 4 Batch 356 Loss 1.0884\n",
      "Epoch 4 Batch 357 Loss 1.2696\n",
      "Epoch 4 Batch 358 Loss 1.0419\n",
      "Epoch 4 Batch 359 Loss 1.3618\n",
      "Epoch 4 Batch 360 Loss 0.9756\n",
      "Epoch 4 Batch 361 Loss 1.0053\n",
      "Epoch 4 Batch 362 Loss 1.2406\n",
      "Epoch 4 Batch 363 Loss 1.2311\n",
      "Epoch 4 Batch 364 Loss 1.0578\n",
      "Epoch 4 Batch 365 Loss 1.0637\n",
      "Epoch 4 Batch 366 Loss 1.0921\n",
      "Epoch 4 Batch 367 Loss 1.1535\n",
      "Epoch 4 Batch 368 Loss 1.0849\n",
      "Epoch 4 Batch 369 Loss 1.1392\n",
      "Epoch 4 Batch 370 Loss 1.1951\n",
      "Epoch 4 Batch 371 Loss 1.3141\n",
      "Epoch 4 Batch 372 Loss 1.4723\n",
      "Epoch 4 Batch 373 Loss 1.5728\n",
      "Epoch 4 Batch 374 Loss 1.3839\n",
      "Epoch 4 Batch 375 Loss 1.1992\n",
      "Epoch 4 Batch 376 Loss 1.4710\n",
      "Epoch 4 Batch 377 Loss 1.1951\n",
      "Epoch 4 Batch 378 Loss 1.0098\n",
      "Epoch 4 Batch 379 Loss 1.0652\n",
      "Epoch 4 Batch 380 Loss 1.0527\n",
      "Epoch 4 Batch 381 Loss 1.2306\n",
      "Epoch 4 Batch 382 Loss 1.5303\n",
      "Epoch 4 Batch 383 Loss 1.1094\n",
      "Epoch 4 Batch 384 Loss 1.4395\n",
      "Epoch 4 Batch 385 Loss 1.4048\n",
      "Epoch 4 Batch 386 Loss 1.2198\n",
      "Epoch 4 Batch 387 Loss 1.2640\n",
      "Epoch 4 Batch 388 Loss 1.3443\n",
      "Epoch 4 Batch 389 Loss 1.3573\n",
      "Epoch 4 Batch 390 Loss 1.2928\n",
      "Epoch 4 Batch 391 Loss 1.4948\n",
      "Epoch 4 Batch 392 Loss 1.2077\n",
      "Epoch 4 Batch 393 Loss 0.9671\n",
      "Epoch 4 Batch 394 Loss 1.2216\n",
      "Epoch 4 Batch 395 Loss 1.3473\n",
      "Epoch 4 Batch 396 Loss 1.4298\n",
      "Epoch 4 Batch 397 Loss 1.0947\n",
      "Epoch 4 Batch 398 Loss 1.2516\n",
      "Epoch 4 Batch 399 Loss 1.5008\n",
      "Epoch 4 Batch 400 Loss 1.3418\n",
      "Epoch 4 Batch 401 Loss 1.3424\n",
      "Epoch 4 Batch 402 Loss 1.1923\n",
      "Epoch 4 Batch 403 Loss 1.0752\n",
      "Epoch 4 Batch 404 Loss 1.3226\n",
      "Epoch 4 Batch 405 Loss 1.1324\n",
      "Epoch 4 Batch 406 Loss 1.4188\n",
      "Epoch 4 Batch 407 Loss 1.3049\n",
      "Epoch 4 Batch 408 Loss 1.0172\n",
      "Epoch 4 Batch 409 Loss 1.0309\n",
      "Epoch 4 Batch 410 Loss 1.3294\n",
      "Epoch 4 Batch 411 Loss 1.2566\n",
      "Epoch 4 Batch 412 Loss 1.2973\n",
      "Epoch 4 Batch 413 Loss 1.3973\n",
      "Epoch 4 Batch 414 Loss 1.3162\n",
      "Epoch 4 Batch 415 Loss 1.3471\n",
      "Epoch 4 Batch 416 Loss 1.0391\n",
      "Epoch 4 Batch 417 Loss 1.2897\n",
      "Epoch 4 Batch 418 Loss 1.3043\n",
      "Epoch 4 Batch 419 Loss 1.0444\n",
      "Epoch 4 Batch 420 Loss 1.0801\n",
      "Epoch 4 Batch 421 Loss 1.4563\n",
      "Epoch 4 Batch 422 Loss 1.2563\n",
      "Epoch 4 Batch 423 Loss 1.5462\n",
      "Epoch 4 Batch 424 Loss 1.2552\n",
      "Epoch 4 Batch 425 Loss 1.1179\n",
      "Epoch 4 Batch 426 Loss 1.4031\n",
      "Epoch 4 Batch 427 Loss 1.0167\n",
      "Epoch 4 Batch 428 Loss 1.1402\n",
      "Epoch 4 Batch 429 Loss 1.2511\n",
      "Epoch 4 Batch 430 Loss 1.0873\n",
      "Epoch 4 Batch 431 Loss 1.0014\n",
      "Epoch 4 Batch 432 Loss 1.3884\n",
      "Epoch 4 Batch 433 Loss 1.1617\n",
      "Epoch 4 Batch 434 Loss 1.2657\n",
      "Epoch 4 Batch 435 Loss 1.1737\n",
      "Epoch 4 Batch 436 Loss 1.1410\n",
      "Epoch 4 Batch 437 Loss 1.2729\n",
      "Epoch 4 Batch 438 Loss 1.6984\n",
      "Epoch 4 Batch 439 Loss 1.1752\n",
      "Epoch 4 Batch 440 Loss 1.1247\n",
      "Epoch 4 Batch 441 Loss 1.3982\n",
      "Epoch 4 Batch 442 Loss 1.4198\n",
      "Epoch 4 Batch 443 Loss 1.2839\n",
      "Epoch 4 Batch 444 Loss 1.1516\n",
      "Epoch 4 Batch 445 Loss 1.4367\n",
      "Epoch 4 Batch 446 Loss 1.3104\n",
      "Epoch 4 Batch 447 Loss 1.0737\n",
      "Epoch 4 Batch 448 Loss 1.0411\n",
      "Epoch 4 Batch 449 Loss 1.3002\n",
      "Epoch 4 Batch 450 Loss 1.0739\n",
      "Epoch 4 Batch 451 Loss 0.9867\n",
      "Epoch 4 Batch 452 Loss 0.9052\n",
      "Epoch 4 Batch 453 Loss 1.5093\n",
      "Epoch 4 Batch 454 Loss 1.4110\n",
      "Epoch 4 Batch 455 Loss 1.2513\n",
      "Epoch 4 Batch 456 Loss 1.2185\n",
      "Epoch 4 Batch 457 Loss 1.3808\n",
      "Epoch 4 Batch 458 Loss 1.1322\n",
      "Epoch 4 Batch 459 Loss 1.2126\n",
      "Epoch 4 Batch 460 Loss 1.1624\n",
      "Epoch 4 Batch 461 Loss 1.1885\n",
      "Epoch 4 Batch 462 Loss 1.2626\n",
      "Epoch 4 Batch 463 Loss 0.7723\n",
      "Epoch 4 Batch 464 Loss 1.2117\n",
      "Epoch 4 Batch 465 Loss 1.1782\n",
      "Epoch 4 Batch 466 Loss 1.2249\n",
      "Epoch 4 Batch 467 Loss 1.2650\n",
      "Epoch 4 Batch 468 Loss 1.2586\n",
      "Epoch 4 Batch 469 Loss 1.4264\n",
      "Epoch 4 Batch 470 Loss 1.2515\n",
      "Epoch 4 Batch 471 Loss 0.9457\n",
      "Epoch 4 Batch 472 Loss 1.0582\n",
      "Epoch 4 Batch 473 Loss 1.1506\n",
      "Epoch 4 Batch 474 Loss 1.2138\n",
      "Epoch 4 Batch 475 Loss 1.2265\n",
      "Epoch 4 Batch 476 Loss 1.0727\n",
      "Epoch 4 Batch 477 Loss 1.3716\n",
      "Epoch 4 Batch 478 Loss 1.0457\n",
      "Epoch 4 Batch 479 Loss 1.3322\n",
      "Epoch 4 Batch 480 Loss 1.4843\n",
      "Epoch 4 Batch 481 Loss 1.2070\n",
      "Epoch 4 Batch 482 Loss 1.1636\n",
      "Epoch 4 Batch 483 Loss 1.2750\n",
      "Epoch 4 Batch 484 Loss 1.2094\n",
      "Epoch 4 Batch 485 Loss 1.2199\n",
      "Epoch 4 Batch 486 Loss 1.1166\n",
      "Epoch 4 Batch 487 Loss 1.0462\n",
      "Epoch 4 Batch 488 Loss 1.2256\n",
      "Epoch 4 Batch 489 Loss 1.0036\n",
      "Epoch 4 Batch 490 Loss 1.3502\n",
      "Epoch 4 Batch 491 Loss 1.1182\n",
      "Epoch 4 Batch 492 Loss 1.3142\n",
      "Epoch 4 Batch 493 Loss 1.1017\n",
      "Epoch 4 Batch 494 Loss 1.1383\n",
      "Epoch 4 Batch 495 Loss 1.1882\n",
      "Epoch 4 Batch 496 Loss 1.3476\n",
      "Epoch 4 Batch 497 Loss 1.2938\n",
      "Epoch 4 Batch 498 Loss 1.3648\n",
      "Epoch 4 Batch 499 Loss 1.1507\n",
      "Epoch 4 Batch 500 Loss 1.1337\n",
      "Epoch 4 Batch 501 Loss 1.1914\n",
      "Epoch 4 Batch 502 Loss 1.2075\n",
      "Epoch 4 Batch 503 Loss 1.2135\n",
      "Epoch 4 Batch 504 Loss 1.0974\n",
      "Epoch 4 Batch 505 Loss 0.9451\n",
      "Epoch 4 Batch 506 Loss 1.3293\n",
      "Epoch 4 Batch 507 Loss 1.3775\n",
      "Epoch 4 Batch 508 Loss 0.9564\n",
      "Epoch 4 Batch 509 Loss 1.1545\n",
      "Epoch 4 Batch 510 Loss 1.2748\n",
      "Epoch 4 Batch 511 Loss 1.4096\n",
      "Epoch 4 Batch 512 Loss 1.1164\n",
      "Epoch 4 Batch 513 Loss 1.3017\n",
      "Epoch 4 Batch 514 Loss 1.1460\n",
      "Epoch 4 Batch 515 Loss 1.0645\n",
      "Epoch 4 Batch 516 Loss 1.5980\n",
      "Epoch 4 Batch 517 Loss 1.0876\n",
      "Epoch 4 Batch 518 Loss 1.1861\n",
      "Epoch 4 Batch 519 Loss 1.3604\n",
      "Epoch 4 Batch 520 Loss 1.1809\n",
      "Epoch 4 Batch 521 Loss 1.3382\n",
      "Epoch 4 Batch 522 Loss 1.0790\n",
      "Epoch 4 Batch 523 Loss 1.4284\n",
      "Epoch 4 Batch 524 Loss 1.0478\n",
      "Epoch 4 Batch 525 Loss 1.2001\n",
      "Epoch 4 Batch 526 Loss 1.2716\n",
      "Epoch 4 Batch 527 Loss 1.3734\n",
      "Epoch 4 Batch 528 Loss 1.1300\n",
      "Epoch 4 Batch 529 Loss 1.2207\n",
      "Epoch 4 Batch 530 Loss 1.7766\n",
      "Epoch 4 Batch 531 Loss 1.0647\n",
      "Epoch 4 Batch 532 Loss 1.3642\n",
      "Epoch 4 Batch 533 Loss 1.1868\n",
      "Epoch 4 Batch 534 Loss 1.3460\n",
      "Epoch 4 Batch 535 Loss 1.2182\n",
      "Epoch 4 Batch 536 Loss 1.0006\n",
      "Epoch 4 Batch 537 Loss 1.3619\n",
      "Epoch 4 Batch 538 Loss 1.0889\n",
      "Epoch 4 Batch 539 Loss 1.3609\n",
      "Epoch 4 Batch 540 Loss 1.0606\n",
      "Epoch 4 Batch 541 Loss 1.2219\n",
      "Epoch 4 Batch 542 Loss 1.2216\n",
      "Epoch 4 Batch 543 Loss 1.1768\n",
      "Epoch 4 Batch 544 Loss 1.5365\n",
      "Epoch 4 Batch 545 Loss 1.1909\n",
      "Epoch 4 Batch 546 Loss 1.0487\n",
      "Epoch 4 Batch 547 Loss 1.4505\n",
      "Epoch 4 Batch 548 Loss 1.0824\n",
      "Epoch 4 Batch 549 Loss 0.9727\n",
      "Epoch 4 Batch 550 Loss 1.1957\n",
      "Epoch 4 Batch 551 Loss 1.1944\n",
      "Epoch 4 Batch 552 Loss 1.3898\n",
      "Epoch 4 Batch 553 Loss 1.2894\n",
      "Epoch 4 Batch 554 Loss 1.4106\n",
      "Epoch 4 Batch 555 Loss 0.9951\n",
      "Epoch 4 Batch 556 Loss 1.1699\n",
      "Epoch 4 Batch 557 Loss 1.0900\n",
      "Epoch 4 Batch 558 Loss 1.3109\n",
      "Epoch 4 Batch 559 Loss 0.9808\n",
      "Epoch 4 Batch 560 Loss 1.1217\n",
      "Epoch 4 Batch 561 Loss 1.4123\n",
      "Epoch 4 Batch 562 Loss 1.2939\n",
      "Epoch 4 Batch 563 Loss 1.2194\n",
      "Epoch 4 Batch 564 Loss 1.4844\n",
      "Epoch 4 Batch 565 Loss 1.3342\n",
      "Epoch 4 Batch 566 Loss 1.0944\n",
      "Epoch 4 Batch 567 Loss 1.3501\n",
      "Epoch 4 Batch 568 Loss 1.4654\n",
      "Epoch 4 Batch 569 Loss 1.3335\n",
      "Epoch 4 Batch 570 Loss 1.5242\n",
      "Epoch 4 Batch 571 Loss 1.1112\n",
      "Epoch 4 Batch 572 Loss 1.0445\n",
      "Epoch 4 Batch 573 Loss 1.3218\n",
      "Epoch 4 Batch 574 Loss 1.1861\n",
      "Epoch 4 Batch 575 Loss 1.1542\n",
      "Epoch 4 Batch 576 Loss 1.1912\n",
      "Epoch 4 Batch 577 Loss 1.1999\n",
      "Epoch 4 Batch 578 Loss 1.1312\n",
      "Epoch 4 Batch 579 Loss 1.0180\n",
      "Epoch 4 Batch 580 Loss 1.2903\n",
      "Epoch 4 Batch 581 Loss 1.1016\n",
      "Epoch 4 Batch 582 Loss 1.4789\n",
      "Epoch 4 Batch 583 Loss 1.3042\n",
      "Epoch 4 Batch 584 Loss 1.4108\n",
      "Epoch 4 Batch 585 Loss 1.0760\n",
      "Epoch 4 Batch 586 Loss 1.3329\n",
      "Epoch 4 Batch 587 Loss 1.0353\n",
      "Epoch 4 Batch 588 Loss 1.1113\n",
      "Epoch 4 Batch 589 Loss 1.3900\n",
      "Epoch 4 Batch 590 Loss 1.1714\n",
      "Epoch 4 Batch 591 Loss 1.4775\n",
      "Epoch 4 Batch 592 Loss 1.2400\n",
      "Epoch 4 Batch 593 Loss 1.5122\n",
      "Epoch 4 Batch 594 Loss 1.3749\n",
      "Epoch 4 Batch 595 Loss 1.1741\n",
      "Epoch 4 Batch 596 Loss 1.0592\n",
      "Epoch 4 Batch 597 Loss 1.4719\n",
      "Epoch 4 Batch 598 Loss 1.1810\n",
      "Epoch 4 Batch 599 Loss 1.4299\n",
      "Epoch 4 Batch 600 Loss 1.3004\n",
      "Epoch 4 Batch 601 Loss 1.2233\n",
      "Epoch 4 Batch 602 Loss 1.2393\n",
      "Epoch 4 Batch 603 Loss 0.9864\n",
      "Epoch 4 Batch 604 Loss 1.4218\n",
      "Epoch 4 Batch 605 Loss 1.3084\n",
      "Epoch 4 Batch 606 Loss 1.0966\n",
      "Epoch 4 Batch 607 Loss 1.3895\n",
      "Epoch 4 Batch 608 Loss 1.0995\n",
      "Epoch 4 Batch 609 Loss 1.2213\n",
      "Epoch 4 Batch 610 Loss 1.1144\n",
      "Epoch 4 Batch 611 Loss 1.1321\n",
      "Epoch 4 Batch 612 Loss 1.2639\n",
      "Epoch 4 Batch 613 Loss 1.5149\n",
      "Epoch 4 Batch 614 Loss 1.3364\n",
      "Epoch 4 Batch 615 Loss 1.1166\n",
      "Epoch 4 Batch 616 Loss 1.0701\n",
      "Epoch 4 Batch 617 Loss 1.2030\n",
      "Epoch 4 Batch 618 Loss 1.2758\n",
      "Epoch 4 Batch 619 Loss 1.3676\n",
      "Epoch 4 Batch 620 Loss 1.5990\n",
      "Epoch 4 Batch 621 Loss 1.0875\n",
      "Epoch 4 Batch 622 Loss 1.2365\n",
      "Epoch 4 Batch 623 Loss 1.2090\n",
      "Epoch 4 Batch 624 Loss 1.2115\n",
      "Epoch 4 Batch 625 Loss 1.0936\n",
      "Epoch 4 Batch 626 Loss 1.3285\n",
      "Epoch 4 Batch 627 Loss 1.1629\n",
      "Epoch 4 Batch 628 Loss 1.0275\n",
      "Epoch 4 Batch 629 Loss 1.4519\n",
      "Epoch 4 Batch 630 Loss 1.2999\n",
      "Epoch 4 Batch 631 Loss 1.2100\n",
      "Epoch 4 Batch 632 Loss 1.3005\n",
      "Epoch 4 Batch 633 Loss 1.3246\n",
      "Epoch 4 Batch 634 Loss 0.9701\n",
      "Epoch 4 Batch 635 Loss 1.1277\n",
      "Epoch 4 Batch 636 Loss 1.5285\n",
      "Epoch 4 Batch 637 Loss 1.3749\n",
      "Epoch 4 Batch 638 Loss 1.3726\n",
      "Epoch 4 Batch 639 Loss 1.1324\n",
      "Epoch 4 Batch 640 Loss 1.0996\n",
      "Epoch 4 Batch 641 Loss 1.1581\n",
      "Epoch 4 Batch 642 Loss 1.4152\n",
      "Epoch 4 Batch 643 Loss 1.0717\n",
      "Epoch 4 Batch 644 Loss 1.0884\n",
      "Epoch 4 Batch 645 Loss 1.0162\n",
      "Epoch 4 Batch 646 Loss 1.2840\n",
      "Epoch 4 Batch 647 Loss 1.5903\n",
      "Epoch 4 Batch 648 Loss 1.3924\n",
      "Epoch 4 Batch 649 Loss 1.3093\n",
      "Epoch 4 Batch 650 Loss 1.4317\n",
      "Epoch 4 Batch 651 Loss 0.9823\n",
      "Epoch 4 Batch 652 Loss 1.2077\n",
      "Epoch 4 Batch 653 Loss 1.0708\n",
      "Epoch 4 Batch 654 Loss 1.1336\n",
      "Epoch 4 Batch 655 Loss 1.1396\n",
      "Epoch 4 Batch 656 Loss 1.2855\n",
      "Epoch 4 Batch 657 Loss 1.2371\n",
      "Epoch 4 Batch 658 Loss 1.2324\n",
      "Epoch 4 Batch 659 Loss 1.2295\n",
      "Epoch 4 Batch 660 Loss 1.5117\n",
      "Epoch 4 Batch 661 Loss 1.2847\n",
      "Epoch 4 Batch 662 Loss 1.4748\n",
      "Epoch 4 Batch 663 Loss 1.2039\n",
      "Epoch 4 Batch 664 Loss 1.1518\n",
      "Epoch 4 Batch 665 Loss 1.1740\n",
      "Epoch 4 Batch 666 Loss 1.1648\n",
      "Epoch 4 Batch 667 Loss 1.1100\n",
      "Epoch 4 Batch 668 Loss 1.2427\n",
      "Epoch 4 Batch 669 Loss 1.1307\n",
      "Epoch 4 Batch 670 Loss 1.3154\n",
      "Epoch 4 Batch 671 Loss 1.4256\n",
      "Epoch 4 Batch 672 Loss 1.2701\n",
      "Epoch 4 Batch 673 Loss 1.1390\n",
      "Epoch 4 Batch 674 Loss 1.1849\n",
      "Epoch 4 Batch 675 Loss 1.7107\n",
      "Epoch 4 Batch 676 Loss 1.0772\n",
      "Epoch 4 Batch 677 Loss 1.1953\n",
      "Epoch 4 Batch 678 Loss 1.5184\n",
      "Epoch 4 Batch 679 Loss 1.0932\n",
      "Epoch 4 Batch 680 Loss 1.3452\n",
      "Epoch 4 Batch 681 Loss 1.3835\n",
      "Epoch 4 Batch 682 Loss 0.9623\n",
      "Epoch 4 Batch 683 Loss 0.9802\n",
      "Epoch 4 Batch 684 Loss 1.2689\n",
      "Epoch 4 Batch 685 Loss 1.1808\n",
      "Epoch 4 Batch 686 Loss 1.0954\n",
      "Epoch 4 Batch 687 Loss 0.9149\n",
      "Epoch 4 Batch 688 Loss 1.3616\n",
      "Epoch 4 Batch 689 Loss 1.3396\n",
      "Epoch 4 Batch 690 Loss 1.4914\n",
      "Epoch 4 Batch 691 Loss 1.1395\n",
      "Epoch 4 Batch 692 Loss 1.1780\n",
      "Epoch 4 Batch 693 Loss 1.4558\n",
      "Epoch 4 Batch 694 Loss 1.4719\n",
      "Epoch 4 Batch 695 Loss 1.2637\n",
      "Epoch 4 Batch 696 Loss 1.1897\n",
      "Epoch 4 Batch 697 Loss 1.5022\n",
      "Epoch 4 Batch 698 Loss 1.0027\n",
      "Epoch 4 Batch 699 Loss 1.0940\n",
      "Epoch 4 Batch 700 Loss 1.0596\n",
      "Epoch 4 Batch 701 Loss 1.0361\n",
      "Epoch 4 Batch 702 Loss 1.1876\n",
      "Epoch 4 Batch 703 Loss 0.9925\n",
      "Epoch 4 Batch 704 Loss 1.2389\n",
      "Epoch 4 Batch 705 Loss 1.2465\n",
      "Epoch 4 Batch 706 Loss 1.5494\n",
      "Epoch 4 Batch 707 Loss 1.1073\n",
      "Epoch 4 Batch 708 Loss 1.2810\n",
      "Epoch 4 Batch 709 Loss 1.0935\n",
      "Epoch 4 Batch 710 Loss 1.1251\n",
      "Epoch 4 Batch 711 Loss 1.0728\n",
      "Epoch 4 Batch 712 Loss 1.1005\n",
      "Epoch 4 Batch 713 Loss 1.3118\n",
      "Epoch 4 Batch 714 Loss 1.3487\n",
      "Epoch 4 Batch 715 Loss 1.2603\n",
      "Epoch 4 Batch 716 Loss 0.9003\n",
      "Epoch 4 Batch 717 Loss 1.6440\n",
      "Epoch 4 Batch 718 Loss 1.1414\n",
      "Epoch 4 Batch 719 Loss 1.2570\n",
      "Epoch 4 Batch 720 Loss 1.1435\n",
      "Epoch 4 Batch 721 Loss 1.0718\n",
      "Epoch 4 Batch 722 Loss 1.3029\n",
      "Epoch 4 Batch 723 Loss 1.2763\n",
      "Epoch 4 Batch 724 Loss 1.3340\n",
      "Epoch 4 Batch 725 Loss 1.2515\n",
      "Epoch 4 Batch 726 Loss 1.0333\n",
      "Epoch 4 Batch 727 Loss 1.1670\n",
      "Epoch 4 Batch 728 Loss 1.1331\n",
      "Epoch 4 Batch 729 Loss 1.4654\n",
      "Epoch 4 Batch 730 Loss 1.1702\n",
      "Epoch 4 Batch 731 Loss 1.2737\n",
      "Epoch 4 Batch 732 Loss 1.4642\n",
      "Epoch 4 Batch 733 Loss 1.0240\n",
      "Epoch 4 Batch 734 Loss 1.3644\n",
      "Epoch 4 Batch 735 Loss 1.1548\n",
      "Epoch 4 Batch 736 Loss 1.2480\n",
      "Epoch 4 Batch 737 Loss 1.2024\n",
      "Epoch 4 Batch 738 Loss 1.0351\n",
      "Epoch 4 Batch 739 Loss 1.1753\n",
      "Epoch 4 Batch 740 Loss 1.2896\n",
      "Epoch 4 Batch 741 Loss 1.2359\n",
      "Epoch 4 Batch 742 Loss 1.2081\n",
      "Epoch 4 Batch 743 Loss 0.9208\n",
      "Epoch 4 Batch 744 Loss 1.0040\n",
      "Epoch 4 Batch 745 Loss 1.5967\n",
      "Epoch 4 Batch 746 Loss 1.3848\n",
      "Epoch 4 Batch 747 Loss 1.5937\n",
      "Epoch 4 Batch 748 Loss 1.2080\n",
      "Epoch 4 Batch 749 Loss 1.1331\n",
      "Epoch 4 Batch 750 Loss 1.1888\n",
      "Epoch 4 Batch 751 Loss 1.0225\n",
      "Epoch 4 Batch 752 Loss 1.1818\n",
      "Epoch 4 Batch 753 Loss 1.1675\n",
      "Epoch 4 Batch 754 Loss 1.1319\n",
      "Epoch 4 Batch 755 Loss 1.4503\n",
      "Epoch 4 Batch 756 Loss 1.4903\n",
      "Epoch 4 Batch 757 Loss 1.4105\n",
      "Epoch 4 Batch 758 Loss 1.0671\n",
      "Epoch 4 Batch 759 Loss 1.3843\n",
      "Epoch 4 Batch 760 Loss 1.0884\n",
      "Epoch 4 Batch 761 Loss 1.1010\n",
      "Epoch 4 Batch 762 Loss 1.0590\n",
      "Epoch 4 Batch 763 Loss 1.1647\n",
      "Epoch 4 Batch 764 Loss 1.3449\n",
      "Epoch 4 Batch 765 Loss 1.0575\n",
      "Epoch 4 Batch 766 Loss 1.0804\n",
      "Epoch 4 Batch 767 Loss 1.2480\n",
      "Epoch 4 Batch 768 Loss 1.1431\n",
      "Epoch 4 Batch 769 Loss 1.0653\n",
      "Epoch 4 Batch 770 Loss 1.1819\n",
      "Epoch 4 Batch 771 Loss 1.2402\n",
      "Epoch 4 Batch 772 Loss 1.2485\n",
      "Epoch 4 Batch 773 Loss 0.8852\n",
      "Epoch 4 Batch 774 Loss 1.1894\n",
      "Epoch 4 Batch 775 Loss 1.2624\n",
      "Epoch 4 Batch 776 Loss 1.1969\n",
      "Epoch 4 Batch 777 Loss 1.3310\n",
      "Epoch 4 Batch 778 Loss 1.0947\n",
      "Epoch 4 Batch 779 Loss 1.0864\n",
      "Epoch 4 Batch 780 Loss 1.2883\n",
      "Epoch 4 Batch 781 Loss 1.1542\n",
      "Epoch 4 Batch 782 Loss 1.3393\n",
      "Epoch 4 Batch 783 Loss 1.2106\n",
      "Epoch 4 Batch 784 Loss 1.2839\n",
      "Epoch 4 Batch 785 Loss 0.9936\n",
      "Epoch 4 Batch 786 Loss 1.1089\n",
      "Epoch 4 Batch 787 Loss 0.9140\n",
      "Epoch 4 Batch 788 Loss 1.2385\n",
      "Epoch 4 Batch 789 Loss 1.2830\n",
      "Epoch 4 Batch 790 Loss 1.2169\n",
      "Epoch 4 Batch 791 Loss 1.1031\n",
      "Epoch 4 Batch 792 Loss 1.2543\n",
      "Epoch 4 Batch 793 Loss 1.2039\n",
      "Epoch 4 Batch 794 Loss 1.3005\n",
      "Epoch 4 Batch 795 Loss 1.0641\n",
      "Epoch 4 Batch 796 Loss 1.0360\n",
      "Epoch 4 Batch 797 Loss 1.3902\n",
      "Epoch 4 Batch 798 Loss 1.2431\n",
      "Epoch 4 Batch 799 Loss 1.1657\n",
      "Epoch 4 Batch 800 Loss 1.0512\n",
      "Epoch 4 Batch 801 Loss 1.0634\n",
      "Epoch 4 Batch 802 Loss 1.0254\n",
      "Epoch 4 Batch 803 Loss 1.2942\n",
      "Epoch 4 Batch 804 Loss 1.3809\n",
      "Epoch 4 Batch 805 Loss 1.2893\n",
      "Epoch 4 Batch 806 Loss 1.2577\n",
      "Epoch 4 Batch 807 Loss 1.0507\n",
      "Epoch 4 Batch 808 Loss 1.1979\n",
      "Epoch 4 Batch 809 Loss 1.3587\n",
      "Epoch 4 Batch 810 Loss 1.1645\n",
      "Epoch 4 Batch 811 Loss 1.1654\n",
      "Epoch 4 Batch 812 Loss 1.0386\n",
      "Epoch 4 Batch 813 Loss 1.0902\n",
      "Epoch 4 Batch 814 Loss 0.9552\n",
      "Epoch 4 Batch 815 Loss 1.1611\n",
      "Epoch 4 Batch 816 Loss 1.3259\n",
      "Epoch 4 Batch 817 Loss 1.2512\n",
      "Epoch 4 Batch 818 Loss 1.2415\n",
      "Epoch 4 Batch 819 Loss 1.0666\n",
      "Epoch 4 Batch 820 Loss 1.3845\n",
      "Epoch 4 Batch 821 Loss 0.9695\n",
      "Epoch 4 Batch 822 Loss 1.3173\n",
      "Epoch 4 Batch 823 Loss 1.0112\n",
      "Epoch 4 Batch 824 Loss 1.3445\n",
      "Epoch 4 Batch 825 Loss 1.1421\n",
      "Epoch 4 Batch 826 Loss 1.4382\n",
      "Epoch 4 Batch 827 Loss 1.3530\n",
      "Epoch 4 Batch 828 Loss 1.4877\n",
      "Epoch 4 Batch 829 Loss 1.4532\n",
      "Epoch 4 Batch 830 Loss 0.9400\n",
      "Epoch 4 Batch 831 Loss 1.0092\n",
      "Epoch 4 Batch 832 Loss 1.1709\n",
      "Epoch 4 Batch 833 Loss 1.2653\n",
      "Epoch 4 Batch 834 Loss 1.1581\n",
      "Epoch 4 Batch 835 Loss 0.9848\n",
      "Epoch 4 Batch 836 Loss 1.0351\n",
      "Epoch 4 Batch 837 Loss 1.0559\n",
      "Epoch 4 Batch 838 Loss 1.3458\n",
      "Epoch 4 Batch 839 Loss 0.8765\n",
      "Epoch 4 Batch 840 Loss 1.3325\n",
      "Epoch 4 Batch 841 Loss 1.2335\n",
      "Epoch 4 Batch 842 Loss 1.2610\n",
      "Epoch 4 Batch 843 Loss 1.1449\n",
      "Epoch 4 Batch 844 Loss 1.2164\n",
      "Epoch 4 Batch 845 Loss 1.4853\n",
      "Epoch 4 Batch 846 Loss 1.0648\n",
      "Epoch 4 Batch 847 Loss 1.2832\n",
      "Epoch 4 Batch 848 Loss 1.2050\n",
      "Epoch 4 Batch 849 Loss 0.9681\n",
      "Epoch 4 Batch 850 Loss 0.9976\n",
      "Epoch 4 Batch 851 Loss 1.2597\n",
      "Epoch 4 Batch 852 Loss 1.3271\n",
      "Epoch 4 Batch 853 Loss 1.2544\n",
      "Epoch 4 Batch 854 Loss 1.3446\n",
      "Epoch 4 Batch 855 Loss 1.2579\n",
      "Epoch 4 Batch 856 Loss 1.2937\n",
      "Epoch 4 Batch 857 Loss 1.2930\n",
      "Epoch 4 Batch 858 Loss 1.4492\n",
      "Epoch 4 Batch 859 Loss 1.3260\n",
      "Epoch 4 Batch 860 Loss 1.0083\n",
      "Epoch 4 Batch 861 Loss 1.4556\n",
      "Epoch 4 Batch 862 Loss 1.0252\n",
      "Epoch 4 Batch 863 Loss 1.1781\n",
      "Epoch 4 Batch 864 Loss 1.1917\n",
      "Epoch 4 Batch 865 Loss 1.0290\n",
      "Epoch 4 Batch 866 Loss 1.1267\n",
      "Epoch 4 Batch 867 Loss 0.8548\n",
      "Epoch 4 Batch 868 Loss 1.5028\n",
      "Epoch 4 Batch 869 Loss 1.1314\n",
      "Epoch 4 Batch 870 Loss 1.1089\n",
      "Epoch 4 Batch 871 Loss 1.2391\n",
      "Epoch 4 Batch 872 Loss 1.1375\n",
      "Epoch 4 Batch 873 Loss 1.2676\n",
      "Epoch 4 Batch 874 Loss 1.1964\n",
      "Epoch 4 Batch 875 Loss 1.1705\n",
      "Epoch 4 Batch 876 Loss 1.0375\n",
      "Epoch 4 Batch 877 Loss 1.0639\n",
      "Epoch 4 Batch 878 Loss 1.1198\n",
      "Epoch 4 Batch 879 Loss 1.0751\n",
      "Epoch 4 Batch 880 Loss 1.3990\n",
      "Epoch 4 Batch 881 Loss 1.2355\n",
      "Epoch 4 Batch 882 Loss 1.1889\n",
      "Epoch 4 Batch 883 Loss 1.4536\n",
      "Epoch 4 Batch 884 Loss 1.1514\n",
      "Epoch 4 Batch 885 Loss 1.2002\n",
      "Epoch 4 Batch 886 Loss 1.4147\n",
      "Epoch 4 Batch 887 Loss 1.4250\n",
      "Epoch 4 Batch 888 Loss 1.1682\n",
      "Epoch 4 Batch 889 Loss 1.1670\n",
      "Epoch 4 Batch 890 Loss 1.0776\n",
      "Epoch 4 Batch 891 Loss 1.2319\n",
      "Epoch 4 Batch 892 Loss 1.3309\n",
      "Epoch 4 Batch 893 Loss 1.1946\n",
      "Epoch 4 Batch 894 Loss 1.4254\n",
      "Epoch 4 Batch 895 Loss 1.2370\n",
      "Epoch 4 Batch 896 Loss 1.3929\n",
      "Epoch 4 Batch 897 Loss 1.0794\n",
      "Epoch 4 Batch 898 Loss 1.0395\n",
      "Epoch 4 Batch 899 Loss 1.1497\n",
      "Epoch 4 Batch 900 Loss 1.3219\n",
      "Epoch 4 Batch 901 Loss 1.1259\n",
      "Epoch 4 Batch 902 Loss 1.3204\n",
      "Epoch 4 Batch 903 Loss 1.1589\n",
      "Epoch 4 Batch 904 Loss 1.4727\n",
      "Epoch 4 Batch 905 Loss 0.8592\n",
      "Epoch 4 Batch 906 Loss 1.2562\n",
      "Epoch 4 Batch 907 Loss 1.1149\n",
      "Epoch 4 Batch 908 Loss 1.1117\n",
      "Epoch 4 Batch 909 Loss 1.4132\n",
      "Epoch 4 Batch 910 Loss 1.2087\n",
      "Epoch 4 Batch 911 Loss 1.2571\n",
      "Epoch 4 Batch 912 Loss 1.2263\n",
      "Epoch 4 Batch 913 Loss 1.1503\n",
      "Epoch 4 Batch 914 Loss 1.1398\n",
      "Epoch 4 Batch 915 Loss 1.0211\n",
      "Epoch 4 Batch 916 Loss 1.2762\n",
      "Epoch 4 Batch 917 Loss 1.3286\n",
      "Epoch 4 Batch 918 Loss 1.3112\n",
      "Epoch 4 Batch 919 Loss 1.3777\n",
      "Epoch 4 Batch 920 Loss 1.2183\n",
      "Epoch 4 Batch 921 Loss 1.2915\n",
      "Epoch 4 Batch 922 Loss 1.5203\n",
      "Epoch 4 Batch 923 Loss 1.4335\n",
      "Epoch 4 Batch 924 Loss 1.0868\n",
      "Epoch 4 Batch 925 Loss 1.6733\n",
      "Epoch 4 Batch 926 Loss 1.2582\n",
      "Epoch 4 Batch 927 Loss 1.0749\n",
      "Epoch 4 Batch 928 Loss 1.1454\n",
      "Epoch 4 Batch 929 Loss 1.1282\n",
      "Epoch 4 Batch 930 Loss 1.2534\n",
      "Epoch 4 Batch 931 Loss 1.1478\n",
      "Epoch 4 Batch 932 Loss 1.0438\n",
      "Epoch 4 Batch 933 Loss 1.1042\n",
      "Epoch 4 Batch 934 Loss 1.3221\n",
      "Epoch 4 Batch 935 Loss 1.0332\n",
      "Epoch 4 Batch 936 Loss 1.1061\n",
      "Epoch 4 Batch 937 Loss 1.0999\n",
      "Epoch 4 Batch 938 Loss 1.3046\n",
      "Epoch 4 Batch 939 Loss 1.0973\n",
      "Epoch 4 Batch 940 Loss 1.2312\n",
      "Epoch 4 Batch 941 Loss 1.0349\n",
      "Epoch 4 Batch 942 Loss 0.9082\n",
      "Epoch 4 Batch 943 Loss 1.1429\n",
      "Epoch 4 Batch 944 Loss 1.6769\n",
      "Epoch 4 Batch 945 Loss 1.2436\n",
      "Epoch 4 Batch 946 Loss 1.2523\n",
      "Epoch 4 Batch 947 Loss 1.2774\n",
      "Epoch 4 Batch 948 Loss 1.0651\n",
      "Epoch 4 Batch 949 Loss 0.9669\n",
      "Epoch 4 Batch 950 Loss 1.2136\n",
      "Epoch 4 Batch 951 Loss 1.4565\n",
      "Epoch 4 Batch 952 Loss 1.4618\n",
      "Epoch 4 Batch 953 Loss 1.2073\n",
      "Epoch 4 Batch 954 Loss 1.1517\n",
      "Epoch 4 Batch 955 Loss 1.1008\n",
      "Epoch 4 Batch 956 Loss 1.0824\n",
      "Epoch 4 Batch 957 Loss 1.1978\n",
      "Epoch 4 Batch 958 Loss 1.4015\n",
      "Epoch 4 Batch 959 Loss 1.2034\n",
      "Epoch 4 Batch 960 Loss 1.2030\n",
      "Epoch 4 Batch 961 Loss 1.1994\n",
      "Epoch 4 Batch 962 Loss 0.9352\n",
      "Epoch 4 Batch 963 Loss 0.9205\n",
      "Epoch 4 Batch 964 Loss 1.3562\n",
      "Epoch 4 Batch 965 Loss 1.1344\n",
      "Epoch 4 Batch 966 Loss 1.0814\n",
      "Epoch 4 Batch 967 Loss 1.1389\n",
      "Epoch 4 Batch 968 Loss 1.1180\n",
      "Epoch 4 Batch 969 Loss 1.2172\n",
      "Epoch 4 Batch 970 Loss 1.2749\n",
      "Epoch 4 Batch 971 Loss 1.3694\n",
      "Epoch 4 Batch 972 Loss 1.1773\n",
      "Epoch 4 Batch 973 Loss 1.3631\n",
      "Epoch 4 Batch 974 Loss 1.0480\n",
      "Epoch 4 Batch 975 Loss 1.4991\n",
      "Epoch 4 Batch 976 Loss 1.0887\n",
      "Epoch 4 Batch 977 Loss 1.4168\n",
      "Epoch 4 Batch 978 Loss 1.1984\n",
      "Epoch 4 Batch 979 Loss 1.4117\n",
      "Epoch 4 Batch 980 Loss 1.3750\n",
      "Epoch 4 Batch 981 Loss 1.2948\n",
      "Epoch 4 Batch 982 Loss 1.1281\n",
      "Epoch 4 Batch 983 Loss 1.1662\n",
      "Epoch 4 Batch 984 Loss 1.2960\n",
      "Epoch 4 Batch 985 Loss 1.0759\n",
      "Epoch 4 Batch 986 Loss 1.3029\n",
      "Epoch 4 Batch 987 Loss 1.3008\n",
      "Epoch 4 Batch 988 Loss 1.2322\n",
      "Epoch 4 Batch 989 Loss 0.9903\n",
      "Epoch 4 Batch 990 Loss 1.1909\n",
      "Epoch 4 Batch 991 Loss 1.2812\n",
      "Epoch 4 Batch 992 Loss 1.1662\n",
      "Epoch 4 Batch 993 Loss 1.4778\n",
      "Epoch 4 Batch 994 Loss 1.1513\n",
      "Epoch 4 Batch 995 Loss 1.2022\n",
      "Epoch 4 Batch 996 Loss 1.0029\n",
      "Epoch 4 Batch 997 Loss 1.0471\n",
      "Epoch 4 Batch 998 Loss 1.3059\n",
      "Epoch 4 Batch 999 Loss 1.0931\n",
      "Epoch 4 Batch 1000 Loss 1.2413\n",
      "Epoch 4 Batch 1001 Loss 1.1701\n",
      "Epoch 4 Batch 1002 Loss 1.0302\n",
      "Epoch 4 Batch 1003 Loss 1.0888\n",
      "Epoch 4 Batch 1004 Loss 1.2657\n",
      "Epoch 4 Batch 1005 Loss 1.0578\n",
      "Epoch 4 Batch 1006 Loss 1.2199\n",
      "Epoch 4 Batch 1007 Loss 1.3033\n",
      "Epoch 4 Batch 1008 Loss 1.1838\n",
      "Epoch 4 Batch 1009 Loss 1.2940\n",
      "Epoch 4 Batch 1010 Loss 1.2158\n",
      "Epoch 4 Batch 1011 Loss 1.2386\n",
      "Epoch 4 Batch 1012 Loss 1.1725\n",
      "Epoch 4 Batch 1013 Loss 1.3230\n",
      "Epoch 4 Batch 1014 Loss 1.0856\n",
      "Epoch 4 Batch 1015 Loss 1.4707\n",
      "Epoch 4 Batch 1016 Loss 1.5152\n",
      "Epoch 4 Batch 1017 Loss 1.3893\n",
      "Epoch 4 Batch 1018 Loss 1.0321\n",
      "Epoch 4 Batch 1019 Loss 1.2966\n",
      "Epoch 4 Batch 1020 Loss 1.0273\n",
      "Epoch 4 Batch 1021 Loss 1.3950\n",
      "Epoch 4 Batch 1022 Loss 1.0305\n",
      "Epoch 4 Batch 1023 Loss 1.2023\n",
      "Epoch 4 Batch 1024 Loss 1.3873\n",
      "Epoch 4 Batch 1025 Loss 1.3618\n",
      "Epoch 4 Batch 1026 Loss 1.2840\n",
      "Epoch 4 Batch 1027 Loss 1.3230\n",
      "Epoch 4 Batch 1028 Loss 1.2139\n",
      "Epoch 4 Batch 1029 Loss 1.2558\n",
      "Epoch 4 Batch 1030 Loss 1.4784\n",
      "Epoch 4 Batch 1031 Loss 1.0636\n",
      "Epoch 4 Batch 1032 Loss 1.1022\n",
      "Epoch 4 Batch 1033 Loss 1.3282\n",
      "Epoch 4 Batch 1034 Loss 1.1676\n",
      "Epoch 4 Batch 1035 Loss 1.1279\n",
      "Epoch 4 Batch 1036 Loss 1.0955\n",
      "Epoch 4 Batch 1037 Loss 1.1391\n",
      "Epoch 4 Batch 1038 Loss 1.2405\n",
      "Epoch 4 Batch 1039 Loss 1.3674\n",
      "Epoch 4 Batch 1040 Loss 1.0320\n",
      "Epoch 4 Batch 1041 Loss 1.0065\n",
      "Epoch 4 Batch 1042 Loss 1.2627\n",
      "Epoch 4 Batch 1043 Loss 1.3876\n",
      "Epoch 4 Batch 1044 Loss 1.3425\n",
      "Epoch 4 Batch 1045 Loss 1.4542\n",
      "Epoch 4 Batch 1046 Loss 1.2140\n",
      "Epoch 4 Batch 1047 Loss 1.0899\n",
      "Epoch 4 Batch 1048 Loss 1.0883\n",
      "Epoch 4 Batch 1049 Loss 1.2633\n",
      "Epoch 4 Batch 1050 Loss 1.1580\n",
      "Epoch 4 Batch 1051 Loss 1.0155\n",
      "Epoch 4 Batch 1052 Loss 1.3202\n",
      "Epoch 4 Batch 1053 Loss 1.3245\n",
      "Epoch 4 Batch 1054 Loss 1.1149\n",
      "Epoch 4 Batch 1055 Loss 1.1909\n",
      "Epoch 4 Batch 1056 Loss 1.0636\n",
      "Epoch 4 Batch 1057 Loss 1.3260\n",
      "Epoch 4 Batch 1058 Loss 1.4264\n",
      "Epoch 4 Batch 1059 Loss 1.2384\n",
      "Epoch 4 Batch 1060 Loss 1.3078\n",
      "Epoch 4 Batch 1061 Loss 1.0798\n",
      "Epoch 4 Batch 1062 Loss 1.3295\n",
      "Epoch 4 Batch 1063 Loss 1.2033\n",
      "Epoch 4 Batch 1064 Loss 1.1814\n",
      "Epoch 4 Batch 1065 Loss 1.3192\n",
      "Epoch 4 Batch 1066 Loss 1.1398\n",
      "Epoch 4 Batch 1067 Loss 1.4655\n",
      "Epoch 4 Batch 1068 Loss 1.1998\n",
      "Epoch 4 Batch 1069 Loss 1.2515\n",
      "Epoch 4 Batch 1070 Loss 1.3798\n",
      "Epoch 4 Batch 1071 Loss 1.1596\n",
      "Epoch 4 Batch 1072 Loss 1.1185\n",
      "Epoch 4 Batch 1073 Loss 1.1124\n",
      "Epoch 4 Batch 1074 Loss 1.2002\n",
      "Epoch 4 Batch 1075 Loss 1.2975\n",
      "Epoch 4 Batch 1076 Loss 1.3853\n",
      "Epoch 4 Batch 1077 Loss 1.2067\n",
      "Epoch 4 Batch 1078 Loss 1.5581\n",
      "Epoch 4 Batch 1079 Loss 1.1987\n",
      "Epoch 4 Batch 1080 Loss 1.0827\n",
      "Epoch 4 Batch 1081 Loss 1.2288\n",
      "Epoch 4 Batch 1082 Loss 1.5297\n",
      "Epoch 4 Batch 1083 Loss 1.1869\n",
      "Epoch 4 Batch 1084 Loss 1.0640\n",
      "Epoch 4 Batch 1085 Loss 1.1306\n",
      "Epoch 4 Batch 1086 Loss 1.1088\n",
      "Epoch 4 Batch 1087 Loss 1.0663\n",
      "Epoch 4 Batch 1088 Loss 1.1505\n",
      "Epoch 4 Batch 1089 Loss 1.2472\n",
      "Epoch 4 Batch 1090 Loss 1.3348\n",
      "Epoch 4 Batch 1091 Loss 0.9820\n",
      "Epoch 4 Batch 1092 Loss 1.2504\n",
      "Epoch 4 Batch 1093 Loss 1.2442\n",
      "Epoch 4 Batch 1094 Loss 1.0267\n",
      "Epoch 4 Batch 1095 Loss 1.1388\n",
      "Epoch 4 Batch 1096 Loss 0.9244\n",
      "Epoch 4 Batch 1097 Loss 0.9166\n",
      "Epoch 4 Batch 1098 Loss 1.0686\n",
      "Epoch 4 Batch 1099 Loss 1.2738\n",
      "Epoch 4 Batch 1100 Loss 1.3714\n",
      "Epoch 4 Batch 1101 Loss 1.0515\n",
      "Epoch 4 Batch 1102 Loss 1.4752\n",
      "Epoch 4 Batch 1103 Loss 1.2237\n",
      "Epoch 4 Batch 1104 Loss 1.2946\n",
      "Epoch 4 Batch 1105 Loss 1.0972\n",
      "Epoch 4 Batch 1106 Loss 1.0626\n",
      "Epoch 4 Batch 1107 Loss 1.4392\n",
      "Epoch 4 Batch 1108 Loss 1.3816\n",
      "Epoch 4 Batch 1109 Loss 1.1802\n",
      "Epoch 4 Batch 1110 Loss 1.1021\n",
      "Epoch 4 Batch 1111 Loss 1.2416\n",
      "Epoch 4 Batch 1112 Loss 1.0977\n",
      "Epoch 4 Batch 1113 Loss 1.0621\n",
      "Epoch 4 Batch 1114 Loss 1.0539\n",
      "Epoch 4 Batch 1115 Loss 1.3355\n",
      "Epoch 4 Batch 1116 Loss 1.2313\n",
      "Epoch 4 Batch 1117 Loss 1.1533\n",
      "Epoch 4 Batch 1118 Loss 1.1489\n",
      "Epoch 4 Batch 1119 Loss 1.3395\n",
      "Epoch 4 Batch 1120 Loss 1.1698\n",
      "Epoch 4 Batch 1121 Loss 1.4033\n",
      "Epoch 4 Batch 1122 Loss 1.0957\n",
      "Epoch 4 Batch 1123 Loss 1.3349\n",
      "Epoch 4 Batch 1124 Loss 1.2087\n",
      "Epoch 4 Batch 1125 Loss 1.3681\n",
      "Epoch 4 Batch 1126 Loss 1.0591\n",
      "Epoch 4 Batch 1127 Loss 1.3485\n",
      "Epoch 4 Batch 1128 Loss 1.4641\n",
      "Epoch 4 Batch 1129 Loss 1.2056\n",
      "Epoch 4 Batch 1130 Loss 1.1304\n",
      "Epoch 4 Batch 1131 Loss 1.4755\n",
      "Epoch 4 Batch 1132 Loss 0.9878\n",
      "Epoch 4 Batch 1133 Loss 1.2813\n",
      "Epoch 4 Batch 1134 Loss 1.0145\n",
      "Epoch 4 Batch 1135 Loss 1.0821\n",
      "Epoch 4 Batch 1136 Loss 1.0642\n",
      "Epoch 4 Batch 1137 Loss 1.1666\n",
      "Epoch 4 Batch 1138 Loss 1.0767\n",
      "Epoch 4 Batch 1139 Loss 1.0137\n",
      "Epoch 4 Batch 1140 Loss 1.4525\n",
      "Epoch 4 Batch 1141 Loss 1.2328\n",
      "Epoch 4 Batch 1142 Loss 1.2772\n",
      "Epoch 4 Batch 1143 Loss 1.0632\n",
      "Epoch 4 Batch 1144 Loss 1.1453\n",
      "Epoch 4 Batch 1145 Loss 1.3311\n",
      "Epoch 4 Batch 1146 Loss 1.1505\n",
      "Epoch 4 Batch 1147 Loss 1.4297\n",
      "Epoch 4 Batch 1148 Loss 1.4203\n",
      "Epoch 4 Batch 1149 Loss 1.5151\n",
      "Epoch 4 Batch 1150 Loss 1.2557\n",
      "Epoch 4 Batch 1151 Loss 1.1340\n",
      "Epoch 4 Batch 1152 Loss 1.3964\n",
      "Epoch 4 Batch 1153 Loss 0.9735\n",
      "Epoch 4 Batch 1154 Loss 1.1909\n",
      "Epoch 4 Batch 1155 Loss 1.1788\n",
      "Epoch 4 Batch 1156 Loss 0.9650\n",
      "Epoch 4 Batch 1157 Loss 1.0926\n",
      "Epoch 4 Batch 1158 Loss 1.2518\n",
      "Epoch 4 Batch 1159 Loss 1.0783\n",
      "Epoch 4 Batch 1160 Loss 1.2061\n",
      "Epoch 4 Batch 1161 Loss 1.1044\n",
      "Epoch 4 Batch 1162 Loss 1.5918\n",
      "Epoch 4 Batch 1163 Loss 1.2036\n",
      "Epoch 4 Batch 1164 Loss 1.2190\n",
      "Epoch 4 Batch 1165 Loss 1.3691\n",
      "Epoch 4 Batch 1166 Loss 1.0375\n",
      "Epoch 4 Batch 1167 Loss 1.2079\n",
      "Epoch 4 Batch 1168 Loss 1.0783\n",
      "Epoch 4 Batch 1169 Loss 1.4808\n",
      "Epoch 4 Batch 1170 Loss 1.2539\n",
      "Epoch 4 Batch 1171 Loss 1.3096\n",
      "Epoch 4 Batch 1172 Loss 1.2953\n",
      "Epoch 4 Batch 1173 Loss 1.2498\n",
      "Epoch 4 Batch 1174 Loss 1.1060\n",
      "Epoch 4 Batch 1175 Loss 1.2005\n",
      "Epoch 4 Batch 1176 Loss 1.1371\n",
      "Epoch 4 Batch 1177 Loss 1.1283\n",
      "Epoch 4 Batch 1178 Loss 1.0881\n",
      "Epoch 4 Batch 1179 Loss 1.3273\n",
      "Epoch 4 Batch 1180 Loss 1.4313\n",
      "Epoch 4 Batch 1181 Loss 1.1750\n",
      "Epoch 4 Batch 1182 Loss 1.3044\n",
      "Epoch 4 Batch 1183 Loss 1.3555\n",
      "Epoch 4 Batch 1184 Loss 1.0099\n",
      "Epoch 4 Batch 1185 Loss 1.3223\n",
      "Epoch 4 Batch 1186 Loss 0.8639\n",
      "Epoch 4 Batch 1187 Loss 1.4915\n",
      "Epoch 4 Batch 1188 Loss 1.0678\n",
      "Epoch 4 Batch 1189 Loss 1.1142\n",
      "Epoch 4 Batch 1190 Loss 1.3696\n",
      "Epoch 4 Batch 1191 Loss 1.0694\n",
      "Epoch 4 Batch 1192 Loss 1.2111\n",
      "Epoch 4 Batch 1193 Loss 1.3185\n",
      "Epoch 4 Batch 1194 Loss 1.0012\n",
      "Epoch 4 Batch 1195 Loss 1.2618\n",
      "Epoch 4 Batch 1196 Loss 1.1116\n",
      "Epoch 4 Batch 1197 Loss 1.1050\n",
      "Epoch 4 Batch 1198 Loss 1.0697\n",
      "Epoch 4 Batch 1199 Loss 1.0925\n",
      "Epoch 4 Batch 1200 Loss 1.3406\n",
      "Epoch 4 Batch 1201 Loss 1.3128\n",
      "Epoch 4 Batch 1202 Loss 1.0202\n",
      "Epoch 4 Batch 1203 Loss 1.2856\n",
      "Epoch 4 Batch 1204 Loss 0.9416\n",
      "Epoch 4 Batch 1205 Loss 1.1722\n",
      "Epoch 4 Batch 1206 Loss 1.2798\n",
      "Epoch 4 Batch 1207 Loss 1.3299\n",
      "Epoch 4 Batch 1208 Loss 1.0530\n",
      "Epoch 4 Batch 1209 Loss 0.9521\n",
      "Epoch 4 Batch 1210 Loss 1.2858\n",
      "Epoch 4 Batch 1211 Loss 0.8808\n",
      "Epoch 4 Batch 1212 Loss 1.0975\n",
      "Epoch 4 Batch 1213 Loss 1.1939\n",
      "Epoch 4 Batch 1214 Loss 1.2605\n",
      "Epoch 4 Batch 1215 Loss 1.4479\n",
      "Epoch 4 Batch 1216 Loss 1.2300\n",
      "Epoch 4 Batch 1217 Loss 1.2389\n",
      "Epoch 4 Batch 1218 Loss 1.4363\n",
      "Epoch 4 Batch 1219 Loss 1.3558\n",
      "Epoch 4 Batch 1220 Loss 1.0040\n",
      "Epoch 4 Batch 1221 Loss 1.4916\n",
      "Epoch 4 Batch 1222 Loss 0.9663\n",
      "Epoch 4 Batch 1223 Loss 1.2055\n",
      "Epoch 4 Batch 1224 Loss 1.0436\n",
      "Epoch 4 Batch 1225 Loss 1.4527\n",
      "Epoch 4 Batch 1226 Loss 1.1595\n",
      "Epoch 4 Batch 1227 Loss 1.2208\n",
      "Epoch 4 Batch 1228 Loss 0.8797\n",
      "Epoch 4 Batch 1229 Loss 1.2214\n",
      "Epoch 4 Batch 1230 Loss 1.2817\n",
      "Epoch 4 Batch 1231 Loss 1.5725\n",
      "Epoch 4 Batch 1232 Loss 1.0119\n",
      "Epoch 4 Batch 1233 Loss 1.4156\n",
      "Epoch 4 Batch 1234 Loss 1.4896\n",
      "Epoch 4 Batch 1235 Loss 1.1109\n",
      "Epoch 4 Batch 1236 Loss 1.2408\n",
      "Epoch 4 Batch 1237 Loss 1.4322\n",
      "Epoch 4 Batch 1238 Loss 1.4741\n",
      "Epoch 4 Batch 1239 Loss 1.2262\n",
      "Epoch 4 Batch 1240 Loss 1.3716\n",
      "Epoch 4 Batch 1241 Loss 1.3080\n",
      "Epoch 4 Batch 1242 Loss 1.3715\n",
      "Epoch 4 Batch 1243 Loss 0.9669\n",
      "Epoch 4 Batch 1244 Loss 1.1802\n",
      "Epoch 4 Batch 1245 Loss 1.0199\n",
      "Epoch 4 Batch 1246 Loss 1.2842\n",
      "Epoch 4 Batch 1247 Loss 1.3932\n",
      "Epoch 4 Batch 1248 Loss 1.2392\n",
      "Epoch 4 Batch 1249 Loss 1.1117\n",
      "Epoch 4 Batch 1250 Loss 1.2656\n",
      "Epoch 4 Batch 1251 Loss 1.5110\n",
      "Epoch 4 Batch 1252 Loss 1.3114\n",
      "Epoch 4 Batch 1253 Loss 1.1998\n",
      "Epoch 4 Batch 1254 Loss 1.3018\n",
      "Epoch 4 Batch 1255 Loss 1.2291\n",
      "Epoch 4 Batch 1256 Loss 1.1129\n",
      "Epoch 4 Batch 1257 Loss 1.3402\n",
      "Epoch 4 Batch 1258 Loss 1.0695\n",
      "Epoch 4 Batch 1259 Loss 1.1745\n",
      "Epoch 4 Batch 1260 Loss 1.1951\n",
      "Epoch 4 Batch 1261 Loss 1.1899\n",
      "Epoch 4 Batch 1262 Loss 1.2123\n",
      "Epoch 4 Batch 1263 Loss 1.1754\n",
      "Epoch 4 Batch 1264 Loss 1.1985\n",
      "Epoch 4 Batch 1265 Loss 1.2715\n",
      "Epoch 4 Batch 1266 Loss 1.0405\n",
      "Epoch 4 Batch 1267 Loss 0.9522\n",
      "Epoch 4 Batch 1268 Loss 1.3701\n",
      "Epoch 4 Batch 1269 Loss 1.0551\n",
      "Epoch 4 Batch 1270 Loss 1.4112\n",
      "Epoch 4 Batch 1271 Loss 1.3791\n",
      "Epoch 4 Batch 1272 Loss 1.2611\n",
      "Epoch 4 Batch 1273 Loss 1.2202\n",
      "Epoch 4 Batch 1274 Loss 1.2987\n",
      "Epoch 4 Batch 1275 Loss 1.0867\n",
      "Epoch 4 Batch 1276 Loss 1.1995\n",
      "Epoch 4 Batch 1277 Loss 1.1139\n",
      "Epoch 4 Batch 1278 Loss 1.1721\n",
      "Epoch 4 Batch 1279 Loss 1.1601\n",
      "Epoch 4 Batch 1280 Loss 1.1715\n",
      "Epoch 4 Batch 1281 Loss 1.3018\n",
      "Epoch 4 Batch 1282 Loss 1.3948\n",
      "Epoch 4 Batch 1283 Loss 1.2281\n",
      "Epoch 4 Batch 1284 Loss 1.1997\n",
      "Epoch 4 Batch 1285 Loss 1.4397\n",
      "Epoch 4 Batch 1286 Loss 0.9767\n",
      "Epoch 4 Batch 1287 Loss 1.2752\n",
      "Epoch 4 Batch 1288 Loss 1.0993\n",
      "Epoch 4 Batch 1289 Loss 1.2830\n",
      "Epoch 4 Batch 1290 Loss 1.3545\n",
      "Epoch 4 Batch 1291 Loss 1.0295\n",
      "Epoch 4 Batch 1292 Loss 1.2694\n",
      "Epoch 4 Batch 1293 Loss 1.2645\n",
      "Epoch 4 Batch 1294 Loss 0.9341\n",
      "Epoch 4 Batch 1295 Loss 1.2685\n",
      "Epoch 4 Batch 1296 Loss 1.3484\n",
      "Epoch 4 Batch 1297 Loss 1.0733\n",
      "Epoch 4 Batch 1298 Loss 1.2689\n",
      "Epoch 4 Batch 1299 Loss 1.0449\n",
      "Epoch 4 Batch 1300 Loss 1.1527\n",
      "Epoch 4 Batch 1301 Loss 1.1860\n",
      "Epoch 4 Batch 1302 Loss 1.5145\n",
      "Epoch 4 Batch 1303 Loss 0.8570\n",
      "Epoch 4 Batch 1304 Loss 1.4055\n",
      "Epoch 4 Batch 1305 Loss 0.9815\n",
      "Epoch 4 Batch 1306 Loss 1.2422\n",
      "Epoch 4 Batch 1307 Loss 1.1140\n",
      "Epoch 4 Batch 1308 Loss 1.4047\n",
      "Epoch 4 Batch 1309 Loss 1.0144\n",
      "Epoch 4 Batch 1310 Loss 1.4207\n",
      "Epoch 4 Batch 1311 Loss 1.4016\n",
      "Epoch 4 Batch 1312 Loss 0.9547\n",
      "Epoch 4 Batch 1313 Loss 1.2859\n",
      "Epoch 4 Batch 1314 Loss 1.4414\n",
      "Epoch 4 Batch 1315 Loss 1.1299\n",
      "Epoch 4 Batch 1316 Loss 1.2895\n",
      "Epoch 4 Batch 1317 Loss 1.1847\n",
      "Epoch 4 Batch 1318 Loss 1.2546\n",
      "Epoch 4 Batch 1319 Loss 1.2208\n",
      "Epoch 4 Batch 1320 Loss 1.4400\n",
      "Epoch 4 Batch 1321 Loss 1.1648\n",
      "Epoch 4 Batch 1322 Loss 1.2167\n",
      "Epoch 4 Batch 1323 Loss 1.0023\n",
      "Epoch 4 Batch 1324 Loss 1.2135\n",
      "Epoch 4 Batch 1325 Loss 1.1627\n",
      "Epoch 4 Batch 1326 Loss 1.7098\n",
      "Epoch 4 Batch 1327 Loss 1.1463\n",
      "Epoch 4 Batch 1328 Loss 1.4179\n",
      "Epoch 4 Batch 1329 Loss 1.2194\n",
      "Epoch 4 Batch 1330 Loss 1.2185\n",
      "Epoch 4 Batch 1331 Loss 1.2638\n",
      "Epoch 4 Batch 1332 Loss 1.3788\n",
      "Epoch 4 Batch 1333 Loss 1.2375\n",
      "Epoch 4 Batch 1334 Loss 1.4203\n",
      "Epoch 4 Batch 1335 Loss 1.2888\n",
      "Epoch 4 Batch 1336 Loss 1.2211\n",
      "Epoch 4 Batch 1337 Loss 1.0738\n",
      "Epoch 4 Batch 1338 Loss 1.3308\n",
      "Epoch 4 Batch 1339 Loss 1.3330\n",
      "Epoch 4 Batch 1340 Loss 1.2732\n",
      "Epoch 4 Batch 1341 Loss 1.0791\n",
      "Epoch 4 Batch 1342 Loss 1.1990\n",
      "Epoch 4 Batch 1343 Loss 1.3592\n",
      "Epoch 4 Batch 1344 Loss 1.2166\n",
      "Epoch 4 Batch 1345 Loss 1.2609\n",
      "Epoch 4 Batch 1346 Loss 0.9352\n",
      "Epoch 4 Batch 1347 Loss 1.0087\n",
      "Epoch 4 Batch 1348 Loss 1.4124\n",
      "Epoch 4 Batch 1349 Loss 1.1187\n",
      "Epoch 4 Batch 1350 Loss 1.3250\n",
      "Epoch 4 Batch 1351 Loss 1.2346\n",
      "Epoch 4 Batch 1352 Loss 1.3897\n",
      "Epoch 4 Batch 1353 Loss 1.0937\n",
      "Epoch 4 Batch 1354 Loss 1.2667\n",
      "Epoch 4 Batch 1355 Loss 1.3029\n",
      "Epoch 4 Batch 1356 Loss 1.4961\n",
      "Epoch 4 Batch 1357 Loss 1.2761\n",
      "Epoch 4 Batch 1358 Loss 1.4481\n",
      "Epoch 4 Batch 1359 Loss 1.4505\n",
      "Epoch 4 Batch 1360 Loss 1.2036\n",
      "Epoch 4 Batch 1361 Loss 1.3344\n",
      "Epoch 4 Batch 1362 Loss 1.1607\n",
      "Epoch 4 Batch 1363 Loss 1.3747\n",
      "Epoch 4 Batch 1364 Loss 1.2546\n",
      "Epoch 4 Batch 1365 Loss 1.2349\n",
      "Epoch 4 Batch 1366 Loss 0.8825\n",
      "Epoch 4 Batch 1367 Loss 1.3011\n",
      "Epoch 4 Batch 1368 Loss 1.4278\n",
      "Epoch 4 Batch 1369 Loss 1.0179\n",
      "Epoch 4 Batch 1370 Loss 1.2465\n",
      "Epoch 4 Batch 1371 Loss 1.6559\n",
      "Epoch 4 Batch 1372 Loss 0.9080\n",
      "Epoch 4 Batch 1373 Loss 1.0897\n",
      "Epoch 4 Batch 1374 Loss 1.3630\n",
      "Epoch 4 Batch 1375 Loss 1.0597\n",
      "Epoch 4 Batch 1376 Loss 1.5077\n",
      "Epoch 4 Batch 1377 Loss 1.5790\n",
      "Epoch 4 Batch 1378 Loss 1.3724\n",
      "Epoch 4 Batch 1379 Loss 1.0683\n",
      "Epoch 4 Batch 1380 Loss 1.2170\n",
      "Epoch 4 Batch 1381 Loss 1.0350\n",
      "Epoch 4 Batch 1382 Loss 1.0128\n",
      "Epoch 4 Batch 1383 Loss 1.2988\n",
      "Epoch 4 Batch 1384 Loss 1.1684\n",
      "Epoch 4 Batch 1385 Loss 1.1608\n",
      "Epoch 4 Batch 1386 Loss 1.2972\n",
      "Epoch 4 Batch 1387 Loss 0.9961\n",
      "Epoch 4 Batch 1388 Loss 1.2639\n",
      "Epoch 4 Batch 1389 Loss 1.1424\n",
      "Epoch 4 Batch 1390 Loss 1.3680\n",
      "Epoch 4 Batch 1391 Loss 1.1350\n",
      "Epoch 4 Batch 1392 Loss 1.0727\n",
      "Epoch 4 Batch 1393 Loss 1.0627\n",
      "Epoch 4 Batch 1394 Loss 1.2618\n",
      "Epoch 4 Batch 1395 Loss 1.2480\n",
      "Epoch 4 Batch 1396 Loss 1.1405\n",
      "Epoch 4 Batch 1397 Loss 1.2624\n",
      "Epoch 4 Batch 1398 Loss 1.3730\n",
      "Epoch 4 Batch 1399 Loss 1.1155\n",
      "Epoch 4 Batch 1400 Loss 1.1903\n",
      "Epoch 4 Batch 1401 Loss 0.9089\n",
      "Epoch 4 Batch 1402 Loss 1.1796\n",
      "Epoch 4 Batch 1403 Loss 1.1871\n",
      "Epoch 4 Batch 1404 Loss 1.3498\n",
      "Epoch 4 Batch 1405 Loss 0.9708\n",
      "Epoch 4 Batch 1406 Loss 1.2923\n",
      "Epoch 4 Batch 1407 Loss 1.0546\n",
      "Epoch 4 Batch 1408 Loss 1.2920\n",
      "Epoch 4 Batch 1409 Loss 1.3703\n",
      "Epoch 4 Batch 1410 Loss 1.4761\n",
      "Epoch 4 Batch 1411 Loss 1.3208\n",
      "Epoch 4 Batch 1412 Loss 1.2156\n",
      "Epoch 4 Batch 1413 Loss 1.2398\n",
      "Epoch 4 Batch 1414 Loss 1.1265\n",
      "Epoch 4 Batch 1415 Loss 1.2111\n",
      "Epoch 4 Batch 1416 Loss 1.5844\n",
      "Epoch 4 Batch 1417 Loss 1.0727\n",
      "Epoch 4 Batch 1418 Loss 1.4810\n",
      "Epoch 4 Batch 1419 Loss 1.2221\n",
      "Epoch 4 Batch 1420 Loss 1.2166\n",
      "Epoch 4 Batch 1421 Loss 1.0260\n",
      "Epoch 4 Batch 1422 Loss 1.3522\n",
      "Epoch 4 Batch 1423 Loss 1.1050\n",
      "Epoch 4 Batch 1424 Loss 1.4007\n",
      "Epoch 4 Batch 1425 Loss 1.0571\n",
      "Epoch 4 Batch 1426 Loss 1.0408\n",
      "Epoch 4 Batch 1427 Loss 1.2804\n",
      "Epoch 4 Batch 1428 Loss 1.0050\n",
      "Epoch 4 Batch 1429 Loss 1.3911\n",
      "Epoch 4 Batch 1430 Loss 1.2423\n",
      "Epoch 4 Batch 1431 Loss 1.3171\n",
      "Epoch 4 Batch 1432 Loss 1.0026\n",
      "Epoch 4 Batch 1433 Loss 0.8352\n",
      "Epoch 4 Batch 1434 Loss 1.3848\n",
      "Epoch 4 Batch 1435 Loss 1.3233\n",
      "Epoch 4 Batch 1436 Loss 1.0085\n",
      "Epoch 4 Batch 1437 Loss 1.0893\n",
      "Epoch 4 Batch 1438 Loss 1.6326\n",
      "Epoch 4 Batch 1439 Loss 1.3333\n",
      "Epoch 4 Batch 1440 Loss 1.0079\n",
      "Epoch 4 Batch 1441 Loss 0.9954\n",
      "Epoch 4 Batch 1442 Loss 1.3859\n",
      "Epoch 4 Batch 1443 Loss 1.1921\n",
      "Epoch 4 Batch 1444 Loss 1.4730\n",
      "Epoch 4 Batch 1445 Loss 1.0326\n",
      "Epoch 4 Batch 1446 Loss 1.3627\n",
      "Epoch 4 Batch 1447 Loss 1.0408\n",
      "Epoch 4 Batch 1448 Loss 1.0224\n",
      "Epoch 4 Batch 1449 Loss 1.2820\n",
      "Epoch 4 Batch 1450 Loss 1.1672\n",
      "Epoch 4 Batch 1451 Loss 1.1153\n",
      "Epoch 4 Batch 1452 Loss 1.4731\n",
      "Epoch 4 Batch 1453 Loss 1.1750\n",
      "Epoch 4 Batch 1454 Loss 0.9822\n",
      "Epoch 4 Batch 1455 Loss 0.9077\n",
      "Epoch 4 Batch 1456 Loss 1.3219\n",
      "Epoch 4 Batch 1457 Loss 1.1274\n",
      "Epoch 4 Batch 1458 Loss 1.2396\n",
      "Epoch 4 Batch 1459 Loss 1.1018\n",
      "Epoch 4 Batch 1460 Loss 1.2550\n",
      "Epoch 4 Batch 1461 Loss 1.4567\n",
      "Epoch 4 Batch 1462 Loss 1.1231\n",
      "Epoch 4 Batch 1463 Loss 1.2014\n",
      "Epoch 4 Batch 1464 Loss 1.1500\n",
      "Epoch 4 Batch 1465 Loss 1.3783\n",
      "Epoch 4 Batch 1466 Loss 1.3000\n",
      "Epoch 4 Batch 1467 Loss 1.4181\n",
      "Epoch 4 Batch 1468 Loss 1.2527\n",
      "Epoch 4 Batch 1469 Loss 1.3137\n",
      "Epoch 4 Batch 1470 Loss 1.2518\n",
      "Epoch 4 Batch 1471 Loss 1.1697\n",
      "Epoch 4 Batch 1472 Loss 1.2586\n",
      "Epoch 4 Batch 1473 Loss 1.3282\n",
      "Epoch 4 Batch 1474 Loss 1.1998\n",
      "Epoch 4 Batch 1475 Loss 1.1368\n",
      "Epoch 4 Batch 1476 Loss 1.0953\n",
      "Epoch 4 Batch 1477 Loss 1.1502\n",
      "Epoch 4 Batch 1478 Loss 1.1274\n",
      "Epoch 4 Batch 1479 Loss 1.5292\n",
      "Epoch 4 Batch 1480 Loss 1.2367\n",
      "Epoch 4 Batch 1481 Loss 1.2509\n",
      "Epoch 4 Batch 1482 Loss 1.3623\n",
      "Epoch 4 Batch 1483 Loss 1.3269\n",
      "Epoch 4 Batch 1484 Loss 1.1910\n",
      "Epoch 4 Batch 1485 Loss 1.3452\n",
      "Epoch 4 Batch 1486 Loss 0.9035\n",
      "Epoch 4 Batch 1487 Loss 1.0662\n",
      "Epoch 4 Batch 1488 Loss 1.3807\n",
      "Epoch 4 Batch 1489 Loss 1.1845\n",
      "Epoch 4 Batch 1490 Loss 1.3879\n",
      "Epoch 4 Batch 1491 Loss 1.7124\n",
      "Epoch 4 Batch 1492 Loss 1.2968\n",
      "Epoch 4 Batch 1493 Loss 1.3243\n",
      "Epoch 4 Batch 1494 Loss 1.3653\n",
      "Epoch 4 Batch 1495 Loss 1.1769\n",
      "Epoch 4 Batch 1496 Loss 1.2869\n",
      "Epoch 4 Batch 1497 Loss 1.2578\n",
      "Epoch 4 Batch 1498 Loss 1.3272\n",
      "Epoch 4 Batch 1499 Loss 1.1279\n",
      "Epoch 4 Batch 1500 Loss 1.2256\n",
      "Epoch 4 Batch 1501 Loss 1.3121\n",
      "Epoch 4 Batch 1502 Loss 1.0864\n",
      "Epoch 4 Batch 1503 Loss 1.1635\n",
      "Epoch 4 Batch 1504 Loss 1.2837\n",
      "Epoch 4 Batch 1505 Loss 1.2445\n",
      "Epoch 4 Batch 1506 Loss 1.2038\n",
      "Epoch 4 Batch 1507 Loss 1.6001\n",
      "Epoch 4 Batch 1508 Loss 1.1708\n",
      "Epoch 4 Batch 1509 Loss 1.4646\n",
      "Epoch 4 Batch 1510 Loss 1.0981\n",
      "Epoch 4 Batch 1511 Loss 1.1588\n",
      "Epoch 4 Batch 1512 Loss 1.0795\n",
      "Epoch 4 Batch 1513 Loss 1.1447\n",
      "Epoch 4 Batch 1514 Loss 1.0385\n",
      "Epoch 4 Batch 1515 Loss 1.4013\n",
      "Epoch 4 Batch 1516 Loss 1.1025\n",
      "Epoch 4 Batch 1517 Loss 1.2760\n",
      "Epoch 4 Batch 1518 Loss 1.3694\n",
      "Epoch 4 Batch 1519 Loss 1.2899\n",
      "Epoch 4 Batch 1520 Loss 0.9874\n",
      "Epoch 4 Batch 1521 Loss 1.0925\n",
      "Epoch 4 Batch 1522 Loss 1.2083\n",
      "Epoch 4 Batch 1523 Loss 1.2807\n",
      "Epoch 4 Batch 1524 Loss 1.3325\n",
      "Epoch 4 Batch 1525 Loss 1.6671\n",
      "Epoch 4 Batch 1526 Loss 1.2220\n",
      "Epoch 4 Batch 1527 Loss 1.2918\n",
      "Epoch 4 Batch 1528 Loss 1.3986\n",
      "Epoch 4 Batch 1529 Loss 1.0901\n",
      "Epoch 4 Batch 1530 Loss 1.0575\n",
      "Epoch 4 Batch 1531 Loss 1.3047\n",
      "Epoch 4 Batch 1532 Loss 1.3178\n",
      "Epoch 4 Batch 1533 Loss 1.2361\n",
      "Epoch 4 Batch 1534 Loss 1.4011\n",
      "Epoch 4 Batch 1535 Loss 1.0066\n",
      "Epoch 4 Batch 1536 Loss 1.0212\n",
      "Epoch 4 Batch 1537 Loss 1.2928\n",
      "Epoch 4 Batch 1538 Loss 1.1877\n",
      "Epoch 4 Batch 1539 Loss 1.0270\n",
      "Epoch 4 Batch 1540 Loss 1.1142\n",
      "Epoch 4 Batch 1541 Loss 1.2239\n",
      "Epoch 4 Batch 1542 Loss 1.0984\n",
      "Epoch 4 Batch 1543 Loss 1.2556\n",
      "Epoch 4 Batch 1544 Loss 1.3427\n",
      "Epoch 4 Batch 1545 Loss 1.2273\n",
      "Epoch 4 Batch 1546 Loss 1.1777\n",
      "Epoch 4 Batch 1547 Loss 0.9168\n",
      "Epoch 4 Batch 1548 Loss 0.9116\n",
      "Epoch 4 Batch 1549 Loss 1.3709\n",
      "Epoch 4 Batch 1550 Loss 1.1233\n",
      "Epoch 4 Batch 1551 Loss 1.2070\n",
      "Epoch 4 Batch 1552 Loss 1.4328\n",
      "Epoch 4 Batch 1553 Loss 1.2790\n",
      "Epoch 4 Batch 1554 Loss 1.4479\n",
      "Epoch 4 Batch 1555 Loss 1.3851\n",
      "Epoch 4 Batch 1556 Loss 1.4654\n",
      "Epoch 4 Batch 1557 Loss 1.3655\n",
      "Epoch 4 Batch 1558 Loss 1.0373\n",
      "Epoch 4 Batch 1559 Loss 1.2426\n",
      "Epoch 4 Batch 1560 Loss 0.9050\n",
      "Epoch 4 Batch 1561 Loss 1.1247\n",
      "Epoch 4 Batch 1562 Loss 1.1217\n",
      "Epoch 4 Batch 1563 Loss 1.3155\n",
      "Epoch 4 Batch 1564 Loss 1.5446\n",
      "Epoch 4 Batch 1565 Loss 1.4069\n",
      "Epoch 4 Batch 1566 Loss 1.1650\n",
      "Epoch 4 Batch 1567 Loss 1.3559\n",
      "Epoch 4 Batch 1568 Loss 1.5945\n",
      "Epoch 4 Batch 1569 Loss 1.4482\n",
      "Epoch 4 Batch 1570 Loss 1.3316\n",
      "Epoch 4 Batch 1571 Loss 1.0858\n",
      "Epoch 4 Batch 1572 Loss 1.2164\n",
      "Epoch 4 Batch 1573 Loss 1.2734\n",
      "Epoch 4 Batch 1574 Loss 1.0863\n",
      "Epoch 4 Batch 1575 Loss 1.3872\n",
      "Epoch 4 Batch 1576 Loss 1.7846\n",
      "Epoch 4 Batch 1577 Loss 1.1646\n",
      "Epoch 4 Batch 1578 Loss 1.1454\n",
      "Epoch 4 Batch 1579 Loss 0.8840\n",
      "Epoch 4 Batch 1580 Loss 0.9914\n",
      "Epoch 4 Batch 1581 Loss 1.1747\n",
      "Epoch 4 Batch 1582 Loss 1.5159\n",
      "Epoch 4 Batch 1583 Loss 0.9074\n",
      "Epoch 4 Batch 1584 Loss 1.3768\n",
      "Epoch 4 Batch 1585 Loss 1.1664\n",
      "Epoch 4 Batch 1586 Loss 1.0836\n",
      "Epoch 4 Batch 1587 Loss 1.4373\n",
      "Epoch 4 Batch 1588 Loss 1.2375\n",
      "Epoch 4 Batch 1589 Loss 1.3263\n",
      "Epoch 4 Batch 1590 Loss 1.3925\n",
      "Epoch 4 Batch 1591 Loss 1.2507\n",
      "Epoch 4 Batch 1592 Loss 1.1231\n",
      "Epoch 4 Batch 1593 Loss 1.5609\n",
      "Epoch 4 Batch 1594 Loss 1.2704\n",
      "Epoch 4 Batch 1595 Loss 1.4478\n",
      "Epoch 4 Batch 1596 Loss 0.8858\n",
      "Epoch 4 Batch 1597 Loss 1.0806\n",
      "Epoch 4 Batch 1598 Loss 0.9765\n",
      "Epoch 4 Batch 1599 Loss 1.2211\n",
      "Epoch 4 Batch 1600 Loss 1.2292\n",
      "Epoch 4 Batch 1601 Loss 1.3104\n",
      "Epoch 4 Batch 1602 Loss 1.2385\n",
      "Epoch 4 Batch 1603 Loss 0.9779\n",
      "Epoch 4 Batch 1604 Loss 1.3885\n",
      "Epoch 4 Batch 1605 Loss 1.2397\n",
      "Epoch 4 Batch 1606 Loss 1.2717\n",
      "Epoch 4 Batch 1607 Loss 1.0687\n",
      "Epoch 4 Batch 1608 Loss 1.0876\n",
      "Epoch 4 Batch 1609 Loss 1.2311\n",
      "Epoch 4 Batch 1610 Loss 1.3948\n",
      "Epoch 4 Batch 1611 Loss 1.4879\n",
      "Epoch 4 Batch 1612 Loss 1.1936\n",
      "Epoch 4 Batch 1613 Loss 1.1323\n",
      "Epoch 4 Batch 1614 Loss 1.4572\n",
      "Epoch 4 Batch 1615 Loss 1.1519\n",
      "Epoch 4 Batch 1616 Loss 1.0378\n",
      "Epoch 4 Batch 1617 Loss 1.1274\n",
      "Epoch 4 Batch 1618 Loss 0.9839\n",
      "Epoch 4 Batch 1619 Loss 1.0081\n",
      "Epoch 4 Batch 1620 Loss 1.2695\n",
      "Epoch 4 Batch 1621 Loss 1.1081\n",
      "Epoch 4 Batch 1622 Loss 0.9622\n",
      "Epoch 4 Batch 1623 Loss 1.2876\n",
      "Epoch 4 Batch 1624 Loss 1.2441\n",
      "Epoch 4 Batch 1625 Loss 1.2758\n",
      "Epoch 4 Batch 1626 Loss 1.3333\n",
      "Epoch 4 Batch 1627 Loss 1.2202\n",
      "Epoch 4 Batch 1628 Loss 1.0317\n",
      "Epoch 4 Batch 1629 Loss 1.2748\n",
      "Epoch 4 Batch 1630 Loss 1.4435\n",
      "Epoch 4 Batch 1631 Loss 1.2018\n",
      "Epoch 4 Batch 1632 Loss 1.2379\n",
      "Epoch 4 Batch 1633 Loss 1.1925\n",
      "Epoch 4 Batch 1634 Loss 1.0735\n",
      "Epoch 4 Batch 1635 Loss 1.0550\n",
      "Epoch 4 Batch 1636 Loss 1.1718\n",
      "Epoch 4 Batch 1637 Loss 1.1104\n",
      "Epoch 4 Batch 1638 Loss 1.4957\n",
      "Epoch 4 Batch 1639 Loss 1.4138\n",
      "Epoch 4 Batch 1640 Loss 1.1970\n",
      "Epoch 4 Batch 1641 Loss 0.8972\n",
      "Epoch 4 Batch 1642 Loss 1.0190\n",
      "Epoch 4 Batch 1643 Loss 1.0737\n",
      "Epoch 4 Batch 1644 Loss 1.2792\n",
      "Epoch 4 Batch 1645 Loss 1.3734\n",
      "Epoch 4 Batch 1646 Loss 1.1485\n",
      "Epoch 4 Batch 1647 Loss 1.2282\n",
      "Epoch 4 Batch 1648 Loss 1.3123\n",
      "Epoch 4 Batch 1649 Loss 1.3536\n",
      "Epoch 4 Batch 1650 Loss 1.1988\n",
      "Epoch 4 Batch 1651 Loss 1.2764\n",
      "Epoch 4 Batch 1652 Loss 1.4703\n",
      "Epoch 4 Batch 1653 Loss 1.3608\n",
      "Epoch 4 Batch 1654 Loss 1.3808\n",
      "Epoch 4 Batch 1655 Loss 1.0832\n",
      "Epoch 4 Batch 1656 Loss 1.2219\n",
      "Epoch 4 Batch 1657 Loss 1.2570\n",
      "Epoch 4 Batch 1658 Loss 1.2805\n",
      "Epoch 4 Batch 1659 Loss 1.1392\n",
      "Epoch 4 Batch 1660 Loss 1.3041\n",
      "Epoch 4 Batch 1661 Loss 1.2508\n",
      "Epoch 4 Batch 1662 Loss 1.0867\n",
      "Epoch 4 Batch 1663 Loss 1.0852\n",
      "Epoch 4 Batch 1664 Loss 1.2157\n",
      "Epoch 4 Batch 1665 Loss 1.4117\n",
      "Epoch 4 Batch 1666 Loss 1.3140\n",
      "Epoch 4 Batch 1667 Loss 1.2360\n",
      "Epoch 4 Batch 1668 Loss 1.1338\n",
      "Epoch 4 Batch 1669 Loss 1.0964\n",
      "Epoch 4 Batch 1670 Loss 1.3532\n",
      "Epoch 4 Batch 1671 Loss 1.0853\n",
      "Epoch 4 Batch 1672 Loss 1.2638\n",
      "Epoch 4 Batch 1673 Loss 1.3393\n",
      "Epoch 4 Batch 1674 Loss 1.1775\n",
      "Epoch 4 Batch 1675 Loss 1.0570\n",
      "Epoch 4 Batch 1676 Loss 1.0107\n",
      "Epoch 4 Batch 1677 Loss 0.9864\n",
      "Epoch 4 Batch 1678 Loss 1.3944\n",
      "Epoch 4 Batch 1679 Loss 1.1702\n",
      "Epoch 4 Batch 1680 Loss 1.0196\n",
      "Epoch 4 Batch 1681 Loss 0.8832\n",
      "Epoch 4 Batch 1682 Loss 1.2351\n",
      "Epoch 4 Batch 1683 Loss 1.0845\n",
      "Epoch 4 Batch 1684 Loss 1.0141\n",
      "Epoch 4 Batch 1685 Loss 0.9505\n",
      "Epoch 4 Batch 1686 Loss 1.1923\n",
      "Epoch 4 Batch 1687 Loss 1.2480\n",
      "Epoch 4 Batch 1688 Loss 1.1689\n",
      "Epoch 4 Batch 1689 Loss 1.4540\n",
      "Epoch 4 Batch 1690 Loss 1.4133\n",
      "Epoch 4 Batch 1691 Loss 1.3102\n",
      "Epoch 4 Batch 1692 Loss 1.1865\n",
      "Epoch 4 Batch 1693 Loss 1.5214\n",
      "Epoch 4 Batch 1694 Loss 1.1927\n",
      "Epoch 4 Batch 1695 Loss 1.3141\n",
      "Epoch 4 Batch 1696 Loss 1.1017\n",
      "Epoch 4 Batch 1697 Loss 1.4864\n",
      "Epoch 4 Batch 1698 Loss 1.2137\n",
      "Epoch 4 Batch 1699 Loss 1.6568\n",
      "Epoch 4 Batch 1700 Loss 1.3049\n",
      "Epoch 4 Batch 1701 Loss 1.1084\n",
      "Epoch 4 Batch 1702 Loss 1.1045\n",
      "Epoch 4 Batch 1703 Loss 1.2362\n",
      "Epoch 4 Batch 1704 Loss 1.1848\n",
      "Epoch 4 Batch 1705 Loss 1.0859\n",
      "Epoch 4 Batch 1706 Loss 1.1217\n",
      "Epoch 4 Batch 1707 Loss 1.2773\n",
      "Epoch 4 Batch 1708 Loss 1.0213\n",
      "Epoch 4 Batch 1709 Loss 1.2216\n",
      "Epoch 4 Batch 1710 Loss 1.1503\n",
      "Epoch 4 Batch 1711 Loss 1.2095\n",
      "Epoch 4 Batch 1712 Loss 1.1756\n",
      "Epoch 4 Batch 1713 Loss 1.0704\n",
      "Epoch 4 Batch 1714 Loss 1.1335\n",
      "Epoch 4 Batch 1715 Loss 1.0705\n",
      "Epoch 4 Batch 1716 Loss 1.1099\n",
      "Epoch 4 Batch 1717 Loss 1.2538\n",
      "Epoch 4 Batch 1718 Loss 1.0154\n",
      "Epoch 4 Batch 1719 Loss 1.7175\n",
      "Epoch 4 Batch 1720 Loss 1.2410\n",
      "Epoch 4 Batch 1721 Loss 1.0478\n",
      "Epoch 4 Batch 1722 Loss 1.1696\n",
      "Epoch 4 Batch 1723 Loss 1.2667\n",
      "Epoch 4 Batch 1724 Loss 1.3011\n",
      "Epoch 4 Batch 1725 Loss 0.8695\n",
      "Epoch 4 Batch 1726 Loss 1.0869\n",
      "Epoch 4 Batch 1727 Loss 1.3154\n",
      "Epoch 4 Batch 1728 Loss 0.9704\n",
      "Epoch 4 Batch 1729 Loss 1.7161\n",
      "Epoch 4 Batch 1730 Loss 1.3485\n",
      "Epoch 4 Batch 1731 Loss 1.1816\n",
      "Epoch 4 Batch 1732 Loss 0.9242\n",
      "Epoch 4 Batch 1733 Loss 1.1508\n",
      "Epoch 4 Batch 1734 Loss 1.1339\n",
      "Epoch 4 Batch 1735 Loss 1.4413\n",
      "Epoch 4 Batch 1736 Loss 1.3025\n",
      "Epoch 4 Batch 1737 Loss 1.0686\n",
      "Epoch 4 Batch 1738 Loss 1.4329\n",
      "Epoch 4 Batch 1739 Loss 1.2155\n",
      "Epoch 4 Batch 1740 Loss 1.2496\n",
      "Epoch 4 Batch 1741 Loss 1.2818\n",
      "Epoch 4 Batch 1742 Loss 1.0818\n",
      "Epoch 4 Batch 1743 Loss 0.9104\n",
      "Epoch 4 Batch 1744 Loss 1.0292\n",
      "Epoch 4 Batch 1745 Loss 0.9979\n",
      "Epoch 4 Batch 1746 Loss 1.5363\n",
      "Epoch 4 Batch 1747 Loss 1.2700\n",
      "Epoch 4 Batch 1748 Loss 1.1406\n",
      "Epoch 4 Batch 1749 Loss 1.4441\n",
      "Epoch 4 Batch 1750 Loss 0.9033\n",
      "Epoch 4 Batch 1751 Loss 1.2924\n",
      "Epoch 4 Batch 1752 Loss 1.2509\n",
      "Epoch 4 Batch 1753 Loss 1.0237\n",
      "Epoch 4 Batch 1754 Loss 1.1369\n",
      "Epoch 4 Batch 1755 Loss 1.5185\n",
      "Epoch 4 Batch 1756 Loss 1.4007\n",
      "Epoch 4 Batch 1757 Loss 0.9866\n",
      "Epoch 4 Batch 1758 Loss 1.2034\n",
      "Epoch 4 Batch 1759 Loss 1.3957\n",
      "Epoch 4 Batch 1760 Loss 1.3472\n",
      "Epoch 4 Batch 1761 Loss 1.2089\n",
      "Epoch 4 Batch 1762 Loss 1.2823\n",
      "Epoch 4 Batch 1763 Loss 1.0015\n",
      "Epoch 4 Batch 1764 Loss 1.0670\n",
      "Epoch 4 Batch 1765 Loss 1.2777\n",
      "Epoch 4 Batch 1766 Loss 1.1984\n",
      "Epoch 4 Batch 1767 Loss 0.9593\n",
      "Epoch 4 Batch 1768 Loss 1.0890\n",
      "Epoch 4 Batch 1769 Loss 1.2001\n",
      "Epoch 4 Batch 1770 Loss 1.3885\n",
      "Epoch 4 Batch 1771 Loss 1.3843\n",
      "Epoch 4 Batch 1772 Loss 1.4547\n",
      "Epoch 4 Batch 1773 Loss 1.1254\n",
      "Epoch 4 Batch 1774 Loss 1.5561\n",
      "Epoch 4 Batch 1775 Loss 1.2421\n",
      "Epoch 4 Batch 1776 Loss 1.1404\n",
      "Epoch 4 Batch 1777 Loss 1.2051\n",
      "Epoch 4 Batch 1778 Loss 1.3302\n",
      "Epoch 4 Batch 1779 Loss 1.3862\n",
      "Epoch 4 Batch 1780 Loss 1.5106\n",
      "Epoch 4 Batch 1781 Loss 1.4913\n",
      "Epoch 4 Batch 1782 Loss 1.3076\n",
      "Epoch 4 Batch 1783 Loss 1.2647\n",
      "Epoch 4 Batch 1784 Loss 0.8411\n",
      "Epoch 4 Batch 1785 Loss 1.1006\n",
      "Epoch 4 Batch 1786 Loss 1.2580\n",
      "Epoch 4 Batch 1787 Loss 1.2580\n",
      "Epoch 4 Batch 1788 Loss 1.4730\n",
      "Epoch 4 Batch 1789 Loss 1.2285\n",
      "Epoch 4 Batch 1790 Loss 1.6048\n",
      "Epoch 4 Batch 1791 Loss 1.1083\n",
      "Epoch 4 Batch 1792 Loss 0.9327\n",
      "Epoch 4 Batch 1793 Loss 1.2656\n",
      "Epoch 4 Batch 1794 Loss 1.0005\n",
      "Epoch 4 Batch 1795 Loss 1.1285\n",
      "Epoch 4 Batch 1796 Loss 1.4644\n",
      "Epoch 4 Batch 1797 Loss 0.8413\n",
      "Epoch 4 Batch 1798 Loss 1.3996\n",
      "Epoch 4 Batch 1799 Loss 1.3546\n",
      "Epoch 4 Batch 1800 Loss 1.1171\n",
      "Epoch 4 Batch 1801 Loss 1.1640\n",
      "Epoch 4 Batch 1802 Loss 1.2225\n",
      "Epoch 4 Batch 1803 Loss 1.1509\n",
      "Epoch 4 Batch 1804 Loss 1.1736\n",
      "Epoch 4 Batch 1805 Loss 1.2092\n",
      "Epoch 4 Batch 1806 Loss 1.1550\n",
      "Epoch 4 Batch 1807 Loss 1.1911\n",
      "Epoch 4 Batch 1808 Loss 1.3155\n",
      "Epoch 4 Batch 1809 Loss 1.3385\n",
      "Epoch 4 Batch 1810 Loss 1.3500\n",
      "Epoch 4 Batch 1811 Loss 1.4169\n",
      "Epoch 4 Batch 1812 Loss 1.4135\n",
      "Epoch 4 Batch 1813 Loss 1.0139\n",
      "Epoch 4 Batch 1814 Loss 1.4094\n",
      "Epoch 4 Batch 1815 Loss 1.1353\n",
      "Epoch 4 Batch 1816 Loss 1.0717\n",
      "Epoch 4 Batch 1817 Loss 1.3554\n",
      "Epoch 4 Batch 1818 Loss 1.2845\n",
      "Epoch 4 Batch 1819 Loss 1.0247\n",
      "Epoch 4 Batch 1820 Loss 1.0752\n",
      "Epoch 4 Batch 1821 Loss 1.1966\n",
      "Epoch 4 Batch 1822 Loss 1.0442\n",
      "Epoch 4 Batch 1823 Loss 1.4111\n",
      "Epoch 4 Batch 1824 Loss 0.9917\n",
      "Epoch 4 Batch 1825 Loss 1.0402\n",
      "Epoch 4 Batch 1826 Loss 1.0616\n",
      "Epoch 4 Batch 1827 Loss 1.4435\n",
      "Epoch 4 Batch 1828 Loss 1.1265\n",
      "Epoch 4 Batch 1829 Loss 1.1805\n",
      "Epoch 4 Batch 1830 Loss 0.9899\n",
      "Epoch 4 Batch 1831 Loss 1.1024\n",
      "Epoch 4 Batch 1832 Loss 1.3638\n",
      "Epoch 4 Batch 1833 Loss 1.0540\n",
      "Epoch 4 Batch 1834 Loss 1.7261\n",
      "Epoch 4 Batch 1835 Loss 1.2506\n",
      "Epoch 4 Batch 1836 Loss 1.2012\n",
      "Epoch 4 Batch 1837 Loss 1.2130\n",
      "Epoch 4 Batch 1838 Loss 1.3283\n",
      "Epoch 4 Batch 1839 Loss 1.1587\n",
      "Epoch 4 Batch 1840 Loss 1.0589\n",
      "Epoch 4 Batch 1841 Loss 1.3909\n",
      "Epoch 4 Batch 1842 Loss 1.2566\n",
      "Epoch 4 Batch 1843 Loss 1.2057\n",
      "Epoch 4 Batch 1844 Loss 1.2604\n",
      "Epoch 4 Batch 1845 Loss 1.3471\n",
      "Epoch 4 Batch 1846 Loss 1.5333\n",
      "Epoch 4 Batch 1847 Loss 0.8809\n",
      "Epoch 4 Batch 1848 Loss 1.2461\n",
      "Epoch 4 Batch 1849 Loss 1.0120\n",
      "Epoch 4 Batch 1850 Loss 1.1934\n",
      "Epoch 4 Batch 1851 Loss 1.2432\n",
      "Epoch 4 Batch 1852 Loss 1.1620\n",
      "Epoch 4 Batch 1853 Loss 1.3655\n",
      "Epoch 4 Batch 1854 Loss 1.2126\n",
      "Epoch 4 Batch 1855 Loss 1.3254\n",
      "Epoch 4 Batch 1856 Loss 1.5324\n",
      "Epoch 4 Batch 1857 Loss 1.1428\n",
      "Epoch 4 Batch 1858 Loss 1.3384\n",
      "Epoch 4 Batch 1859 Loss 1.3827\n",
      "Epoch 4 Batch 1860 Loss 1.3777\n",
      "Epoch 4 Batch 1861 Loss 1.5129\n",
      "Epoch 4 Batch 1862 Loss 1.4029\n",
      "Epoch 4 Batch 1863 Loss 1.0668\n",
      "Epoch 4 Batch 1864 Loss 1.6238\n",
      "Epoch 4 Batch 1865 Loss 1.2303\n",
      "Epoch 4 Batch 1866 Loss 1.1981\n",
      "Epoch 4 Batch 1867 Loss 1.1127\n",
      "Epoch 4 Batch 1868 Loss 1.0904\n",
      "Epoch 4 Batch 1869 Loss 1.0632\n",
      "Epoch 4 Batch 1870 Loss 1.0392\n",
      "Epoch 4 Batch 1871 Loss 1.1152\n",
      "Epoch 4 Batch 1872 Loss 1.3105\n",
      "Epoch 4 Batch 1873 Loss 1.1538\n",
      "Epoch 4 Batch 1874 Loss 1.3158\n",
      "Epoch 4 Batch 1875 Loss 1.1098\n",
      "Epoch 4 Batch 1876 Loss 1.2858\n",
      "Epoch 4 Batch 1877 Loss 1.1175\n",
      "Epoch 4 Batch 1878 Loss 1.2952\n",
      "Epoch 4 Batch 1879 Loss 1.2759\n",
      "Epoch 4 Batch 1880 Loss 1.0458\n",
      "Epoch 4 Batch 1881 Loss 1.1686\n",
      "Epoch 4 Batch 1882 Loss 1.0746\n",
      "Epoch 4 Batch 1883 Loss 1.1640\n",
      "Epoch 4 Batch 1884 Loss 1.2335\n",
      "Epoch 4 Batch 1885 Loss 1.0301\n",
      "Epoch 4 Batch 1886 Loss 1.0038\n",
      "Epoch 4 Batch 1887 Loss 1.1588\n",
      "Epoch 4 Batch 1888 Loss 1.2010\n",
      "Epoch 4 Batch 1889 Loss 1.2856\n",
      "Epoch 4 Batch 1890 Loss 1.2364\n",
      "Epoch 4 Batch 1891 Loss 1.1670\n",
      "Epoch 4 Batch 1892 Loss 1.3809\n",
      "Epoch 4 Batch 1893 Loss 1.2002\n",
      "Epoch 4 Batch 1894 Loss 1.3481\n",
      "Epoch 4 Batch 1895 Loss 1.1181\n",
      "Epoch 4 Batch 1896 Loss 1.3044\n",
      "Epoch 4 Batch 1897 Loss 1.1585\n",
      "Epoch 4 Batch 1898 Loss 1.4474\n",
      "Epoch 4 Batch 1899 Loss 1.0434\n",
      "Epoch 4 Batch 1900 Loss 1.3732\n",
      "Epoch 4 Batch 1901 Loss 1.3188\n",
      "Epoch 4 Batch 1902 Loss 1.2563\n",
      "Epoch 4 Batch 1903 Loss 1.4591\n",
      "Epoch 4 Batch 1904 Loss 1.2624\n",
      "Epoch 4 Batch 1905 Loss 1.2414\n",
      "Epoch 4 Batch 1906 Loss 1.3563\n",
      "Epoch 4 Batch 1907 Loss 1.3128\n",
      "Epoch 4 Batch 1908 Loss 1.1409\n",
      "Epoch 4 Batch 1909 Loss 1.3433\n",
      "Epoch 4 Batch 1910 Loss 1.1128\n",
      "Epoch 4 Batch 1911 Loss 1.3399\n",
      "Epoch 4 Batch 1912 Loss 1.1495\n",
      "Epoch 4 Batch 1913 Loss 1.1111\n",
      "Epoch 4 Batch 1914 Loss 1.2734\n",
      "Epoch 4 Batch 1915 Loss 1.0143\n",
      "Epoch 4 Batch 1916 Loss 1.1683\n",
      "Epoch 4 Batch 1917 Loss 1.3867\n",
      "Epoch 4 Batch 1918 Loss 1.1448\n",
      "Epoch 4 Batch 1919 Loss 1.4652\n",
      "Epoch 4 Batch 1920 Loss 1.2271\n",
      "Epoch 4 Batch 1921 Loss 1.3052\n",
      "Epoch 4 Batch 1922 Loss 1.1225\n",
      "Epoch 4 Batch 1923 Loss 1.3338\n",
      "Epoch 4 Batch 1924 Loss 1.5203\n",
      "Epoch 4 Batch 1925 Loss 1.3396\n",
      "Epoch 4 Batch 1926 Loss 1.2033\n",
      "Epoch 4 Batch 1927 Loss 1.1040\n",
      "Epoch 4 Batch 1928 Loss 1.1306\n",
      "Epoch 4 Batch 1929 Loss 1.0907\n",
      "Epoch 4 Batch 1930 Loss 1.0008\n",
      "Epoch 4 Batch 1931 Loss 0.9935\n",
      "Epoch 4 Batch 1932 Loss 1.0703\n",
      "Epoch 4 Batch 1933 Loss 1.1942\n",
      "Epoch 4 Batch 1934 Loss 1.3508\n",
      "Epoch 4 Batch 1935 Loss 1.3256\n",
      "Epoch 4 Batch 1936 Loss 1.6871\n",
      "Epoch 4 Batch 1937 Loss 1.2363\n",
      "Epoch 4 Batch 1938 Loss 1.0171\n",
      "Epoch 4 Batch 1939 Loss 1.2118\n",
      "Epoch 4 Batch 1940 Loss 1.0980\n",
      "Epoch 4 Batch 1941 Loss 1.2038\n",
      "Epoch 4 Batch 1942 Loss 1.1643\n",
      "Epoch 4 Batch 1943 Loss 1.0786\n",
      "Epoch 4 Batch 1944 Loss 1.2646\n",
      "Epoch 4 Batch 1945 Loss 1.2655\n",
      "Epoch 4 Batch 1946 Loss 1.0148\n",
      "Epoch 4 Batch 1947 Loss 1.0760\n",
      "Epoch 4 Batch 1948 Loss 1.2853\n",
      "Epoch 4 Batch 1949 Loss 0.9729\n",
      "Epoch 4 Batch 1950 Loss 1.3639\n",
      "Epoch 4 Batch 1951 Loss 1.1179\n",
      "Epoch 4 Batch 1952 Loss 1.0993\n",
      "Epoch 4 Batch 1953 Loss 0.9315\n",
      "Epoch 4 Batch 1954 Loss 1.2348\n",
      "Epoch 4 Batch 1955 Loss 1.2250\n",
      "Epoch 4 Batch 1956 Loss 1.2614\n",
      "Epoch 4 Batch 1957 Loss 1.3481\n",
      "Epoch 4 Batch 1958 Loss 1.4100\n",
      "Epoch 4 Batch 1959 Loss 1.2564\n",
      "Epoch 4 Batch 1960 Loss 1.1020\n",
      "Epoch 4 Batch 1961 Loss 1.4028\n",
      "Epoch 4 Batch 1962 Loss 1.1582\n",
      "Epoch 4 Batch 1963 Loss 1.0720\n",
      "Epoch 4 Batch 1964 Loss 1.5303\n",
      "Epoch 4 Batch 1965 Loss 1.5577\n",
      "Epoch 4 Batch 1966 Loss 1.2352\n",
      "Epoch 4 Batch 1967 Loss 1.1778\n",
      "Epoch 4 Batch 1968 Loss 1.0936\n",
      "Epoch 4 Batch 1969 Loss 1.1148\n",
      "Epoch 4 Batch 1970 Loss 1.3754\n",
      "Epoch 4 Batch 1971 Loss 0.8886\n",
      "Epoch 4 Batch 1972 Loss 1.1778\n",
      "Epoch 4 Batch 1973 Loss 1.3660\n",
      "Epoch 4 Batch 1974 Loss 1.2500\n",
      "Epoch 4 Batch 1975 Loss 1.3767\n",
      "Epoch 4 Batch 1976 Loss 1.3651\n",
      "Epoch 4 Batch 1977 Loss 1.1019\n",
      "Epoch 4 Batch 1978 Loss 1.1201\n",
      "Epoch 4 Batch 1979 Loss 1.4237\n",
      "Epoch 4 Batch 1980 Loss 0.9793\n",
      "Epoch 4 Batch 1981 Loss 1.1095\n",
      "Epoch 4 Batch 1982 Loss 1.1950\n",
      "Epoch 4 Batch 1983 Loss 1.2771\n",
      "Epoch 4 Batch 1984 Loss 1.1327\n",
      "Epoch 4 Batch 1985 Loss 1.0489\n",
      "Epoch 4 Batch 1986 Loss 1.2610\n",
      "Epoch 4 Batch 1987 Loss 1.4748\n",
      "Epoch 4 Batch 1988 Loss 1.0810\n",
      "Epoch 4 Batch 1989 Loss 1.3701\n",
      "Epoch 4 Batch 1990 Loss 1.0474\n",
      "Epoch 4 Batch 1991 Loss 1.0133\n",
      "Epoch 4 Batch 1992 Loss 1.1408\n",
      "Epoch 4 Batch 1993 Loss 0.7580\n",
      "Epoch 4 Batch 1994 Loss 1.1125\n",
      "Epoch 4 Batch 1995 Loss 1.0978\n",
      "Epoch 4 Batch 1996 Loss 1.3189\n",
      "Epoch 4 Batch 1997 Loss 1.0933\n",
      "Epoch 4 Batch 1998 Loss 1.0351\n",
      "Epoch 4 Batch 1999 Loss 1.2176\n",
      "Epoch 4 Batch 2000 Loss 1.3214\n",
      "Epoch 4 Batch 2001 Loss 1.1135\n",
      "Epoch 4 Batch 2002 Loss 1.0561\n",
      "Epoch 4 Batch 2003 Loss 1.3510\n",
      "Epoch 4 Batch 2004 Loss 1.4215\n",
      "Epoch 4 Batch 2005 Loss 1.2612\n",
      "Epoch 4 Batch 2006 Loss 1.3962\n",
      "Epoch 4 Batch 2007 Loss 1.4284\n",
      "Epoch 4 Batch 2008 Loss 0.9608\n",
      "Epoch 4 Batch 2009 Loss 1.2798\n",
      "Epoch 4 Batch 2010 Loss 0.8973\n",
      "Epoch 4 Batch 2011 Loss 1.1850\n",
      "Epoch 4 Batch 2012 Loss 1.0110\n",
      "Epoch 4 Batch 2013 Loss 1.2745\n",
      "Epoch 4 Batch 2014 Loss 1.0167\n",
      "Epoch 4 Batch 2015 Loss 1.1483\n",
      "Epoch 4 Batch 2016 Loss 1.2023\n",
      "Epoch 4 Batch 2017 Loss 1.2671\n",
      "Epoch 4 Batch 2018 Loss 1.1752\n",
      "Epoch 4 Batch 2019 Loss 1.0991\n",
      "Epoch 4 Batch 2020 Loss 1.2954\n",
      "Epoch 4 Batch 2021 Loss 1.3792\n",
      "Epoch 4 Batch 2022 Loss 0.9602\n",
      "Epoch 4 Batch 2023 Loss 1.1288\n",
      "Epoch 4 Batch 2024 Loss 1.4571\n",
      "Epoch 4 Batch 2025 Loss 1.3737\n",
      "Epoch 4 Batch 2026 Loss 1.2343\n",
      "Epoch 4 Batch 2027 Loss 1.2762\n",
      "Epoch 4 Batch 2028 Loss 1.3281\n",
      "Epoch 4 Batch 2029 Loss 1.2466\n",
      "Epoch 4 Batch 2030 Loss 1.3301\n",
      "Epoch 4 Batch 2031 Loss 1.2353\n",
      "Epoch 4 Batch 2032 Loss 1.4524\n",
      "Epoch 4 Batch 2033 Loss 1.3512\n",
      "Epoch 4 Batch 2034 Loss 1.2915\n",
      "Epoch 4 Batch 2035 Loss 1.5216\n",
      "Epoch 4 Batch 2036 Loss 1.3107\n",
      "Epoch 4 Batch 2037 Loss 1.0854\n",
      "Epoch 4 Batch 2038 Loss 1.3200\n",
      "Epoch 4 Batch 2039 Loss 1.4168\n",
      "Epoch 4 Batch 2040 Loss 1.2853\n",
      "Epoch 4 Batch 2041 Loss 1.3987\n",
      "Epoch 4 Batch 2042 Loss 1.2897\n",
      "Epoch 4 Batch 2043 Loss 1.4018\n",
      "Epoch 4 Batch 2044 Loss 1.2413\n",
      "Epoch 4 Batch 2045 Loss 1.1440\n",
      "Epoch 4 Batch 2046 Loss 0.8583\n",
      "Epoch 4 Batch 2047 Loss 1.4977\n",
      "Epoch 4 Batch 2048 Loss 1.0662\n",
      "Epoch 4 Batch 2049 Loss 1.2691\n",
      "Epoch 4 Batch 2050 Loss 1.2147\n",
      "Epoch 4 Batch 2051 Loss 0.9780\n",
      "Epoch 4 Batch 2052 Loss 1.1599\n",
      "Epoch 4 Batch 2053 Loss 1.1829\n",
      "Epoch 4 Batch 2054 Loss 1.3019\n",
      "Epoch 4 Batch 2055 Loss 1.2024\n",
      "Epoch 4 Batch 2056 Loss 1.1674\n",
      "Epoch 4 Batch 2057 Loss 1.0492\n",
      "Epoch 4 Batch 2058 Loss 1.2082\n",
      "Epoch 4 Batch 2059 Loss 1.3342\n",
      "Epoch 4 Batch 2060 Loss 1.2673\n",
      "Epoch 4 Batch 2061 Loss 1.3683\n",
      "Epoch 4 Batch 2062 Loss 1.2204\n",
      "Epoch 4 Batch 2063 Loss 1.2745\n",
      "Epoch 4 Batch 2064 Loss 0.9926\n",
      "Epoch 4 Batch 2065 Loss 1.2103\n",
      "Epoch 4 Batch 2066 Loss 0.9724\n",
      "Epoch 4 Batch 2067 Loss 1.1045\n",
      "Epoch 4 Batch 2068 Loss 1.1780\n",
      "Epoch 4 Batch 2069 Loss 1.1662\n",
      "Epoch 4 Batch 2070 Loss 1.0894\n",
      "Epoch 4 Batch 2071 Loss 1.4457\n",
      "Epoch 4 Batch 2072 Loss 1.3916\n",
      "Epoch 4 Batch 2073 Loss 1.4976\n",
      "Epoch 4 Batch 2074 Loss 1.1767\n",
      "Epoch 4 Batch 2075 Loss 1.3026\n",
      "Epoch 4 Batch 2076 Loss 1.5042\n",
      "Epoch 4 Batch 2077 Loss 1.1795\n",
      "Epoch 4 Batch 2078 Loss 1.4403\n",
      "Epoch 4 Batch 2079 Loss 1.1770\n",
      "Epoch 4 Batch 2080 Loss 1.2362\n",
      "Epoch 4 Batch 2081 Loss 0.9990\n",
      "Epoch 4 Batch 2082 Loss 1.4469\n",
      "Epoch 4 Batch 2083 Loss 1.2395\n",
      "Epoch 4 Batch 2084 Loss 1.3171\n",
      "Epoch 4 Batch 2085 Loss 1.2698\n",
      "Epoch 4 Batch 2086 Loss 1.3388\n",
      "Epoch 4 Batch 2087 Loss 1.3900\n",
      "Epoch 4 Batch 2088 Loss 1.4040\n",
      "Epoch 4 Batch 2089 Loss 1.3486\n",
      "Epoch 4 Batch 2090 Loss 1.1673\n",
      "Epoch 4 Batch 2091 Loss 1.4358\n",
      "Epoch 4 Batch 2092 Loss 1.0659\n",
      "Epoch 4 Batch 2093 Loss 1.2632\n",
      "Epoch 4 Batch 2094 Loss 1.1775\n",
      "Epoch 4 Batch 2095 Loss 1.5252\n",
      "Epoch 4 Batch 2096 Loss 1.3602\n",
      "Epoch 4 Batch 2097 Loss 1.3364\n",
      "Epoch 4 Batch 2098 Loss 1.1771\n",
      "Epoch 4 Batch 2099 Loss 1.2231\n",
      "Epoch 4 Batch 2100 Loss 1.1608\n",
      "Epoch 4 Batch 2101 Loss 1.0825\n",
      "Epoch 4 Batch 2102 Loss 1.2138\n",
      "Epoch 4 Batch 2103 Loss 1.1028\n",
      "Epoch 4 Batch 2104 Loss 1.2863\n",
      "Epoch 4 Batch 2105 Loss 1.2793\n",
      "Epoch 4 Batch 2106 Loss 1.4236\n",
      "Epoch 4 Batch 2107 Loss 1.4700\n",
      "Epoch 4 Batch 2108 Loss 1.1874\n",
      "Epoch 4 Batch 2109 Loss 1.2864\n",
      "Epoch 4 Batch 2110 Loss 1.1368\n",
      "Epoch 4 Batch 2111 Loss 0.9545\n",
      "Epoch 4 Batch 2112 Loss 1.1153\n",
      "Epoch 4 Batch 2113 Loss 1.4356\n",
      "Epoch 4 Batch 2114 Loss 1.8000\n",
      "Epoch 4 Batch 2115 Loss 1.1000\n",
      "Epoch 4 Batch 2116 Loss 1.4398\n",
      "Epoch 4 Batch 2117 Loss 1.4448\n",
      "Epoch 4 Batch 2118 Loss 1.0072\n",
      "Epoch 4 Batch 2119 Loss 1.2773\n",
      "Epoch 4 Batch 2120 Loss 1.3538\n",
      "Epoch 4 Batch 2121 Loss 1.1651\n",
      "Epoch 4 Batch 2122 Loss 1.2733\n",
      "Epoch 4 Batch 2123 Loss 1.1306\n",
      "Epoch 4 Batch 2124 Loss 1.0414\n",
      "Epoch 4 Batch 2125 Loss 1.1174\n",
      "Epoch 4 Batch 2126 Loss 1.1191\n",
      "Epoch 4 Batch 2127 Loss 1.1895\n",
      "Epoch 4 Batch 2128 Loss 1.1394\n",
      "Epoch 4 Batch 2129 Loss 1.0941\n",
      "Epoch 4 Batch 2130 Loss 1.6043\n",
      "Epoch 4 Batch 2131 Loss 1.2755\n",
      "Epoch 4 Batch 2132 Loss 1.5569\n",
      "Epoch 4 Batch 2133 Loss 1.1087\n",
      "Epoch 4 Batch 2134 Loss 1.1241\n",
      "Epoch 4 Batch 2135 Loss 1.0631\n",
      "Epoch 4 Batch 2136 Loss 1.1527\n",
      "Epoch 4 Batch 2137 Loss 1.2490\n",
      "Epoch 4 Batch 2138 Loss 1.1499\n",
      "Epoch 4 Batch 2139 Loss 1.3810\n",
      "Epoch 4 Batch 2140 Loss 0.8882\n",
      "Epoch 4 Batch 2141 Loss 1.3846\n",
      "Epoch 4 Batch 2142 Loss 1.2162\n",
      "Epoch 4 Batch 2143 Loss 1.1603\n",
      "Epoch 4 Batch 2144 Loss 1.4474\n",
      "Epoch 4 Batch 2145 Loss 1.0886\n",
      "Epoch 4 Batch 2146 Loss 0.9965\n",
      "Epoch 4 Batch 2147 Loss 0.8972\n",
      "Epoch 4 Batch 2148 Loss 1.0867\n",
      "Epoch 4 Batch 2149 Loss 1.0113\n",
      "Epoch 4 Batch 2150 Loss 1.2997\n",
      "Epoch 4 Batch 2151 Loss 1.0040\n",
      "Epoch 4 Batch 2152 Loss 0.9904\n",
      "Epoch 4 Batch 2153 Loss 0.8684\n",
      "Epoch 4 Batch 2154 Loss 1.2680\n",
      "Epoch 4 Batch 2155 Loss 1.2906\n",
      "Epoch 4 Batch 2156 Loss 1.0920\n",
      "Epoch 4 Batch 2157 Loss 1.2325\n",
      "Epoch 4 Batch 2158 Loss 1.1922\n",
      "Epoch 4 Batch 2159 Loss 1.3665\n",
      "Epoch 4 Batch 2160 Loss 1.1249\n",
      "Epoch 4 Batch 2161 Loss 1.1123\n",
      "Epoch 4 Batch 2162 Loss 1.2945\n",
      "Epoch 4 Batch 2163 Loss 1.2741\n",
      "Epoch 4 Batch 2164 Loss 1.3389\n",
      "Epoch 4 Batch 2165 Loss 1.4243\n",
      "Epoch 4 Batch 2166 Loss 1.3325\n",
      "Epoch 4 Batch 2167 Loss 1.4436\n",
      "Epoch 4 Batch 2168 Loss 1.0640\n",
      "Epoch 4 Batch 2169 Loss 1.3740\n",
      "Epoch 4 Batch 2170 Loss 0.9238\n",
      "Epoch 4 Batch 2171 Loss 1.1291\n",
      "Epoch 4 Batch 2172 Loss 1.3679\n",
      "Epoch 4 Batch 2173 Loss 1.4090\n",
      "Epoch 4 Batch 2174 Loss 1.3985\n",
      "Epoch 4 Batch 2175 Loss 0.8523\n",
      "Epoch 4 Batch 2176 Loss 1.3528\n",
      "Epoch 4 Batch 2177 Loss 1.2767\n",
      "Epoch 4 Batch 2178 Loss 1.2119\n",
      "Epoch 4 Batch 2179 Loss 1.3184\n",
      "Epoch 4 Batch 2180 Loss 1.1905\n",
      "Epoch 4 Batch 2181 Loss 1.0566\n",
      "Epoch 4 Batch 2182 Loss 1.2660\n",
      "Epoch 4 Batch 2183 Loss 1.1994\n",
      "Epoch 4 Batch 2184 Loss 1.6101\n",
      "Epoch 4 Batch 2185 Loss 1.2434\n",
      "Epoch 4 Batch 2186 Loss 1.3388\n",
      "Epoch 4 Batch 2187 Loss 1.2367\n",
      "Epoch 4 Batch 2188 Loss 1.1189\n",
      "Epoch 4 Batch 2189 Loss 1.1637\n",
      "Epoch 4 Batch 2190 Loss 1.5295\n",
      "Epoch 4 Batch 2191 Loss 1.3686\n",
      "Epoch 4 Batch 2192 Loss 0.8455\n",
      "Epoch 4 Batch 2193 Loss 1.2139\n",
      "Epoch 4 Batch 2194 Loss 1.0145\n",
      "Epoch 4 Batch 2195 Loss 1.5048\n",
      "Epoch 4 Batch 2196 Loss 1.0795\n",
      "Epoch 4 Batch 2197 Loss 1.2687\n",
      "Epoch 4 Batch 2198 Loss 1.3274\n",
      "Epoch 4 Batch 2199 Loss 1.1791\n",
      "Epoch 4 Batch 2200 Loss 1.1657\n",
      "Epoch 4 Batch 2201 Loss 1.1826\n",
      "Epoch 4 Batch 2202 Loss 1.2739\n",
      "Epoch 4 Batch 2203 Loss 1.0815\n",
      "Epoch 4 Batch 2204 Loss 1.6784\n",
      "Epoch 4 Batch 2205 Loss 1.1768\n",
      "Epoch 4 Batch 2206 Loss 1.2461\n",
      "Epoch 4 Batch 2207 Loss 1.1214\n",
      "Epoch 4 Batch 2208 Loss 1.0093\n",
      "Epoch 4 Batch 2209 Loss 1.0654\n",
      "Epoch 4 Batch 2210 Loss 1.0614\n",
      "Epoch 4 Batch 2211 Loss 1.3261\n",
      "Epoch 4 Batch 2212 Loss 1.1809\n",
      "Epoch 4 Batch 2213 Loss 1.3858\n",
      "Epoch 4 Batch 2214 Loss 1.3172\n",
      "Epoch 4 Batch 2215 Loss 1.2515\n",
      "Epoch 4 Batch 2216 Loss 1.3516\n",
      "Epoch 4 Batch 2217 Loss 1.1089\n",
      "Epoch 4 Batch 2218 Loss 1.3665\n",
      "Epoch 4 Batch 2219 Loss 1.4305\n",
      "Epoch 4 Batch 2220 Loss 1.2247\n",
      "Epoch 4 Batch 2221 Loss 1.3100\n",
      "Epoch 4 Batch 2222 Loss 1.2367\n",
      "Epoch 4 Batch 2223 Loss 1.3949\n",
      "Epoch 4 Batch 2224 Loss 1.4555\n",
      "Epoch 4 Batch 2225 Loss 1.3217\n",
      "Epoch 4 Batch 2226 Loss 1.1701\n",
      "Epoch 4 Batch 2227 Loss 1.3408\n",
      "Epoch 4 Batch 2228 Loss 1.1659\n",
      "Epoch 4 Batch 2229 Loss 1.3737\n",
      "Epoch 4 Batch 2230 Loss 1.2990\n",
      "Epoch 4 Batch 2231 Loss 1.1831\n",
      "Epoch 4 Batch 2232 Loss 1.0538\n",
      "Epoch 4 Batch 2233 Loss 1.3825\n",
      "Epoch 4 Batch 2234 Loss 1.1714\n",
      "Epoch 4 Batch 2235 Loss 1.0675\n",
      "Epoch 4 Batch 2236 Loss 1.1674\n",
      "Epoch 4 Batch 2237 Loss 1.3139\n",
      "Epoch 4 Batch 2238 Loss 1.4280\n",
      "Epoch 4 Batch 2239 Loss 1.0299\n",
      "Epoch 4 Batch 2240 Loss 1.1792\n",
      "Epoch 4 Batch 2241 Loss 1.1643\n",
      "Epoch 4 Batch 2242 Loss 1.0638\n",
      "Epoch 4 Batch 2243 Loss 1.3685\n",
      "Epoch 4 Batch 2244 Loss 1.3953\n",
      "Epoch 4 Batch 2245 Loss 1.0161\n",
      "Epoch 4 Batch 2246 Loss 1.2177\n",
      "Epoch 4 Batch 2247 Loss 1.1343\n",
      "Epoch 4 Batch 2248 Loss 1.2003\n",
      "Epoch 4 Batch 2249 Loss 1.1963\n",
      "Epoch 4 Batch 2250 Loss 1.1465\n",
      "Epoch 4 Batch 2251 Loss 0.9664\n",
      "Epoch 4 Batch 2252 Loss 1.0056\n",
      "Epoch 4 Batch 2253 Loss 1.2014\n",
      "Epoch 4 Batch 2254 Loss 1.2536\n",
      "Epoch 4 Batch 2255 Loss 1.2222\n",
      "Epoch 4 Batch 2256 Loss 1.1685\n",
      "Epoch 4 Batch 2257 Loss 1.3915\n",
      "Epoch 4 Batch 2258 Loss 1.4127\n",
      "Epoch 4 Batch 2259 Loss 1.4059\n",
      "Epoch 4 Batch 2260 Loss 1.0781\n",
      "Epoch 4 Batch 2261 Loss 1.4211\n",
      "Epoch 4 Batch 2262 Loss 1.1100\n",
      "Epoch 4 Batch 2263 Loss 1.2917\n",
      "Epoch 4 Batch 2264 Loss 1.2471\n",
      "Epoch 4 Batch 2265 Loss 1.4683\n",
      "Epoch 4 Batch 2266 Loss 1.1197\n",
      "Epoch 4 Batch 2267 Loss 1.1956\n",
      "Epoch 4 Batch 2268 Loss 1.3594\n",
      "Epoch 4 Batch 2269 Loss 1.0942\n",
      "Epoch 4 Batch 2270 Loss 1.2303\n",
      "Epoch 4 Batch 2271 Loss 1.2694\n",
      "Epoch 4 Batch 2272 Loss 1.1731\n",
      "Epoch 4 Batch 2273 Loss 1.4940\n",
      "Epoch 4 Batch 2274 Loss 1.0968\n",
      "Epoch 4 Batch 2275 Loss 1.2588\n",
      "Epoch 4 Batch 2276 Loss 1.1948\n",
      "Epoch 4 Batch 2277 Loss 1.3526\n",
      "Epoch 4 Batch 2278 Loss 1.4159\n",
      "Epoch 4 Batch 2279 Loss 1.1119\n",
      "Epoch 4 Batch 2280 Loss 1.4245\n",
      "Epoch 4 Batch 2281 Loss 1.2770\n",
      "Epoch 4 Batch 2282 Loss 1.3560\n",
      "Epoch 4 Batch 2283 Loss 1.0148\n",
      "Epoch 4 Batch 2284 Loss 1.3570\n",
      "Epoch 4 Batch 2285 Loss 1.3274\n",
      "Epoch 4 Batch 2286 Loss 1.3112\n",
      "Epoch 4 Batch 2287 Loss 1.2279\n",
      "Epoch 4 Batch 2288 Loss 1.1952\n",
      "Epoch 4 Batch 2289 Loss 1.2300\n",
      "Epoch 4 Batch 2290 Loss 1.3126\n",
      "Epoch 4 Batch 2291 Loss 1.0265\n",
      "Epoch 4 Batch 2292 Loss 1.2065\n",
      "Epoch 4 Batch 2293 Loss 1.1638\n",
      "Epoch 4 Batch 2294 Loss 1.4185\n",
      "Epoch 4 Batch 2295 Loss 1.3130\n",
      "Epoch 4 Batch 2296 Loss 1.2552\n",
      "Epoch 4 Batch 2297 Loss 1.3286\n",
      "Epoch 4 Batch 2298 Loss 1.1397\n",
      "Epoch 4 Batch 2299 Loss 1.0054\n",
      "Epoch 4 Batch 2300 Loss 1.1520\n",
      "Epoch 4 Batch 2301 Loss 1.3227\n",
      "Epoch 4 Batch 2302 Loss 1.2833\n",
      "Epoch 4 Batch 2303 Loss 1.2556\n",
      "Epoch 4 Batch 2304 Loss 1.1912\n",
      "Epoch 4 Batch 2305 Loss 1.0961\n",
      "Epoch 4 Batch 2306 Loss 1.0333\n",
      "Epoch 4 Batch 2307 Loss 0.9142\n",
      "Epoch 4 Batch 2308 Loss 0.9682\n",
      "Epoch 4 Batch 2309 Loss 1.3298\n",
      "Epoch 4 Batch 2310 Loss 1.0730\n",
      "Epoch 4 Batch 2311 Loss 1.4275\n",
      "Epoch 4 Batch 2312 Loss 1.2046\n",
      "Epoch 4 Batch 2313 Loss 1.1976\n",
      "Epoch 4 Batch 2314 Loss 1.5720\n",
      "Epoch 4 Batch 2315 Loss 1.3030\n",
      "Epoch 4 Batch 2316 Loss 0.9550\n",
      "Epoch 4 Batch 2317 Loss 1.3684\n",
      "Epoch 4 Batch 2318 Loss 1.4008\n",
      "Epoch 4 Batch 2319 Loss 1.2709\n",
      "Epoch 4 Batch 2320 Loss 1.2196\n",
      "Epoch 4 Batch 2321 Loss 1.4368\n",
      "Epoch 4 Batch 2322 Loss 1.2944\n",
      "Epoch 4 Batch 2323 Loss 1.3152\n",
      "Epoch 4 Batch 2324 Loss 1.0597\n",
      "Epoch 4 Batch 2325 Loss 1.2799\n",
      "Epoch 4 Batch 2326 Loss 1.2498\n",
      "Epoch 4 Batch 2327 Loss 1.5477\n",
      "Epoch 4 Batch 2328 Loss 1.3992\n",
      "Epoch 4 Batch 2329 Loss 1.1952\n",
      "Epoch 4 Batch 2330 Loss 1.4167\n",
      "Epoch 4 Batch 2331 Loss 1.1885\n",
      "Epoch 4 Batch 2332 Loss 1.0829\n",
      "Epoch 4 Batch 2333 Loss 1.1310\n",
      "Epoch 4 Batch 2334 Loss 1.0527\n",
      "Epoch 4 Batch 2335 Loss 1.2018\n",
      "Epoch 4 Batch 2336 Loss 1.0546\n",
      "Epoch 4 Batch 2337 Loss 1.2120\n",
      "Epoch 4 Batch 2338 Loss 0.9898\n",
      "Epoch 4 Batch 2339 Loss 1.2676\n",
      "Epoch 4 Batch 2340 Loss 1.3712\n",
      "Epoch 4 Batch 2341 Loss 1.3393\n",
      "Epoch 4 Batch 2342 Loss 1.1726\n",
      "Epoch 4 Batch 2343 Loss 1.2112\n",
      "Epoch 4 Batch 2344 Loss 0.9010\n",
      "Epoch 4 Batch 2345 Loss 1.7374\n",
      "Epoch 4 Batch 2346 Loss 1.2720\n",
      "Epoch 4 Batch 2347 Loss 1.1959\n",
      "Epoch 4 Batch 2348 Loss 1.0843\n",
      "Epoch 4 Batch 2349 Loss 1.1121\n",
      "Epoch 4 Batch 2350 Loss 1.6384\n",
      "Epoch 4 Batch 2351 Loss 1.2966\n",
      "Epoch 4 Batch 2352 Loss 1.2278\n",
      "Epoch 4 Batch 2353 Loss 0.9514\n",
      "Epoch 4 Batch 2354 Loss 1.1572\n",
      "Epoch 4 Batch 2355 Loss 1.1827\n",
      "Epoch 4 Batch 2356 Loss 1.2151\n",
      "Epoch 4 Batch 2357 Loss 1.2551\n",
      "Epoch 4 Batch 2358 Loss 1.2286\n",
      "Epoch 4 Batch 2359 Loss 0.9849\n",
      "Epoch 4 Batch 2360 Loss 1.2345\n",
      "Epoch 4 Batch 2361 Loss 1.1983\n",
      "Epoch 4 Batch 2362 Loss 1.4594\n",
      "Epoch 4 Batch 2363 Loss 1.4252\n",
      "Epoch 4 Batch 2364 Loss 1.3309\n",
      "Epoch 4 Batch 2365 Loss 0.9564\n",
      "Epoch 4 Batch 2366 Loss 1.2710\n",
      "Epoch 4 Batch 2367 Loss 0.9595\n",
      "Epoch 4 Batch 2368 Loss 1.3311\n",
      "Epoch 4 Batch 2369 Loss 1.1040\n",
      "Epoch 4 Batch 2370 Loss 1.2627\n",
      "Epoch 4 Batch 2371 Loss 1.1905\n",
      "Epoch 4 Batch 2372 Loss 1.2215\n",
      "Epoch 4 Batch 2373 Loss 1.1946\n",
      "Epoch 4 Batch 2374 Loss 1.1876\n",
      "Epoch 4 Batch 2375 Loss 1.3025\n",
      "Epoch 4 Batch 2376 Loss 1.2544\n",
      "Epoch 4 Batch 2377 Loss 1.2310\n",
      "Epoch 4 Batch 2378 Loss 1.2368\n",
      "Epoch 4 Batch 2379 Loss 1.1775\n",
      "Epoch 4 Batch 2380 Loss 1.2705\n",
      "Epoch 4 Batch 2381 Loss 1.1892\n",
      "Epoch 4 Batch 2382 Loss 1.3206\n",
      "Epoch 4 Batch 2383 Loss 1.1995\n",
      "Epoch 4 Batch 2384 Loss 1.1991\n",
      "Epoch 4 Batch 2385 Loss 1.0276\n",
      "Epoch 4 Batch 2386 Loss 1.4090\n",
      "Epoch 4 Batch 2387 Loss 0.9513\n",
      "Epoch 4 Batch 2388 Loss 0.9574\n",
      "Epoch 4 Batch 2389 Loss 1.2125\n",
      "Epoch 4 Batch 2390 Loss 1.4303\n",
      "Epoch 4 Batch 2391 Loss 1.2660\n",
      "Epoch 4 Batch 2392 Loss 1.4043\n",
      "Epoch 4 Batch 2393 Loss 1.1551\n",
      "Epoch 4 Batch 2394 Loss 0.8781\n",
      "Epoch 4 Batch 2395 Loss 1.0724\n",
      "Epoch 4 Batch 2396 Loss 1.2196\n",
      "Epoch 4 Batch 2397 Loss 1.2135\n",
      "Epoch 4 Batch 2398 Loss 1.0993\n",
      "Epoch 4 Batch 2399 Loss 1.1364\n",
      "Epoch 4 Batch 2400 Loss 1.0608\n",
      "Epoch 4 Batch 2401 Loss 1.0622\n",
      "Epoch 4 Batch 2402 Loss 1.5802\n",
      "Epoch 4 Batch 2403 Loss 1.2317\n",
      "Epoch 4 Batch 2404 Loss 1.1389\n",
      "Epoch 4 Batch 2405 Loss 1.3095\n",
      "Epoch 4 Batch 2406 Loss 1.0155\n",
      "Epoch 4 Batch 2407 Loss 1.5356\n",
      "Epoch 4 Batch 2408 Loss 1.0638\n",
      "Epoch 4 Batch 2409 Loss 1.0789\n",
      "Epoch 4 Batch 2410 Loss 1.0758\n",
      "Epoch 4 Batch 2411 Loss 1.2588\n",
      "Epoch 4 Batch 2412 Loss 1.2055\n",
      "Epoch 4 Batch 2413 Loss 1.4050\n",
      "Epoch 4 Batch 2414 Loss 1.0879\n",
      "Epoch 4 Batch 2415 Loss 1.1956\n",
      "Epoch 4 Batch 2416 Loss 0.8993\n",
      "Epoch 4 Batch 2417 Loss 1.3079\n",
      "Epoch 4 Batch 2418 Loss 1.3679\n",
      "Epoch 4 Batch 2419 Loss 1.2385\n",
      "Epoch 4 Batch 2420 Loss 1.3247\n",
      "Epoch 4 Batch 2421 Loss 1.1481\n",
      "Epoch 4 Batch 2422 Loss 1.2586\n",
      "Epoch 4 Batch 2423 Loss 1.1752\n",
      "Epoch 4 Batch 2424 Loss 1.1383\n",
      "Epoch 4 Batch 2425 Loss 0.9484\n",
      "Epoch 4 Batch 2426 Loss 0.9993\n",
      "Epoch 4 Batch 2427 Loss 1.2004\n",
      "Epoch 4 Batch 2428 Loss 1.0703\n",
      "Epoch 4 Batch 2429 Loss 1.2896\n",
      "Epoch 4 Batch 2430 Loss 1.5368\n",
      "Epoch 4 Batch 2431 Loss 1.0313\n",
      "Epoch 4 Batch 2432 Loss 1.2302\n",
      "Epoch 4 Batch 2433 Loss 1.5337\n",
      "Epoch 4 Batch 2434 Loss 1.1832\n",
      "Epoch 4 Batch 2435 Loss 1.0611\n",
      "Epoch 4 Batch 2436 Loss 1.1102\n",
      "Epoch 4 Batch 2437 Loss 1.3085\n",
      "Epoch 4 Batch 2438 Loss 1.0361\n",
      "Epoch 4 Batch 2439 Loss 1.3184\n",
      "Epoch 4 Batch 2440 Loss 1.1014\n",
      "Epoch 4 Batch 2441 Loss 1.6680\n",
      "Epoch 4 Batch 2442 Loss 1.4270\n",
      "Epoch 4 Batch 2443 Loss 1.3241\n",
      "Epoch 4 Batch 2444 Loss 1.1503\n",
      "Epoch 4 Batch 2445 Loss 1.0791\n",
      "Epoch 4 Batch 2446 Loss 1.3522\n",
      "Epoch 4 Batch 2447 Loss 1.6031\n",
      "Epoch 4 Batch 2448 Loss 1.4864\n",
      "Epoch 4 Batch 2449 Loss 1.1419\n",
      "Epoch 4 Batch 2450 Loss 1.0492\n",
      "Epoch 4 Batch 2451 Loss 1.1588\n",
      "Epoch 4 Batch 2452 Loss 1.6996\n",
      "Epoch 4 Batch 2453 Loss 1.7236\n",
      "Epoch 4 Batch 2454 Loss 1.1568\n",
      "Epoch 4 Batch 2455 Loss 1.0873\n",
      "Epoch 4 Batch 2456 Loss 1.2489\n",
      "Epoch 4 Batch 2457 Loss 1.3221\n",
      "Epoch 4 Batch 2458 Loss 1.4448\n",
      "Epoch 4 Batch 2459 Loss 1.0506\n",
      "Epoch 4 Batch 2460 Loss 1.2101\n",
      "Epoch 4 Batch 2461 Loss 1.2060\n",
      "Epoch 4 Batch 2462 Loss 1.4358\n",
      "Epoch 4 Batch 2463 Loss 1.0730\n",
      "Epoch 4 Batch 2464 Loss 0.9129\n",
      "Epoch 4 Batch 2465 Loss 1.2937\n",
      "Epoch 4 Batch 2466 Loss 1.3636\n",
      "Epoch 4 Batch 2467 Loss 1.3330\n",
      "Epoch 4 Batch 2468 Loss 0.8274\n",
      "Epoch 4 Batch 2469 Loss 0.9500\n",
      "Epoch 4 Batch 2470 Loss 1.2962\n",
      "Epoch 4 Batch 2471 Loss 1.2679\n",
      "Epoch 4 Batch 2472 Loss 1.2893\n",
      "Epoch 4 Batch 2473 Loss 1.3242\n",
      "Epoch 4 Batch 2474 Loss 1.4220\n",
      "Epoch 4 Batch 2475 Loss 1.1503\n",
      "Epoch 4 Batch 2476 Loss 1.0069\n",
      "Epoch 4 Batch 2477 Loss 1.0616\n",
      "Epoch 4 Batch 2478 Loss 0.9792\n",
      "Epoch 4 Batch 2479 Loss 1.0302\n",
      "Epoch 4 Batch 2480 Loss 1.3301\n",
      "Epoch 4 Batch 2481 Loss 1.2783\n",
      "Epoch 4 Batch 2482 Loss 1.1285\n",
      "Epoch 4 Batch 2483 Loss 1.2567\n",
      "Epoch 4 Batch 2484 Loss 1.2499\n",
      "Epoch 4 Batch 2485 Loss 1.1459\n",
      "Epoch 4 Batch 2486 Loss 1.1127\n",
      "Epoch 4 Batch 2487 Loss 1.3859\n",
      "Epoch 4 Batch 2488 Loss 1.1386\n",
      "Epoch 4 Batch 2489 Loss 1.0649\n",
      "Epoch 4 Batch 2490 Loss 1.2177\n",
      "Epoch 4 Batch 2491 Loss 1.1947\n",
      "Epoch 4 Batch 2492 Loss 1.3178\n",
      "Epoch 4 Batch 2493 Loss 1.0871\n",
      "Epoch 4 Batch 2494 Loss 0.9626\n",
      "Epoch 4 Batch 2495 Loss 1.0310\n",
      "Epoch 4 Batch 2496 Loss 1.3114\n",
      "Epoch 4 Batch 2497 Loss 1.2403\n",
      "Epoch 4 Batch 2498 Loss 1.3414\n",
      "Epoch 4 Batch 2499 Loss 1.1043\n",
      "Epoch 4 Batch 2500 Loss 1.2274\n",
      "Epoch 4 Batch 2501 Loss 1.7153\n",
      "Epoch 4 Batch 2502 Loss 1.5810\n",
      "Epoch 4 Batch 2503 Loss 1.0580\n",
      "Epoch 4 Batch 2504 Loss 1.2229\n",
      "Epoch 4 Batch 2505 Loss 1.0873\n",
      "Epoch 4 Batch 2506 Loss 1.1176\n",
      "Epoch 4 Batch 2507 Loss 1.1138\n",
      "Epoch 4 Batch 2508 Loss 1.2342\n",
      "Epoch 4 Batch 2509 Loss 1.2032\n",
      "Epoch 4 Batch 2510 Loss 1.1750\n",
      "Epoch 4 Batch 2511 Loss 1.3103\n",
      "Epoch 4 Batch 2512 Loss 1.5365\n",
      "Epoch 4 Batch 2513 Loss 1.3438\n",
      "Epoch 4 Batch 2514 Loss 1.0743\n",
      "Epoch 4 Batch 2515 Loss 1.3198\n",
      "Epoch 4 Batch 2516 Loss 1.1967\n",
      "Epoch 4 Batch 2517 Loss 1.1124\n",
      "Epoch 4 Batch 2518 Loss 1.1873\n",
      "Epoch 4 Batch 2519 Loss 1.1066\n",
      "Epoch 4 Batch 2520 Loss 1.2698\n",
      "Epoch 4 Batch 2521 Loss 0.9140\n",
      "Epoch 4 Batch 2522 Loss 1.4745\n",
      "Epoch 4 Batch 2523 Loss 1.0987\n",
      "Epoch 4 Batch 2524 Loss 1.0808\n",
      "Epoch 4 Batch 2525 Loss 1.0281\n",
      "Epoch 4 Batch 2526 Loss 1.2321\n",
      "Epoch 4 Batch 2527 Loss 1.4498\n",
      "Epoch 4 Batch 2528 Loss 1.0396\n",
      "Epoch 4 Batch 2529 Loss 1.3560\n",
      "Epoch 4 Batch 2530 Loss 1.5610\n",
      "Epoch 4 Batch 2531 Loss 1.5420\n",
      "Epoch 4 Batch 2532 Loss 1.0894\n",
      "Epoch 4 Batch 2533 Loss 1.0908\n",
      "Epoch 4 Batch 2534 Loss 1.2073\n",
      "Epoch 4 Batch 2535 Loss 0.8660\n",
      "Epoch 4 Batch 2536 Loss 1.1750\n",
      "Epoch 4 Batch 2537 Loss 1.3308\n",
      "Epoch 4 Batch 2538 Loss 1.0867\n",
      "Epoch 4 Batch 2539 Loss 1.2685\n",
      "Epoch 4 Batch 2540 Loss 1.1540\n",
      "Epoch 4 Batch 2541 Loss 1.2697\n",
      "Epoch 4 Batch 2542 Loss 1.1080\n",
      "Epoch 4 Batch 2543 Loss 1.0136\n",
      "Epoch 4 Batch 2544 Loss 1.3544\n",
      "Epoch 4 Batch 2545 Loss 1.2664\n",
      "Epoch 4 Batch 2546 Loss 1.2483\n",
      "Epoch 4 Batch 2547 Loss 1.4058\n",
      "Epoch 4 Batch 2548 Loss 1.1468\n",
      "Epoch 4 Batch 2549 Loss 1.1987\n",
      "Epoch 4 Batch 2550 Loss 1.1612\n",
      "Epoch 4 Batch 2551 Loss 1.1775\n",
      "Epoch 4 Batch 2552 Loss 1.5141\n",
      "Epoch 4 Batch 2553 Loss 1.2319\n",
      "Epoch 4 Batch 2554 Loss 1.0061\n",
      "Epoch 4 Batch 2555 Loss 1.3534\n",
      "Epoch 4 Batch 2556 Loss 1.3288\n",
      "Epoch 4 Batch 2557 Loss 1.1166\n",
      "Epoch 4 Batch 2558 Loss 0.9984\n",
      "Epoch 4 Batch 2559 Loss 1.2070\n",
      "Epoch 4 Batch 2560 Loss 1.0920\n",
      "Epoch 4 Batch 2561 Loss 1.1694\n",
      "Epoch 4 Batch 2562 Loss 1.4904\n",
      "Epoch 4 Batch 2563 Loss 0.9997\n",
      "Epoch 4 Batch 2564 Loss 1.3322\n",
      "Epoch 4 Batch 2565 Loss 1.5725\n",
      "Epoch 4 Batch 2566 Loss 1.1555\n",
      "Epoch 4 Batch 2567 Loss 1.4289\n",
      "Epoch 4 Batch 2568 Loss 1.6120\n",
      "Epoch 4 Batch 2569 Loss 1.4162\n",
      "Epoch 4 Batch 2570 Loss 1.1680\n",
      "Epoch 4 Batch 2571 Loss 1.1817\n",
      "Epoch 4 Batch 2572 Loss 1.4048\n",
      "Epoch 4 Batch 2573 Loss 1.2106\n",
      "Epoch 4 Batch 2574 Loss 1.7155\n",
      "Epoch 4 Batch 2575 Loss 1.1396\n",
      "Epoch 4 Batch 2576 Loss 1.2191\n",
      "Epoch 4 Batch 2577 Loss 1.0078\n",
      "Epoch 4 Batch 2578 Loss 1.1971\n",
      "Epoch 4 Batch 2579 Loss 0.8467\n",
      "Epoch 4 Batch 2580 Loss 1.0989\n",
      "Epoch 4 Batch 2581 Loss 1.4545\n",
      "Epoch 4 Batch 2582 Loss 1.4099\n",
      "Epoch 4 Batch 2583 Loss 0.9800\n",
      "Epoch 4 Batch 2584 Loss 1.0358\n",
      "Epoch 4 Batch 2585 Loss 1.2105\n",
      "Epoch 4 Batch 2586 Loss 1.1693\n",
      "Epoch 4 Batch 2587 Loss 1.2239\n",
      "Epoch 4 Batch 2588 Loss 1.0929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [2:08:46<32:06, 1926.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 4 at /mnt/pycharm_class04/data/checkpoints/training_checkpoints_seq2seq/ckpt/ckpt-2\n",
      "Epoch 4 Loss 1.2221\n",
      "Time taken for 1 epoch 1927.3391466140747 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.8580\n",
      "Epoch 5 Batch 1 Loss 1.3293\n",
      "Epoch 5 Batch 2 Loss 1.4148\n",
      "Epoch 5 Batch 3 Loss 1.0564\n",
      "Epoch 5 Batch 4 Loss 0.9249\n",
      "Epoch 5 Batch 5 Loss 1.2833\n",
      "Epoch 5 Batch 6 Loss 1.4440\n",
      "Epoch 5 Batch 7 Loss 1.3153\n",
      "Epoch 5 Batch 8 Loss 1.2021\n",
      "Epoch 5 Batch 9 Loss 1.2706\n",
      "Epoch 5 Batch 10 Loss 1.2313\n",
      "Epoch 5 Batch 11 Loss 1.3164\n",
      "Epoch 5 Batch 12 Loss 1.0845\n",
      "Epoch 5 Batch 13 Loss 1.1815\n",
      "Epoch 5 Batch 14 Loss 0.9677\n",
      "Epoch 5 Batch 15 Loss 0.9933\n",
      "Epoch 5 Batch 16 Loss 0.9846\n",
      "Epoch 5 Batch 17 Loss 1.0539\n",
      "Epoch 5 Batch 18 Loss 1.2779\n",
      "Epoch 5 Batch 19 Loss 1.3919\n",
      "Epoch 5 Batch 20 Loss 0.7661\n",
      "Epoch 5 Batch 21 Loss 1.2117\n",
      "Epoch 5 Batch 22 Loss 1.2456\n",
      "Epoch 5 Batch 23 Loss 1.1634\n",
      "Epoch 5 Batch 24 Loss 1.1582\n",
      "Epoch 5 Batch 25 Loss 1.1728\n",
      "Epoch 5 Batch 26 Loss 1.1643\n",
      "Epoch 5 Batch 27 Loss 1.2196\n",
      "Epoch 5 Batch 28 Loss 1.0384\n",
      "Epoch 5 Batch 29 Loss 1.3604\n",
      "Epoch 5 Batch 30 Loss 1.0320\n",
      "Epoch 5 Batch 31 Loss 1.1477\n",
      "Epoch 5 Batch 32 Loss 0.9603\n",
      "Epoch 5 Batch 33 Loss 1.0760\n",
      "Epoch 5 Batch 34 Loss 1.0379\n",
      "Epoch 5 Batch 35 Loss 0.9689\n",
      "Epoch 5 Batch 36 Loss 1.2348\n",
      "Epoch 5 Batch 37 Loss 1.1047\n",
      "Epoch 5 Batch 38 Loss 1.3230\n",
      "Epoch 5 Batch 39 Loss 1.2789\n",
      "Epoch 5 Batch 40 Loss 0.8600\n",
      "Epoch 5 Batch 41 Loss 1.1089\n",
      "Epoch 5 Batch 42 Loss 1.2881\n",
      "Epoch 5 Batch 43 Loss 1.0628\n",
      "Epoch 5 Batch 44 Loss 0.9817\n",
      "Epoch 5 Batch 45 Loss 0.9980\n",
      "Epoch 5 Batch 46 Loss 1.0855\n",
      "Epoch 5 Batch 47 Loss 0.9925\n",
      "Epoch 5 Batch 48 Loss 0.9479\n",
      "Epoch 5 Batch 49 Loss 1.1133\n",
      "Epoch 5 Batch 50 Loss 1.1113\n",
      "Epoch 5 Batch 51 Loss 1.0643\n",
      "Epoch 5 Batch 52 Loss 1.1708\n",
      "Epoch 5 Batch 53 Loss 1.3393\n",
      "Epoch 5 Batch 54 Loss 1.0129\n",
      "Epoch 5 Batch 55 Loss 1.0474\n",
      "Epoch 5 Batch 56 Loss 0.8597\n",
      "Epoch 5 Batch 57 Loss 1.2581\n",
      "Epoch 5 Batch 58 Loss 1.0915\n",
      "Epoch 5 Batch 59 Loss 1.2072\n",
      "Epoch 5 Batch 60 Loss 1.0243\n",
      "Epoch 5 Batch 61 Loss 1.1625\n",
      "Epoch 5 Batch 62 Loss 1.0173\n",
      "Epoch 5 Batch 63 Loss 1.1880\n",
      "Epoch 5 Batch 64 Loss 0.9249\n",
      "Epoch 5 Batch 65 Loss 1.0800\n",
      "Epoch 5 Batch 66 Loss 1.0684\n",
      "Epoch 5 Batch 67 Loss 1.0591\n",
      "Epoch 5 Batch 68 Loss 1.1132\n",
      "Epoch 5 Batch 69 Loss 0.9888\n",
      "Epoch 5 Batch 70 Loss 0.9045\n",
      "Epoch 5 Batch 71 Loss 1.1694\n",
      "Epoch 5 Batch 72 Loss 1.2069\n",
      "Epoch 5 Batch 73 Loss 1.2414\n",
      "Epoch 5 Batch 74 Loss 1.0938\n",
      "Epoch 5 Batch 75 Loss 1.1952\n",
      "Epoch 5 Batch 76 Loss 1.0884\n",
      "Epoch 5 Batch 77 Loss 1.2162\n",
      "Epoch 5 Batch 78 Loss 1.3406\n",
      "Epoch 5 Batch 79 Loss 0.9694\n",
      "Epoch 5 Batch 80 Loss 1.1134\n",
      "Epoch 5 Batch 81 Loss 1.3020\n",
      "Epoch 5 Batch 82 Loss 0.8307\n",
      "Epoch 5 Batch 83 Loss 0.9335\n",
      "Epoch 5 Batch 84 Loss 0.8438\n",
      "Epoch 5 Batch 85 Loss 1.0173\n",
      "Epoch 5 Batch 86 Loss 0.8686\n",
      "Epoch 5 Batch 87 Loss 0.9283\n",
      "Epoch 5 Batch 88 Loss 0.9615\n",
      "Epoch 5 Batch 89 Loss 1.1172\n",
      "Epoch 5 Batch 90 Loss 1.0222\n",
      "Epoch 5 Batch 91 Loss 1.2468\n",
      "Epoch 5 Batch 92 Loss 1.2559\n",
      "Epoch 5 Batch 93 Loss 1.1289\n",
      "Epoch 5 Batch 94 Loss 1.0772\n",
      "Epoch 5 Batch 95 Loss 0.9414\n",
      "Epoch 5 Batch 96 Loss 1.4548\n",
      "Epoch 5 Batch 97 Loss 1.0934\n",
      "Epoch 5 Batch 98 Loss 1.0765\n",
      "Epoch 5 Batch 99 Loss 0.9460\n",
      "Epoch 5 Batch 100 Loss 1.2896\n",
      "Epoch 5 Batch 101 Loss 1.1299\n",
      "Epoch 5 Batch 102 Loss 1.2143\n",
      "Epoch 5 Batch 103 Loss 1.3388\n",
      "Epoch 5 Batch 104 Loss 0.9929\n",
      "Epoch 5 Batch 105 Loss 1.1084\n",
      "Epoch 5 Batch 106 Loss 1.2117\n",
      "Epoch 5 Batch 107 Loss 0.9293\n",
      "Epoch 5 Batch 108 Loss 1.0876\n",
      "Epoch 5 Batch 109 Loss 1.2584\n",
      "Epoch 5 Batch 110 Loss 0.8193\n",
      "Epoch 5 Batch 111 Loss 1.0156\n",
      "Epoch 5 Batch 112 Loss 1.1656\n",
      "Epoch 5 Batch 113 Loss 1.2721\n",
      "Epoch 5 Batch 114 Loss 1.2341\n",
      "Epoch 5 Batch 115 Loss 1.2576\n",
      "Epoch 5 Batch 116 Loss 1.1733\n",
      "Epoch 5 Batch 117 Loss 1.0699\n",
      "Epoch 5 Batch 118 Loss 1.0978\n",
      "Epoch 5 Batch 119 Loss 1.2815\n",
      "Epoch 5 Batch 120 Loss 1.1307\n",
      "Epoch 5 Batch 121 Loss 1.0051\n",
      "Epoch 5 Batch 122 Loss 1.1519\n",
      "Epoch 5 Batch 123 Loss 1.1303\n",
      "Epoch 5 Batch 124 Loss 1.2366\n",
      "Epoch 5 Batch 125 Loss 1.1827\n",
      "Epoch 5 Batch 126 Loss 0.9534\n",
      "Epoch 5 Batch 127 Loss 0.8581\n",
      "Epoch 5 Batch 128 Loss 1.4220\n",
      "Epoch 5 Batch 129 Loss 1.1193\n",
      "Epoch 5 Batch 130 Loss 1.0443\n",
      "Epoch 5 Batch 131 Loss 1.2382\n",
      "Epoch 5 Batch 132 Loss 1.1762\n",
      "Epoch 5 Batch 133 Loss 1.1807\n",
      "Epoch 5 Batch 134 Loss 0.9244\n",
      "Epoch 5 Batch 135 Loss 0.9102\n",
      "Epoch 5 Batch 136 Loss 1.2517\n",
      "Epoch 5 Batch 137 Loss 1.2072\n",
      "Epoch 5 Batch 138 Loss 1.1516\n",
      "Epoch 5 Batch 139 Loss 1.0731\n",
      "Epoch 5 Batch 140 Loss 1.3895\n",
      "Epoch 5 Batch 141 Loss 0.8336\n",
      "Epoch 5 Batch 142 Loss 1.1296\n",
      "Epoch 5 Batch 143 Loss 1.0255\n",
      "Epoch 5 Batch 144 Loss 0.9709\n",
      "Epoch 5 Batch 145 Loss 1.0851\n",
      "Epoch 5 Batch 146 Loss 1.0677\n",
      "Epoch 5 Batch 147 Loss 1.0880\n",
      "Epoch 5 Batch 148 Loss 1.0197\n",
      "Epoch 5 Batch 149 Loss 1.0339\n",
      "Epoch 5 Batch 150 Loss 1.1223\n",
      "Epoch 5 Batch 151 Loss 1.2009\n",
      "Epoch 5 Batch 152 Loss 1.1873\n",
      "Epoch 5 Batch 153 Loss 1.2326\n",
      "Epoch 5 Batch 154 Loss 1.0164\n",
      "Epoch 5 Batch 155 Loss 1.1805\n",
      "Epoch 5 Batch 156 Loss 1.1997\n",
      "Epoch 5 Batch 157 Loss 1.3215\n",
      "Epoch 5 Batch 158 Loss 1.0967\n",
      "Epoch 5 Batch 159 Loss 1.1381\n",
      "Epoch 5 Batch 160 Loss 1.0614\n",
      "Epoch 5 Batch 161 Loss 1.1295\n",
      "Epoch 5 Batch 162 Loss 1.1302\n",
      "Epoch 5 Batch 163 Loss 1.5443\n",
      "Epoch 5 Batch 164 Loss 1.4118\n",
      "Epoch 5 Batch 165 Loss 0.9380\n",
      "Epoch 5 Batch 166 Loss 1.1822\n",
      "Epoch 5 Batch 167 Loss 1.0452\n",
      "Epoch 5 Batch 168 Loss 1.0756\n",
      "Epoch 5 Batch 169 Loss 1.2678\n",
      "Epoch 5 Batch 170 Loss 1.0794\n",
      "Epoch 5 Batch 171 Loss 1.2370\n",
      "Epoch 5 Batch 172 Loss 1.0696\n",
      "Epoch 5 Batch 173 Loss 1.4325\n",
      "Epoch 5 Batch 174 Loss 1.0656\n",
      "Epoch 5 Batch 175 Loss 1.2127\n",
      "Epoch 5 Batch 176 Loss 1.2559\n",
      "Epoch 5 Batch 177 Loss 0.8856\n",
      "Epoch 5 Batch 178 Loss 1.1024\n",
      "Epoch 5 Batch 179 Loss 1.0226\n",
      "Epoch 5 Batch 180 Loss 1.1187\n",
      "Epoch 5 Batch 181 Loss 1.2671\n",
      "Epoch 5 Batch 182 Loss 1.1114\n",
      "Epoch 5 Batch 183 Loss 0.9346\n",
      "Epoch 5 Batch 184 Loss 1.1775\n",
      "Epoch 5 Batch 185 Loss 1.3840\n",
      "Epoch 5 Batch 186 Loss 1.3701\n",
      "Epoch 5 Batch 187 Loss 1.1686\n",
      "Epoch 5 Batch 188 Loss 1.1957\n",
      "Epoch 5 Batch 189 Loss 1.0630\n",
      "Epoch 5 Batch 190 Loss 1.1370\n",
      "Epoch 5 Batch 191 Loss 1.2958\n",
      "Epoch 5 Batch 192 Loss 0.9246\n",
      "Epoch 5 Batch 193 Loss 1.1529\n",
      "Epoch 5 Batch 194 Loss 0.9626\n",
      "Epoch 5 Batch 195 Loss 1.2020\n",
      "Epoch 5 Batch 196 Loss 0.9839\n",
      "Epoch 5 Batch 197 Loss 1.2209\n",
      "Epoch 5 Batch 198 Loss 1.0633\n",
      "Epoch 5 Batch 199 Loss 1.2329\n",
      "Epoch 5 Batch 200 Loss 1.2564\n",
      "Epoch 5 Batch 201 Loss 0.9643\n",
      "Epoch 5 Batch 202 Loss 1.0747\n",
      "Epoch 5 Batch 203 Loss 1.0634\n",
      "Epoch 5 Batch 204 Loss 1.0224\n",
      "Epoch 5 Batch 205 Loss 1.0844\n",
      "Epoch 5 Batch 206 Loss 1.0695\n",
      "Epoch 5 Batch 207 Loss 1.2487\n",
      "Epoch 5 Batch 208 Loss 1.2773\n",
      "Epoch 5 Batch 209 Loss 1.0383\n",
      "Epoch 5 Batch 210 Loss 0.9881\n",
      "Epoch 5 Batch 211 Loss 1.0810\n",
      "Epoch 5 Batch 212 Loss 1.0843\n",
      "Epoch 5 Batch 213 Loss 1.1297\n",
      "Epoch 5 Batch 214 Loss 1.0983\n",
      "Epoch 5 Batch 215 Loss 1.2165\n",
      "Epoch 5 Batch 216 Loss 1.2611\n",
      "Epoch 5 Batch 217 Loss 1.2383\n",
      "Epoch 5 Batch 218 Loss 1.2052\n",
      "Epoch 5 Batch 219 Loss 1.1756\n",
      "Epoch 5 Batch 220 Loss 1.2295\n",
      "Epoch 5 Batch 221 Loss 0.9740\n",
      "Epoch 5 Batch 222 Loss 1.1632\n",
      "Epoch 5 Batch 223 Loss 1.3128\n",
      "Epoch 5 Batch 224 Loss 1.1687\n",
      "Epoch 5 Batch 225 Loss 1.3237\n",
      "Epoch 5 Batch 226 Loss 1.1006\n",
      "Epoch 5 Batch 227 Loss 1.0260\n",
      "Epoch 5 Batch 228 Loss 1.3692\n",
      "Epoch 5 Batch 229 Loss 1.2396\n",
      "Epoch 5 Batch 230 Loss 1.0405\n",
      "Epoch 5 Batch 231 Loss 1.1389\n",
      "Epoch 5 Batch 232 Loss 1.2003\n",
      "Epoch 5 Batch 233 Loss 1.1149\n",
      "Epoch 5 Batch 234 Loss 1.2181\n",
      "Epoch 5 Batch 235 Loss 0.9661\n",
      "Epoch 5 Batch 236 Loss 1.0958\n",
      "Epoch 5 Batch 237 Loss 1.1688\n",
      "Epoch 5 Batch 238 Loss 1.0615\n",
      "Epoch 5 Batch 239 Loss 0.9455\n",
      "Epoch 5 Batch 240 Loss 1.3799\n",
      "Epoch 5 Batch 241 Loss 1.2153\n",
      "Epoch 5 Batch 242 Loss 1.0336\n",
      "Epoch 5 Batch 243 Loss 1.1547\n",
      "Epoch 5 Batch 244 Loss 1.0102\n",
      "Epoch 5 Batch 245 Loss 1.3392\n",
      "Epoch 5 Batch 246 Loss 0.9674\n",
      "Epoch 5 Batch 247 Loss 1.3338\n",
      "Epoch 5 Batch 248 Loss 1.0869\n",
      "Epoch 5 Batch 249 Loss 1.0358\n",
      "Epoch 5 Batch 250 Loss 1.0316\n",
      "Epoch 5 Batch 251 Loss 1.2970\n",
      "Epoch 5 Batch 252 Loss 1.3235\n",
      "Epoch 5 Batch 253 Loss 1.0982\n",
      "Epoch 5 Batch 254 Loss 1.0818\n",
      "Epoch 5 Batch 255 Loss 1.0889\n",
      "Epoch 5 Batch 256 Loss 1.2050\n",
      "Epoch 5 Batch 257 Loss 1.1175\n",
      "Epoch 5 Batch 258 Loss 1.0323\n",
      "Epoch 5 Batch 259 Loss 1.1764\n",
      "Epoch 5 Batch 260 Loss 1.3055\n",
      "Epoch 5 Batch 261 Loss 1.0754\n",
      "Epoch 5 Batch 262 Loss 1.0734\n",
      "Epoch 5 Batch 263 Loss 1.2119\n",
      "Epoch 5 Batch 264 Loss 1.0348\n",
      "Epoch 5 Batch 265 Loss 0.9789\n",
      "Epoch 5 Batch 266 Loss 1.2746\n",
      "Epoch 5 Batch 267 Loss 1.0176\n",
      "Epoch 5 Batch 268 Loss 0.9766\n",
      "Epoch 5 Batch 269 Loss 1.3841\n",
      "Epoch 5 Batch 270 Loss 0.9923\n",
      "Epoch 5 Batch 271 Loss 1.2300\n",
      "Epoch 5 Batch 272 Loss 1.0752\n",
      "Epoch 5 Batch 273 Loss 0.7945\n",
      "Epoch 5 Batch 274 Loss 1.1246\n",
      "Epoch 5 Batch 275 Loss 1.0747\n",
      "Epoch 5 Batch 276 Loss 1.1619\n",
      "Epoch 5 Batch 277 Loss 0.9980\n",
      "Epoch 5 Batch 278 Loss 1.2367\n",
      "Epoch 5 Batch 279 Loss 1.2027\n",
      "Epoch 5 Batch 280 Loss 0.9314\n",
      "Epoch 5 Batch 281 Loss 1.1434\n",
      "Epoch 5 Batch 282 Loss 0.8408\n",
      "Epoch 5 Batch 283 Loss 1.2633\n",
      "Epoch 5 Batch 284 Loss 1.2371\n",
      "Epoch 5 Batch 285 Loss 0.9420\n",
      "Epoch 5 Batch 286 Loss 1.2803\n",
      "Epoch 5 Batch 287 Loss 1.1428\n",
      "Epoch 5 Batch 288 Loss 1.0021\n",
      "Epoch 5 Batch 289 Loss 1.1004\n",
      "Epoch 5 Batch 290 Loss 1.1164\n",
      "Epoch 5 Batch 291 Loss 1.1910\n",
      "Epoch 5 Batch 292 Loss 0.9659\n",
      "Epoch 5 Batch 293 Loss 1.3369\n",
      "Epoch 5 Batch 294 Loss 1.2144\n",
      "Epoch 5 Batch 295 Loss 1.1327\n",
      "Epoch 5 Batch 296 Loss 1.0864\n",
      "Epoch 5 Batch 297 Loss 0.9900\n",
      "Epoch 5 Batch 298 Loss 1.2721\n",
      "Epoch 5 Batch 299 Loss 1.2170\n",
      "Epoch 5 Batch 300 Loss 1.0012\n",
      "Epoch 5 Batch 301 Loss 1.0494\n",
      "Epoch 5 Batch 302 Loss 1.0728\n",
      "Epoch 5 Batch 303 Loss 1.1979\n",
      "Epoch 5 Batch 304 Loss 1.2899\n",
      "Epoch 5 Batch 305 Loss 1.1658\n",
      "Epoch 5 Batch 306 Loss 1.0976\n",
      "Epoch 5 Batch 307 Loss 0.9599\n",
      "Epoch 5 Batch 308 Loss 1.1727\n",
      "Epoch 5 Batch 309 Loss 1.1004\n",
      "Epoch 5 Batch 310 Loss 0.9250\n",
      "Epoch 5 Batch 311 Loss 0.9609\n",
      "Epoch 5 Batch 312 Loss 0.9748\n",
      "Epoch 5 Batch 313 Loss 1.2897\n",
      "Epoch 5 Batch 314 Loss 1.0782\n",
      "Epoch 5 Batch 315 Loss 1.1250\n",
      "Epoch 5 Batch 316 Loss 1.1251\n",
      "Epoch 5 Batch 317 Loss 1.0593\n",
      "Epoch 5 Batch 318 Loss 1.2517\n",
      "Epoch 5 Batch 319 Loss 1.1575\n",
      "Epoch 5 Batch 320 Loss 1.1651\n",
      "Epoch 5 Batch 321 Loss 1.0473\n",
      "Epoch 5 Batch 322 Loss 1.2611\n",
      "Epoch 5 Batch 323 Loss 1.1142\n",
      "Epoch 5 Batch 324 Loss 0.9948\n",
      "Epoch 5 Batch 325 Loss 1.0005\n",
      "Epoch 5 Batch 326 Loss 1.3921\n",
      "Epoch 5 Batch 327 Loss 0.9821\n",
      "Epoch 5 Batch 328 Loss 1.0043\n",
      "Epoch 5 Batch 329 Loss 1.0312\n",
      "Epoch 5 Batch 330 Loss 0.9910\n",
      "Epoch 5 Batch 331 Loss 0.9828\n",
      "Epoch 5 Batch 332 Loss 1.1460\n",
      "Epoch 5 Batch 333 Loss 1.0884\n",
      "Epoch 5 Batch 334 Loss 1.1367\n",
      "Epoch 5 Batch 335 Loss 1.0945\n",
      "Epoch 5 Batch 336 Loss 0.9615\n",
      "Epoch 5 Batch 337 Loss 1.0243\n",
      "Epoch 5 Batch 338 Loss 1.1679\n",
      "Epoch 5 Batch 339 Loss 1.2394\n",
      "Epoch 5 Batch 340 Loss 1.2214\n",
      "Epoch 5 Batch 341 Loss 0.9508\n",
      "Epoch 5 Batch 342 Loss 0.9746\n",
      "Epoch 5 Batch 343 Loss 1.0130\n",
      "Epoch 5 Batch 344 Loss 1.0152\n",
      "Epoch 5 Batch 345 Loss 1.3700\n",
      "Epoch 5 Batch 346 Loss 0.9466\n",
      "Epoch 5 Batch 347 Loss 1.2028\n",
      "Epoch 5 Batch 348 Loss 1.1990\n",
      "Epoch 5 Batch 349 Loss 1.0467\n",
      "Epoch 5 Batch 350 Loss 1.1866\n",
      "Epoch 5 Batch 351 Loss 0.9688\n",
      "Epoch 5 Batch 352 Loss 1.0622\n",
      "Epoch 5 Batch 353 Loss 0.9103\n",
      "Epoch 5 Batch 354 Loss 1.1292\n",
      "Epoch 5 Batch 355 Loss 1.2207\n",
      "Epoch 5 Batch 356 Loss 1.2304\n",
      "Epoch 5 Batch 357 Loss 1.2192\n",
      "Epoch 5 Batch 358 Loss 1.1011\n",
      "Epoch 5 Batch 359 Loss 0.8563\n",
      "Epoch 5 Batch 360 Loss 1.1664\n",
      "Epoch 5 Batch 361 Loss 1.1486\n",
      "Epoch 5 Batch 362 Loss 1.0524\n",
      "Epoch 5 Batch 363 Loss 1.1233\n",
      "Epoch 5 Batch 364 Loss 1.1890\n",
      "Epoch 5 Batch 365 Loss 1.1068\n",
      "Epoch 5 Batch 366 Loss 0.9541\n",
      "Epoch 5 Batch 367 Loss 1.2164\n",
      "Epoch 5 Batch 368 Loss 1.5234\n",
      "Epoch 5 Batch 369 Loss 1.0838\n",
      "Epoch 5 Batch 370 Loss 1.3410\n",
      "Epoch 5 Batch 371 Loss 0.9094\n",
      "Epoch 5 Batch 372 Loss 1.3720\n",
      "Epoch 5 Batch 373 Loss 1.1926\n",
      "Epoch 5 Batch 374 Loss 0.9818\n",
      "Epoch 5 Batch 375 Loss 1.0850\n",
      "Epoch 5 Batch 376 Loss 1.1765\n",
      "Epoch 5 Batch 377 Loss 0.9726\n",
      "Epoch 5 Batch 378 Loss 0.8711\n",
      "Epoch 5 Batch 379 Loss 1.0071\n",
      "Epoch 5 Batch 380 Loss 1.1327\n",
      "Epoch 5 Batch 381 Loss 1.2286\n",
      "Epoch 5 Batch 382 Loss 1.2081\n",
      "Epoch 5 Batch 383 Loss 1.0867\n",
      "Epoch 5 Batch 384 Loss 1.1410\n",
      "Epoch 5 Batch 385 Loss 0.7595\n",
      "Epoch 5 Batch 386 Loss 1.1092\n",
      "Epoch 5 Batch 387 Loss 1.1460\n",
      "Epoch 5 Batch 388 Loss 0.9749\n",
      "Epoch 5 Batch 389 Loss 0.9034\n",
      "Epoch 5 Batch 390 Loss 1.4617\n",
      "Epoch 5 Batch 391 Loss 1.2237\n",
      "Epoch 5 Batch 392 Loss 0.9589\n",
      "Epoch 5 Batch 393 Loss 1.2249\n",
      "Epoch 5 Batch 394 Loss 1.3062\n",
      "Epoch 5 Batch 395 Loss 1.0199\n",
      "Epoch 5 Batch 396 Loss 0.9409\n",
      "Epoch 5 Batch 397 Loss 1.0287\n",
      "Epoch 5 Batch 398 Loss 0.8438\n",
      "Epoch 5 Batch 399 Loss 1.0773\n",
      "Epoch 5 Batch 400 Loss 1.0215\n",
      "Epoch 5 Batch 401 Loss 1.0073\n",
      "Epoch 5 Batch 402 Loss 0.9150\n",
      "Epoch 5 Batch 403 Loss 1.0401\n",
      "Epoch 5 Batch 404 Loss 1.2692\n",
      "Epoch 5 Batch 405 Loss 1.3161\n",
      "Epoch 5 Batch 406 Loss 1.0280\n",
      "Epoch 5 Batch 407 Loss 1.3225\n",
      "Epoch 5 Batch 408 Loss 1.0191\n",
      "Epoch 5 Batch 409 Loss 0.9943\n",
      "Epoch 5 Batch 410 Loss 1.0034\n",
      "Epoch 5 Batch 411 Loss 0.9460\n",
      "Epoch 5 Batch 412 Loss 0.9076\n",
      "Epoch 5 Batch 413 Loss 1.0710\n",
      "Epoch 5 Batch 414 Loss 0.9489\n",
      "Epoch 5 Batch 415 Loss 1.2856\n",
      "Epoch 5 Batch 416 Loss 0.9405\n",
      "Epoch 5 Batch 417 Loss 1.0273\n",
      "Epoch 5 Batch 418 Loss 1.1393\n",
      "Epoch 5 Batch 419 Loss 0.9130\n",
      "Epoch 5 Batch 420 Loss 1.1584\n",
      "Epoch 5 Batch 421 Loss 1.0964\n",
      "Epoch 5 Batch 422 Loss 1.1055\n",
      "Epoch 5 Batch 423 Loss 1.4254\n",
      "Epoch 5 Batch 424 Loss 1.1085\n",
      "Epoch 5 Batch 425 Loss 0.8088\n",
      "Epoch 5 Batch 426 Loss 1.1946\n",
      "Epoch 5 Batch 427 Loss 0.9800\n",
      "Epoch 5 Batch 428 Loss 0.9373\n",
      "Epoch 5 Batch 429 Loss 1.0939\n",
      "Epoch 5 Batch 430 Loss 0.9718\n",
      "Epoch 5 Batch 431 Loss 1.0979\n",
      "Epoch 5 Batch 432 Loss 1.1324\n",
      "Epoch 5 Batch 433 Loss 1.0495\n",
      "Epoch 5 Batch 434 Loss 1.4824\n",
      "Epoch 5 Batch 435 Loss 1.2546\n",
      "Epoch 5 Batch 436 Loss 0.9910\n",
      "Epoch 5 Batch 437 Loss 1.2169\n",
      "Epoch 5 Batch 438 Loss 1.2236\n",
      "Epoch 5 Batch 439 Loss 0.9664\n",
      "Epoch 5 Batch 440 Loss 1.1193\n",
      "Epoch 5 Batch 441 Loss 1.0088\n",
      "Epoch 5 Batch 442 Loss 0.9845\n",
      "Epoch 5 Batch 443 Loss 1.0675\n",
      "Epoch 5 Batch 444 Loss 1.2988\n",
      "Epoch 5 Batch 445 Loss 1.1248\n",
      "Epoch 5 Batch 446 Loss 1.1436\n",
      "Epoch 5 Batch 447 Loss 1.1321\n",
      "Epoch 5 Batch 448 Loss 1.2541\n",
      "Epoch 5 Batch 449 Loss 0.9777\n",
      "Epoch 5 Batch 450 Loss 1.1757\n",
      "Epoch 5 Batch 451 Loss 0.8045\n",
      "Epoch 5 Batch 452 Loss 1.1357\n",
      "Epoch 5 Batch 453 Loss 1.2267\n",
      "Epoch 5 Batch 454 Loss 1.1227\n",
      "Epoch 5 Batch 455 Loss 1.0488\n",
      "Epoch 5 Batch 456 Loss 0.9854\n",
      "Epoch 5 Batch 457 Loss 1.0778\n",
      "Epoch 5 Batch 458 Loss 0.9933\n",
      "Epoch 5 Batch 459 Loss 0.9575\n",
      "Epoch 5 Batch 460 Loss 1.1283\n",
      "Epoch 5 Batch 461 Loss 0.8696\n",
      "Epoch 5 Batch 462 Loss 1.3578\n",
      "Epoch 5 Batch 463 Loss 1.2309\n",
      "Epoch 5 Batch 464 Loss 0.9850\n",
      "Epoch 5 Batch 465 Loss 1.0247\n",
      "Epoch 5 Batch 466 Loss 0.8914\n",
      "Epoch 5 Batch 467 Loss 1.2677\n",
      "Epoch 5 Batch 468 Loss 1.0790\n",
      "Epoch 5 Batch 469 Loss 0.9006\n",
      "Epoch 5 Batch 470 Loss 1.3214\n",
      "Epoch 5 Batch 471 Loss 1.0497\n",
      "Epoch 5 Batch 472 Loss 1.1314\n",
      "Epoch 5 Batch 473 Loss 0.9859\n",
      "Epoch 5 Batch 474 Loss 1.1417\n",
      "Epoch 5 Batch 475 Loss 0.9371\n",
      "Epoch 5 Batch 476 Loss 1.4200\n",
      "Epoch 5 Batch 477 Loss 1.1321\n",
      "Epoch 5 Batch 478 Loss 1.0724\n",
      "Epoch 5 Batch 479 Loss 1.0780\n",
      "Epoch 5 Batch 480 Loss 1.0062\n",
      "Epoch 5 Batch 481 Loss 1.0261\n",
      "Epoch 5 Batch 482 Loss 1.1484\n",
      "Epoch 5 Batch 483 Loss 1.1109\n",
      "Epoch 5 Batch 484 Loss 1.0879\n",
      "Epoch 5 Batch 485 Loss 1.3318\n",
      "Epoch 5 Batch 486 Loss 0.9905\n",
      "Epoch 5 Batch 487 Loss 1.0385\n",
      "Epoch 5 Batch 488 Loss 1.0656\n",
      "Epoch 5 Batch 489 Loss 1.0226\n",
      "Epoch 5 Batch 490 Loss 0.9352\n",
      "Epoch 5 Batch 491 Loss 0.9979\n",
      "Epoch 5 Batch 492 Loss 1.1821\n",
      "Epoch 5 Batch 493 Loss 1.1833\n",
      "Epoch 5 Batch 494 Loss 1.2725\n",
      "Epoch 5 Batch 495 Loss 1.2588\n",
      "Epoch 5 Batch 496 Loss 0.7474\n",
      "Epoch 5 Batch 497 Loss 1.0750\n",
      "Epoch 5 Batch 498 Loss 0.9911\n",
      "Epoch 5 Batch 499 Loss 1.2178\n",
      "Epoch 5 Batch 500 Loss 1.1373\n",
      "Epoch 5 Batch 501 Loss 1.1116\n",
      "Epoch 5 Batch 502 Loss 0.8735\n",
      "Epoch 5 Batch 503 Loss 1.0502\n",
      "Epoch 5 Batch 504 Loss 1.1543\n",
      "Epoch 5 Batch 505 Loss 0.9178\n",
      "Epoch 5 Batch 506 Loss 1.1472\n",
      "Epoch 5 Batch 507 Loss 1.4699\n",
      "Epoch 5 Batch 508 Loss 0.9685\n",
      "Epoch 5 Batch 509 Loss 1.2078\n",
      "Epoch 5 Batch 510 Loss 1.1801\n",
      "Epoch 5 Batch 511 Loss 1.1005\n",
      "Epoch 5 Batch 512 Loss 1.0627\n",
      "Epoch 5 Batch 513 Loss 1.4891\n",
      "Epoch 5 Batch 514 Loss 1.2054\n",
      "Epoch 5 Batch 515 Loss 1.0314\n",
      "Epoch 5 Batch 516 Loss 1.2797\n",
      "Epoch 5 Batch 517 Loss 1.3182\n",
      "Epoch 5 Batch 518 Loss 1.1225\n",
      "Epoch 5 Batch 519 Loss 1.2365\n",
      "Epoch 5 Batch 520 Loss 0.9898\n",
      "Epoch 5 Batch 521 Loss 1.0795\n",
      "Epoch 5 Batch 522 Loss 1.3311\n",
      "Epoch 5 Batch 523 Loss 1.2467\n",
      "Epoch 5 Batch 524 Loss 0.9856\n",
      "Epoch 5 Batch 525 Loss 1.0353\n",
      "Epoch 5 Batch 526 Loss 1.0309\n",
      "Epoch 5 Batch 527 Loss 1.1232\n",
      "Epoch 5 Batch 528 Loss 1.3361\n",
      "Epoch 5 Batch 529 Loss 1.3591\n",
      "Epoch 5 Batch 530 Loss 1.0561\n",
      "Epoch 5 Batch 531 Loss 0.7926\n",
      "Epoch 5 Batch 532 Loss 1.1337\n",
      "Epoch 5 Batch 533 Loss 1.2966\n",
      "Epoch 5 Batch 534 Loss 0.9857\n",
      "Epoch 5 Batch 535 Loss 1.1912\n",
      "Epoch 5 Batch 536 Loss 1.3140\n",
      "Epoch 5 Batch 537 Loss 1.0398\n",
      "Epoch 5 Batch 538 Loss 1.1701\n",
      "Epoch 5 Batch 539 Loss 0.9393\n",
      "Epoch 5 Batch 540 Loss 1.2043\n",
      "Epoch 5 Batch 541 Loss 1.0892\n",
      "Epoch 5 Batch 542 Loss 1.0433\n",
      "Epoch 5 Batch 543 Loss 1.2113\n",
      "Epoch 5 Batch 544 Loss 1.2581\n",
      "Epoch 5 Batch 545 Loss 0.8536\n",
      "Epoch 5 Batch 546 Loss 1.1736\n",
      "Epoch 5 Batch 547 Loss 1.1198\n",
      "Epoch 5 Batch 548 Loss 1.1019\n",
      "Epoch 5 Batch 549 Loss 1.2502\n",
      "Epoch 5 Batch 550 Loss 0.9916\n",
      "Epoch 5 Batch 551 Loss 0.9703\n",
      "Epoch 5 Batch 552 Loss 0.9499\n",
      "Epoch 5 Batch 553 Loss 0.8705\n",
      "Epoch 5 Batch 554 Loss 1.0465\n",
      "Epoch 5 Batch 555 Loss 1.0624\n",
      "Epoch 5 Batch 556 Loss 1.1822\n",
      "Epoch 5 Batch 557 Loss 1.0816\n",
      "Epoch 5 Batch 558 Loss 1.0596\n",
      "Epoch 5 Batch 559 Loss 0.9097\n",
      "Epoch 5 Batch 560 Loss 1.0269\n",
      "Epoch 5 Batch 561 Loss 1.0123\n",
      "Epoch 5 Batch 562 Loss 0.9436\n",
      "Epoch 5 Batch 563 Loss 1.1017\n",
      "Epoch 5 Batch 564 Loss 1.0240\n",
      "Epoch 5 Batch 565 Loss 1.2326\n",
      "Epoch 5 Batch 566 Loss 0.9373\n",
      "Epoch 5 Batch 567 Loss 1.1136\n",
      "Epoch 5 Batch 568 Loss 1.1081\n",
      "Epoch 5 Batch 569 Loss 1.1747\n",
      "Epoch 5 Batch 570 Loss 0.9716\n",
      "Epoch 5 Batch 571 Loss 1.1902\n",
      "Epoch 5 Batch 572 Loss 0.9301\n",
      "Epoch 5 Batch 573 Loss 1.1108\n",
      "Epoch 5 Batch 574 Loss 1.1606\n",
      "Epoch 5 Batch 575 Loss 0.9180\n",
      "Epoch 5 Batch 576 Loss 1.2112\n",
      "Epoch 5 Batch 577 Loss 1.1481\n",
      "Epoch 5 Batch 578 Loss 1.0791\n",
      "Epoch 5 Batch 579 Loss 1.5101\n",
      "Epoch 5 Batch 580 Loss 1.2302\n",
      "Epoch 5 Batch 581 Loss 1.2343\n",
      "Epoch 5 Batch 582 Loss 1.1667\n",
      "Epoch 5 Batch 583 Loss 1.0775\n",
      "Epoch 5 Batch 584 Loss 0.8991\n",
      "Epoch 5 Batch 585 Loss 1.0739\n",
      "Epoch 5 Batch 586 Loss 1.1510\n",
      "Epoch 5 Batch 587 Loss 1.4001\n",
      "Epoch 5 Batch 588 Loss 1.1287\n",
      "Epoch 5 Batch 589 Loss 1.1535\n",
      "Epoch 5 Batch 590 Loss 1.3118\n",
      "Epoch 5 Batch 591 Loss 0.9847\n",
      "Epoch 5 Batch 592 Loss 0.9600\n",
      "Epoch 5 Batch 593 Loss 1.2457\n",
      "Epoch 5 Batch 594 Loss 1.0193\n",
      "Epoch 5 Batch 595 Loss 0.9471\n",
      "Epoch 5 Batch 596 Loss 1.2058\n",
      "Epoch 5 Batch 597 Loss 1.2808\n",
      "Epoch 5 Batch 598 Loss 1.0887\n",
      "Epoch 5 Batch 599 Loss 1.1319\n",
      "Epoch 5 Batch 600 Loss 1.1035\n",
      "Epoch 5 Batch 601 Loss 0.7764\n",
      "Epoch 5 Batch 602 Loss 1.0289\n",
      "Epoch 5 Batch 603 Loss 1.0020\n",
      "Epoch 5 Batch 604 Loss 1.0321\n",
      "Epoch 5 Batch 605 Loss 1.0411\n",
      "Epoch 5 Batch 606 Loss 1.2416\n",
      "Epoch 5 Batch 607 Loss 0.9445\n",
      "Epoch 5 Batch 608 Loss 1.1958\n",
      "Epoch 5 Batch 609 Loss 1.4431\n",
      "Epoch 5 Batch 610 Loss 1.1497\n",
      "Epoch 5 Batch 611 Loss 1.0420\n",
      "Epoch 5 Batch 612 Loss 1.1532\n",
      "Epoch 5 Batch 613 Loss 1.1770\n",
      "Epoch 5 Batch 614 Loss 1.1792\n",
      "Epoch 5 Batch 615 Loss 0.8917\n",
      "Epoch 5 Batch 616 Loss 0.9121\n",
      "Epoch 5 Batch 617 Loss 1.4339\n",
      "Epoch 5 Batch 618 Loss 1.0616\n",
      "Epoch 5 Batch 619 Loss 0.8520\n",
      "Epoch 5 Batch 620 Loss 1.0347\n",
      "Epoch 5 Batch 621 Loss 0.8257\n",
      "Epoch 5 Batch 622 Loss 1.0333\n",
      "Epoch 5 Batch 623 Loss 0.9993\n",
      "Epoch 5 Batch 624 Loss 1.0113\n",
      "Epoch 5 Batch 625 Loss 1.1812\n",
      "Epoch 5 Batch 626 Loss 1.1112\n",
      "Epoch 5 Batch 627 Loss 1.1532\n",
      "Epoch 5 Batch 628 Loss 0.9198\n",
      "Epoch 5 Batch 629 Loss 1.3006\n",
      "Epoch 5 Batch 630 Loss 0.9586\n",
      "Epoch 5 Batch 631 Loss 1.0809\n",
      "Epoch 5 Batch 632 Loss 0.8328\n",
      "Epoch 5 Batch 633 Loss 1.3506\n",
      "Epoch 5 Batch 634 Loss 1.0743\n",
      "Epoch 5 Batch 635 Loss 1.1905\n",
      "Epoch 5 Batch 636 Loss 1.0167\n",
      "Epoch 5 Batch 637 Loss 1.0576\n",
      "Epoch 5 Batch 638 Loss 0.8084\n",
      "Epoch 5 Batch 639 Loss 1.2267\n",
      "Epoch 5 Batch 640 Loss 1.1474\n",
      "Epoch 5 Batch 641 Loss 1.2787\n",
      "Epoch 5 Batch 642 Loss 1.3029\n",
      "Epoch 5 Batch 643 Loss 1.2135\n",
      "Epoch 5 Batch 644 Loss 1.0371\n",
      "Epoch 5 Batch 645 Loss 0.9376\n",
      "Epoch 5 Batch 646 Loss 0.9743\n",
      "Epoch 5 Batch 647 Loss 1.2496\n",
      "Epoch 5 Batch 648 Loss 1.1027\n",
      "Epoch 5 Batch 649 Loss 1.2236\n",
      "Epoch 5 Batch 650 Loss 0.8960\n",
      "Epoch 5 Batch 651 Loss 1.1631\n",
      "Epoch 5 Batch 652 Loss 1.0641\n",
      "Epoch 5 Batch 653 Loss 1.0514\n",
      "Epoch 5 Batch 654 Loss 1.1417\n",
      "Epoch 5 Batch 655 Loss 1.1578\n",
      "Epoch 5 Batch 656 Loss 1.0759\n",
      "Epoch 5 Batch 657 Loss 1.1799\n",
      "Epoch 5 Batch 658 Loss 1.1766\n",
      "Epoch 5 Batch 659 Loss 1.2834\n",
      "Epoch 5 Batch 660 Loss 1.0716\n",
      "Epoch 5 Batch 661 Loss 1.3403\n",
      "Epoch 5 Batch 662 Loss 1.0800\n",
      "Epoch 5 Batch 663 Loss 1.0786\n",
      "Epoch 5 Batch 664 Loss 1.1604\n",
      "Epoch 5 Batch 665 Loss 1.3715\n",
      "Epoch 5 Batch 666 Loss 1.3799\n",
      "Epoch 5 Batch 667 Loss 0.9567\n",
      "Epoch 5 Batch 668 Loss 0.8655\n",
      "Epoch 5 Batch 669 Loss 1.2236\n",
      "Epoch 5 Batch 670 Loss 0.8983\n",
      "Epoch 5 Batch 671 Loss 1.2501\n",
      "Epoch 5 Batch 672 Loss 1.0501\n",
      "Epoch 5 Batch 673 Loss 1.0023\n",
      "Epoch 5 Batch 674 Loss 1.1419\n",
      "Epoch 5 Batch 675 Loss 0.9323\n",
      "Epoch 5 Batch 676 Loss 0.9768\n",
      "Epoch 5 Batch 677 Loss 1.1834\n",
      "Epoch 5 Batch 678 Loss 1.1952\n",
      "Epoch 5 Batch 679 Loss 1.0620\n",
      "Epoch 5 Batch 680 Loss 1.2865\n",
      "Epoch 5 Batch 681 Loss 1.3827\n",
      "Epoch 5 Batch 682 Loss 1.1720\n",
      "Epoch 5 Batch 683 Loss 1.4910\n",
      "Epoch 5 Batch 684 Loss 1.0519\n",
      "Epoch 5 Batch 685 Loss 1.2723\n",
      "Epoch 5 Batch 686 Loss 1.4142\n",
      "Epoch 5 Batch 687 Loss 1.0573\n",
      "Epoch 5 Batch 688 Loss 0.9034\n",
      "Epoch 5 Batch 689 Loss 1.0842\n",
      "Epoch 5 Batch 690 Loss 1.3310\n",
      "Epoch 5 Batch 691 Loss 1.0361\n",
      "Epoch 5 Batch 692 Loss 0.9762\n",
      "Epoch 5 Batch 693 Loss 1.1558\n",
      "Epoch 5 Batch 694 Loss 1.0756\n",
      "Epoch 5 Batch 695 Loss 1.3523\n",
      "Epoch 5 Batch 696 Loss 1.4652\n",
      "Epoch 5 Batch 697 Loss 1.1499\n",
      "Epoch 5 Batch 698 Loss 1.3366\n",
      "Epoch 5 Batch 699 Loss 1.1929\n",
      "Epoch 5 Batch 700 Loss 1.2637\n",
      "Epoch 5 Batch 701 Loss 0.9222\n",
      "Epoch 5 Batch 702 Loss 1.1184\n",
      "Epoch 5 Batch 703 Loss 0.9761\n",
      "Epoch 5 Batch 704 Loss 1.4155\n",
      "Epoch 5 Batch 705 Loss 0.9403\n",
      "Epoch 5 Batch 706 Loss 1.4107\n",
      "Epoch 5 Batch 707 Loss 1.1760\n",
      "Epoch 5 Batch 708 Loss 1.1393\n",
      "Epoch 5 Batch 709 Loss 1.1910\n",
      "Epoch 5 Batch 710 Loss 1.0927\n",
      "Epoch 5 Batch 711 Loss 1.0601\n",
      "Epoch 5 Batch 712 Loss 1.3755\n",
      "Epoch 5 Batch 713 Loss 1.2362\n",
      "Epoch 5 Batch 714 Loss 1.3062\n",
      "Epoch 5 Batch 715 Loss 1.0446\n",
      "Epoch 5 Batch 716 Loss 1.2247\n",
      "Epoch 5 Batch 717 Loss 0.9155\n",
      "Epoch 5 Batch 718 Loss 1.0239\n",
      "Epoch 5 Batch 719 Loss 1.2032\n",
      "Epoch 5 Batch 720 Loss 0.8967\n",
      "Epoch 5 Batch 721 Loss 1.3162\n",
      "Epoch 5 Batch 722 Loss 1.1500\n",
      "Epoch 5 Batch 723 Loss 0.9854\n",
      "Epoch 5 Batch 724 Loss 1.1293\n",
      "Epoch 5 Batch 725 Loss 1.1247\n",
      "Epoch 5 Batch 726 Loss 1.1662\n",
      "Epoch 5 Batch 727 Loss 1.0394\n",
      "Epoch 5 Batch 728 Loss 1.0652\n",
      "Epoch 5 Batch 729 Loss 1.2830\n",
      "Epoch 5 Batch 730 Loss 1.1440\n",
      "Epoch 5 Batch 731 Loss 0.9911\n",
      "Epoch 5 Batch 732 Loss 1.0305\n",
      "Epoch 5 Batch 733 Loss 1.2137\n",
      "Epoch 5 Batch 734 Loss 1.0965\n",
      "Epoch 5 Batch 735 Loss 0.9986\n",
      "Epoch 5 Batch 736 Loss 1.1223\n",
      "Epoch 5 Batch 737 Loss 1.0500\n",
      "Epoch 5 Batch 738 Loss 1.2025\n",
      "Epoch 5 Batch 739 Loss 1.1952\n",
      "Epoch 5 Batch 740 Loss 1.3589\n",
      "Epoch 5 Batch 741 Loss 1.2396\n",
      "Epoch 5 Batch 742 Loss 1.2615\n",
      "Epoch 5 Batch 743 Loss 1.0600\n",
      "Epoch 5 Batch 744 Loss 1.1648\n",
      "Epoch 5 Batch 745 Loss 0.8067\n",
      "Epoch 5 Batch 746 Loss 1.2755\n",
      "Epoch 5 Batch 747 Loss 1.0829\n",
      "Epoch 5 Batch 748 Loss 1.2760\n",
      "Epoch 5 Batch 749 Loss 0.8858\n",
      "Epoch 5 Batch 750 Loss 0.9758\n",
      "Epoch 5 Batch 751 Loss 1.0717\n",
      "Epoch 5 Batch 752 Loss 1.0623\n",
      "Epoch 5 Batch 753 Loss 1.0338\n",
      "Epoch 5 Batch 754 Loss 0.9521\n",
      "Epoch 5 Batch 755 Loss 1.2561\n",
      "Epoch 5 Batch 756 Loss 1.0693\n",
      "Epoch 5 Batch 757 Loss 0.9613\n",
      "Epoch 5 Batch 758 Loss 1.0067\n",
      "Epoch 5 Batch 759 Loss 1.4481\n",
      "Epoch 5 Batch 760 Loss 1.1308\n",
      "Epoch 5 Batch 761 Loss 1.1266\n",
      "Epoch 5 Batch 762 Loss 1.0802\n",
      "Epoch 5 Batch 763 Loss 1.2133\n",
      "Epoch 5 Batch 764 Loss 1.0270\n",
      "Epoch 5 Batch 765 Loss 1.3392\n",
      "Epoch 5 Batch 766 Loss 0.9417\n",
      "Epoch 5 Batch 767 Loss 1.0507\n",
      "Epoch 5 Batch 768 Loss 1.1597\n",
      "Epoch 5 Batch 769 Loss 0.9434\n",
      "Epoch 5 Batch 770 Loss 1.1698\n",
      "Epoch 5 Batch 771 Loss 0.9868\n",
      "Epoch 5 Batch 772 Loss 1.0602\n",
      "Epoch 5 Batch 773 Loss 1.0704\n",
      "Epoch 5 Batch 774 Loss 1.3140\n",
      "Epoch 5 Batch 775 Loss 0.8724\n",
      "Epoch 5 Batch 776 Loss 1.0106\n",
      "Epoch 5 Batch 777 Loss 1.1202\n",
      "Epoch 5 Batch 778 Loss 0.9944\n",
      "Epoch 5 Batch 779 Loss 0.9995\n",
      "Epoch 5 Batch 780 Loss 1.1609\n",
      "Epoch 5 Batch 781 Loss 1.3357\n",
      "Epoch 5 Batch 782 Loss 1.1114\n",
      "Epoch 5 Batch 783 Loss 1.3879\n",
      "Epoch 5 Batch 784 Loss 1.2010\n",
      "Epoch 5 Batch 785 Loss 1.0616\n",
      "Epoch 5 Batch 786 Loss 1.0677\n",
      "Epoch 5 Batch 787 Loss 1.2583\n",
      "Epoch 5 Batch 788 Loss 1.1172\n",
      "Epoch 5 Batch 789 Loss 1.0241\n",
      "Epoch 5 Batch 790 Loss 1.2683\n",
      "Epoch 5 Batch 791 Loss 0.9616\n",
      "Epoch 5 Batch 792 Loss 1.0009\n",
      "Epoch 5 Batch 793 Loss 1.2065\n",
      "Epoch 5 Batch 794 Loss 1.3650\n",
      "Epoch 5 Batch 795 Loss 1.2213\n",
      "Epoch 5 Batch 796 Loss 1.2442\n",
      "Epoch 5 Batch 797 Loss 1.4222\n",
      "Epoch 5 Batch 798 Loss 0.9297\n",
      "Epoch 5 Batch 799 Loss 1.1981\n",
      "Epoch 5 Batch 800 Loss 0.8180\n",
      "Epoch 5 Batch 801 Loss 0.9392\n",
      "Epoch 5 Batch 802 Loss 1.1430\n",
      "Epoch 5 Batch 803 Loss 1.0001\n",
      "Epoch 5 Batch 804 Loss 1.1386\n",
      "Epoch 5 Batch 805 Loss 1.1125\n",
      "Epoch 5 Batch 806 Loss 1.0149\n",
      "Epoch 5 Batch 807 Loss 1.0677\n",
      "Epoch 5 Batch 808 Loss 1.0749\n",
      "Epoch 5 Batch 809 Loss 1.0747\n",
      "Epoch 5 Batch 810 Loss 1.1045\n",
      "Epoch 5 Batch 811 Loss 1.0060\n",
      "Epoch 5 Batch 812 Loss 1.2567\n",
      "Epoch 5 Batch 813 Loss 1.0934\n",
      "Epoch 5 Batch 814 Loss 1.1650\n",
      "Epoch 5 Batch 815 Loss 1.1649\n",
      "Epoch 5 Batch 816 Loss 1.2148\n",
      "Epoch 5 Batch 817 Loss 1.1785\n",
      "Epoch 5 Batch 818 Loss 1.0184\n",
      "Epoch 5 Batch 819 Loss 1.1433\n",
      "Epoch 5 Batch 820 Loss 1.2870\n",
      "Epoch 5 Batch 821 Loss 1.0507\n",
      "Epoch 5 Batch 822 Loss 1.0904\n",
      "Epoch 5 Batch 823 Loss 1.3292\n",
      "Epoch 5 Batch 824 Loss 1.1532\n",
      "Epoch 5 Batch 825 Loss 1.0016\n",
      "Epoch 5 Batch 826 Loss 1.4662\n",
      "Epoch 5 Batch 827 Loss 1.1626\n",
      "Epoch 5 Batch 828 Loss 1.1456\n",
      "Epoch 5 Batch 829 Loss 1.1116\n",
      "Epoch 5 Batch 830 Loss 1.5178\n",
      "Epoch 5 Batch 831 Loss 1.1815\n",
      "Epoch 5 Batch 832 Loss 1.4710\n",
      "Epoch 5 Batch 833 Loss 1.2853\n",
      "Epoch 5 Batch 834 Loss 1.1311\n",
      "Epoch 5 Batch 835 Loss 1.0005\n",
      "Epoch 5 Batch 836 Loss 1.2108\n",
      "Epoch 5 Batch 837 Loss 0.8589\n",
      "Epoch 5 Batch 838 Loss 1.0173\n",
      "Epoch 5 Batch 839 Loss 1.1800\n",
      "Epoch 5 Batch 840 Loss 1.2973\n",
      "Epoch 5 Batch 841 Loss 1.0232\n",
      "Epoch 5 Batch 842 Loss 1.1965\n",
      "Epoch 5 Batch 843 Loss 1.2407\n",
      "Epoch 5 Batch 844 Loss 0.9734\n",
      "Epoch 5 Batch 845 Loss 1.1831\n",
      "Epoch 5 Batch 846 Loss 1.0849\n",
      "Epoch 5 Batch 847 Loss 0.8219\n",
      "Epoch 5 Batch 848 Loss 1.2047\n",
      "Epoch 5 Batch 849 Loss 1.5064\n",
      "Epoch 5 Batch 850 Loss 0.9340\n",
      "Epoch 5 Batch 851 Loss 1.2831\n",
      "Epoch 5 Batch 852 Loss 1.1537\n",
      "Epoch 5 Batch 853 Loss 0.8618\n",
      "Epoch 5 Batch 854 Loss 1.2501\n",
      "Epoch 5 Batch 855 Loss 1.3554\n",
      "Epoch 5 Batch 856 Loss 1.1493\n",
      "Epoch 5 Batch 857 Loss 0.9990\n",
      "Epoch 5 Batch 858 Loss 1.1242\n",
      "Epoch 5 Batch 859 Loss 1.1503\n",
      "Epoch 5 Batch 860 Loss 1.2294\n",
      "Epoch 5 Batch 861 Loss 0.9361\n",
      "Epoch 5 Batch 862 Loss 1.2908\n",
      "Epoch 5 Batch 863 Loss 1.1997\n",
      "Epoch 5 Batch 864 Loss 1.1298\n",
      "Epoch 5 Batch 865 Loss 1.0746\n",
      "Epoch 5 Batch 866 Loss 0.8653\n",
      "Epoch 5 Batch 867 Loss 1.3361\n",
      "Epoch 5 Batch 868 Loss 1.0605\n",
      "Epoch 5 Batch 869 Loss 0.9844\n",
      "Epoch 5 Batch 870 Loss 1.1068\n",
      "Epoch 5 Batch 871 Loss 1.0073\n",
      "Epoch 5 Batch 872 Loss 1.0218\n",
      "Epoch 5 Batch 873 Loss 1.0741\n",
      "Epoch 5 Batch 874 Loss 1.0451\n",
      "Epoch 5 Batch 875 Loss 1.3527\n",
      "Epoch 5 Batch 876 Loss 1.3440\n",
      "Epoch 5 Batch 877 Loss 1.3385\n",
      "Epoch 5 Batch 878 Loss 1.3658\n",
      "Epoch 5 Batch 879 Loss 1.0503\n",
      "Epoch 5 Batch 880 Loss 1.3649\n",
      "Epoch 5 Batch 881 Loss 0.9442\n",
      "Epoch 5 Batch 882 Loss 1.0657\n",
      "Epoch 5 Batch 883 Loss 0.9387\n",
      "Epoch 5 Batch 884 Loss 1.0824\n",
      "Epoch 5 Batch 885 Loss 1.1212\n",
      "Epoch 5 Batch 886 Loss 1.5902\n",
      "Epoch 5 Batch 887 Loss 0.9424\n",
      "Epoch 5 Batch 888 Loss 0.8681\n",
      "Epoch 5 Batch 889 Loss 1.2216\n",
      "Epoch 5 Batch 890 Loss 1.1800\n",
      "Epoch 5 Batch 891 Loss 1.3990\n",
      "Epoch 5 Batch 892 Loss 1.2426\n",
      "Epoch 5 Batch 893 Loss 1.0659\n",
      "Epoch 5 Batch 894 Loss 0.9355\n",
      "Epoch 5 Batch 895 Loss 1.1071\n",
      "Epoch 5 Batch 896 Loss 1.2534\n",
      "Epoch 5 Batch 897 Loss 1.2610\n",
      "Epoch 5 Batch 898 Loss 1.3210\n",
      "Epoch 5 Batch 899 Loss 0.9470\n",
      "Epoch 5 Batch 900 Loss 0.8446\n",
      "Epoch 5 Batch 901 Loss 0.8976\n",
      "Epoch 5 Batch 902 Loss 1.3107\n",
      "Epoch 5 Batch 903 Loss 1.2656\n",
      "Epoch 5 Batch 904 Loss 1.1686\n",
      "Epoch 5 Batch 905 Loss 1.2881\n",
      "Epoch 5 Batch 906 Loss 0.9046\n",
      "Epoch 5 Batch 907 Loss 1.1155\n",
      "Epoch 5 Batch 908 Loss 1.3769\n",
      "Epoch 5 Batch 909 Loss 0.8473\n",
      "Epoch 5 Batch 910 Loss 1.0750\n",
      "Epoch 5 Batch 911 Loss 1.2020\n",
      "Epoch 5 Batch 912 Loss 1.2772\n",
      "Epoch 5 Batch 913 Loss 1.0500\n",
      "Epoch 5 Batch 914 Loss 1.1296\n",
      "Epoch 5 Batch 915 Loss 1.0961\n",
      "Epoch 5 Batch 916 Loss 1.2754\n",
      "Epoch 5 Batch 917 Loss 1.1438\n",
      "Epoch 5 Batch 918 Loss 1.1603\n",
      "Epoch 5 Batch 919 Loss 0.9211\n",
      "Epoch 5 Batch 920 Loss 1.0834\n",
      "Epoch 5 Batch 921 Loss 1.1075\n",
      "Epoch 5 Batch 922 Loss 1.1535\n",
      "Epoch 5 Batch 923 Loss 0.9355\n",
      "Epoch 5 Batch 924 Loss 0.8731\n",
      "Epoch 5 Batch 925 Loss 1.0540\n",
      "Epoch 5 Batch 926 Loss 1.0277\n",
      "Epoch 5 Batch 927 Loss 1.2517\n",
      "Epoch 5 Batch 928 Loss 1.3164\n",
      "Epoch 5 Batch 929 Loss 1.0015\n",
      "Epoch 5 Batch 930 Loss 1.1237\n",
      "Epoch 5 Batch 931 Loss 1.1859\n",
      "Epoch 5 Batch 932 Loss 0.8001\n",
      "Epoch 5 Batch 933 Loss 1.2692\n",
      "Epoch 5 Batch 934 Loss 1.0711\n",
      "Epoch 5 Batch 935 Loss 0.8884\n",
      "Epoch 5 Batch 936 Loss 0.9860\n",
      "Epoch 5 Batch 937 Loss 1.2389\n",
      "Epoch 5 Batch 938 Loss 1.5324\n",
      "Epoch 5 Batch 939 Loss 1.0372\n",
      "Epoch 5 Batch 940 Loss 1.3289\n",
      "Epoch 5 Batch 941 Loss 1.1546\n",
      "Epoch 5 Batch 942 Loss 1.0507\n",
      "Epoch 5 Batch 943 Loss 1.1996\n",
      "Epoch 5 Batch 944 Loss 1.1054\n",
      "Epoch 5 Batch 945 Loss 1.3176\n",
      "Epoch 5 Batch 946 Loss 1.0626\n",
      "Epoch 5 Batch 947 Loss 0.9351\n",
      "Epoch 5 Batch 948 Loss 0.9964\n",
      "Epoch 5 Batch 949 Loss 1.3720\n",
      "Epoch 5 Batch 950 Loss 1.0240\n",
      "Epoch 5 Batch 951 Loss 1.0002\n",
      "Epoch 5 Batch 952 Loss 1.1073\n",
      "Epoch 5 Batch 953 Loss 1.1413\n",
      "Epoch 5 Batch 954 Loss 0.8629\n",
      "Epoch 5 Batch 955 Loss 1.0975\n",
      "Epoch 5 Batch 956 Loss 1.2072\n",
      "Epoch 5 Batch 957 Loss 1.1792\n",
      "Epoch 5 Batch 958 Loss 1.1645\n",
      "Epoch 5 Batch 959 Loss 0.9601\n",
      "Epoch 5 Batch 960 Loss 0.9538\n",
      "Epoch 5 Batch 961 Loss 1.0667\n",
      "Epoch 5 Batch 962 Loss 1.0819\n",
      "Epoch 5 Batch 963 Loss 1.0311\n",
      "Epoch 5 Batch 964 Loss 1.3016\n",
      "Epoch 5 Batch 965 Loss 0.9400\n",
      "Epoch 5 Batch 966 Loss 1.3188\n",
      "Epoch 5 Batch 967 Loss 1.1186\n",
      "Epoch 5 Batch 968 Loss 1.0272\n",
      "Epoch 5 Batch 969 Loss 0.8465\n",
      "Epoch 5 Batch 970 Loss 0.8273\n",
      "Epoch 5 Batch 971 Loss 1.2312\n",
      "Epoch 5 Batch 972 Loss 1.3472\n",
      "Epoch 5 Batch 973 Loss 1.0572\n",
      "Epoch 5 Batch 974 Loss 1.0439\n",
      "Epoch 5 Batch 975 Loss 1.2656\n",
      "Epoch 5 Batch 976 Loss 1.0319\n",
      "Epoch 5 Batch 977 Loss 1.3058\n",
      "Epoch 5 Batch 978 Loss 1.1448\n",
      "Epoch 5 Batch 979 Loss 0.8268\n",
      "Epoch 5 Batch 980 Loss 1.0666\n",
      "Epoch 5 Batch 981 Loss 1.3183\n",
      "Epoch 5 Batch 982 Loss 1.0724\n",
      "Epoch 5 Batch 983 Loss 1.3667\n",
      "Epoch 5 Batch 984 Loss 1.4219\n",
      "Epoch 5 Batch 985 Loss 1.1894\n",
      "Epoch 5 Batch 986 Loss 1.2784\n",
      "Epoch 5 Batch 987 Loss 1.4067\n",
      "Epoch 5 Batch 988 Loss 1.0185\n",
      "Epoch 5 Batch 989 Loss 1.2024\n",
      "Epoch 5 Batch 990 Loss 1.4422\n",
      "Epoch 5 Batch 991 Loss 1.0015\n",
      "Epoch 5 Batch 992 Loss 1.1467\n",
      "Epoch 5 Batch 993 Loss 1.0875\n",
      "Epoch 5 Batch 994 Loss 1.3534\n",
      "Epoch 5 Batch 995 Loss 1.0967\n",
      "Epoch 5 Batch 996 Loss 1.5270\n",
      "Epoch 5 Batch 997 Loss 1.0108\n",
      "Epoch 5 Batch 998 Loss 1.0352\n",
      "Epoch 5 Batch 999 Loss 1.1187\n",
      "Epoch 5 Batch 1000 Loss 1.0866\n",
      "Epoch 5 Batch 1001 Loss 1.2356\n",
      "Epoch 5 Batch 1002 Loss 1.3037\n",
      "Epoch 5 Batch 1003 Loss 1.2605\n",
      "Epoch 5 Batch 1004 Loss 0.9467\n",
      "Epoch 5 Batch 1005 Loss 1.0240\n",
      "Epoch 5 Batch 1006 Loss 0.9623\n",
      "Epoch 5 Batch 1007 Loss 1.1157\n",
      "Epoch 5 Batch 1008 Loss 1.4496\n",
      "Epoch 5 Batch 1009 Loss 1.1573\n",
      "Epoch 5 Batch 1010 Loss 0.9869\n",
      "Epoch 5 Batch 1011 Loss 1.5313\n",
      "Epoch 5 Batch 1012 Loss 0.8785\n",
      "Epoch 5 Batch 1013 Loss 1.1002\n",
      "Epoch 5 Batch 1014 Loss 1.1393\n",
      "Epoch 5 Batch 1015 Loss 1.2891\n",
      "Epoch 5 Batch 1016 Loss 1.2203\n",
      "Epoch 5 Batch 1017 Loss 1.1517\n",
      "Epoch 5 Batch 1018 Loss 1.1109\n",
      "Epoch 5 Batch 1019 Loss 1.1999\n",
      "Epoch 5 Batch 1020 Loss 0.9638\n",
      "Epoch 5 Batch 1021 Loss 1.0705\n",
      "Epoch 5 Batch 1022 Loss 0.9755\n",
      "Epoch 5 Batch 1023 Loss 1.2479\n",
      "Epoch 5 Batch 1024 Loss 1.1470\n",
      "Epoch 5 Batch 1025 Loss 1.0591\n",
      "Epoch 5 Batch 1026 Loss 1.0811\n",
      "Epoch 5 Batch 1027 Loss 0.9459\n",
      "Epoch 5 Batch 1028 Loss 0.9950\n",
      "Epoch 5 Batch 1029 Loss 1.0695\n",
      "Epoch 5 Batch 1030 Loss 1.1622\n",
      "Epoch 5 Batch 1031 Loss 1.2470\n",
      "Epoch 5 Batch 1032 Loss 0.9261\n",
      "Epoch 5 Batch 1033 Loss 1.2434\n",
      "Epoch 5 Batch 1034 Loss 1.1236\n",
      "Epoch 5 Batch 1035 Loss 1.4494\n",
      "Epoch 5 Batch 1036 Loss 1.2757\n",
      "Epoch 5 Batch 1037 Loss 1.0569\n",
      "Epoch 5 Batch 1038 Loss 1.1645\n",
      "Epoch 5 Batch 1039 Loss 1.1034\n",
      "Epoch 5 Batch 1040 Loss 1.1926\n",
      "Epoch 5 Batch 1041 Loss 0.9331\n",
      "Epoch 5 Batch 1042 Loss 1.2757\n",
      "Epoch 5 Batch 1043 Loss 1.1745\n",
      "Epoch 5 Batch 1044 Loss 1.2051\n",
      "Epoch 5 Batch 1045 Loss 0.9460\n",
      "Epoch 5 Batch 1046 Loss 1.0568\n",
      "Epoch 5 Batch 1047 Loss 0.9593\n",
      "Epoch 5 Batch 1048 Loss 1.1542\n",
      "Epoch 5 Batch 1049 Loss 0.7602\n",
      "Epoch 5 Batch 1050 Loss 1.0736\n",
      "Epoch 5 Batch 1051 Loss 1.2658\n",
      "Epoch 5 Batch 1052 Loss 0.9675\n",
      "Epoch 5 Batch 1053 Loss 1.1404\n",
      "Epoch 5 Batch 1054 Loss 1.2456\n",
      "Epoch 5 Batch 1055 Loss 1.0130\n",
      "Epoch 5 Batch 1056 Loss 0.8121\n",
      "Epoch 5 Batch 1057 Loss 1.0440\n",
      "Epoch 5 Batch 1058 Loss 0.9419\n",
      "Epoch 5 Batch 1059 Loss 1.2526\n",
      "Epoch 5 Batch 1060 Loss 1.2418\n",
      "Epoch 5 Batch 1061 Loss 1.1223\n",
      "Epoch 5 Batch 1062 Loss 1.4630\n",
      "Epoch 5 Batch 1063 Loss 1.0619\n",
      "Epoch 5 Batch 1064 Loss 1.3026\n",
      "Epoch 5 Batch 1065 Loss 1.0501\n",
      "Epoch 5 Batch 1066 Loss 1.5348\n",
      "Epoch 5 Batch 1067 Loss 1.3489\n",
      "Epoch 5 Batch 1068 Loss 1.0123\n",
      "Epoch 5 Batch 1069 Loss 1.0452\n",
      "Epoch 5 Batch 1070 Loss 1.1910\n",
      "Epoch 5 Batch 1071 Loss 1.1406\n",
      "Epoch 5 Batch 1072 Loss 1.0519\n",
      "Epoch 5 Batch 1073 Loss 1.1411\n",
      "Epoch 5 Batch 1074 Loss 1.1119\n",
      "Epoch 5 Batch 1075 Loss 1.1121\n",
      "Epoch 5 Batch 1076 Loss 1.4122\n",
      "Epoch 5 Batch 1077 Loss 1.0249\n",
      "Epoch 5 Batch 1078 Loss 1.1410\n",
      "Epoch 5 Batch 1079 Loss 1.0039\n",
      "Epoch 5 Batch 1080 Loss 1.1442\n",
      "Epoch 5 Batch 1081 Loss 0.9579\n",
      "Epoch 5 Batch 1082 Loss 1.2693\n",
      "Epoch 5 Batch 1083 Loss 1.2038\n",
      "Epoch 5 Batch 1084 Loss 0.9871\n",
      "Epoch 5 Batch 1085 Loss 1.0556\n",
      "Epoch 5 Batch 1086 Loss 0.9581\n",
      "Epoch 5 Batch 1087 Loss 1.2909\n",
      "Epoch 5 Batch 1088 Loss 1.0501\n",
      "Epoch 5 Batch 1089 Loss 1.0363\n",
      "Epoch 5 Batch 1090 Loss 1.2417\n",
      "Epoch 5 Batch 1091 Loss 1.1872\n",
      "Epoch 5 Batch 1092 Loss 1.0090\n",
      "Epoch 5 Batch 1093 Loss 1.3582\n",
      "Epoch 5 Batch 1094 Loss 1.1905\n",
      "Epoch 5 Batch 1095 Loss 1.0818\n",
      "Epoch 5 Batch 1096 Loss 1.0825\n",
      "Epoch 5 Batch 1097 Loss 1.1928\n",
      "Epoch 5 Batch 1098 Loss 1.3164\n",
      "Epoch 5 Batch 1099 Loss 1.1263\n",
      "Epoch 5 Batch 1100 Loss 1.1334\n",
      "Epoch 5 Batch 1101 Loss 1.3747\n",
      "Epoch 5 Batch 1102 Loss 0.9691\n",
      "Epoch 5 Batch 1103 Loss 1.2891\n",
      "Epoch 5 Batch 1104 Loss 1.0316\n",
      "Epoch 5 Batch 1105 Loss 0.8661\n",
      "Epoch 5 Batch 1106 Loss 1.2250\n",
      "Epoch 5 Batch 1107 Loss 1.2523\n",
      "Epoch 5 Batch 1108 Loss 0.9420\n",
      "Epoch 5 Batch 1109 Loss 1.1602\n",
      "Epoch 5 Batch 1110 Loss 1.0593\n",
      "Epoch 5 Batch 1111 Loss 1.2420\n",
      "Epoch 5 Batch 1112 Loss 0.9217\n",
      "Epoch 5 Batch 1113 Loss 1.1834\n",
      "Epoch 5 Batch 1114 Loss 0.9129\n",
      "Epoch 5 Batch 1115 Loss 1.2404\n",
      "Epoch 5 Batch 1116 Loss 0.9613\n",
      "Epoch 5 Batch 1117 Loss 1.2888\n",
      "Epoch 5 Batch 1118 Loss 1.4682\n",
      "Epoch 5 Batch 1119 Loss 0.7399\n",
      "Epoch 5 Batch 1120 Loss 1.0412\n",
      "Epoch 5 Batch 1121 Loss 1.4591\n",
      "Epoch 5 Batch 1122 Loss 0.9229\n",
      "Epoch 5 Batch 1123 Loss 0.9101\n",
      "Epoch 5 Batch 1124 Loss 0.9540\n",
      "Epoch 5 Batch 1125 Loss 0.8739\n",
      "Epoch 5 Batch 1126 Loss 1.3545\n",
      "Epoch 5 Batch 1127 Loss 0.9418\n",
      "Epoch 5 Batch 1128 Loss 1.1155\n",
      "Epoch 5 Batch 1129 Loss 1.0962\n",
      "Epoch 5 Batch 1130 Loss 1.2013\n",
      "Epoch 5 Batch 1131 Loss 0.9131\n",
      "Epoch 5 Batch 1132 Loss 1.0462\n",
      "Epoch 5 Batch 1133 Loss 0.9731\n",
      "Epoch 5 Batch 1134 Loss 0.9964\n",
      "Epoch 5 Batch 1135 Loss 1.1688\n",
      "Epoch 5 Batch 1136 Loss 1.2711\n",
      "Epoch 5 Batch 1137 Loss 1.2834\n",
      "Epoch 5 Batch 1138 Loss 1.1826\n",
      "Epoch 5 Batch 1139 Loss 1.0358\n",
      "Epoch 5 Batch 1140 Loss 1.3368\n",
      "Epoch 5 Batch 1141 Loss 1.2001\n",
      "Epoch 5 Batch 1142 Loss 1.0009\n",
      "Epoch 5 Batch 1143 Loss 1.3950\n",
      "Epoch 5 Batch 1144 Loss 1.2803\n",
      "Epoch 5 Batch 1145 Loss 0.9575\n",
      "Epoch 5 Batch 1146 Loss 1.2605\n",
      "Epoch 5 Batch 1147 Loss 1.0154\n",
      "Epoch 5 Batch 1148 Loss 1.1478\n",
      "Epoch 5 Batch 1149 Loss 1.2913\n",
      "Epoch 5 Batch 1150 Loss 1.1397\n",
      "Epoch 5 Batch 1151 Loss 1.4997\n",
      "Epoch 5 Batch 1152 Loss 1.2047\n",
      "Epoch 5 Batch 1153 Loss 0.9094\n",
      "Epoch 5 Batch 1154 Loss 1.0967\n",
      "Epoch 5 Batch 1155 Loss 0.9904\n",
      "Epoch 5 Batch 1156 Loss 1.1152\n",
      "Epoch 5 Batch 1157 Loss 1.2551\n",
      "Epoch 5 Batch 1158 Loss 1.0996\n",
      "Epoch 5 Batch 1159 Loss 1.1624\n",
      "Epoch 5 Batch 1160 Loss 1.1015\n",
      "Epoch 5 Batch 1161 Loss 1.0483\n",
      "Epoch 5 Batch 1162 Loss 1.0913\n",
      "Epoch 5 Batch 1163 Loss 1.0031\n",
      "Epoch 5 Batch 1164 Loss 1.0616\n",
      "Epoch 5 Batch 1165 Loss 0.9752\n",
      "Epoch 5 Batch 1166 Loss 1.0891\n",
      "Epoch 5 Batch 1167 Loss 1.0842\n",
      "Epoch 5 Batch 1168 Loss 1.4164\n",
      "Epoch 5 Batch 1169 Loss 1.2121\n",
      "Epoch 5 Batch 1170 Loss 0.8588\n",
      "Epoch 5 Batch 1171 Loss 1.1718\n",
      "Epoch 5 Batch 1172 Loss 1.0331\n",
      "Epoch 5 Batch 1173 Loss 1.2866\n",
      "Epoch 5 Batch 1174 Loss 1.1387\n",
      "Epoch 5 Batch 1175 Loss 1.1613\n",
      "Epoch 5 Batch 1176 Loss 1.1697\n",
      "Epoch 5 Batch 1177 Loss 1.0494\n",
      "Epoch 5 Batch 1178 Loss 1.0824\n",
      "Epoch 5 Batch 1179 Loss 0.9300\n",
      "Epoch 5 Batch 1180 Loss 1.0580\n",
      "Epoch 5 Batch 1181 Loss 0.9441\n",
      "Epoch 5 Batch 1182 Loss 1.2046\n",
      "Epoch 5 Batch 1183 Loss 1.1242\n",
      "Epoch 5 Batch 1184 Loss 1.1209\n",
      "Epoch 5 Batch 1185 Loss 1.1367\n",
      "Epoch 5 Batch 1186 Loss 1.3212\n",
      "Epoch 5 Batch 1187 Loss 0.9181\n",
      "Epoch 5 Batch 1188 Loss 1.4671\n",
      "Epoch 5 Batch 1189 Loss 1.0046\n",
      "Epoch 5 Batch 1190 Loss 1.2723\n",
      "Epoch 5 Batch 1191 Loss 0.9696\n",
      "Epoch 5 Batch 1192 Loss 1.2654\n",
      "Epoch 5 Batch 1193 Loss 1.2768\n",
      "Epoch 5 Batch 1194 Loss 1.0764\n",
      "Epoch 5 Batch 1195 Loss 1.2896\n",
      "Epoch 5 Batch 1196 Loss 1.3865\n",
      "Epoch 5 Batch 1197 Loss 1.1843\n",
      "Epoch 5 Batch 1198 Loss 0.9656\n",
      "Epoch 5 Batch 1199 Loss 1.0373\n",
      "Epoch 5 Batch 1200 Loss 1.1942\n",
      "Epoch 5 Batch 1201 Loss 1.0981\n",
      "Epoch 5 Batch 1202 Loss 0.9115\n",
      "Epoch 5 Batch 1203 Loss 0.9305\n",
      "Epoch 5 Batch 1204 Loss 1.1896\n",
      "Epoch 5 Batch 1205 Loss 1.1761\n",
      "Epoch 5 Batch 1206 Loss 0.8285\n",
      "Epoch 5 Batch 1207 Loss 1.2101\n",
      "Epoch 5 Batch 1208 Loss 0.9040\n",
      "Epoch 5 Batch 1209 Loss 1.2186\n",
      "Epoch 5 Batch 1210 Loss 1.0064\n",
      "Epoch 5 Batch 1211 Loss 0.9495\n",
      "Epoch 5 Batch 1212 Loss 1.0956\n",
      "Epoch 5 Batch 1213 Loss 1.3026\n",
      "Epoch 5 Batch 1214 Loss 1.2981\n",
      "Epoch 5 Batch 1215 Loss 1.2077\n",
      "Epoch 5 Batch 1216 Loss 1.3872\n",
      "Epoch 5 Batch 1217 Loss 1.4471\n",
      "Epoch 5 Batch 1218 Loss 1.1134\n",
      "Epoch 5 Batch 1219 Loss 1.2928\n",
      "Epoch 5 Batch 1220 Loss 1.2786\n",
      "Epoch 5 Batch 1221 Loss 0.7689\n",
      "Epoch 5 Batch 1222 Loss 1.3564\n",
      "Epoch 5 Batch 1223 Loss 1.3128\n",
      "Epoch 5 Batch 1224 Loss 1.3171\n",
      "Epoch 5 Batch 1225 Loss 1.0718\n",
      "Epoch 5 Batch 1226 Loss 1.0624\n",
      "Epoch 5 Batch 1227 Loss 1.1303\n",
      "Epoch 5 Batch 1228 Loss 0.8931\n",
      "Epoch 5 Batch 1229 Loss 1.0674\n",
      "Epoch 5 Batch 1230 Loss 1.2348\n",
      "Epoch 5 Batch 1231 Loss 1.2355\n",
      "Epoch 5 Batch 1232 Loss 1.1481\n",
      "Epoch 5 Batch 1233 Loss 1.1228\n",
      "Epoch 5 Batch 1234 Loss 1.1489\n",
      "Epoch 5 Batch 1235 Loss 1.0968\n",
      "Epoch 5 Batch 1236 Loss 1.0437\n",
      "Epoch 5 Batch 1237 Loss 1.1416\n",
      "Epoch 5 Batch 1238 Loss 1.1982\n",
      "Epoch 5 Batch 1239 Loss 0.9018\n",
      "Epoch 5 Batch 1240 Loss 1.0120\n",
      "Epoch 5 Batch 1241 Loss 1.0470\n",
      "Epoch 5 Batch 1242 Loss 1.1949\n",
      "Epoch 5 Batch 1243 Loss 1.2195\n",
      "Epoch 5 Batch 1244 Loss 1.1403\n",
      "Epoch 5 Batch 1245 Loss 1.1668\n",
      "Epoch 5 Batch 1246 Loss 1.2396\n",
      "Epoch 5 Batch 1247 Loss 1.0034\n",
      "Epoch 5 Batch 1248 Loss 1.1367\n",
      "Epoch 5 Batch 1249 Loss 1.1086\n",
      "Epoch 5 Batch 1250 Loss 1.0350\n",
      "Epoch 5 Batch 1251 Loss 0.8927\n",
      "Epoch 5 Batch 1252 Loss 0.8669\n",
      "Epoch 5 Batch 1253 Loss 1.3221\n",
      "Epoch 5 Batch 1254 Loss 0.8914\n",
      "Epoch 5 Batch 1255 Loss 1.1494\n",
      "Epoch 5 Batch 1256 Loss 0.9945\n",
      "Epoch 5 Batch 1257 Loss 0.9237\n",
      "Epoch 5 Batch 1258 Loss 1.4421\n",
      "Epoch 5 Batch 1259 Loss 0.9135\n",
      "Epoch 5 Batch 1260 Loss 1.1534\n",
      "Epoch 5 Batch 1261 Loss 1.3931\n",
      "Epoch 5 Batch 1262 Loss 1.1288\n",
      "Epoch 5 Batch 1263 Loss 0.9907\n",
      "Epoch 5 Batch 1264 Loss 1.3483\n",
      "Epoch 5 Batch 1265 Loss 1.1734\n",
      "Epoch 5 Batch 1266 Loss 0.9163\n",
      "Epoch 5 Batch 1267 Loss 1.1059\n",
      "Epoch 5 Batch 1268 Loss 0.8871\n",
      "Epoch 5 Batch 1269 Loss 0.9644\n",
      "Epoch 5 Batch 1270 Loss 1.0855\n",
      "Epoch 5 Batch 1271 Loss 1.2269\n",
      "Epoch 5 Batch 1272 Loss 1.4158\n",
      "Epoch 5 Batch 1273 Loss 1.2657\n",
      "Epoch 5 Batch 1274 Loss 1.0826\n",
      "Epoch 5 Batch 1275 Loss 1.0570\n",
      "Epoch 5 Batch 1276 Loss 1.2506\n",
      "Epoch 5 Batch 1277 Loss 0.8349\n",
      "Epoch 5 Batch 1278 Loss 1.1008\n",
      "Epoch 5 Batch 1279 Loss 1.1397\n",
      "Epoch 5 Batch 1280 Loss 1.2000\n",
      "Epoch 5 Batch 1281 Loss 1.1330\n",
      "Epoch 5 Batch 1282 Loss 1.1537\n",
      "Epoch 5 Batch 1283 Loss 1.1016\n",
      "Epoch 5 Batch 1284 Loss 1.0957\n",
      "Epoch 5 Batch 1285 Loss 1.5108\n",
      "Epoch 5 Batch 1286 Loss 1.2238\n",
      "Epoch 5 Batch 1287 Loss 1.1121\n",
      "Epoch 5 Batch 1288 Loss 1.0891\n",
      "Epoch 5 Batch 1289 Loss 1.3354\n",
      "Epoch 5 Batch 1290 Loss 1.2261\n",
      "Epoch 5 Batch 1291 Loss 1.2483\n",
      "Epoch 5 Batch 1292 Loss 1.0196\n",
      "Epoch 5 Batch 1293 Loss 1.0919\n",
      "Epoch 5 Batch 1294 Loss 1.4314\n",
      "Epoch 5 Batch 1295 Loss 1.0448\n",
      "Epoch 5 Batch 1296 Loss 0.8696\n",
      "Epoch 5 Batch 1297 Loss 1.4369\n",
      "Epoch 5 Batch 1298 Loss 1.2448\n",
      "Epoch 5 Batch 1299 Loss 1.0250\n",
      "Epoch 5 Batch 1300 Loss 0.8480\n",
      "Epoch 5 Batch 1301 Loss 0.7908\n",
      "Epoch 5 Batch 1302 Loss 1.3352\n",
      "Epoch 5 Batch 1303 Loss 1.0432\n",
      "Epoch 5 Batch 1304 Loss 1.2644\n",
      "Epoch 5 Batch 1305 Loss 1.2157\n",
      "Epoch 5 Batch 1306 Loss 1.2346\n",
      "Epoch 5 Batch 1307 Loss 1.0253\n",
      "Epoch 5 Batch 1308 Loss 1.1540\n",
      "Epoch 5 Batch 1309 Loss 0.9938\n",
      "Epoch 5 Batch 1310 Loss 1.1713\n",
      "Epoch 5 Batch 1311 Loss 1.3851\n",
      "Epoch 5 Batch 1312 Loss 1.2018\n",
      "Epoch 5 Batch 1313 Loss 1.0874\n",
      "Epoch 5 Batch 1314 Loss 1.1523\n",
      "Epoch 5 Batch 1315 Loss 1.1294\n",
      "Epoch 5 Batch 1316 Loss 1.2127\n",
      "Epoch 5 Batch 1317 Loss 0.8256\n",
      "Epoch 5 Batch 1318 Loss 0.8126\n",
      "Epoch 5 Batch 1319 Loss 1.1641\n",
      "Epoch 5 Batch 1320 Loss 1.0872\n",
      "Epoch 5 Batch 1321 Loss 0.9585\n",
      "Epoch 5 Batch 1322 Loss 1.0745\n",
      "Epoch 5 Batch 1323 Loss 1.1105\n",
      "Epoch 5 Batch 1324 Loss 1.6587\n",
      "Epoch 5 Batch 1325 Loss 1.0871\n",
      "Epoch 5 Batch 1326 Loss 1.4195\n",
      "Epoch 5 Batch 1327 Loss 1.2776\n",
      "Epoch 5 Batch 1328 Loss 1.0750\n",
      "Epoch 5 Batch 1329 Loss 1.1593\n",
      "Epoch 5 Batch 1330 Loss 1.2604\n",
      "Epoch 5 Batch 1331 Loss 1.3256\n",
      "Epoch 5 Batch 1332 Loss 1.2387\n",
      "Epoch 5 Batch 1333 Loss 1.2238\n",
      "Epoch 5 Batch 1334 Loss 0.9848\n",
      "Epoch 5 Batch 1335 Loss 0.9100\n",
      "Epoch 5 Batch 1336 Loss 1.1966\n",
      "Epoch 5 Batch 1337 Loss 1.3277\n",
      "Epoch 5 Batch 1338 Loss 1.2201\n",
      "Epoch 5 Batch 1339 Loss 1.2085\n",
      "Epoch 5 Batch 1340 Loss 0.9466\n",
      "Epoch 5 Batch 1341 Loss 1.1780\n",
      "Epoch 5 Batch 1342 Loss 1.1723\n",
      "Epoch 5 Batch 1343 Loss 1.1700\n",
      "Epoch 5 Batch 1344 Loss 1.3134\n",
      "Epoch 5 Batch 1345 Loss 1.1334\n",
      "Epoch 5 Batch 1346 Loss 1.1736\n",
      "Epoch 5 Batch 1347 Loss 1.4331\n",
      "Epoch 5 Batch 1348 Loss 1.3210\n",
      "Epoch 5 Batch 1349 Loss 1.3406\n",
      "Epoch 5 Batch 1350 Loss 0.9295\n",
      "Epoch 5 Batch 1351 Loss 1.2303\n",
      "Epoch 5 Batch 1352 Loss 1.1797\n",
      "Epoch 5 Batch 1353 Loss 1.1713\n",
      "Epoch 5 Batch 1354 Loss 1.0919\n",
      "Epoch 5 Batch 1355 Loss 1.1492\n",
      "Epoch 5 Batch 1356 Loss 1.0313\n",
      "Epoch 5 Batch 1357 Loss 1.1566\n",
      "Epoch 5 Batch 1358 Loss 1.2391\n",
      "Epoch 5 Batch 1359 Loss 1.3537\n",
      "Epoch 5 Batch 1360 Loss 1.2078\n",
      "Epoch 5 Batch 1361 Loss 1.1362\n",
      "Epoch 5 Batch 1362 Loss 1.2434\n",
      "Epoch 5 Batch 1363 Loss 0.9484\n",
      "Epoch 5 Batch 1364 Loss 1.2336\n",
      "Epoch 5 Batch 1365 Loss 1.0660\n",
      "Epoch 5 Batch 1366 Loss 1.1096\n",
      "Epoch 5 Batch 1367 Loss 0.9856\n",
      "Epoch 5 Batch 1368 Loss 1.2502\n",
      "Epoch 5 Batch 1369 Loss 0.8565\n",
      "Epoch 5 Batch 1370 Loss 1.0616\n",
      "Epoch 5 Batch 1371 Loss 1.4587\n",
      "Epoch 5 Batch 1372 Loss 1.1578\n",
      "Epoch 5 Batch 1373 Loss 1.2211\n",
      "Epoch 5 Batch 1374 Loss 1.2312\n",
      "Epoch 5 Batch 1375 Loss 1.0887\n",
      "Epoch 5 Batch 1376 Loss 1.0676\n",
      "Epoch 5 Batch 1377 Loss 1.0215\n",
      "Epoch 5 Batch 1378 Loss 0.9864\n",
      "Epoch 5 Batch 1379 Loss 1.1931\n",
      "Epoch 5 Batch 1380 Loss 1.1414\n",
      "Epoch 5 Batch 1381 Loss 1.0257\n",
      "Epoch 5 Batch 1382 Loss 1.1304\n",
      "Epoch 5 Batch 1383 Loss 1.5255\n",
      "Epoch 5 Batch 1384 Loss 1.0343\n",
      "Epoch 5 Batch 1385 Loss 1.0331\n",
      "Epoch 5 Batch 1386 Loss 1.2470\n",
      "Epoch 5 Batch 1387 Loss 1.1569\n",
      "Epoch 5 Batch 1388 Loss 0.9579\n",
      "Epoch 5 Batch 1389 Loss 1.0618\n",
      "Epoch 5 Batch 1390 Loss 1.0740\n",
      "Epoch 5 Batch 1391 Loss 1.0159\n",
      "Epoch 5 Batch 1392 Loss 0.9953\n",
      "Epoch 5 Batch 1393 Loss 1.1248\n",
      "Epoch 5 Batch 1394 Loss 0.9305\n",
      "Epoch 5 Batch 1395 Loss 1.2126\n",
      "Epoch 5 Batch 1396 Loss 1.1727\n",
      "Epoch 5 Batch 1397 Loss 1.0175\n",
      "Epoch 5 Batch 1398 Loss 0.9871\n",
      "Epoch 5 Batch 1399 Loss 1.4257\n",
      "Epoch 5 Batch 1400 Loss 1.5253\n",
      "Epoch 5 Batch 1401 Loss 0.9968\n",
      "Epoch 5 Batch 1402 Loss 1.2159\n",
      "Epoch 5 Batch 1403 Loss 1.1385\n",
      "Epoch 5 Batch 1404 Loss 1.1580\n",
      "Epoch 5 Batch 1405 Loss 1.4464\n",
      "Epoch 5 Batch 1406 Loss 1.4525\n",
      "Epoch 5 Batch 1407 Loss 1.2113\n",
      "Epoch 5 Batch 1408 Loss 1.2425\n",
      "Epoch 5 Batch 1409 Loss 1.0617\n",
      "Epoch 5 Batch 1410 Loss 1.3842\n",
      "Epoch 5 Batch 1411 Loss 1.2279\n",
      "Epoch 5 Batch 1412 Loss 0.7466\n",
      "Epoch 5 Batch 1413 Loss 1.1565\n",
      "Epoch 5 Batch 1414 Loss 1.1396\n",
      "Epoch 5 Batch 1415 Loss 1.3265\n",
      "Epoch 5 Batch 1416 Loss 1.2284\n",
      "Epoch 5 Batch 1417 Loss 1.3374\n",
      "Epoch 5 Batch 1418 Loss 1.0357\n",
      "Epoch 5 Batch 1419 Loss 0.9016\n",
      "Epoch 5 Batch 1420 Loss 1.1599\n",
      "Epoch 5 Batch 1421 Loss 1.0951\n",
      "Epoch 5 Batch 1422 Loss 1.3934\n",
      "Epoch 5 Batch 1423 Loss 0.8388\n",
      "Epoch 5 Batch 1424 Loss 1.0972\n",
      "Epoch 5 Batch 1425 Loss 1.1414\n",
      "Epoch 5 Batch 1426 Loss 1.2774\n",
      "Epoch 5 Batch 1427 Loss 1.3171\n",
      "Epoch 5 Batch 1428 Loss 1.2649\n",
      "Epoch 5 Batch 1429 Loss 1.3137\n",
      "Epoch 5 Batch 1430 Loss 1.0907\n",
      "Epoch 5 Batch 1431 Loss 1.2429\n",
      "Epoch 5 Batch 1432 Loss 1.0837\n",
      "Epoch 5 Batch 1433 Loss 1.0817\n",
      "Epoch 5 Batch 1434 Loss 1.1329\n",
      "Epoch 5 Batch 1435 Loss 1.0088\n",
      "Epoch 5 Batch 1436 Loss 1.0352\n",
      "Epoch 5 Batch 1437 Loss 1.2881\n",
      "Epoch 5 Batch 1438 Loss 1.1972\n",
      "Epoch 5 Batch 1439 Loss 1.0663\n",
      "Epoch 5 Batch 1440 Loss 1.1881\n",
      "Epoch 5 Batch 1441 Loss 1.1463\n",
      "Epoch 5 Batch 1442 Loss 1.2937\n",
      "Epoch 5 Batch 1443 Loss 1.2730\n",
      "Epoch 5 Batch 1444 Loss 0.9719\n",
      "Epoch 5 Batch 1445 Loss 1.1273\n",
      "Epoch 5 Batch 1446 Loss 1.3411\n",
      "Epoch 5 Batch 1447 Loss 1.0542\n",
      "Epoch 5 Batch 1448 Loss 1.0686\n",
      "Epoch 5 Batch 1449 Loss 1.2329\n",
      "Epoch 5 Batch 1450 Loss 1.4060\n",
      "Epoch 5 Batch 1451 Loss 0.9022\n",
      "Epoch 5 Batch 1452 Loss 1.4019\n",
      "Epoch 5 Batch 1453 Loss 1.3992\n",
      "Epoch 5 Batch 1454 Loss 1.2723\n",
      "Epoch 5 Batch 1455 Loss 1.1049\n",
      "Epoch 5 Batch 1456 Loss 0.9760\n",
      "Epoch 5 Batch 1457 Loss 1.0012\n",
      "Epoch 5 Batch 1458 Loss 1.3950\n",
      "Epoch 5 Batch 1459 Loss 1.3072\n",
      "Epoch 5 Batch 1460 Loss 1.0204\n",
      "Epoch 5 Batch 1461 Loss 1.2324\n",
      "Epoch 5 Batch 1462 Loss 1.4761\n",
      "Epoch 5 Batch 1463 Loss 1.0167\n",
      "Epoch 5 Batch 1464 Loss 0.8647\n",
      "Epoch 5 Batch 1465 Loss 0.9782\n",
      "Epoch 5 Batch 1466 Loss 1.1189\n",
      "Epoch 5 Batch 1467 Loss 1.2363\n",
      "Epoch 5 Batch 1468 Loss 1.1536\n",
      "Epoch 5 Batch 1469 Loss 1.3724\n",
      "Epoch 5 Batch 1470 Loss 0.9809\n",
      "Epoch 5 Batch 1471 Loss 1.1055\n",
      "Epoch 5 Batch 1472 Loss 1.4169\n",
      "Epoch 5 Batch 1473 Loss 0.9901\n",
      "Epoch 5 Batch 1474 Loss 1.2318\n",
      "Epoch 5 Batch 1475 Loss 0.9660\n",
      "Epoch 5 Batch 1476 Loss 1.2395\n",
      "Epoch 5 Batch 1477 Loss 1.1761\n",
      "Epoch 5 Batch 1478 Loss 1.1057\n",
      "Epoch 5 Batch 1479 Loss 1.0507\n",
      "Epoch 5 Batch 1480 Loss 1.0880\n",
      "Epoch 5 Batch 1481 Loss 1.5428\n",
      "Epoch 5 Batch 1482 Loss 1.2610\n",
      "Epoch 5 Batch 1483 Loss 1.3669\n",
      "Epoch 5 Batch 1484 Loss 1.0031\n",
      "Epoch 5 Batch 1485 Loss 1.4312\n",
      "Epoch 5 Batch 1486 Loss 1.2184\n",
      "Epoch 5 Batch 1487 Loss 0.9334\n",
      "Epoch 5 Batch 1488 Loss 1.2070\n",
      "Epoch 5 Batch 1489 Loss 1.1630\n",
      "Epoch 5 Batch 1490 Loss 1.1761\n",
      "Epoch 5 Batch 1491 Loss 1.0261\n",
      "Epoch 5 Batch 1492 Loss 1.1818\n",
      "Epoch 5 Batch 1493 Loss 1.4017\n",
      "Epoch 5 Batch 1494 Loss 1.1022\n",
      "Epoch 5 Batch 1495 Loss 1.2669\n",
      "Epoch 5 Batch 1496 Loss 1.3905\n",
      "Epoch 5 Batch 1497 Loss 1.1477\n",
      "Epoch 5 Batch 1498 Loss 1.4496\n",
      "Epoch 5 Batch 1499 Loss 0.8109\n",
      "Epoch 5 Batch 1500 Loss 1.0412\n",
      "Epoch 5 Batch 1501 Loss 1.1644\n",
      "Epoch 5 Batch 1502 Loss 1.1296\n",
      "Epoch 5 Batch 1503 Loss 1.2363\n",
      "Epoch 5 Batch 1504 Loss 1.1688\n",
      "Epoch 5 Batch 1505 Loss 0.9099\n",
      "Epoch 5 Batch 1506 Loss 1.4494\n",
      "Epoch 5 Batch 1507 Loss 1.0289\n",
      "Epoch 5 Batch 1508 Loss 1.0813\n",
      "Epoch 5 Batch 1509 Loss 0.9511\n",
      "Epoch 5 Batch 1510 Loss 1.1790\n",
      "Epoch 5 Batch 1511 Loss 1.2398\n",
      "Epoch 5 Batch 1512 Loss 1.1436\n",
      "Epoch 5 Batch 1513 Loss 1.2216\n",
      "Epoch 5 Batch 1514 Loss 1.1160\n",
      "Epoch 5 Batch 1515 Loss 1.4045\n",
      "Epoch 5 Batch 1516 Loss 1.1614\n",
      "Epoch 5 Batch 1517 Loss 1.0692\n",
      "Epoch 5 Batch 1518 Loss 1.1354\n",
      "Epoch 5 Batch 1519 Loss 1.0544\n",
      "Epoch 5 Batch 1520 Loss 1.0972\n",
      "Epoch 5 Batch 1521 Loss 1.0527\n",
      "Epoch 5 Batch 1522 Loss 1.2235\n",
      "Epoch 5 Batch 1523 Loss 0.9424\n",
      "Epoch 5 Batch 1524 Loss 1.0408\n",
      "Epoch 5 Batch 1525 Loss 1.3386\n",
      "Epoch 5 Batch 1526 Loss 0.8879\n",
      "Epoch 5 Batch 1527 Loss 1.0232\n",
      "Epoch 5 Batch 1528 Loss 1.1532\n",
      "Epoch 5 Batch 1529 Loss 1.1508\n",
      "Epoch 5 Batch 1530 Loss 1.0593\n",
      "Epoch 5 Batch 1531 Loss 1.3156\n",
      "Epoch 5 Batch 1532 Loss 1.0906\n",
      "Epoch 5 Batch 1533 Loss 1.2942\n",
      "Epoch 5 Batch 1534 Loss 1.0940\n",
      "Epoch 5 Batch 1535 Loss 1.1159\n",
      "Epoch 5 Batch 1536 Loss 1.0531\n",
      "Epoch 5 Batch 1537 Loss 1.1127\n",
      "Epoch 5 Batch 1538 Loss 0.9276\n",
      "Epoch 5 Batch 1539 Loss 1.1648\n",
      "Epoch 5 Batch 1540 Loss 1.1608\n",
      "Epoch 5 Batch 1541 Loss 1.2429\n",
      "Epoch 5 Batch 1542 Loss 1.1177\n",
      "Epoch 5 Batch 1543 Loss 1.2969\n",
      "Epoch 5 Batch 1544 Loss 0.8705\n",
      "Epoch 5 Batch 1545 Loss 1.0186\n",
      "Epoch 5 Batch 1546 Loss 1.1381\n",
      "Epoch 5 Batch 1547 Loss 1.2543\n",
      "Epoch 5 Batch 1548 Loss 1.1849\n",
      "Epoch 5 Batch 1549 Loss 1.3193\n",
      "Epoch 5 Batch 1550 Loss 1.0900\n",
      "Epoch 5 Batch 1551 Loss 1.4420\n",
      "Epoch 5 Batch 1552 Loss 1.1252\n",
      "Epoch 5 Batch 1553 Loss 1.1735\n",
      "Epoch 5 Batch 1554 Loss 0.9789\n",
      "Epoch 5 Batch 1555 Loss 1.2945\n",
      "Epoch 5 Batch 1556 Loss 1.2385\n",
      "Epoch 5 Batch 1557 Loss 1.2735\n",
      "Epoch 5 Batch 1558 Loss 0.9776\n",
      "Epoch 5 Batch 1559 Loss 1.1868\n",
      "Epoch 5 Batch 1560 Loss 1.1907\n",
      "Epoch 5 Batch 1561 Loss 1.0649\n",
      "Epoch 5 Batch 1562 Loss 1.0970\n",
      "Epoch 5 Batch 1563 Loss 1.1896\n",
      "Epoch 5 Batch 1564 Loss 1.2941\n",
      "Epoch 5 Batch 1565 Loss 0.9326\n",
      "Epoch 5 Batch 1566 Loss 0.9728\n",
      "Epoch 5 Batch 1567 Loss 1.0455\n",
      "Epoch 5 Batch 1568 Loss 1.1631\n",
      "Epoch 5 Batch 1569 Loss 1.1510\n",
      "Epoch 5 Batch 1570 Loss 1.1238\n",
      "Epoch 5 Batch 1571 Loss 1.0850\n",
      "Epoch 5 Batch 1572 Loss 1.0482\n",
      "Epoch 5 Batch 1573 Loss 1.2772\n",
      "Epoch 5 Batch 1574 Loss 1.0838\n",
      "Epoch 5 Batch 1575 Loss 1.4598\n",
      "Epoch 5 Batch 1576 Loss 0.9970\n",
      "Epoch 5 Batch 1577 Loss 1.2163\n",
      "Epoch 5 Batch 1578 Loss 1.2817\n",
      "Epoch 5 Batch 1579 Loss 1.1441\n",
      "Epoch 5 Batch 1580 Loss 1.3005\n",
      "Epoch 5 Batch 1581 Loss 1.1595\n",
      "Epoch 5 Batch 1582 Loss 1.3720\n",
      "Epoch 5 Batch 1583 Loss 1.4914\n",
      "Epoch 5 Batch 1584 Loss 1.2436\n",
      "Epoch 5 Batch 1585 Loss 1.3933\n",
      "Epoch 5 Batch 1586 Loss 1.2807\n",
      "Epoch 5 Batch 1587 Loss 1.3790\n",
      "Epoch 5 Batch 1588 Loss 1.1307\n",
      "Epoch 5 Batch 1589 Loss 1.4746\n",
      "Epoch 5 Batch 1590 Loss 1.0138\n",
      "Epoch 5 Batch 1591 Loss 1.3311\n",
      "Epoch 5 Batch 1592 Loss 1.3406\n",
      "Epoch 5 Batch 1593 Loss 1.3335\n",
      "Epoch 5 Batch 1594 Loss 1.2149\n",
      "Epoch 5 Batch 1595 Loss 1.7102\n",
      "Epoch 5 Batch 1596 Loss 1.2130\n",
      "Epoch 5 Batch 1597 Loss 0.9864\n",
      "Epoch 5 Batch 1598 Loss 1.2579\n",
      "Epoch 5 Batch 1599 Loss 1.3342\n",
      "Epoch 5 Batch 1600 Loss 1.1396\n",
      "Epoch 5 Batch 1601 Loss 1.1703\n",
      "Epoch 5 Batch 1602 Loss 1.3294\n",
      "Epoch 5 Batch 1603 Loss 1.1654\n",
      "Epoch 5 Batch 1604 Loss 1.0418\n",
      "Epoch 5 Batch 1605 Loss 1.2846\n",
      "Epoch 5 Batch 1606 Loss 1.2797\n",
      "Epoch 5 Batch 1607 Loss 1.2668\n",
      "Epoch 5 Batch 1608 Loss 1.3513\n",
      "Epoch 5 Batch 1609 Loss 1.1460\n",
      "Epoch 5 Batch 1610 Loss 1.0089\n",
      "Epoch 5 Batch 1611 Loss 0.9380\n",
      "Epoch 5 Batch 1612 Loss 1.2610\n",
      "Epoch 5 Batch 1613 Loss 1.0457\n",
      "Epoch 5 Batch 1614 Loss 0.8834\n",
      "Epoch 5 Batch 1615 Loss 1.0681\n",
      "Epoch 5 Batch 1616 Loss 1.0824\n",
      "Epoch 5 Batch 1617 Loss 1.2749\n",
      "Epoch 5 Batch 1618 Loss 1.0643\n",
      "Epoch 5 Batch 1619 Loss 1.4088\n",
      "Epoch 5 Batch 1620 Loss 1.3952\n",
      "Epoch 5 Batch 1621 Loss 1.2928\n",
      "Epoch 5 Batch 1622 Loss 1.3389\n",
      "Epoch 5 Batch 1623 Loss 1.3144\n",
      "Epoch 5 Batch 1624 Loss 1.1847\n",
      "Epoch 5 Batch 1625 Loss 1.0310\n",
      "Epoch 5 Batch 1626 Loss 1.3194\n",
      "Epoch 5 Batch 1627 Loss 1.3811\n",
      "Epoch 5 Batch 1628 Loss 1.1529\n",
      "Epoch 5 Batch 1629 Loss 1.0925\n",
      "Epoch 5 Batch 1630 Loss 1.0749\n",
      "Epoch 5 Batch 1631 Loss 1.1616\n",
      "Epoch 5 Batch 1632 Loss 1.1940\n",
      "Epoch 5 Batch 1633 Loss 1.0034\n",
      "Epoch 5 Batch 1634 Loss 1.2479\n",
      "Epoch 5 Batch 1635 Loss 1.0614\n",
      "Epoch 5 Batch 1636 Loss 1.0860\n",
      "Epoch 5 Batch 1637 Loss 1.0612\n",
      "Epoch 5 Batch 1638 Loss 1.1875\n",
      "Epoch 5 Batch 1639 Loss 1.0420\n",
      "Epoch 5 Batch 1640 Loss 1.5356\n",
      "Epoch 5 Batch 1641 Loss 1.1969\n",
      "Epoch 5 Batch 1642 Loss 1.1693\n",
      "Epoch 5 Batch 1643 Loss 1.0948\n",
      "Epoch 5 Batch 1644 Loss 1.1705\n",
      "Epoch 5 Batch 1645 Loss 1.1972\n",
      "Epoch 5 Batch 1646 Loss 0.9883\n",
      "Epoch 5 Batch 1647 Loss 1.1329\n",
      "Epoch 5 Batch 1648 Loss 1.6097\n",
      "Epoch 5 Batch 1649 Loss 1.4428\n",
      "Epoch 5 Batch 1650 Loss 1.3496\n",
      "Epoch 5 Batch 1651 Loss 1.4060\n",
      "Epoch 5 Batch 1652 Loss 1.1104\n",
      "Epoch 5 Batch 1653 Loss 1.2725\n",
      "Epoch 5 Batch 1654 Loss 1.4272\n",
      "Epoch 5 Batch 1655 Loss 1.1132\n",
      "Epoch 5 Batch 1656 Loss 1.0191\n",
      "Epoch 5 Batch 1657 Loss 1.0268\n",
      "Epoch 5 Batch 1658 Loss 0.9286\n",
      "Epoch 5 Batch 1659 Loss 1.0783\n",
      "Epoch 5 Batch 1660 Loss 1.3268\n",
      "Epoch 5 Batch 1661 Loss 1.3717\n",
      "Epoch 5 Batch 1662 Loss 1.1587\n",
      "Epoch 5 Batch 1663 Loss 1.1645\n",
      "Epoch 5 Batch 1664 Loss 1.1196\n",
      "Epoch 5 Batch 1665 Loss 1.0051\n",
      "Epoch 5 Batch 1666 Loss 1.1847\n",
      "Epoch 5 Batch 1667 Loss 0.9286\n",
      "Epoch 5 Batch 1668 Loss 1.1779\n",
      "Epoch 5 Batch 1669 Loss 1.2104\n",
      "Epoch 5 Batch 1670 Loss 1.6844\n",
      "Epoch 5 Batch 1671 Loss 0.9526\n",
      "Epoch 5 Batch 1672 Loss 1.2939\n",
      "Epoch 5 Batch 1673 Loss 1.3694\n",
      "Epoch 5 Batch 1674 Loss 0.9756\n",
      "Epoch 5 Batch 1675 Loss 1.1483\n",
      "Epoch 5 Batch 1676 Loss 1.2434\n",
      "Epoch 5 Batch 1677 Loss 1.1210\n",
      "Epoch 5 Batch 1678 Loss 1.1747\n",
      "Epoch 5 Batch 1679 Loss 1.2243\n",
      "Epoch 5 Batch 1680 Loss 1.3309\n",
      "Epoch 5 Batch 1681 Loss 1.1585\n",
      "Epoch 5 Batch 1682 Loss 1.1678\n",
      "Epoch 5 Batch 1683 Loss 1.4561\n",
      "Epoch 5 Batch 1684 Loss 1.0586\n",
      "Epoch 5 Batch 1685 Loss 1.1271\n",
      "Epoch 5 Batch 1686 Loss 0.9668\n",
      "Epoch 5 Batch 1687 Loss 1.2011\n",
      "Epoch 5 Batch 1688 Loss 1.2503\n",
      "Epoch 5 Batch 1689 Loss 1.1893\n",
      "Epoch 5 Batch 1690 Loss 1.0854\n",
      "Epoch 5 Batch 1691 Loss 1.0200\n",
      "Epoch 5 Batch 1692 Loss 1.2552\n",
      "Epoch 5 Batch 1693 Loss 0.8427\n",
      "Epoch 5 Batch 1694 Loss 1.1998\n",
      "Epoch 5 Batch 1695 Loss 1.0483\n",
      "Epoch 5 Batch 1696 Loss 1.3533\n",
      "Epoch 5 Batch 1697 Loss 1.2752\n",
      "Epoch 5 Batch 1698 Loss 1.2539\n",
      "Epoch 5 Batch 1699 Loss 1.1533\n",
      "Epoch 5 Batch 1700 Loss 1.0276\n",
      "Epoch 5 Batch 1701 Loss 1.2805\n",
      "Epoch 5 Batch 1702 Loss 1.0298\n",
      "Epoch 5 Batch 1703 Loss 1.1760\n",
      "Epoch 5 Batch 1704 Loss 1.1683\n",
      "Epoch 5 Batch 1705 Loss 1.3291\n",
      "Epoch 5 Batch 1706 Loss 1.1356\n",
      "Epoch 5 Batch 1707 Loss 1.4067\n",
      "Epoch 5 Batch 1708 Loss 1.0083\n",
      "Epoch 5 Batch 1709 Loss 1.1960\n",
      "Epoch 5 Batch 1710 Loss 1.2542\n",
      "Epoch 5 Batch 1711 Loss 1.3066\n",
      "Epoch 5 Batch 1712 Loss 1.1405\n",
      "Epoch 5 Batch 1713 Loss 0.9985\n",
      "Epoch 5 Batch 1714 Loss 1.1719\n",
      "Epoch 5 Batch 1715 Loss 1.1797\n",
      "Epoch 5 Batch 1716 Loss 1.1718\n",
      "Epoch 5 Batch 1717 Loss 1.2266\n",
      "Epoch 5 Batch 1718 Loss 1.4340\n",
      "Epoch 5 Batch 1719 Loss 1.0976\n",
      "Epoch 5 Batch 1720 Loss 1.0983\n",
      "Epoch 5 Batch 1721 Loss 1.1898\n",
      "Epoch 5 Batch 1722 Loss 1.2702\n",
      "Epoch 5 Batch 1723 Loss 1.0143\n",
      "Epoch 5 Batch 1724 Loss 1.1073\n",
      "Epoch 5 Batch 1725 Loss 0.9984\n",
      "Epoch 5 Batch 1726 Loss 1.1374\n",
      "Epoch 5 Batch 1727 Loss 1.2844\n",
      "Epoch 5 Batch 1728 Loss 1.3869\n",
      "Epoch 5 Batch 1729 Loss 1.0560\n",
      "Epoch 5 Batch 1730 Loss 0.9910\n",
      "Epoch 5 Batch 1731 Loss 1.2394\n",
      "Epoch 5 Batch 1732 Loss 1.3542\n",
      "Epoch 5 Batch 1733 Loss 1.1730\n",
      "Epoch 5 Batch 1734 Loss 0.9575\n",
      "Epoch 5 Batch 1735 Loss 1.4359\n",
      "Epoch 5 Batch 1736 Loss 1.0529\n",
      "Epoch 5 Batch 1737 Loss 1.1838\n",
      "Epoch 5 Batch 1738 Loss 1.2152\n",
      "Epoch 5 Batch 1739 Loss 1.1382\n",
      "Epoch 5 Batch 1740 Loss 1.0683\n",
      "Epoch 5 Batch 1741 Loss 1.0295\n",
      "Epoch 5 Batch 1742 Loss 1.3190\n",
      "Epoch 5 Batch 1743 Loss 1.1478\n",
      "Epoch 5 Batch 1744 Loss 1.1971\n",
      "Epoch 5 Batch 1745 Loss 1.1868\n",
      "Epoch 5 Batch 1746 Loss 1.1805\n",
      "Epoch 5 Batch 1747 Loss 1.1143\n",
      "Epoch 5 Batch 1748 Loss 1.1016\n",
      "Epoch 5 Batch 1749 Loss 1.1573\n",
      "Epoch 5 Batch 1750 Loss 1.0762\n",
      "Epoch 5 Batch 1751 Loss 1.0974\n",
      "Epoch 5 Batch 1752 Loss 1.3403\n",
      "Epoch 5 Batch 1753 Loss 1.0393\n",
      "Epoch 5 Batch 1754 Loss 1.1927\n",
      "Epoch 5 Batch 1755 Loss 1.0101\n",
      "Epoch 5 Batch 1756 Loss 1.1931\n",
      "Epoch 5 Batch 1757 Loss 1.1191\n",
      "Epoch 5 Batch 1758 Loss 1.4031\n",
      "Epoch 5 Batch 1759 Loss 1.0179\n",
      "Epoch 5 Batch 1760 Loss 1.1827\n",
      "Epoch 5 Batch 1761 Loss 1.2841\n",
      "Epoch 5 Batch 1762 Loss 1.0913\n",
      "Epoch 5 Batch 1763 Loss 1.1922\n",
      "Epoch 5 Batch 1764 Loss 1.3002\n",
      "Epoch 5 Batch 1765 Loss 1.4065\n",
      "Epoch 5 Batch 1766 Loss 1.0173\n",
      "Epoch 5 Batch 1767 Loss 1.0816\n",
      "Epoch 5 Batch 1768 Loss 1.2361\n",
      "Epoch 5 Batch 1769 Loss 1.1403\n",
      "Epoch 5 Batch 1770 Loss 0.9241\n",
      "Epoch 5 Batch 1771 Loss 0.9436\n",
      "Epoch 5 Batch 1772 Loss 1.0223\n",
      "Epoch 5 Batch 1773 Loss 1.0516\n",
      "Epoch 5 Batch 1774 Loss 1.0527\n",
      "Epoch 5 Batch 1775 Loss 1.1873\n",
      "Epoch 5 Batch 1776 Loss 1.2207\n",
      "Epoch 5 Batch 1777 Loss 1.0941\n",
      "Epoch 5 Batch 1778 Loss 1.0347\n",
      "Epoch 5 Batch 1779 Loss 1.0722\n",
      "Epoch 5 Batch 1780 Loss 1.3292\n",
      "Epoch 5 Batch 1781 Loss 1.2609\n",
      "Epoch 5 Batch 1782 Loss 1.1589\n",
      "Epoch 5 Batch 1783 Loss 0.9373\n",
      "Epoch 5 Batch 1784 Loss 1.1616\n",
      "Epoch 5 Batch 1785 Loss 1.0872\n",
      "Epoch 5 Batch 1786 Loss 0.9536\n",
      "Epoch 5 Batch 1787 Loss 1.3179\n",
      "Epoch 5 Batch 1788 Loss 1.3042\n",
      "Epoch 5 Batch 1789 Loss 1.2235\n",
      "Epoch 5 Batch 1790 Loss 1.1335\n",
      "Epoch 5 Batch 1791 Loss 1.1247\n",
      "Epoch 5 Batch 1792 Loss 1.1401\n",
      "Epoch 5 Batch 1793 Loss 0.9996\n",
      "Epoch 5 Batch 1794 Loss 0.9913\n",
      "Epoch 5 Batch 1795 Loss 1.0478\n",
      "Epoch 5 Batch 1796 Loss 1.1709\n",
      "Epoch 5 Batch 1797 Loss 1.1057\n",
      "Epoch 5 Batch 1798 Loss 0.9568\n",
      "Epoch 5 Batch 1799 Loss 1.3467\n",
      "Epoch 5 Batch 1800 Loss 1.0353\n",
      "Epoch 5 Batch 1801 Loss 1.1033\n",
      "Epoch 5 Batch 1802 Loss 1.2390\n",
      "Epoch 5 Batch 1803 Loss 1.3985\n",
      "Epoch 5 Batch 1804 Loss 1.3922\n",
      "Epoch 5 Batch 1805 Loss 1.0644\n",
      "Epoch 5 Batch 1806 Loss 1.4509\n",
      "Epoch 5 Batch 1807 Loss 1.2974\n",
      "Epoch 5 Batch 1808 Loss 1.1984\n",
      "Epoch 5 Batch 1809 Loss 1.1900\n",
      "Epoch 5 Batch 1810 Loss 1.1303\n",
      "Epoch 5 Batch 1811 Loss 1.4364\n",
      "Epoch 5 Batch 1812 Loss 1.0481\n",
      "Epoch 5 Batch 1813 Loss 1.2429\n",
      "Epoch 5 Batch 1814 Loss 1.0376\n",
      "Epoch 5 Batch 1815 Loss 1.0442\n",
      "Epoch 5 Batch 1816 Loss 1.2148\n",
      "Epoch 5 Batch 1817 Loss 1.3028\n",
      "Epoch 5 Batch 1818 Loss 1.2588\n",
      "Epoch 5 Batch 1819 Loss 1.1175\n",
      "Epoch 5 Batch 1820 Loss 1.1429\n",
      "Epoch 5 Batch 1821 Loss 0.9646\n",
      "Epoch 5 Batch 1822 Loss 1.0484\n",
      "Epoch 5 Batch 1823 Loss 1.3867\n",
      "Epoch 5 Batch 1824 Loss 1.0471\n",
      "Epoch 5 Batch 1825 Loss 1.0326\n",
      "Epoch 5 Batch 1826 Loss 1.1943\n",
      "Epoch 5 Batch 1827 Loss 1.1877\n",
      "Epoch 5 Batch 1828 Loss 1.3926\n",
      "Epoch 5 Batch 1829 Loss 1.1463\n",
      "Epoch 5 Batch 1830 Loss 1.0444\n",
      "Epoch 5 Batch 1831 Loss 0.9508\n",
      "Epoch 5 Batch 1832 Loss 1.1170\n",
      "Epoch 5 Batch 1833 Loss 1.2811\n",
      "Epoch 5 Batch 1834 Loss 1.1059\n",
      "Epoch 5 Batch 1835 Loss 1.3817\n",
      "Epoch 5 Batch 1836 Loss 1.4531\n",
      "Epoch 5 Batch 1837 Loss 1.1798\n",
      "Epoch 5 Batch 1838 Loss 1.1711\n",
      "Epoch 5 Batch 1839 Loss 0.8709\n",
      "Epoch 5 Batch 1840 Loss 1.1616\n",
      "Epoch 5 Batch 1841 Loss 1.0994\n",
      "Epoch 5 Batch 1842 Loss 1.1819\n",
      "Epoch 5 Batch 1843 Loss 1.0625\n",
      "Epoch 5 Batch 1844 Loss 1.3603\n",
      "Epoch 5 Batch 1845 Loss 1.3015\n",
      "Epoch 5 Batch 1846 Loss 0.9665\n",
      "Epoch 5 Batch 1847 Loss 1.1416\n",
      "Epoch 5 Batch 1848 Loss 1.3168\n",
      "Epoch 5 Batch 1849 Loss 1.1898\n",
      "Epoch 5 Batch 1850 Loss 1.2305\n",
      "Epoch 5 Batch 1851 Loss 1.0979\n",
      "Epoch 5 Batch 1852 Loss 1.4148\n",
      "Epoch 5 Batch 1853 Loss 1.1992\n",
      "Epoch 5 Batch 1854 Loss 1.2867\n",
      "Epoch 5 Batch 1855 Loss 1.0550\n",
      "Epoch 5 Batch 1856 Loss 1.1186\n",
      "Epoch 5 Batch 1857 Loss 0.9566\n",
      "Epoch 5 Batch 1858 Loss 1.1776\n",
      "Epoch 5 Batch 1859 Loss 0.9982\n",
      "Epoch 5 Batch 1860 Loss 1.1290\n",
      "Epoch 5 Batch 1861 Loss 1.0537\n",
      "Epoch 5 Batch 1862 Loss 0.8997\n",
      "Epoch 5 Batch 1863 Loss 0.9249\n",
      "Epoch 5 Batch 1864 Loss 1.0891\n",
      "Epoch 5 Batch 1865 Loss 1.2792\n",
      "Epoch 5 Batch 1866 Loss 1.2038\n",
      "Epoch 5 Batch 1867 Loss 1.2147\n",
      "Epoch 5 Batch 1868 Loss 1.4175\n",
      "Epoch 5 Batch 1869 Loss 0.8864\n",
      "Epoch 5 Batch 1870 Loss 1.2936\n",
      "Epoch 5 Batch 1871 Loss 1.1255\n",
      "Epoch 5 Batch 1872 Loss 1.3577\n",
      "Epoch 5 Batch 1873 Loss 1.1345\n",
      "Epoch 5 Batch 1874 Loss 1.0192\n",
      "Epoch 5 Batch 1875 Loss 1.1017\n",
      "Epoch 5 Batch 1876 Loss 1.2028\n",
      "Epoch 5 Batch 1877 Loss 0.9914\n",
      "Epoch 5 Batch 1878 Loss 1.4667\n",
      "Epoch 5 Batch 1879 Loss 1.2760\n",
      "Epoch 5 Batch 1880 Loss 1.1882\n",
      "Epoch 5 Batch 1881 Loss 0.8711\n",
      "Epoch 5 Batch 1882 Loss 1.0133\n",
      "Epoch 5 Batch 1883 Loss 1.3663\n",
      "Epoch 5 Batch 1884 Loss 1.3553\n",
      "Epoch 5 Batch 1885 Loss 1.2617\n",
      "Epoch 5 Batch 1886 Loss 1.0112\n",
      "Epoch 5 Batch 1887 Loss 1.0648\n",
      "Epoch 5 Batch 1888 Loss 1.3152\n",
      "Epoch 5 Batch 1889 Loss 1.0108\n",
      "Epoch 5 Batch 1890 Loss 1.3262\n",
      "Epoch 5 Batch 1891 Loss 0.8014\n",
      "Epoch 5 Batch 1892 Loss 1.2188\n",
      "Epoch 5 Batch 1893 Loss 1.3218\n",
      "Epoch 5 Batch 1894 Loss 1.2725\n",
      "Epoch 5 Batch 1895 Loss 1.0116\n",
      "Epoch 5 Batch 1896 Loss 0.9456\n",
      "Epoch 5 Batch 1897 Loss 1.4056\n",
      "Epoch 5 Batch 1898 Loss 1.2737\n",
      "Epoch 5 Batch 1899 Loss 1.1597\n",
      "Epoch 5 Batch 1900 Loss 1.6140\n",
      "Epoch 5 Batch 1901 Loss 1.1132\n",
      "Epoch 5 Batch 1902 Loss 1.1578\n",
      "Epoch 5 Batch 1903 Loss 1.1203\n",
      "Epoch 5 Batch 1904 Loss 1.0816\n",
      "Epoch 5 Batch 1905 Loss 1.2701\n",
      "Epoch 5 Batch 1906 Loss 1.0821\n",
      "Epoch 5 Batch 1907 Loss 1.3822\n",
      "Epoch 5 Batch 1908 Loss 1.2497\n",
      "Epoch 5 Batch 1909 Loss 1.2612\n",
      "Epoch 5 Batch 1910 Loss 0.9727\n",
      "Epoch 5 Batch 1911 Loss 0.9213\n",
      "Epoch 5 Batch 1912 Loss 1.2332\n",
      "Epoch 5 Batch 1913 Loss 1.1344\n",
      "Epoch 5 Batch 1914 Loss 1.2917\n",
      "Epoch 5 Batch 1915 Loss 0.9320\n",
      "Epoch 5 Batch 1916 Loss 1.0006\n",
      "Epoch 5 Batch 1917 Loss 1.2542\n",
      "Epoch 5 Batch 1918 Loss 1.2429\n",
      "Epoch 5 Batch 1919 Loss 1.2334\n",
      "Epoch 5 Batch 1920 Loss 1.1961\n",
      "Epoch 5 Batch 1921 Loss 1.1390\n",
      "Epoch 5 Batch 1922 Loss 0.9706\n",
      "Epoch 5 Batch 1923 Loss 0.9463\n",
      "Epoch 5 Batch 1924 Loss 1.0409\n",
      "Epoch 5 Batch 1925 Loss 1.0964\n",
      "Epoch 5 Batch 1926 Loss 1.0428\n",
      "Epoch 5 Batch 1927 Loss 1.1197\n",
      "Epoch 5 Batch 1928 Loss 1.0631\n",
      "Epoch 5 Batch 1929 Loss 1.2318\n",
      "Epoch 5 Batch 1930 Loss 1.2099\n",
      "Epoch 5 Batch 1931 Loss 1.2410\n",
      "Epoch 5 Batch 1932 Loss 1.0342\n",
      "Epoch 5 Batch 1933 Loss 1.0568\n",
      "Epoch 5 Batch 1934 Loss 1.2773\n",
      "Epoch 5 Batch 1935 Loss 1.0084\n",
      "Epoch 5 Batch 1936 Loss 1.1029\n",
      "Epoch 5 Batch 1937 Loss 0.8165\n",
      "Epoch 5 Batch 1938 Loss 1.1568\n",
      "Epoch 5 Batch 1939 Loss 1.2604\n",
      "Epoch 5 Batch 1940 Loss 1.0609\n",
      "Epoch 5 Batch 1941 Loss 1.0650\n",
      "Epoch 5 Batch 1942 Loss 1.0598\n",
      "Epoch 5 Batch 1943 Loss 1.3423\n",
      "Epoch 5 Batch 1944 Loss 1.2009\n",
      "Epoch 5 Batch 1945 Loss 1.3211\n",
      "Epoch 5 Batch 1946 Loss 1.2590\n",
      "Epoch 5 Batch 1947 Loss 1.0212\n",
      "Epoch 5 Batch 1948 Loss 1.4990\n",
      "Epoch 5 Batch 1949 Loss 0.8979\n",
      "Epoch 5 Batch 1950 Loss 1.1974\n",
      "Epoch 5 Batch 1951 Loss 0.9191\n",
      "Epoch 5 Batch 1952 Loss 0.9991\n",
      "Epoch 5 Batch 1953 Loss 1.0857\n",
      "Epoch 5 Batch 1954 Loss 0.9912\n",
      "Epoch 5 Batch 1955 Loss 1.2071\n",
      "Epoch 5 Batch 1956 Loss 0.9846\n",
      "Epoch 5 Batch 1957 Loss 0.9886\n",
      "Epoch 5 Batch 1958 Loss 1.1853\n",
      "Epoch 5 Batch 1959 Loss 1.0002\n",
      "Epoch 5 Batch 1960 Loss 1.1909\n",
      "Epoch 5 Batch 1961 Loss 1.1148\n",
      "Epoch 5 Batch 1962 Loss 1.1829\n",
      "Epoch 5 Batch 1963 Loss 1.0793\n",
      "Epoch 5 Batch 1964 Loss 1.0662\n",
      "Epoch 5 Batch 1965 Loss 0.9780\n",
      "Epoch 5 Batch 1966 Loss 1.2565\n",
      "Epoch 5 Batch 1967 Loss 1.2432\n",
      "Epoch 5 Batch 1968 Loss 1.4018\n",
      "Epoch 5 Batch 1969 Loss 1.1905\n",
      "Epoch 5 Batch 1970 Loss 1.1387\n",
      "Epoch 5 Batch 1971 Loss 1.3563\n",
      "Epoch 5 Batch 1972 Loss 0.9968\n",
      "Epoch 5 Batch 1973 Loss 1.2735\n",
      "Epoch 5 Batch 1974 Loss 1.4224\n",
      "Epoch 5 Batch 1975 Loss 1.1457\n",
      "Epoch 5 Batch 1976 Loss 1.1457\n",
      "Epoch 5 Batch 1977 Loss 1.1155\n",
      "Epoch 5 Batch 1978 Loss 1.1801\n",
      "Epoch 5 Batch 1979 Loss 1.0565\n",
      "Epoch 5 Batch 1980 Loss 1.1697\n",
      "Epoch 5 Batch 1981 Loss 0.9057\n",
      "Epoch 5 Batch 1982 Loss 1.2042\n",
      "Epoch 5 Batch 1983 Loss 1.1912\n",
      "Epoch 5 Batch 1984 Loss 1.0555\n",
      "Epoch 5 Batch 1985 Loss 1.1980\n",
      "Epoch 5 Batch 1986 Loss 1.0928\n",
      "Epoch 5 Batch 1987 Loss 1.1537\n",
      "Epoch 5 Batch 1988 Loss 1.2012\n",
      "Epoch 5 Batch 1989 Loss 0.9062\n",
      "Epoch 5 Batch 1990 Loss 1.0042\n",
      "Epoch 5 Batch 1991 Loss 1.0601\n",
      "Epoch 5 Batch 1992 Loss 0.9389\n",
      "Epoch 5 Batch 1993 Loss 0.9984\n",
      "Epoch 5 Batch 1994 Loss 1.1393\n",
      "Epoch 5 Batch 1995 Loss 0.9743\n",
      "Epoch 5 Batch 1996 Loss 1.1828\n",
      "Epoch 5 Batch 1997 Loss 1.0126\n",
      "Epoch 5 Batch 1998 Loss 1.1951\n",
      "Epoch 5 Batch 1999 Loss 0.9087\n",
      "Epoch 5 Batch 2000 Loss 0.9587\n",
      "Epoch 5 Batch 2001 Loss 1.1019\n",
      "Epoch 5 Batch 2002 Loss 1.1003\n",
      "Epoch 5 Batch 2003 Loss 1.1343\n",
      "Epoch 5 Batch 2004 Loss 1.1425\n",
      "Epoch 5 Batch 2005 Loss 1.0268\n",
      "Epoch 5 Batch 2006 Loss 1.0236\n",
      "Epoch 5 Batch 2007 Loss 0.9928\n",
      "Epoch 5 Batch 2008 Loss 0.9485\n",
      "Epoch 5 Batch 2009 Loss 1.2312\n",
      "Epoch 5 Batch 2010 Loss 1.2522\n",
      "Epoch 5 Batch 2011 Loss 1.0344\n",
      "Epoch 5 Batch 2012 Loss 1.0153\n",
      "Epoch 5 Batch 2013 Loss 1.1166\n",
      "Epoch 5 Batch 2014 Loss 0.9833\n",
      "Epoch 5 Batch 2015 Loss 1.2738\n",
      "Epoch 5 Batch 2016 Loss 1.0024\n",
      "Epoch 5 Batch 2017 Loss 1.2335\n",
      "Epoch 5 Batch 2018 Loss 1.0239\n",
      "Epoch 5 Batch 2019 Loss 1.2283\n",
      "Epoch 5 Batch 2020 Loss 0.8853\n",
      "Epoch 5 Batch 2021 Loss 0.9811\n",
      "Epoch 5 Batch 2022 Loss 1.1498\n",
      "Epoch 5 Batch 2023 Loss 1.0920\n",
      "Epoch 5 Batch 2024 Loss 1.1338\n",
      "Epoch 5 Batch 2025 Loss 0.8787\n",
      "Epoch 5 Batch 2026 Loss 1.4113\n",
      "Epoch 5 Batch 2027 Loss 1.0401\n",
      "Epoch 5 Batch 2028 Loss 1.1248\n",
      "Epoch 5 Batch 2029 Loss 1.0528\n",
      "Epoch 5 Batch 2030 Loss 1.2611\n",
      "Epoch 5 Batch 2031 Loss 1.1775\n",
      "Epoch 5 Batch 2032 Loss 1.2647\n",
      "Epoch 5 Batch 2033 Loss 1.0859\n",
      "Epoch 5 Batch 2034 Loss 1.4012\n",
      "Epoch 5 Batch 2035 Loss 1.5013\n",
      "Epoch 5 Batch 2036 Loss 1.2168\n",
      "Epoch 5 Batch 2037 Loss 0.9754\n",
      "Epoch 5 Batch 2038 Loss 0.9620\n",
      "Epoch 5 Batch 2039 Loss 1.0005\n",
      "Epoch 5 Batch 2040 Loss 1.1418\n",
      "Epoch 5 Batch 2041 Loss 1.1358\n",
      "Epoch 5 Batch 2042 Loss 0.9003\n",
      "Epoch 5 Batch 2043 Loss 1.1304\n",
      "Epoch 5 Batch 2044 Loss 1.1257\n",
      "Epoch 5 Batch 2045 Loss 1.0608\n",
      "Epoch 5 Batch 2046 Loss 1.0133\n",
      "Epoch 5 Batch 2047 Loss 1.1274\n",
      "Epoch 5 Batch 2048 Loss 1.2129\n",
      "Epoch 5 Batch 2049 Loss 1.2823\n",
      "Epoch 5 Batch 2050 Loss 1.1129\n",
      "Epoch 5 Batch 2051 Loss 1.4243\n",
      "Epoch 5 Batch 2052 Loss 1.3558\n",
      "Epoch 5 Batch 2053 Loss 1.2399\n",
      "Epoch 5 Batch 2054 Loss 1.2227\n",
      "Epoch 5 Batch 2055 Loss 0.9791\n",
      "Epoch 5 Batch 2056 Loss 1.0907\n",
      "Epoch 5 Batch 2057 Loss 1.1585\n",
      "Epoch 5 Batch 2058 Loss 1.1114\n",
      "Epoch 5 Batch 2059 Loss 1.1852\n",
      "Epoch 5 Batch 2060 Loss 1.1039\n",
      "Epoch 5 Batch 2061 Loss 1.3504\n",
      "Epoch 5 Batch 2062 Loss 1.2907\n",
      "Epoch 5 Batch 2063 Loss 1.0771\n",
      "Epoch 5 Batch 2064 Loss 1.0866\n",
      "Epoch 5 Batch 2065 Loss 0.8844\n",
      "Epoch 5 Batch 2066 Loss 1.1007\n",
      "Epoch 5 Batch 2067 Loss 1.0445\n",
      "Epoch 5 Batch 2068 Loss 1.2115\n",
      "Epoch 5 Batch 2069 Loss 0.9745\n",
      "Epoch 5 Batch 2070 Loss 1.0765\n",
      "Epoch 5 Batch 2071 Loss 1.0987\n",
      "Epoch 5 Batch 2072 Loss 1.0679\n",
      "Epoch 5 Batch 2073 Loss 1.3914\n",
      "Epoch 5 Batch 2074 Loss 1.2328\n",
      "Epoch 5 Batch 2075 Loss 1.3166\n",
      "Epoch 5 Batch 2076 Loss 1.0479\n",
      "Epoch 5 Batch 2077 Loss 1.1250\n",
      "Epoch 5 Batch 2078 Loss 1.0204\n",
      "Epoch 5 Batch 2079 Loss 1.1132\n",
      "Epoch 5 Batch 2080 Loss 1.0172\n",
      "Epoch 5 Batch 2081 Loss 1.1707\n",
      "Epoch 5 Batch 2082 Loss 1.0788\n",
      "Epoch 5 Batch 2083 Loss 1.0190\n",
      "Epoch 5 Batch 2084 Loss 1.0501\n",
      "Epoch 5 Batch 2085 Loss 1.1735\n",
      "Epoch 5 Batch 2086 Loss 1.0543\n",
      "Epoch 5 Batch 2087 Loss 1.1831\n",
      "Epoch 5 Batch 2088 Loss 0.9276\n",
      "Epoch 5 Batch 2089 Loss 1.1243\n",
      "Epoch 5 Batch 2090 Loss 1.1310\n",
      "Epoch 5 Batch 2091 Loss 1.1354\n",
      "Epoch 5 Batch 2092 Loss 1.2687\n",
      "Epoch 5 Batch 2093 Loss 1.0694\n",
      "Epoch 5 Batch 2094 Loss 1.1221\n",
      "Epoch 5 Batch 2095 Loss 1.1394\n",
      "Epoch 5 Batch 2096 Loss 1.2906\n",
      "Epoch 5 Batch 2097 Loss 1.0721\n",
      "Epoch 5 Batch 2098 Loss 1.1632\n",
      "Epoch 5 Batch 2099 Loss 1.1976\n",
      "Epoch 5 Batch 2100 Loss 1.1097\n",
      "Epoch 5 Batch 2101 Loss 1.0887\n",
      "Epoch 5 Batch 2102 Loss 1.3549\n",
      "Epoch 5 Batch 2103 Loss 1.1681\n",
      "Epoch 5 Batch 2104 Loss 1.1796\n",
      "Epoch 5 Batch 2105 Loss 0.9536\n",
      "Epoch 5 Batch 2106 Loss 1.1396\n",
      "Epoch 5 Batch 2107 Loss 1.1134\n",
      "Epoch 5 Batch 2108 Loss 1.2387\n",
      "Epoch 5 Batch 2109 Loss 1.1009\n",
      "Epoch 5 Batch 2110 Loss 1.3050\n",
      "Epoch 5 Batch 2111 Loss 1.0303\n",
      "Epoch 5 Batch 2112 Loss 0.9959\n",
      "Epoch 5 Batch 2113 Loss 1.0196\n",
      "Epoch 5 Batch 2114 Loss 0.8696\n",
      "Epoch 5 Batch 2115 Loss 1.2415\n",
      "Epoch 5 Batch 2116 Loss 1.0144\n",
      "Epoch 5 Batch 2117 Loss 1.1594\n",
      "Epoch 5 Batch 2118 Loss 1.2302\n",
      "Epoch 5 Batch 2119 Loss 0.9963\n",
      "Epoch 5 Batch 2120 Loss 1.0919\n",
      "Epoch 5 Batch 2121 Loss 1.0627\n",
      "Epoch 5 Batch 2122 Loss 1.3176\n",
      "Epoch 5 Batch 2123 Loss 1.1302\n",
      "Epoch 5 Batch 2124 Loss 1.1966\n",
      "Epoch 5 Batch 2125 Loss 1.0085\n",
      "Epoch 5 Batch 2126 Loss 1.2184\n",
      "Epoch 5 Batch 2127 Loss 1.2253\n",
      "Epoch 5 Batch 2128 Loss 1.0094\n",
      "Epoch 5 Batch 2129 Loss 1.3264\n",
      "Epoch 5 Batch 2130 Loss 1.1167\n",
      "Epoch 5 Batch 2131 Loss 1.1337\n",
      "Epoch 5 Batch 2132 Loss 1.2939\n",
      "Epoch 5 Batch 2133 Loss 1.0942\n",
      "Epoch 5 Batch 2134 Loss 1.5673\n",
      "Epoch 5 Batch 2135 Loss 1.2850\n",
      "Epoch 5 Batch 2136 Loss 1.1391\n",
      "Epoch 5 Batch 2137 Loss 1.0741\n",
      "Epoch 5 Batch 2138 Loss 1.2924\n",
      "Epoch 5 Batch 2139 Loss 1.1167\n",
      "Epoch 5 Batch 2140 Loss 1.3682\n",
      "Epoch 5 Batch 2141 Loss 0.9958\n",
      "Epoch 5 Batch 2142 Loss 1.1840\n",
      "Epoch 5 Batch 2143 Loss 1.1498\n",
      "Epoch 5 Batch 2144 Loss 1.1323\n",
      "Epoch 5 Batch 2145 Loss 1.1429\n",
      "Epoch 5 Batch 2146 Loss 1.1760\n",
      "Epoch 5 Batch 2147 Loss 1.2502\n",
      "Epoch 5 Batch 2148 Loss 1.2113\n",
      "Epoch 5 Batch 2149 Loss 1.0468\n",
      "Epoch 5 Batch 2150 Loss 1.2292\n",
      "Epoch 5 Batch 2151 Loss 1.2356\n",
      "Epoch 5 Batch 2152 Loss 1.1602\n",
      "Epoch 5 Batch 2153 Loss 1.2074\n",
      "Epoch 5 Batch 2154 Loss 0.9539\n",
      "Epoch 5 Batch 2155 Loss 0.9589\n",
      "Epoch 5 Batch 2156 Loss 1.4604\n",
      "Epoch 5 Batch 2157 Loss 0.8511\n",
      "Epoch 5 Batch 2158 Loss 0.8671\n",
      "Epoch 5 Batch 2159 Loss 1.2533\n",
      "Epoch 5 Batch 2160 Loss 1.2769\n",
      "Epoch 5 Batch 2161 Loss 1.0812\n",
      "Epoch 5 Batch 2162 Loss 0.9053\n",
      "Epoch 5 Batch 2163 Loss 1.0832\n",
      "Epoch 5 Batch 2164 Loss 1.4012\n",
      "Epoch 5 Batch 2165 Loss 1.4161\n",
      "Epoch 5 Batch 2166 Loss 1.2247\n",
      "Epoch 5 Batch 2167 Loss 1.0882\n",
      "Epoch 5 Batch 2168 Loss 1.1710\n",
      "Epoch 5 Batch 2169 Loss 1.0863\n",
      "Epoch 5 Batch 2170 Loss 0.9372\n",
      "Epoch 5 Batch 2171 Loss 1.1150\n",
      "Epoch 5 Batch 2172 Loss 1.1028\n",
      "Epoch 5 Batch 2173 Loss 1.1722\n",
      "Epoch 5 Batch 2174 Loss 1.2115\n",
      "Epoch 5 Batch 2175 Loss 1.1584\n",
      "Epoch 5 Batch 2176 Loss 1.2214\n",
      "Epoch 5 Batch 2177 Loss 1.1228\n",
      "Epoch 5 Batch 2178 Loss 0.9648\n",
      "Epoch 5 Batch 2179 Loss 1.2707\n",
      "Epoch 5 Batch 2180 Loss 1.3428\n",
      "Epoch 5 Batch 2181 Loss 1.0538\n",
      "Epoch 5 Batch 2182 Loss 0.9759\n",
      "Epoch 5 Batch 2183 Loss 1.2203\n",
      "Epoch 5 Batch 2184 Loss 1.0883\n",
      "Epoch 5 Batch 2185 Loss 1.1581\n",
      "Epoch 5 Batch 2186 Loss 1.2321\n",
      "Epoch 5 Batch 2187 Loss 1.2775\n",
      "Epoch 5 Batch 2188 Loss 1.1513\n",
      "Epoch 5 Batch 2189 Loss 1.1424\n",
      "Epoch 5 Batch 2190 Loss 1.7260\n",
      "Epoch 5 Batch 2191 Loss 1.0823\n",
      "Epoch 5 Batch 2192 Loss 1.3083\n",
      "Epoch 5 Batch 2193 Loss 1.1773\n",
      "Epoch 5 Batch 2194 Loss 0.9938\n",
      "Epoch 5 Batch 2195 Loss 1.0788\n",
      "Epoch 5 Batch 2196 Loss 1.2436\n",
      "Epoch 5 Batch 2197 Loss 1.4284\n",
      "Epoch 5 Batch 2198 Loss 1.2261\n",
      "Epoch 5 Batch 2199 Loss 1.2826\n",
      "Epoch 5 Batch 2200 Loss 1.1779\n",
      "Epoch 5 Batch 2201 Loss 1.0089\n",
      "Epoch 5 Batch 2202 Loss 1.2640\n",
      "Epoch 5 Batch 2203 Loss 1.0427\n",
      "Epoch 5 Batch 2204 Loss 1.1344\n",
      "Epoch 5 Batch 2205 Loss 0.9813\n",
      "Epoch 5 Batch 2206 Loss 1.1079\n",
      "Epoch 5 Batch 2207 Loss 1.1384\n",
      "Epoch 5 Batch 2208 Loss 1.1739\n",
      "Epoch 5 Batch 2209 Loss 1.2050\n",
      "Epoch 5 Batch 2210 Loss 1.2141\n",
      "Epoch 5 Batch 2211 Loss 1.1720\n",
      "Epoch 5 Batch 2212 Loss 1.3561\n",
      "Epoch 5 Batch 2213 Loss 1.1720\n",
      "Epoch 5 Batch 2214 Loss 1.2774\n",
      "Epoch 5 Batch 2215 Loss 1.1378\n",
      "Epoch 5 Batch 2216 Loss 0.9778\n",
      "Epoch 5 Batch 2217 Loss 0.9639\n",
      "Epoch 5 Batch 2218 Loss 1.1703\n",
      "Epoch 5 Batch 2219 Loss 1.0996\n",
      "Epoch 5 Batch 2220 Loss 1.0005\n",
      "Epoch 5 Batch 2221 Loss 1.1395\n",
      "Epoch 5 Batch 2222 Loss 1.1704\n",
      "Epoch 5 Batch 2223 Loss 1.0727\n",
      "Epoch 5 Batch 2224 Loss 1.1480\n",
      "Epoch 5 Batch 2225 Loss 1.0970\n",
      "Epoch 5 Batch 2226 Loss 0.9488\n",
      "Epoch 5 Batch 2227 Loss 1.0244\n",
      "Epoch 5 Batch 2228 Loss 1.0617\n",
      "Epoch 5 Batch 2229 Loss 1.2020\n",
      "Epoch 5 Batch 2230 Loss 1.1279\n",
      "Epoch 5 Batch 2231 Loss 0.9087\n",
      "Epoch 5 Batch 2232 Loss 1.1052\n",
      "Epoch 5 Batch 2233 Loss 0.9907\n",
      "Epoch 5 Batch 2234 Loss 1.0873\n",
      "Epoch 5 Batch 2235 Loss 1.4528\n",
      "Epoch 5 Batch 2236 Loss 0.8372\n",
      "Epoch 5 Batch 2237 Loss 1.3642\n",
      "Epoch 5 Batch 2238 Loss 1.2108\n",
      "Epoch 5 Batch 2239 Loss 1.2680\n",
      "Epoch 5 Batch 2240 Loss 1.1954\n",
      "Epoch 5 Batch 2241 Loss 1.2065\n",
      "Epoch 5 Batch 2242 Loss 1.0404\n",
      "Epoch 5 Batch 2243 Loss 1.1456\n",
      "Epoch 5 Batch 2244 Loss 0.8387\n",
      "Epoch 5 Batch 2245 Loss 1.0460\n",
      "Epoch 5 Batch 2246 Loss 1.1108\n",
      "Epoch 5 Batch 2247 Loss 1.1476\n",
      "Epoch 5 Batch 2248 Loss 1.1668\n",
      "Epoch 5 Batch 2249 Loss 0.9838\n",
      "Epoch 5 Batch 2250 Loss 1.1972\n",
      "Epoch 5 Batch 2251 Loss 1.1716\n",
      "Epoch 5 Batch 2252 Loss 1.5177\n",
      "Epoch 5 Batch 2253 Loss 1.2014\n",
      "Epoch 5 Batch 2254 Loss 1.2541\n",
      "Epoch 5 Batch 2255 Loss 1.0194\n",
      "Epoch 5 Batch 2256 Loss 1.2675\n",
      "Epoch 5 Batch 2257 Loss 1.2854\n",
      "Epoch 5 Batch 2258 Loss 0.8699\n",
      "Epoch 5 Batch 2259 Loss 1.0780\n",
      "Epoch 5 Batch 2260 Loss 0.8496\n",
      "Epoch 5 Batch 2261 Loss 1.0576\n",
      "Epoch 5 Batch 2262 Loss 1.1959\n",
      "Epoch 5 Batch 2263 Loss 1.0562\n",
      "Epoch 5 Batch 2264 Loss 1.0120\n",
      "Epoch 5 Batch 2265 Loss 1.1832\n",
      "Epoch 5 Batch 2266 Loss 1.0564\n",
      "Epoch 5 Batch 2267 Loss 1.0435\n",
      "Epoch 5 Batch 2268 Loss 1.0882\n",
      "Epoch 5 Batch 2269 Loss 1.1836\n",
      "Epoch 5 Batch 2270 Loss 1.0467\n",
      "Epoch 5 Batch 2271 Loss 1.0835\n",
      "Epoch 5 Batch 2272 Loss 1.2101\n",
      "Epoch 5 Batch 2273 Loss 1.3467\n",
      "Epoch 5 Batch 2274 Loss 1.0313\n",
      "Epoch 5 Batch 2275 Loss 1.0345\n",
      "Epoch 5 Batch 2276 Loss 1.1190\n",
      "Epoch 5 Batch 2277 Loss 1.1655\n",
      "Epoch 5 Batch 2278 Loss 1.0916\n",
      "Epoch 5 Batch 2279 Loss 1.1329\n",
      "Epoch 5 Batch 2280 Loss 1.2003\n",
      "Epoch 5 Batch 2281 Loss 1.0640\n",
      "Epoch 5 Batch 2282 Loss 0.9774\n",
      "Epoch 5 Batch 2283 Loss 0.9326\n",
      "Epoch 5 Batch 2284 Loss 1.1720\n",
      "Epoch 5 Batch 2285 Loss 1.0641\n",
      "Epoch 5 Batch 2286 Loss 0.9979\n",
      "Epoch 5 Batch 2287 Loss 0.8725\n",
      "Epoch 5 Batch 2288 Loss 1.2079\n",
      "Epoch 5 Batch 2289 Loss 0.8461\n",
      "Epoch 5 Batch 2290 Loss 1.3170\n",
      "Epoch 5 Batch 2291 Loss 1.0405\n",
      "Epoch 5 Batch 2292 Loss 1.0714\n",
      "Epoch 5 Batch 2293 Loss 1.2531\n",
      "Epoch 5 Batch 2294 Loss 0.8620\n",
      "Epoch 5 Batch 2295 Loss 1.3601\n",
      "Epoch 5 Batch 2296 Loss 0.9250\n",
      "Epoch 5 Batch 2297 Loss 1.2983\n",
      "Epoch 5 Batch 2298 Loss 1.1559\n",
      "Epoch 5 Batch 2299 Loss 1.2234\n",
      "Epoch 5 Batch 2300 Loss 1.3058\n",
      "Epoch 5 Batch 2301 Loss 1.2678\n",
      "Epoch 5 Batch 2302 Loss 1.0760\n",
      "Epoch 5 Batch 2303 Loss 0.9438\n",
      "Epoch 5 Batch 2304 Loss 1.1094\n",
      "Epoch 5 Batch 2305 Loss 1.3123\n",
      "Epoch 5 Batch 2306 Loss 1.2532\n",
      "Epoch 5 Batch 2307 Loss 1.0325\n",
      "Epoch 5 Batch 2308 Loss 1.3723\n",
      "Epoch 5 Batch 2309 Loss 1.2047\n",
      "Epoch 5 Batch 2310 Loss 0.9357\n",
      "Epoch 5 Batch 2311 Loss 1.1201\n",
      "Epoch 5 Batch 2312 Loss 1.0900\n",
      "Epoch 5 Batch 2313 Loss 1.0352\n",
      "Epoch 5 Batch 2314 Loss 1.1644\n",
      "Epoch 5 Batch 2315 Loss 0.8035\n",
      "Epoch 5 Batch 2316 Loss 0.9541\n",
      "Epoch 5 Batch 2317 Loss 1.1630\n",
      "Epoch 5 Batch 2318 Loss 0.9788\n",
      "Epoch 5 Batch 2319 Loss 1.3754\n",
      "Epoch 5 Batch 2320 Loss 1.1064\n",
      "Epoch 5 Batch 2321 Loss 1.3816\n",
      "Epoch 5 Batch 2322 Loss 1.0996\n",
      "Epoch 5 Batch 2323 Loss 1.0563\n",
      "Epoch 5 Batch 2324 Loss 0.9400\n",
      "Epoch 5 Batch 2325 Loss 1.0714\n",
      "Epoch 5 Batch 2326 Loss 1.5453\n",
      "Epoch 5 Batch 2327 Loss 0.9730\n",
      "Epoch 5 Batch 2328 Loss 1.3556\n",
      "Epoch 5 Batch 2329 Loss 1.2642\n",
      "Epoch 5 Batch 2330 Loss 1.0384\n",
      "Epoch 5 Batch 2331 Loss 1.0389\n",
      "Epoch 5 Batch 2332 Loss 1.3474\n",
      "Epoch 5 Batch 2333 Loss 1.1471\n",
      "Epoch 5 Batch 2334 Loss 1.0781\n",
      "Epoch 5 Batch 2335 Loss 1.1436\n",
      "Epoch 5 Batch 2336 Loss 1.1208\n",
      "Epoch 5 Batch 2337 Loss 1.2647\n",
      "Epoch 5 Batch 2338 Loss 0.9605\n",
      "Epoch 5 Batch 2339 Loss 0.9764\n",
      "Epoch 5 Batch 2340 Loss 1.0558\n",
      "Epoch 5 Batch 2341 Loss 0.9299\n",
      "Epoch 5 Batch 2342 Loss 1.3767\n",
      "Epoch 5 Batch 2343 Loss 1.2683\n",
      "Epoch 5 Batch 2344 Loss 1.0009\n",
      "Epoch 5 Batch 2345 Loss 1.0005\n",
      "Epoch 5 Batch 2346 Loss 0.9823\n",
      "Epoch 5 Batch 2347 Loss 1.2124\n",
      "Epoch 5 Batch 2348 Loss 1.2450\n",
      "Epoch 5 Batch 2349 Loss 1.5148\n",
      "Epoch 5 Batch 2350 Loss 1.1872\n",
      "Epoch 5 Batch 2351 Loss 1.0487\n",
      "Epoch 5 Batch 2352 Loss 1.2067\n",
      "Epoch 5 Batch 2353 Loss 1.1779\n",
      "Epoch 5 Batch 2354 Loss 1.2469\n",
      "Epoch 5 Batch 2355 Loss 1.1138\n",
      "Epoch 5 Batch 2356 Loss 1.0350\n",
      "Epoch 5 Batch 2357 Loss 1.0177\n",
      "Epoch 5 Batch 2358 Loss 1.3895\n",
      "Epoch 5 Batch 2359 Loss 0.8851\n",
      "Epoch 5 Batch 2360 Loss 1.0527\n",
      "Epoch 5 Batch 2361 Loss 0.9898\n",
      "Epoch 5 Batch 2362 Loss 0.9808\n",
      "Epoch 5 Batch 2363 Loss 1.0135\n",
      "Epoch 5 Batch 2364 Loss 1.1728\n",
      "Epoch 5 Batch 2365 Loss 1.2705\n",
      "Epoch 5 Batch 2366 Loss 1.3254\n",
      "Epoch 5 Batch 2367 Loss 1.2403\n",
      "Epoch 5 Batch 2368 Loss 1.0949\n",
      "Epoch 5 Batch 2369 Loss 1.4657\n",
      "Epoch 5 Batch 2370 Loss 0.9790\n",
      "Epoch 5 Batch 2371 Loss 1.3497\n",
      "Epoch 5 Batch 2372 Loss 1.1034\n",
      "Epoch 5 Batch 2373 Loss 1.2117\n",
      "Epoch 5 Batch 2374 Loss 0.8675\n",
      "Epoch 5 Batch 2375 Loss 1.0203\n",
      "Epoch 5 Batch 2376 Loss 1.0440\n",
      "Epoch 5 Batch 2377 Loss 1.3211\n",
      "Epoch 5 Batch 2378 Loss 0.9610\n",
      "Epoch 5 Batch 2379 Loss 1.2305\n",
      "Epoch 5 Batch 2380 Loss 1.1293\n",
      "Epoch 5 Batch 2381 Loss 1.0782\n",
      "Epoch 5 Batch 2382 Loss 1.3649\n",
      "Epoch 5 Batch 2383 Loss 1.0868\n",
      "Epoch 5 Batch 2384 Loss 1.2076\n",
      "Epoch 5 Batch 2385 Loss 1.1432\n",
      "Epoch 5 Batch 2386 Loss 1.0990\n",
      "Epoch 5 Batch 2387 Loss 1.2497\n",
      "Epoch 5 Batch 2388 Loss 1.2038\n",
      "Epoch 5 Batch 2389 Loss 1.3567\n",
      "Epoch 5 Batch 2390 Loss 1.0750\n",
      "Epoch 5 Batch 2391 Loss 1.2567\n",
      "Epoch 5 Batch 2392 Loss 0.9757\n",
      "Epoch 5 Batch 2393 Loss 1.0976\n",
      "Epoch 5 Batch 2394 Loss 1.0895\n",
      "Epoch 5 Batch 2395 Loss 1.1969\n",
      "Epoch 5 Batch 2396 Loss 1.0699\n",
      "Epoch 5 Batch 2397 Loss 0.9629\n",
      "Epoch 5 Batch 2398 Loss 1.1169\n",
      "Epoch 5 Batch 2399 Loss 1.2142\n",
      "Epoch 5 Batch 2400 Loss 1.2123\n",
      "Epoch 5 Batch 2401 Loss 0.9726\n",
      "Epoch 5 Batch 2402 Loss 1.2071\n",
      "Epoch 5 Batch 2403 Loss 1.1884\n",
      "Epoch 5 Batch 2404 Loss 1.2819\n",
      "Epoch 5 Batch 2405 Loss 1.3546\n",
      "Epoch 5 Batch 2406 Loss 1.1069\n",
      "Epoch 5 Batch 2407 Loss 1.2209\n",
      "Epoch 5 Batch 2408 Loss 1.2594\n",
      "Epoch 5 Batch 2409 Loss 1.1360\n",
      "Epoch 5 Batch 2410 Loss 1.1798\n",
      "Epoch 5 Batch 2411 Loss 1.3673\n",
      "Epoch 5 Batch 2412 Loss 1.3259\n",
      "Epoch 5 Batch 2413 Loss 1.1276\n",
      "Epoch 5 Batch 2414 Loss 1.0701\n",
      "Epoch 5 Batch 2415 Loss 1.2715\n",
      "Epoch 5 Batch 2416 Loss 1.1583\n",
      "Epoch 5 Batch 2417 Loss 1.0661\n",
      "Epoch 5 Batch 2418 Loss 0.9828\n",
      "Epoch 5 Batch 2419 Loss 0.9836\n",
      "Epoch 5 Batch 2420 Loss 0.9177\n",
      "Epoch 5 Batch 2421 Loss 1.2040\n",
      "Epoch 5 Batch 2422 Loss 0.9670\n",
      "Epoch 5 Batch 2423 Loss 0.8611\n",
      "Epoch 5 Batch 2424 Loss 1.3946\n",
      "Epoch 5 Batch 2425 Loss 1.5918\n",
      "Epoch 5 Batch 2426 Loss 1.0468\n",
      "Epoch 5 Batch 2427 Loss 1.1965\n",
      "Epoch 5 Batch 2428 Loss 1.1161\n",
      "Epoch 5 Batch 2429 Loss 1.3074\n",
      "Epoch 5 Batch 2430 Loss 1.1045\n",
      "Epoch 5 Batch 2431 Loss 1.1507\n",
      "Epoch 5 Batch 2432 Loss 1.0007\n",
      "Epoch 5 Batch 2433 Loss 1.0122\n",
      "Epoch 5 Batch 2434 Loss 1.0911\n",
      "Epoch 5 Batch 2435 Loss 0.9238\n",
      "Epoch 5 Batch 2436 Loss 0.7387\n",
      "Epoch 5 Batch 2437 Loss 1.0590\n",
      "Epoch 5 Batch 2438 Loss 1.0848\n",
      "Epoch 5 Batch 2439 Loss 1.1520\n",
      "Epoch 5 Batch 2440 Loss 1.5438\n",
      "Epoch 5 Batch 2441 Loss 1.0108\n",
      "Epoch 5 Batch 2442 Loss 0.9978\n",
      "Epoch 5 Batch 2443 Loss 1.4184\n",
      "Epoch 5 Batch 2444 Loss 0.9981\n",
      "Epoch 5 Batch 2445 Loss 1.2604\n",
      "Epoch 5 Batch 2446 Loss 1.1924\n",
      "Epoch 5 Batch 2447 Loss 1.2819\n",
      "Epoch 5 Batch 2448 Loss 1.1110\n",
      "Epoch 5 Batch 2449 Loss 1.5426\n",
      "Epoch 5 Batch 2450 Loss 1.1847\n",
      "Epoch 5 Batch 2451 Loss 1.2265\n",
      "Epoch 5 Batch 2452 Loss 0.9807\n",
      "Epoch 5 Batch 2453 Loss 1.1910\n",
      "Epoch 5 Batch 2454 Loss 0.8649\n",
      "Epoch 5 Batch 2455 Loss 1.1909\n",
      "Epoch 5 Batch 2456 Loss 0.8861\n",
      "Epoch 5 Batch 2457 Loss 1.1503\n",
      "Epoch 5 Batch 2458 Loss 0.9994\n",
      "Epoch 5 Batch 2459 Loss 1.1712\n",
      "Epoch 5 Batch 2460 Loss 1.0538\n",
      "Epoch 5 Batch 2461 Loss 0.8800\n",
      "Epoch 5 Batch 2462 Loss 1.2160\n",
      "Epoch 5 Batch 2463 Loss 1.0788\n",
      "Epoch 5 Batch 2464 Loss 1.2803\n",
      "Epoch 5 Batch 2465 Loss 1.2146\n",
      "Epoch 5 Batch 2466 Loss 1.1419\n",
      "Epoch 5 Batch 2467 Loss 1.1971\n",
      "Epoch 5 Batch 2468 Loss 1.0915\n",
      "Epoch 5 Batch 2469 Loss 1.1179\n",
      "Epoch 5 Batch 2470 Loss 0.8674\n",
      "Epoch 5 Batch 2471 Loss 0.8552\n",
      "Epoch 5 Batch 2472 Loss 1.2926\n",
      "Epoch 5 Batch 2473 Loss 1.0746\n",
      "Epoch 5 Batch 2474 Loss 1.1923\n",
      "Epoch 5 Batch 2475 Loss 1.0092\n",
      "Epoch 5 Batch 2476 Loss 1.5509\n",
      "Epoch 5 Batch 2477 Loss 1.3580\n",
      "Epoch 5 Batch 2478 Loss 1.3359\n",
      "Epoch 5 Batch 2479 Loss 1.1907\n",
      "Epoch 5 Batch 2480 Loss 1.0450\n",
      "Epoch 5 Batch 2481 Loss 1.2544\n",
      "Epoch 5 Batch 2482 Loss 1.0702\n",
      "Epoch 5 Batch 2483 Loss 1.2186\n",
      "Epoch 5 Batch 2484 Loss 1.1694\n",
      "Epoch 5 Batch 2485 Loss 1.1982\n",
      "Epoch 5 Batch 2486 Loss 0.8221\n",
      "Epoch 5 Batch 2487 Loss 1.4474\n",
      "Epoch 5 Batch 2488 Loss 1.2739\n",
      "Epoch 5 Batch 2489 Loss 1.0387\n",
      "Epoch 5 Batch 2490 Loss 1.4158\n",
      "Epoch 5 Batch 2491 Loss 1.3947\n",
      "Epoch 5 Batch 2492 Loss 1.4732\n",
      "Epoch 5 Batch 2493 Loss 0.9771\n",
      "Epoch 5 Batch 2494 Loss 1.2196\n",
      "Epoch 5 Batch 2495 Loss 1.2466\n",
      "Epoch 5 Batch 2496 Loss 1.1343\n",
      "Epoch 5 Batch 2497 Loss 1.0826\n",
      "Epoch 5 Batch 2498 Loss 1.4327\n",
      "Epoch 5 Batch 2499 Loss 1.0378\n",
      "Epoch 5 Batch 2500 Loss 1.1122\n",
      "Epoch 5 Batch 2501 Loss 1.2387\n",
      "Epoch 5 Batch 2502 Loss 1.0549\n",
      "Epoch 5 Batch 2503 Loss 1.0938\n",
      "Epoch 5 Batch 2504 Loss 1.1810\n",
      "Epoch 5 Batch 2505 Loss 1.2256\n",
      "Epoch 5 Batch 2506 Loss 1.0415\n",
      "Epoch 5 Batch 2507 Loss 1.1836\n",
      "Epoch 5 Batch 2508 Loss 1.3000\n",
      "Epoch 5 Batch 2509 Loss 1.0325\n",
      "Epoch 5 Batch 2510 Loss 1.4750\n",
      "Epoch 5 Batch 2511 Loss 1.3562\n",
      "Epoch 5 Batch 2512 Loss 0.9894\n",
      "Epoch 5 Batch 2513 Loss 1.3040\n",
      "Epoch 5 Batch 2514 Loss 1.2586\n",
      "Epoch 5 Batch 2515 Loss 1.4056\n",
      "Epoch 5 Batch 2516 Loss 1.0261\n",
      "Epoch 5 Batch 2517 Loss 1.2574\n",
      "Epoch 5 Batch 2518 Loss 1.0583\n",
      "Epoch 5 Batch 2519 Loss 1.2104\n",
      "Epoch 5 Batch 2520 Loss 1.2742\n",
      "Epoch 5 Batch 2521 Loss 1.2228\n",
      "Epoch 5 Batch 2522 Loss 1.0262\n",
      "Epoch 5 Batch 2523 Loss 1.2504\n",
      "Epoch 5 Batch 2524 Loss 0.7876\n",
      "Epoch 5 Batch 2525 Loss 1.3567\n",
      "Epoch 5 Batch 2526 Loss 1.0990\n",
      "Epoch 5 Batch 2527 Loss 1.1067\n",
      "Epoch 5 Batch 2528 Loss 1.2707\n",
      "Epoch 5 Batch 2529 Loss 1.1302\n",
      "Epoch 5 Batch 2530 Loss 1.1902\n",
      "Epoch 5 Batch 2531 Loss 1.3050\n",
      "Epoch 5 Batch 2532 Loss 1.0928\n",
      "Epoch 5 Batch 2533 Loss 1.4295\n",
      "Epoch 5 Batch 2534 Loss 1.2022\n",
      "Epoch 5 Batch 2535 Loss 1.3427\n",
      "Epoch 5 Batch 2536 Loss 1.3708\n",
      "Epoch 5 Batch 2537 Loss 1.2704\n",
      "Epoch 5 Batch 2538 Loss 1.3267\n",
      "Epoch 5 Batch 2539 Loss 1.0416\n",
      "Epoch 5 Batch 2540 Loss 1.0876\n",
      "Epoch 5 Batch 2541 Loss 1.3839\n",
      "Epoch 5 Batch 2542 Loss 1.1125\n",
      "Epoch 5 Batch 2543 Loss 1.3395\n",
      "Epoch 5 Batch 2544 Loss 1.1246\n",
      "Epoch 5 Batch 2545 Loss 1.2835\n",
      "Epoch 5 Batch 2546 Loss 1.1341\n",
      "Epoch 5 Batch 2547 Loss 1.0625\n",
      "Epoch 5 Batch 2548 Loss 1.2033\n",
      "Epoch 5 Batch 2549 Loss 1.0626\n",
      "Epoch 5 Batch 2550 Loss 0.8767\n",
      "Epoch 5 Batch 2551 Loss 1.2272\n",
      "Epoch 5 Batch 2552 Loss 1.1625\n",
      "Epoch 5 Batch 2553 Loss 1.2333\n",
      "Epoch 5 Batch 2554 Loss 1.3439\n",
      "Epoch 5 Batch 2555 Loss 1.0948\n",
      "Epoch 5 Batch 2556 Loss 1.2241\n",
      "Epoch 5 Batch 2557 Loss 1.0437\n",
      "Epoch 5 Batch 2558 Loss 1.1992\n",
      "Epoch 5 Batch 2559 Loss 1.1824\n",
      "Epoch 5 Batch 2560 Loss 1.0318\n",
      "Epoch 5 Batch 2561 Loss 1.2037\n",
      "Epoch 5 Batch 2562 Loss 1.0501\n",
      "Epoch 5 Batch 2563 Loss 1.2467\n",
      "Epoch 5 Batch 2564 Loss 1.0190\n",
      "Epoch 5 Batch 2565 Loss 1.3830\n",
      "Epoch 5 Batch 2566 Loss 0.8673\n",
      "Epoch 5 Batch 2567 Loss 1.2135\n",
      "Epoch 5 Batch 2568 Loss 1.1573\n",
      "Epoch 5 Batch 2569 Loss 0.9088\n",
      "Epoch 5 Batch 2570 Loss 1.0935\n",
      "Epoch 5 Batch 2571 Loss 1.1946\n",
      "Epoch 5 Batch 2572 Loss 1.1134\n",
      "Epoch 5 Batch 2573 Loss 1.1349\n",
      "Epoch 5 Batch 2574 Loss 1.4523\n",
      "Epoch 5 Batch 2575 Loss 1.0148\n",
      "Epoch 5 Batch 2576 Loss 1.0292\n",
      "Epoch 5 Batch 2577 Loss 1.0637\n",
      "Epoch 5 Batch 2578 Loss 1.3171\n",
      "Epoch 5 Batch 2579 Loss 0.7645\n",
      "Epoch 5 Batch 2580 Loss 1.0742\n",
      "Epoch 5 Batch 2581 Loss 1.1108\n",
      "Epoch 5 Batch 2582 Loss 1.1507\n",
      "Epoch 5 Batch 2583 Loss 1.3133\n",
      "Epoch 5 Batch 2584 Loss 1.0899\n",
      "Epoch 5 Batch 2585 Loss 1.3489\n",
      "Epoch 5 Batch 2586 Loss 1.2771\n",
      "Epoch 5 Batch 2587 Loss 1.2512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [2:40:48<00:00, 1929.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Batch 2588 Loss 1.2091\n",
      "Epoch 5 Loss 1.1372\n",
      "Time taken for 1 epoch 1921.8741664886475 sec\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = params[\"epochs\"]\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')\n",
    "    \n",
    "for epoch in tqdm(range(epochs)):\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_save_path = ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/pycharm_class04/data/checkpoints/training_checkpoints_seq2seq/ckpt/ckpt-3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time taken for 1 epoch 524.4936063289642 sec\n",
    "\n",
    "Epoch 5 Loss 1.1372\n",
    "\n",
    "Time taken for 1 epoch 1921.8741664886475 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(Seq2Seq=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, seq2seq_checkpoint_prefix, max_to_keep=5)\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ianxiao/Code/DeepLearning/class04/data/checkpoints/training_checkpoints_seq2seq/ckpt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianxiao/Code/DeepLearning/class04/data/checkpoints/training_checkpoints_seq2seq/ckpt/ckpt-3\n"
     ]
    }
   ],
   "source": [
    "print(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,inputs, vocab, params):\n",
    "    attention_plot = np.zeros((params['max_dec_len'], params['max_enc_len']))\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    \n",
    "    enc_hidden = tf.zeros((1, params[\"enc_units\"]))\n",
    "    \n",
    "    enc_output, enc_hidden = model.encoder(inputs, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    dec_input = tf.expand_dims([vocab.START_DECODING_INDEX], 0)\n",
    "    \n",
    "    context_vector, _ = model.attention(dec_hidden, enc_output)\n",
    "\n",
    "    for t in range(params['max_dec_len']):\n",
    "        \n",
    "        context_vector, attention_weights = model.attention(dec_hidden, enc_output)\n",
    "        \n",
    "        predictions, dec_hidden = model.decoder(dec_input,\n",
    "                                         dec_hidden,\n",
    "                                         enc_output,\n",
    "                                         context_vector)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        \n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += vocab.id2word[predicted_id] + ' '\n",
    "        if vocab.id2word[predicted_id] == '<STOP>':\n",
    "            return result, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(sentence, vocab, params):\n",
    "    \n",
    "    sentence, sentence_ids = preprocess_sentence(sentence,params[\"max_enc_len\"],vocab.word2id)\n",
    "    \n",
    "    result, attention_plot = evaluate(model,sentence_ids, vocab, params)\n",
    "    \n",
    "    if vocab.PAD_TOKEN in sentence:\n",
    "        sentence = sentence[:sentence.index(vocab.PAD_TOKEN)]\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted summary: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='技师说：右侧排气管上方，缸体上靠近变速箱|车主说：[图片]|车主说：是不是这个？|车主说：这个号不对|车主说：[图片]|技师说：你先拓下来跟行车证对下|车主说：对了，不是|车主说：你有没有图片？|技师说：那年的车|车主说：14年3.0牧马人|技师说：做前轮这边缸体上|车主说：有没有图片画个圈圈|车主说：要不要拆什么|车主说：？？|技师说：不要拆|车主说：都看了，看不到啊|技师说：[图片]|车主说：[图片]|车主说：这个发动机怎么和我的不一样|技师说：你是客户还是维修技师|技师说：柴油还是汽油版|车主说：汽油|车主说：我自己的车，过户要用|技师说：你要找维修人员，或者专门拓号的人'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <START> 技师说 右侧 排气管 上方 ， 缸体 上 靠近 变速箱 车主说 车主说 是不是 ？ 车主说 号 不 车主说 技师说 先 <UNK> 行车证 对下 车主说 ， 不是 车主说 有没有 ？ 技师说 那年 车 车主说 14 年 3.0 牧马人 技师说 做 前轮 缸体 上 车主说 有没有 画个 圈圈 车主说 不要 拆 车主说 ？ ？ 技师说 不要 拆 车主说 都 看 ， 看不到 技师说 车主说 车主说 发动机 不 技师说 客户 维修 技师 技师说 柴油 汽油 版 车主说 汽油 车主说 车 ， 过户 技师说 找 维修 人员 ， 专门 拓号 人 <STOP> \n",
      "Predicted summary: 排气管 上 ， 缸体 上 缸体 上 <STOP> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_summary(sentence, vocab, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 批量预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_greedy_decode(model, batch_data, vocab, params):\n",
    "    # 判断输入长度\n",
    "    batch_size = len(batch_data)\n",
    "    # 开辟结果存储list\n",
    "    predicts = ['']*batch_size\n",
    "    \n",
    "    inps = tf.convert_to_tensor(batch_data)\n",
    "    # 0. 初始化 encoder 隐藏层\n",
    "    hidden = tf.zeros((batch_size, params['enc_units']))\n",
    "    # 1. 构建encoder\n",
    "    enc_output, enc_hidden = model.encoder(inps, hidden)\n",
    "    # 2. 初始化 decoder 隐藏层\n",
    "    dec_hidden = enc_hidden\n",
    "    # 3. 初始化 decoder的输入 <START> * BATCH_SIZE\n",
    "    dec_input = tf.expand_dims([vocab.START_DECODING_INDEX] * batch_size, 1)\n",
    "    # 4. 基于注意力的context_vector\n",
    "    context_vector, _ = model.attention(dec_hidden, enc_output)\n",
    "    # 5. Teacher forcing - feeding the target as the next input\n",
    "    for t in range(params['max_dec_len']):\n",
    "        # 6. 单步预测\n",
    "        context_vector, attention_weights = model.attention(dec_hidden, enc_output)\n",
    "        predictions, dec_hidden = model.decoder(dec_input,\n",
    "                                               dec_hidden,\n",
    "                                               enc_output,\n",
    "                                               context_vector)\n",
    "        # 7. id转换 贪婪搜索\n",
    "        predicted_ids = tf.argmax(predictions, axis=1).numpy()\n",
    "        for index, predicted_id in enumerate(predicted_ids):\n",
    "            predicts[index] += vocab.id2word[predicted_id] + ' '\n",
    "        # 8. using teacher forcing\n",
    "        dec_input = tf.expand_dims(predicted_ids, 1)\n",
    "        \n",
    "    # 9. 预测结果整理\n",
    "    results = []\n",
    "    for predict in predicts:\n",
    "        # 9.1 去掉句子前后空格\n",
    "        predict = predict.strip()\n",
    "        # 9.2 发现<STOP> 截断\n",
    "        if vocab.STOP_DECODING in predict:\n",
    "            predict = predict[:predict.index(vocab.STOP_DECODING)]\n",
    "        results.append(predict)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, data_X, batch_size, vocab, params):\n",
    "    # 存储结果\n",
    "    results = []\n",
    "    # 样本数量\n",
    "    sample_size = len(data_X)\n",
    "    # batch 操作轮数 math.ceil向上取整 小数 +1\n",
    "    # 因为最后一个batch可能不足一个batch size 大小 ,但是依然需要计算\n",
    "    steps_epoch = math.ceil(sample_size / batch_size)\n",
    "    # [0,steps_epoch)\n",
    "    for i in tqdm(range(steps_epoch)):\n",
    "        batch_data = data_X[i * batch_size:(i + 1) * batch_size]\n",
    "        results += batch_greedy_decode(model, batch_data, vocab, params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [22:16<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 28min 37s, sys: 24min 20s, total: 1h 52min 57s\n",
      "Wall time: 22min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_X = load_test_dataset(params[\"max_enc_len\"])\n",
    "results = greedy_decode(model, test_X, params['batch_size'], vocab, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)/params['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'车子 最低 配 汽车 大师 APP ， APP 内 搜索 名字 ， '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Question</th>\n",
       "      <th>Dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>大众(进口)</td>\n",
       "      <td>高尔夫(进口)</td>\n",
       "      <td>我的帕萨特烧机油怎么办怎么办？</td>\n",
       "      <td>技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>一汽-大众奥迪</td>\n",
       "      <td>奥迪A6</td>\n",
       "      <td>修一下多少钱是换还是修</td>\n",
       "      <td>技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>上汽大众</td>\n",
       "      <td>帕萨特</td>\n",
       "      <td>帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵</td>\n",
       "      <td>技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>南京菲亚特</td>\n",
       "      <td>派力奥</td>\n",
       "      <td>发动机漏气会有什么征兆？</td>\n",
       "      <td>技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>东风本田</td>\n",
       "      <td>思铂睿</td>\n",
       "      <td>请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...</td>\n",
       "      <td>技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID    Brand    Model                                           Question  \\\n",
       "0  Q1   大众(进口)  高尔夫(进口)                                    我的帕萨特烧机油怎么办怎么办？   \n",
       "1  Q2  一汽-大众奥迪     奥迪A6                                        修一下多少钱是换还是修   \n",
       "2  Q3     上汽大众      帕萨特           帕萨特领域    喇叭坏了  店里说方向盘里线坏了 换一根两三百不等 感觉太贵    \n",
       "3  Q4    南京菲亚特      派力奥                                       发动机漏气会有什么征兆？   \n",
       "4  Q5     东风本田      思铂睿  请问 那天右后胎扎了订，补了胎后跑高速80多开始有点抖，110时速以上抖动明显，以为是未做动...   \n",
       "\n",
       "                                            Dialogue  \n",
       "0  技师说：你好，请问你的车跑了多少公里了，如果在保修期内，可以到当地的4店里面进行检查维修。如...  \n",
       "1        技师说：你好师傅！抛光处理一下就好了！50元左右就好了，希望能够帮到你！祝你生活愉快！  \n",
       "2                        技师说：你好，气囊油丝坏了吗，这个价格不贵。可以更换。  \n",
       "3  技师说：你好！一：发动机没力，并伴有“啪啪”的漏气声音。二：发动机没力，并伴有排气管冒黑烟。...  \n",
       "4  技师说：你好师傅！可能前轮平衡快脱落或者不平衡造成的！建议前轮做一下动平衡就好了！希望能够帮...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读入提交数据\n",
    "test_df=pd.read_csv(test_data_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判断是否有空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9121\n",
      "10574\n"
     ]
    }
   ],
   "source": [
    "for idx,result in enumerate(results):\n",
    "    if result=='':print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 赋值结果\n",
    "test_df['Prediction']=results\n",
    "#　提取ID和预测结果两列\n",
    "test_df=test_df[['QID','Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>你好 ！ 车子 烧 机油 ， 建议 及时 维修 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>显示 ， 需要 进行 抛光 处理 ， 价位 800 左右 ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>气囊 问题 ， 更换 ， 价格 不 贵 ， 价格 不 贵 ， 价格 不 贵 ， 价格 不 贵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>分析 检查 排气管 漏气 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>你好 ！ 这种 情况 可能 轮胎 平衡 轴 位置 不 平衡 导致 ， 建议 做个 四轮 动平衡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                         Prediction\n",
       "0  Q1                         你好 ！ 车子 烧 机油 ， 建议 及时 维修 。 \n",
       "1  Q2                    显示 ， 需要 进行 抛光 处理 ， 价位 800 左右 ！ \n",
       "2  Q3  气囊 问题 ， 更换 ， 价格 不 贵 ， 价格 不 贵 ， 价格 不 贵 ， 价格 不 贵...\n",
       "3  Q4                                    分析 检查 排气管 漏气 。 \n",
       "4  Q5   你好 ！ 这种 情况 可能 轮胎 平衡 轴 位置 不 平衡 导致 ， 建议 做个 四轮 动平衡 "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结果处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QID           0\n",
       "Prediction    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判断是否有空值\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([9121, 10574], dtype='int64')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['Prediction']==''].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_proc(sentence):\n",
    "    sentence=sentence.lstrip(' ，！。') #lstrip截掉字符串左边的空格或指定字符\n",
    "    sentence=sentence.replace(' ','')\n",
    "    if sentence=='':\n",
    "        sentence='随时联系'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Prediction']=test_df['Prediction'].apply(submit_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QID           Q9122\n",
       "Prediction     随时联系\n",
       "Name: 9121, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[9121,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>你好！车子烧机油，建议及时维修。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>显示，需要进行抛光处理，价位800左右！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>气囊问题，更换，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>分析检查排气管漏气。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>你好！这种情况可能轮胎平衡轴位置不平衡导致，建议做个四轮动平衡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                                         Prediction\n",
       "0  Q1                                   你好！车子烧机油，建议及时维修。\n",
       "1  Q2                               显示，需要进行抛光处理，价位800左右！\n",
       "2  Q3  气囊问题，更换，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不...\n",
       "3  Q4                                         分析检查排气管漏气。\n",
       "4  Q5                    你好！这种情况可能轮胎平衡轴位置不平衡导致，建议做个四轮动平衡"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_utils import get_result_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取结果存储路径\n",
    "\n",
    "result_save_path = get_result_filename(params[\"batch_size\"],params[\"epochs\"] , params[\"max_enc_len\"], params[\"embedding_dim\"],commit='_4_1_submit_greedy_search_seq2seq_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ianxiao/Code/DeepLearning/class04/result/2020_07_13_17_46_49_batch_size_32_epochs_5_max_length_inp_200_embedding_dim_300_4_1_submit_greedy_search_seq2seq_code.csv'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果.\n",
    "test_df.to_csv(result_save_path,index=None,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>你好！车子烧机油，建议及时维修。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>显示，需要进行抛光处理，价位800左右！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>气囊问题，更换，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>分析检查排气管漏气。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>你好！这种情况可能轮胎平衡轴位置不平衡导致，建议做个四轮动平衡</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q6</td>\n",
       "      <td>车子排气管热涨冷缩，车子排气管积水，排气管积水，排气管积水，排气管积水，排气管积水，排气管积...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q7</td>\n",
       "      <td>你好！防冻液两年添加，添加相同颜色。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q8</td>\n",
       "      <td>发动机机油灯亮，发动机故障灯亮，发动机动力下降，发动机动力下降，发动机动力下降，发动机动力下...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q9</td>\n",
       "      <td>来看，轮胎鼓包，鼓包，轮胎花纹深度出现问题，轮胎鼓包，胎侧没有鼓包，轮胎鼓包，胎侧深度，鼓包...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q10</td>\n",
       "      <td>这种情况主要天气太冷，时间长以后，没有问题，不用担心。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QID                                         Prediction\n",
       "0   Q1                                   你好！车子烧机油，建议及时维修。\n",
       "1   Q2                               显示，需要进行抛光处理，价位800左右！\n",
       "2   Q3  气囊问题，更换，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不贵，价格不...\n",
       "3   Q4                                         分析检查排气管漏气。\n",
       "4   Q5                    你好！这种情况可能轮胎平衡轴位置不平衡导致，建议做个四轮动平衡\n",
       "5   Q6  车子排气管热涨冷缩，车子排气管积水，排气管积水，排气管积水，排气管积水，排气管积水，排气管积...\n",
       "6   Q7                                 你好！防冻液两年添加，添加相同颜色。\n",
       "7   Q8  发动机机油灯亮，发动机故障灯亮，发动机动力下降，发动机动力下降，发动机动力下降，发动机动力下...\n",
       "8   Q9  来看，轮胎鼓包，鼓包，轮胎花纹深度出现问题，轮胎鼓包，胎侧没有鼓包，轮胎鼓包，胎侧深度，鼓包...\n",
       "9  Q10                        这种情况主要天气太冷，时间长以后，没有问题，不用担心。"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取结果\n",
    "test_df=pd.read_csv(result_save_path)\n",
    "# 查看格式\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 角度1：QA 问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 角度2： 摘要问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 角度3： 阅读理解问题\n",
    "\n",
    "> 如果看成是阅读理解问题， 那么就是从Conversation中找出能回答Problem的答案， 由于目前的阅读理解数据集的答案长度通常比较短（一般是几个单词），所以state of the art的作法是根据Problem，从Context中选择一段作为答案，模型只要输出答案的开始和结束位置即可。 但是这个任务的report有点长，常常出现几十个甚至上百个词， 而且report中的词好像并不完全是来自于Conversation。 Report中67.7%的词来自于Conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "* [Download a different dataset](http://www.manythings.org/anki/) to experiment with translations, for example, English to German, or English to French.\n",
    "* Experiment with training on a larger dataset, or using more epochs\n",
    "* [Neural Machine Translation (seq2seq) Tutorial](https://github.com/tensorflow/nmt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
