{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目录\n",
    "\n",
    "* 词向量导入\n",
    "* 数据集加载\n",
    "* 构建word2id并pad成相同长度\n",
    "* 求词向量均值和方差\n",
    "* 生成词向量\n",
    "* 生成训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04052734,  0.0625    , -0.01745605,  0.07861328,  0.03271484,\n",
       "       -0.01263428,  0.00964355,  0.12353516, -0.02148438,  0.15234375,\n",
       "       -0.05834961, -0.10644531,  0.02124023,  0.13574219, -0.13183594,\n",
       "        0.17675781,  0.27148438,  0.13769531, -0.17382812, -0.14160156,\n",
       "       -0.03076172,  0.19628906, -0.03295898,  0.125     ,  0.25390625,\n",
       "        0.12695312, -0.15234375,  0.03198242,  0.01135254, -0.01361084,\n",
       "       -0.12890625,  0.01019287,  0.23925781, -0.08447266,  0.140625  ,\n",
       "        0.13085938, -0.04516602,  0.06494141,  0.02539062,  0.05615234,\n",
       "        0.24609375, -0.20507812,  0.23632812, -0.00860596, -0.02294922,\n",
       "        0.05078125,  0.10644531, -0.03564453,  0.08740234, -0.05712891,\n",
       "        0.08496094,  0.23535156, -0.10107422, -0.03564453, -0.04736328,\n",
       "        0.04736328, -0.14550781, -0.10986328,  0.14746094, -0.23242188,\n",
       "       -0.07275391,  0.19628906, -0.37890625, -0.07226562,  0.04833984,\n",
       "        0.11914062,  0.06103516, -0.12109375, -0.27929688,  0.05200195,\n",
       "        0.04907227, -0.02709961,  0.1328125 ,  0.03369141, -0.32226562,\n",
       "        0.04223633, -0.08789062,  0.15429688,  0.09472656,  0.10351562,\n",
       "       -0.02856445,  0.00128174, -0.00427246,  0.24609375, -0.05957031,\n",
       "       -0.16894531, -0.09619141,  0.16796875,  0.0133667 ,  0.04882812,\n",
       "        0.08349609,  0.06347656, -0.00872803, -0.08642578, -0.03857422,\n",
       "       -0.08251953,  0.15722656,  0.22753906, -0.00762939, -0.19921875,\n",
       "       -0.06347656,  0.12792969, -0.06347656, -0.03027344,  0.0456543 ,\n",
       "        0.06298828, -0.02526855, -0.06787109, -0.01141357, -0.13574219,\n",
       "        0.02978516,  0.10400391, -0.15917969, -0.08447266,  0.29882812,\n",
       "       -0.12597656,  0.11425781, -0.08105469, -0.09082031, -0.07910156,\n",
       "       -0.11181641, -0.09619141,  0.02770996,  0.14257812, -0.26757812,\n",
       "       -0.09375   ,  0.03979492, -0.17871094, -0.02819824,  0.01464844,\n",
       "       -0.31640625, -0.24511719, -0.08935547,  0.09716797, -0.00964355,\n",
       "       -0.14746094,  0.15234375,  0.21582031,  0.05981445,  0.23828125,\n",
       "       -0.05151367,  0.14941406,  0.13574219, -0.03222656, -0.265625  ,\n",
       "       -0.11181641, -0.23046875, -0.140625  ,  0.25585938, -0.15429688,\n",
       "        0.1796875 ,  0.15527344, -0.21582031,  0.36328125, -0.1015625 ,\n",
       "        0.04980469,  0.07177734, -0.14550781, -0.03198242,  0.00952148,\n",
       "       -0.12109375,  0.12109375,  0.09765625,  0.07763672,  0.3203125 ,\n",
       "       -0.22265625, -0.08447266, -0.10742188,  0.11279297, -0.13867188,\n",
       "       -0.21875   ,  0.0145874 ,  0.13378906, -0.00921631,  0.00921631,\n",
       "        0.16894531,  0.16894531, -0.078125  , -0.00665283,  0.03735352,\n",
       "       -0.10888672, -0.25390625,  0.01452637, -0.09716797, -0.19628906,\n",
       "       -0.01782227, -0.28125   , -0.02050781, -0.02905273, -0.09375   ,\n",
       "       -0.17675781,  0.21484375, -0.05224609, -0.11572266, -0.01977539,\n",
       "       -0.10839844, -0.01342773, -0.15332031, -0.140625  , -0.11816406,\n",
       "        0.09228516,  0.109375  ,  0.05761719, -0.03466797,  0.03564453,\n",
       "       -0.12011719, -0.14257812, -0.00072479, -0.06689453,  0.11914062,\n",
       "       -0.10449219,  0.07861328, -0.12792969,  0.09570312, -0.00817871,\n",
       "        0.07128906,  0.20703125, -0.03149414,  0.09570312,  0.17285156,\n",
       "       -0.07958984, -0.02429199, -0.07519531, -0.07568359,  0.09521484,\n",
       "       -0.06494141, -0.00689697, -0.09033203,  0.03100586,  0.19921875,\n",
       "       -0.10644531, -0.11474609,  0.18652344, -0.05078125,  0.0859375 ,\n",
       "        0.00128937, -0.18847656, -0.20019531, -0.02832031,  0.11328125,\n",
       "        0.25976562,  0.22070312,  0.04101562,  0.00171661,  0.07568359,\n",
       "       -0.01196289,  0.0177002 , -0.05883789, -0.25976562, -0.234375  ,\n",
       "       -0.04956055,  0.25976562,  0.15332031,  0.15136719,  0.08300781,\n",
       "       -0.15527344,  0.04931641,  0.07519531, -0.05078125, -0.1328125 ,\n",
       "       -0.13574219,  0.04199219, -0.14257812,  0.02099609,  0.07861328,\n",
       "        0.01611328,  0.01623535, -0.21582031,  0.01599121, -0.04882812,\n",
       "       -0.02404785,  0.13476562,  0.08496094, -0.01196289,  0.10009766,\n",
       "       -0.13867188,  0.08056641, -0.22070312, -0.12011719,  0.18945312,\n",
       "        0.05444336, -0.05053711,  0.00147247,  0.14160156, -0.06494141,\n",
       "       -0.05566406, -0.09033203, -0.0267334 , -0.10498047,  0.02416992,\n",
       "        0.01422119,  0.1875    , -0.16503906,  0.01538086, -0.04174805,\n",
       "        0.05444336, -0.01184082, -0.15625   ,  0.00193024, -0.06982422],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词向量导入\n",
    "wvmodel = KeyedVectors.load_word2vec_format(\"../GoogleNews-vectors-negative300.bin.gz\",binary=True)\n",
    "wvmodel.get_vector(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662 10662\n"
     ]
    }
   ],
   "source": [
    "# 数据集加载\n",
    "pos_samples = open(\"./data/MR/rt-polarity.pos\",errors=\"ignore\").readlines()\n",
    "neg_samples = open(\"./data/MR/rt-polarity.neg\",errors=\"ignore\").readlines()\n",
    "datas = pos_samples+neg_samples\n",
    "datas = [data.split() for data in datas]\n",
    "labels = [1]*len(pos_samples)+[0]*len(neg_samples)\n",
    "print (len(datas),len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal . \\n',\n",
       " 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth . \\n',\n",
       " 'effective but too-tepid biopic\\n',\n",
       " 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start . \\n',\n",
       " \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one . \\n\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simplistic , silly and tedious . \\n',\n",
       " \"it's so laddish and juvenile , only teenage boys could possibly find it funny . \\n\",\n",
       " 'exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \\n',\n",
       " '[garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation . \\n',\n",
       " 'a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification . \\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', \"century's\", 'new', '\"', 'conan', '\"', 'and', 'that', \"he's\", 'going', 'to', 'make', 'a', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', ',', 'jean-claud', 'van', 'damme', 'or', 'steven', 'segal', '.']),\n",
       "       list(['the', 'gorgeously', 'elaborate', 'continuation', 'of', '\"', 'the', 'lord', 'of', 'the', 'rings', '\"', 'trilogy', 'is', 'so', 'huge', 'that', 'a', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co-writer/director', 'peter', \"jackson's\", 'expanded', 'vision', 'of', 'j', '.', 'r', '.', 'r', '.', \"tolkien's\", 'middle-earth', '.']),\n",
       "       list(['effective', 'but', 'too-tepid', 'biopic']),\n",
       "       list(['if', 'you', 'sometimes', 'like', 'to', 'go', 'to', 'the', 'movies', 'to', 'have', 'fun', ',', 'wasabi', 'is', 'a', 'good', 'place', 'to', 'start', '.']),\n",
       "       list(['emerges', 'as', 'something', 'rare', ',', 'an', 'issue', 'movie', \"that's\", 'so', 'honest', 'and', 'keenly', 'observed', 'that', 'it', \"doesn't\", 'feel', 'like', 'one', '.'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(datas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建word2id并pad成相同长度\n",
    "max_sample_length = max([len(sample) for sample in datas])\n",
    "word2id = {\"<pad>\":0}\n",
    "for i,data in enumerate(datas):\n",
    "    for j,word in enumerate(data):\n",
    "        if word2id.get(word)==None:\n",
    "            word2id[word] = len(word2id)\n",
    "        datas[i][j] = word2id[word]\n",
    "    datas[i] = datas[i]+[0]*(max_sample_length-len(datas[i])) #将所有句子pad成max_sample_length的长度\n",
    "    #datas[i] = datas[i][0:max_sample_length]+[0]*(max_sample_length-len(datas[i]))  #包含截断的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sample_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 5,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.001389387 0.17722417\n"
     ]
    }
   ],
   "source": [
    "# 求词向量均值和方差\n",
    "tmp = []\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        tmp.append(wvmodel.get_vector(word))\n",
    "    except:\n",
    "        pass\n",
    "mean = np.mean(np.array(tmp))\n",
    "std = np.std(np.array(tmp))\n",
    "print (mean,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成词向量\n",
    "vocab_size = len(word2id)\n",
    "embed_size = 300\n",
    "#embedding_weights = np.random.normal(-0.0016728516,0.17756976,[vocab_size,embed_size])\n",
    "embedding_weights = np.random.normal(mean,std,[vocab_size,embed_size])\n",
    "for word, index in word2id.items():\n",
    "    try:\n",
    "        embedding_weights[index, :] = wvmodel.get_vector(word)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21402, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱数据集\n",
    "c = list(zip(datas,labels))\n",
    "random.seed(1)\n",
    "random.shuffle(c)\n",
    "datas[:],labels[:] = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 86,\n",
       " 189,\n",
       " 19748,\n",
       " 293,\n",
       " 670,\n",
       " 9126,\n",
       " 91,\n",
       " 1,\n",
       " 5101,\n",
       " 35,\n",
       " 17,\n",
       " 19749,\n",
       " 12,\n",
       " 3834,\n",
       " 2562,\n",
       " 2321,\n",
       " 24,\n",
       " 640,\n",
       " 155,\n",
       " 154,\n",
       " 168,\n",
       " 2683,\n",
       " 35,\n",
       " 1,\n",
       " 749,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 19750,\n",
       " 31,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练集、验证集和测试集\n",
    "k = 0\n",
    "# ；k=3 0,1,2+4-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = datas[:int(k * len(datas) / 10)] + datas[int((k + 1) * len(datas) / 10):]\n",
    "train_labels = labels[:int(k * len(datas) / 10)] + labels[int((k + 1) * len(labels) / 10):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datas = np.array(train_datas[int(0.9 * len(train_datas)):])\n",
    "valid_labels = np.array(train_labels[int(0.9 * len(train_labels)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 59) (960,)\n"
     ]
    }
   ],
   "source": [
    "print (valid_datas.shape,valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = np.array(train_datas[0:int(0.9*len(train_datas))])\n",
    "train_labels = np.array(train_labels[0:int(0.9*len(train_labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8636, 59) (8636,)\n"
     ]
    }
   ],
   "source": [
    "print (train_datas.shape,train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datas = np.array(datas[int(k * len(datas) / 10):int((k + 1) * len(datas) / 10)])\n",
    "test_labels = np.array(labels[int(k * len(datas) / 10):int((k + 1) * len(datas) / 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066, 59) (1066,)\n"
     ]
    }
   ],
   "source": [
    "print (test_datas.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
