{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq-Test beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def config_gpu():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "                print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. nvidia驱动   nvidia-smi\n",
    "2. CUDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img-blog.csdn.net/20180414103300419)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解码是seq2seq模型的常见问题，常用方法有贪心搜索`（Greedy Search）`集束搜索`（Beam Search）`。\n",
    "\n",
    "Decoder根据Encoder的中间语义编码向量c和`<s>`标签得到第一个输出的概率分布`[0.1,0.1,0.3,0.4,0.1]`，选择概率最大的`0.4`，即`moi`。\n",
    "\n",
    "根据隐向量h1和moi得到第二个输出的概率分布`[0.1,0.1,0.1,0.1,0.6]`，选择概率最大的`0.6`，即`suis`。\n",
    "\n",
    "以此类推，直到遇到`</s>`标签，得到最终的序列`moi suis étudiant`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 集束搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的贪心搜索只选择了概率最大的一个，而集束搜索则选择了概率最大的前k个。这个k值也叫做集束宽度（Beam Width）。\n",
    "\n",
    "还是以上面的例子作为说明，k值等于2，则集束搜索的过程如下图："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://img-blog.csdn.net/20180414113522371?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d1b2xpbmRvbmdnbGQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到第一个输出的概率分布`[0.1,0.1,0.3,0.4,0.1]`，选择概率最大的前两个，`0.3`和`0.4`，即`Je`和`moi`。\n",
    "\n",
    "然后`Je`和`moi`分别作为`Decoder`的输入，得到两个概率分布，然后再选择概率和最大的前两个序列，`0.3+0.8`和`0.4+0.6`，即`Je suis`和`moi suis`。\n",
    "\n",
    "以此类推，最终可以得到两个序列，即`Je suis étudiant`和`moi suis étudiant`，很明显前者的概率和最大，为`2.2`，所以这个序列是最终得到的结果。\n",
    "\n",
    "集束搜索本质上也是贪心的思想，只不过它考虑了更多的候选搜索空间，因此可以得到更多的翻译结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "集束搜索可以认为是维特比算法的贪心形式，在维特比所有中由于利用动态规划导致当字典较大时效率低，而集束搜索使用beam size参数来限制在每一步保留下来的可能性词的数量。集束搜索是在测试阶段为了获得更好准确性而采取的一种策略，在训练阶段无需使用。\n",
    "\n",
    "\n",
    "预测的时候,假设词表大小为3,内容为a,b,c。 beam size是2, decoder解码的时候\n",
    "\n",
    "1:生成第1个词的时候,选择概率最大的2个词,假设为a,c,那么当前的2个序列就是a和c。\n",
    "\n",
    "2:生成第2个词的时候,我们将当前序列a和c,分别与词表中的所有词进行组合,得到新的6个序列 aa ab ac ca cb cc,计算每个序列的得分并选择得分最高2个序列,作为新的当前序列,假如为aa、cb。\n",
    "\n",
    "3:后面会不断重复这个过程,直到遇到结束符或者达到最大长度为止。最终输出得分最高的2个序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-07-14 21:22:32,033 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/4m/kfgtcp1x5gbbvg4f44kcwwgw0000gn/T/jieba.cache\n",
      "2020-07-14 21:22:32,034 : DEBUG : Loading model from cache /var/folders/4m/kfgtcp1x5gbbvg4f44kcwwgw0000gn/T/jieba.cache\n",
      "Loading model cost 0.740 seconds.\n",
      "2020-07-14 21:22:32,774 : DEBUG : Loading model cost 0.740 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-07-14 21:22:32,776 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.append('/Users/ianxiao/Code/DeepLearning/class04')\n",
    "from utils.wv_loader import Vocab\n",
    "from utils.data_loader import load_dataset\n",
    "from utils.config import *\n",
    "import numpy as np\n",
    "from utils.gpu_utils import config_gpu\n",
    "from seq2seq_tf2.seq2seq_model import Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GPU设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 加载数据 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 加载vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(vocab_file=vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31819"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 基本参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params[\"vocab_size\"] = vocab.count\n",
    "params[\"embedding_dim\"] = 300\n",
    "params[\"enc_units\"] = 512\n",
    "params[\"attn_units\"] = 512\n",
    "params[\"dec_units\"] = 512\n",
    "\n",
    "params[\"max_enc_len\"] = 200\n",
    "params[\"max_dec_len\"] = 41\n",
    "params[\"epochs\"] = 5\n",
    "params[\"batch_size\"] = 32 \n",
    "params[\"beam_size\"]=3\n",
    "params['min_dec_steps']=4\n",
    "params['max_dec_steps']=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,train_Y,test_X = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82873, 82873, 20000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_Y), len(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 载入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import seq2seq_checkpoint_dir,seq2seq_checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ianxiao/Code/DeepLearning/class04/data/checkpoints/training_checkpoints_seq2seq'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_checkpoint_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(Seq2Seq=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, seq2seq_checkpoint_dir, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /Users/ianxiao/Code/DeepLearning/class04/data/checkpoints/training_checkpoints_seq2seq/ckpt-3\n"
     ]
    }
   ],
   "source": [
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 保存中间信息的类 \n",
    "\n",
    "用于beam search解码过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypothesis:\n",
    "    \"\"\" Class designed to hold hypothesises throughout the beamSearch decoding \"\"\"\n",
    "    def __init__(self, tokens, log_probs, hidden, attn_dists):\n",
    "        self.tokens = tokens  # list of all the tokens from time 0 to the current time step t\n",
    "        self.log_probs = log_probs  # list of the log probabilities of the tokens of the tokens\n",
    "        self.hidden = hidden  # decoder hidden state after the last token decoding\n",
    "        self.attn_dists = attn_dists  # attention dists of all the tokens\n",
    "        self.abstract = \"\"\n",
    "\n",
    "    def extend(self, token, log_prob, hidden, attn_dist):\n",
    "        \"\"\"Method to extend the current hypothesis by adding the next decoded token and all the informations associated with it\"\"\"\n",
    "        return Hypothesis(tokens=self.tokens + [token],  # we add the decoded token\n",
    "                          log_probs=self.log_probs + [log_prob],  # we add the log prob of the decoded token\n",
    "                          hidden=hidden,  # we update the state\n",
    "                          attn_dists=self.attn_dists + [attn_dist])\n",
    "    @property\n",
    "    def latest_token(self):\n",
    "        return self.tokens[-1]\n",
    "\n",
    "    @property\n",
    "    def tot_log_prob(self):\n",
    "        return sum(self.log_probs)\n",
    "\n",
    "    @property\n",
    "    def avg_log_prob(self):\n",
    "        return self.tot_log_prob / len(self.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 单次搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 构造输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"beam_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    2  1080   280    27     8     5    70    22    61    62     4  1365\n",
      "    302     4   758   192   231    85   116    17    77     7   215  3719\n",
      "   1365    35   758  3094    77   231   116    17     4   280    27    18\n",
      "   1314   281   873   173   587   535   285     7  1397   207    62 10334\n",
      "     27     4   572  9753    27     4    27   390  1761    27   634  1870\n",
      "      4   623  4513  4513   491     4    35   116    18    17    77     7\n",
      "      5    88     6     3     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = test_X[:1]\n",
    "print(row)\n",
    "row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_data = tf.convert_to_tensor([row for i in range(params[\"beam_size\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 1, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_search_data = tf.squeeze(beam_search_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inp=beam_search_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 200])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hidden = tf.zeros((params[\"beam_size\"], params['enc_units']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output, enc_hidden = model.encoder(enc_inp, enc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 200, 512]), TensorShape([3, 512]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_output.shape, enc_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 初始化一个Hypothesis类对象列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hyps列表中的每个对象 都包含 用于解码的三种信息 当前输入（tokens\\[-1\\]）、上一步隐状态（hidden）、注意力权重分布(attn_dists)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = [Hypothesis(tokens=[vocab.START_DECODING_INDEX],\n",
    "                   log_probs=[0.0],\n",
    "                   hidden=enc_hidden[0],\n",
    "                   attn_dists=[],\n",
    "                   ) for i in range(params['beam_size'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2], [2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps[0].tokens, hyps[1].tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取最新tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_tokens = [h.latest_token for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**隐藏层状态**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens = [h.hidden for h in hyps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 单步运行decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def log_softmax(x):\n",
    "    x = x - np.max(x)\n",
    "    exp_x = np.exp(x)\n",
    "    #softmax_x = exp_x / np.sum(exp_x)\n",
    "    log_softmax_x = x - np.log(np.sum(exp_x))\n",
    "    return log_softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-666. -333.    0.]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([123, 456, 789], dtype=np.float32)\n",
    "print(log_softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-666. -333.    0.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = tf.convert_to_tensor(logits)\n",
    "print(tf.nn.log_softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_onestep(enc_output,dec_input,dec_hidden):\n",
    "    # 单个时间步 运行\n",
    "    preds, dec_hidden, context_vector,attention_weights = model.call_decoder_onestep(dec_input,dec_hidden, enc_output)\n",
    "    # 拿到top k个index 和 概率\n",
    "    preds = tf.nn.softmax(preds, axis=-1)\n",
    "    top_k_probs, top_k_ids = tf.nn.top_k(tf.squeeze(preds), k=params[\"beam_size\"])\n",
    "    # 计算log概率\n",
    "    top_k_log_probs = tf.math.log(top_k_probs)\n",
    "    # 返回需要保存的中间结果和概率\n",
    "    return preds,dec_hidden,context_vector,attention_weights,top_k_log_probs,top_k_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, [2, 2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latest_tokens), latest_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.START_DECODING_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一个decoder输入 开始标签\n",
    "dec_input = tf.expand_dims(latest_tokens, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder 第一个隐藏层输入\n",
    "dec_hidden = enc_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单步运行\n",
    "preds, dec_hidden, context_vector,attention_weights, top_k_log_probs, top_k_ids = decoder_onestep(enc_output,dec_input,dec_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 31819), dtype=float32, numpy=\n",
       "array([[1.03091296e-08, 1.08978355e-08, 1.12608536e-08, ...,\n",
       "        1.07896243e-08, 1.07373355e-08, 1.10080984e-08],\n",
       "       [1.03091304e-08, 1.08978373e-08, 1.12608545e-08, ...,\n",
       "        1.07896261e-08, 1.07373364e-08, 1.10081002e-08],\n",
       "       [1.03091287e-08, 1.08978346e-08, 1.12608527e-08, ...,\n",
       "        1.07896234e-08, 1.07373346e-08, 1.10080975e-08]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-1.8029443, -2.9281745, -3.149047 ],\n",
       "       [-1.8029442, -2.9281745, -3.149047 ],\n",
       "       [-1.8029443, -2.9281747, -3.1490471]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 512]), TensorShape([3, 512]), TensorShape([3, 200, 1]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_hidden.shape, context_vector.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 3]), TensorShape([3, 3]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_log_probs.shape, top_k_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[  88,   35, 1306],\n",
       "       [  88,   35, 1306],\n",
       "       [  88,   35, 1306]], dtype=int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一轮\n",
    "results = []  # list to hold the top beam_size hypothesises\n",
    "steps = 0  # initial step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现阶段全部可能情况\n",
    "all_hyps = []\n",
    "# 原有的可能情况数量\n",
    "num_orig_hyps = 1 if steps == 0 else len(hyps)\n",
    "\n",
    "# 遍历添加所有可能结果\n",
    "for i in range(num_orig_hyps):\n",
    "    h, new_hidden, attn_dist = hyps[i], dec_hidden[i], attention_weights[i]\n",
    "    # 分裂 添加 beam size 种可能性\n",
    "    for j in range(params['beam_size']):\n",
    "        # 构造可能的情况\n",
    "        new_hyp = h.extend(token = top_k_ids[i, j].numpy(),\n",
    "                                       log_prob = top_k_log_probs[i, j],\n",
    "                                       hidden = new_hidden,\n",
    "                                       attn_dist = attn_dist)\n",
    "        # 添加可能情况\n",
    "        all_hyps.append(new_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Hypothesis at 0x139197290>,\n",
       " <__main__.Hypothesis at 0x139197310>,\n",
       " <__main__.Hypothesis at 0x1391972d0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab {a c f e p}\n",
    "\n",
    "token c b f \n",
    "1. `<start> c ` \n",
    "2. `<start> b`\n",
    "3. `<start> f`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 88]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-1.8029443>]\n",
      "[2, 35]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-2.9281745>]\n",
      "[2, 1306]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-3.149047>]\n"
     ]
    }
   ],
   "source": [
    "for elm_hyps in all_hyps:\n",
    "    print(elm_hyps.tokens)\n",
    "    print(elm_hyps.log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置\n",
    "hyps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照概率来排序\n",
    "sorted_hyps = sorted(all_hyps, key=lambda h: h.avg_log_prob, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 88]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-1.8029443>]\n",
      "[2, 35]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-2.9281745>]\n",
      "[2, 1306]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-3.149047>]\n"
     ]
    }
   ],
   "source": [
    "for elm_hyps in sorted_hyps:\n",
    "    print(elm_hyps.tokens)\n",
    "    print(elm_hyps.log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选top前beam_size句话 top 3\n",
    "for h in sorted_hyps:\n",
    "    if h.latest_token == vocab.STOP_DECODING_INDEX:\n",
    "        # 长度符合预期,遇到句尾,添加到结果集\n",
    "        if steps >= params['min_dec_steps']:\n",
    "            results.append(h)\n",
    "    else:\n",
    "        # 未到结束 ,添加到假设集\n",
    "        hyps.append(h)\n",
    "    \n",
    "    # 如果假设句子正好等于beam_size 或者结果集正好等于beam_size 就不在添加\n",
    "    if len(hyps) == params['beam_size'] or len(results) == params['beam_size']:\n",
    "        break\n",
    "steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 88]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-1.8029443>]\n",
      "[2, 35]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-2.9281745>]\n",
      "[2, 1306]\n",
      "[0.0, <tf.Tensor: shape=(), dtype=float32, numpy=-3.149047>]\n"
     ]
    }
   ],
   "source": [
    "for h in hyps:\n",
    "    print(h.tokens)\n",
    "    print(h.log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyps),len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(results) == 0:\n",
    "    results = hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps_sorted = sorted(results, key=lambda h: h.avg_log_prob, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp = hyps_sorted[0] #平均log_prob最高的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyp.abstract = \" \".join([vocab.id2word[index] for index in best_hyp.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 88]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> 你好'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp.abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "\n",
    "[1] https://www.tensorflow.org/tutorials/seq2seq\n",
    "\n",
    "[2] https://blog.csdn.net/guolindonggld/article/details/79938567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. beam search 方法整合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_beam_decode(model,batch_data,vocab, params):\n",
    "\n",
    "    \n",
    "    # 单步decoder\n",
    "    def decoder_onestep(enc_output,dec_input,dec_hidden):\n",
    "        # 单个时间步 运行\n",
    "        preds, dec_hidden, context_vector,attention_weights = model.call_decoder_onestep(dec_input,dec_hidden, enc_output)\n",
    "        # 拿到top k个index 和 概率\n",
    "        preds = tf.nn.softmax(preds, axis=-1)\n",
    "        top_k_probs, top_k_ids = tf.nn.top_k(tf.squeeze(preds), k=params[\"beam_size\"] * 2)\n",
    "        # 计算log概率\n",
    "        top_k_log_probs = tf.math.log(top_k_probs)\n",
    "        # 返回需要保存的中间结果和概率\n",
    "        return preds,dec_hidden,context_vector,attention_weights,top_k_log_probs,top_k_ids\n",
    "    \n",
    "    enc_hidden = tf.zeros((params[\"beam_size\"], params['enc_units']))\n",
    "    # 计算第encoder的输出\n",
    "    enc_output, enc_hidden = model.encoder(batch_data, enc_hidden)\n",
    "    # 第一个隐藏层输入\n",
    "    dec_hidden = enc_hidden\n",
    "    \n",
    "    # 初始化batch size个 假设对象\n",
    "    hyps = [Hypothesis(tokens=[vocab.START_DECODING_INDEX],\n",
    "                   log_probs=[0.0],\n",
    "                   hidden=enc_hidden[0],\n",
    "                   attn_dists=[],\n",
    "                   ) for _ in range(params[\"beam_size\"])]\n",
    "\n",
    "    \n",
    "    # 初始化结果集\n",
    "    results = []  # list to hold the top beam_size hypothesises\n",
    "    # 遍历步数\n",
    "    steps = 0  # initial step\n",
    "    \n",
    "    # 长度还不够 并且 结果还不够 继续搜索\n",
    "    while steps < params['max_dec_steps'] and len(results) < params['beam_size']:\n",
    "        # 获取最新待使用的token\n",
    "        latest_tokens = [h.latest_token for h in hyps]\n",
    "        # 获取所以隐藏层状态\n",
    "        hiddens = [h.hidden for h in hyps]\n",
    "        # 最新输入\n",
    "        dec_input = tf.expand_dims(latest_tokens, 1)\n",
    "        dec_hidden = tf.stack(hiddens, axis=0)\n",
    "        # 单步运行decoder 计算需要的值\n",
    "        preds, dec_hidden, context_vector,attention_weights, top_k_log_probs, top_k_ids = decoder_onestep(enc_output,dec_input,dec_hidden)\n",
    "        \n",
    "        # 现阶段全部可能情况\n",
    "        all_hyps = []\n",
    "        # 原有的可能情况数量\n",
    "        num_orig_hyps = 1 if steps == 0 else len(hyps)\n",
    "\n",
    "        # 遍历添加所有可能结果\n",
    "        for i in range(num_orig_hyps):\n",
    "            h, new_hidden, attn_dist = hyps[i], dec_hidden[i], attention_weights[i]\n",
    "            # 分裂 添加 beam size 种可能性\n",
    "            for j in range(params['beam_size'] * 2):\n",
    "                # 构造可能的情况\n",
    "                new_hyp = h.extend(token = top_k_ids[i, j].numpy(),\n",
    "                                   log_prob = top_k_log_probs[i, j],\n",
    "                                   hidden = new_hidden,\n",
    "                                   attn_dist = attn_dist)\n",
    "                # 添加可能情况\n",
    "                all_hyps.append(new_hyp)\n",
    "        \n",
    "        # 重置\n",
    "        hyps = []\n",
    "        # 按照概率来排序\n",
    "        sorted_hyps = sorted(all_hyps, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "        \n",
    "        # 筛选top前beam_size句话\n",
    "        for h in sorted_hyps:\n",
    "            if h.latest_token == vocab.STOP_DECODING_INDEX:\n",
    "                # 长度符合预期,遇到句尾,添加到结果集\n",
    "                if steps >= params['min_dec_steps']:\n",
    "                    results.append(h)\n",
    "            else:\n",
    "                # 未到结束 ,添加到假设集\n",
    "                hyps.append(h)\n",
    "\n",
    "            # 如果假设句子正好等于beam_size 或者结果集正好等于beam_size 就不在添加\n",
    "            if len(hyps) == params['beam_size'] or len(results) == params['beam_size']:\n",
    "                break\n",
    "\n",
    "        steps += 1\n",
    "        \n",
    "    if len(results) == 0:\n",
    "        results = hyps\n",
    "    \n",
    "    hyps_sorted = sorted(results, key=lambda h: h.avg_log_prob, reverse=True)\n",
    "    best_hyp = hyps_sorted[0]\n",
    "    best_hyp.abstract = \" \".join([vocab.id2word[index] for index in best_hyp.tokens])\n",
    "    return best_hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /Users/ianxiao/Code/DeepLearning/class04/data/checkpoints/training_checkpoints_seq2seq/ckpt-3\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(params)\n",
    "ckpt = tf.train.Checkpoint(Seq2Seq=model)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, seq2seq_checkpoint_dir, max_to_keep=5)\n",
    "# 如果检查点存在，则恢复最新的检查点。\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Restored from {}\".format(ckpt_manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import load_test_dataset\n",
    "def beam_batch_generator(beam_size, data_X):\n",
    "    for row in data_X:\n",
    "        beam_search_data = tf.convert_to_tensor([row for i in range(beam_size)])\n",
    "        yield beam_search_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "test_X = load_test_dataset(max_enc_len=params['max_enc_len'])\n",
    "test_dataset = beam_batch_generator(params['beam_size'], test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object beam_batch_generator at 0x13d848650>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 单条预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = test_X[4396:4397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = tf.convert_to_tensor([row for i in range(params[\"beam_size\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = tf.squeeze(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 200), dtype=int32, numpy=\n",
       "array([[    2,   503,  1696,  3620,  3418,   701,     1, 22339,   261,\n",
       "          928,  1718,     4,  1408, 15292,     8,  5676,  5171,     8,\n",
       "         2319,  2104,    15,     7,    30,    16,     5, 16340,   182,\n",
       "         2180,  4414,     1,  7296,  3088,     6,    41,     1,    27,\n",
       "         3329,   422, 26936,  4490,   272,    56,   128,     1,   734,\n",
       "        11599,     7,  5676,   924,     8,     5,  7428,     6,   591,\n",
       "         5569,     6,     6,     5,    31,  1349,   900,     6,     6,\n",
       "         7665,   229,    60,     5,    85,   205,    27,     1,    15,\n",
       "            6,    12,     4,    80,    12,     5,    10,  8881,    12,\n",
       "            6,     5,   218,  4527,  2404,     4,   101,  1336,  6621,\n",
       "          358,     1,  1139,   182,     6,    80,    10,     1,     5,\n",
       "          183,  1647,   921,    10, 16589,     5,    10,  2137,  1376,\n",
       "            6,    12,     4,    30,     7,     5,   127,     9,   277,\n",
       "            6,    12,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    2,   503,  1696,  3620,  3418,   701,     1, 22339,   261,\n",
       "          928,  1718,     4,  1408, 15292,     8,  5676,  5171,     8,\n",
       "         2319,  2104,    15,     7,    30,    16,     5, 16340,   182,\n",
       "         2180,  4414,     1,  7296,  3088,     6,    41,     1,    27,\n",
       "         3329,   422, 26936,  4490,   272,    56,   128,     1,   734,\n",
       "        11599,     7,  5676,   924,     8,     5,  7428,     6,   591,\n",
       "         5569,     6,     6,     5,    31,  1349,   900,     6,     6,\n",
       "         7665,   229,    60,     5,    85,   205,    27,     1,    15,\n",
       "            6,    12,     4,    80,    12,     5,    10,  8881,    12,\n",
       "            6,     5,   218,  4527,  2404,     4,   101,  1336,  6621,\n",
       "          358,     1,  1139,   182,     6,    80,    10,     1,     5,\n",
       "          183,  1647,   921,    10, 16589,     5,    10,  2137,  1376,\n",
       "            6,    12,     4,    30,     7,     5,   127,     9,   277,\n",
       "            6,    12,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0],\n",
       "       [    2,   503,  1696,  3620,  3418,   701,     1, 22339,   261,\n",
       "          928,  1718,     4,  1408, 15292,     8,  5676,  5171,     8,\n",
       "         2319,  2104,    15,     7,    30,    16,     5, 16340,   182,\n",
       "         2180,  4414,     1,  7296,  3088,     6,    41,     1,    27,\n",
       "         3329,   422, 26936,  4490,   272,    56,   128,     1,   734,\n",
       "        11599,     7,  5676,   924,     8,     5,  7428,     6,   591,\n",
       "         5569,     6,     6,     5,    31,  1349,   900,     6,     6,\n",
       "         7665,   229,    60,     5,    85,   205,    27,     1,    15,\n",
       "            6,    12,     4,    80,    12,     5,    10,  8881,    12,\n",
       "            6,     5,   218,  4527,  2404,     4,   101,  1336,  6621,\n",
       "          358,     1,  1139,   182,     6,    80,    10,     1,     5,\n",
       "          183,  1647,   921,    10, 16589,     5,    10,  2137,  1376,\n",
       "            6,    12,     4,    30,     7,     5,   127,     9,   277,\n",
       "            6,    12,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data # test数据集中的第一条数据，构造了3份，方便beam search操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得最好的语句\n",
    "best_hyp=batch_beam_decode(model, batch_data,vocab, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> 不是 假 机油 ， 假 假 机油 <STOP>'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyp.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = best_hyp.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START> 不是 假 机油 ， 假 假 机油 <STOP>'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'不是 假 机油 ， 假 假 机油'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict.replace('<START>','')\n",
    "predict = predict.replace('<STOP>','')\n",
    "predict = predict.strip()\n",
    "predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 结果预测及保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = load_test_dataset(max_enc_len=params['max_enc_len'])\n",
    "test_dataset = beam_batch_generator(params['beam_size'], test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "test_dataset_len = len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_decode(model, dataset, dataset_len, vocab, params):\n",
    "    results = []\n",
    "    for batch_data in tqdm(dataset, total=dataset_len):\n",
    "        best_hyp = batch_beam_decode(model, batch_data, vocab, params)\n",
    "        results.append(best_hyp.abstract)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [2:31:00<00:00,  2.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 27min 38s, sys: 56min 18s, total: 6h 23min 56s\n",
      "Wall time: 2h 31min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = beam_decode(model, test_dataset, test_dataset_len, vocab, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 结果保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结果保存路径生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_utils import get_result_filename\n",
    "result_save_path = get_result_filename(params[\"batch_size\"],params[\"epochs\"] , params[\"max_enc_len\"], params[\"embedding_dim\"],commit='_4_1_submit_beam_search_seq2seq_code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测results中是否存在''\n",
    "for idx,result in enumerate(results):\n",
    "    if result=='':print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果数据处理\n",
    "def submit_proc(sentence):\n",
    "    sentence = sentence.lstrip('，！。')\n",
    "    sentence = sentence.replace(' ', '')\n",
    "    sentence = sentence.replace('<START>','')\n",
    "    sentence = sentence.replace('<STOP>','')\n",
    "    sentence = sentence.strip()\n",
    "    if sentence == '':\n",
    "        sentence = '随时联系'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def save_predict_result(results, result_save_path):\n",
    "    # 读取结果\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "    # 填充结果\n",
    "    test_df['Prediction'] = results\n",
    "    test_df['Prediction'] = test_df['Prediction'].apply(submit_proc)\n",
    "    # 提取ID和预测结果两列\n",
    "    test_df = test_df[['QID', 'Prediction']]\n",
    "    # 保存结果\n",
    "    test_df.to_csv(result_save_path, index=None, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predict_result(results, result_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>START&gt;你好！描述，该车发动机烧机油，建议及时进行维修。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>START&gt;抛光处理一下！亲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>START&gt;气囊问题，价格不贵，单独更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>START&gt;分析检查排气管漏气。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>START&gt;你好！描述，这种情况可能轮胎动平衡问题，建议做个四轮动平衡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                           Prediction\n",
       "0  Q1       START>你好！描述，该车发动机烧机油，建议及时进行维修。\n",
       "1  Q2                       START>抛光处理一下！亲\n",
       "2  Q3                START>气囊问题，价格不贵，单独更换。\n",
       "3  Q4                     START>分析检查排气管漏气。\n",
       "4  Q5  START>你好！描述，这种情况可能轮胎动平衡问题，建议做个四轮动平衡"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(result_save_path)\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Prediction'] = test_df['Prediction'].apply(lambda x: x.replace('START>', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>你好！描述，该车发动机烧机油，建议及时进行维修。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>抛光处理一下！亲</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>气囊问题，价格不贵，单独更换。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>分析检查排气管漏气。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>你好！描述，这种情况可能轮胎动平衡问题，建议做个四轮动平衡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  QID                     Prediction\n",
       "0  Q1       你好！描述，该车发动机烧机油，建议及时进行维修。\n",
       "1  Q2                       抛光处理一下！亲\n",
       "2  Q3                气囊问题，价格不贵，单独更换。\n",
       "3  Q4                     分析检查排气管漏气。\n",
       "4  Q5  你好！描述，这种情况可能轮胎动平衡问题，建议做个四轮动平衡"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(result_save_path, index=None, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
